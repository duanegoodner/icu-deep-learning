{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Background Information\n",
    "\n",
    "This project reproduces and expands upon work published in [1] and [2] on Long Short-Term Memory (LSTM) predictive models and adversarial attacks on those models.  The previous studies used Long Short-Term Memory (LSTM) time series classification models trained with data from the Medical Information Mart for Intensive Care (MIMIC-III) database to predict Intensive Care Unit (ICU) patient outcomes. Input features to the classification models consisted of 13 lab measurements and 6 vital signs. A binary variable representing in-hospital mortality was the prediction target.\n",
    "\n",
    "In [1], an adversarial attack algorithm was used to identify small perturbations which, when applied to a real, correctly-classified input features, caused a trained model to misclassify the perturbed input. L1 regularization was applied to the adversarial attack loss function to favor adversarial examples with sparse perturbations that resemble the structure of data entry errors most likely to occur in real medical data. Samples were attacked serially (one a time), and the attack process on a sample was stopped upon finding a single adversarial perturbation to that samples input features. After attacking a full dataset, susceptibility calculations were  performed to identify input feature space regions most vulnerable to adversarial attack.\n",
    "\n",
    "The current study follows an approach similar to that of the previous studies. We use the same dataset, input features, and prediction targets to train a LSTM binary classification model and subsequently search for adversarial examples using an L1 regularized attack algorithm. Aspects of the current work that expand upon the previous studies include a vectorized (faster) approach to data preprocessing, extensive hyperparameter tuning (of both the predictive model and attack algorithm), improved performance of the predictive model, implementation of a GPU-compatible attack algorithm that enables attacking samples in batches, and not halting the attack process upon finding a single adversarial perturbation for a sample (so that additional, lower loss adversarial perturbations can be discovered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Development Environment Setup\n",
    "\n",
    "### 2.1 Docker Container\n",
    "\n",
    "The code and instructions in this notebook assume the development environment has been set up by completing all steps in the [How to run this project](https://github.com/duanegoodner/lstm_adversarial_attack/tree/main#3-how-to-run-this-project) section of the project [README](https://github.com/duanegoodner/lstm_adversarial_attack).  \n",
    "\n",
    "First we import a few modules that we will use to confirm our local project paths are correctly mapped to paths in the container.\n",
    "If you have used the procedure described there to run this notebook inside a `lstm_aa_app` Docker container, then the output of the following code cell should be `PosixPath('/home/devspace/project/notebooks')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "import src_paths\n",
    "# from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path(os.getenv(\"CONTAINER_PROJECT_ROOT\"))\n",
    "os.chdir(project_root / \"src\" / \"lstm_adversarial_attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/devspace/project/src/lstm_adversarial_attack')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_paths as cfg_paths\n",
    "import config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src',\n",
       " '.idea',\n",
       " '.gitignore',\n",
       " 'README.md',\n",
       " '.gitattributes',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " '.git',\n",
       " 'docs',\n",
       " 'docker',\n",
       " 'Untitled.ipynb',\n",
       " 'notebooks']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.name for item in list(src_paths.project_root.iterdir())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `/home/devspace/project` is correctly mapped to your local project root, the output of the next cell match the list of files in the local `lstm_adversarial_attack` project root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. Project File Structure\n",
    "TODO: change to description of running from command line args (if we implement that change)\n",
    "\n",
    "All .py files are in `/home/devspace/project/src/lstm_adversarial_attack`. This directory contains four sub-packages responsible for different parts of the project data pipeline (`query_db`, `preprocess`, `tune_train`, `attack`, and `attack_analysis`). The code snippets in this notebook instantiate classes and call methods of files under the `src` directory. Look to the code and docstrings there for implementation details. \n",
    "\n",
    "\n",
    "Data files are under `/home/devspace/project/data/` in subdirectories with names that match the sub-package names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Standard Library and External Packages\n",
    "Most of the necessary standard library imports and external package imports are handled code in the `src` sub-packages, but we need to import a few things here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pprint\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "# import torch\n",
    "# from IPython.display import Markdown as md\n",
    "# from torch.utils.data import Dataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.2 Internal Project Sub-packages and Modules\n",
    "To make it easier to understand how a particular internal package or module is used, we will wait to import each package / module until just before the notebook code cells where it is first used. For now, we import the `src` path defined in [`notebooks/src_paths.py`](./src_paths.py), and add it to `sys.path` (so we can easily import project code). We also import project config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src_paths\n",
    "# sys.path.append(str(src_paths.lstm_adversarial_attack_pkg))\n",
    "# import lstm_adversarial_attack.config_paths as cfg_paths\n",
    "# import lstm_adversarial_attack.config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check for GPU\n",
    "\n",
    "We won't need a GPU until we reach the HyperParameter Tuning section, but it is good to find out now we have a GPU that PyTorch can use. If we do not have one, we likely do not want to try to run the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cur_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    cur_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"cur_device is {cur_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Database Queries\n",
    "\n",
    "### 5.1 `.sql` files\n",
    "To obtain the necessary raw data, we will use modified versions of files (originally intended for Google Big Query) from https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts/pivot. The paths to the `.sql` query files are stored as a list in variable [`config_paths.DB_QUERIES`](../src/lstm_adversarial_attack/config_paths.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/icustay_detail.sql'),\n",
      " PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_bg.sql'),\n",
      " PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_lab.sql'),\n",
      " PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_vital.sql')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_paths.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Connecting to Database and Executing Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database, and execute the queries, we use the [\\_\\_main__](../src/lstm_adversarial_attack/query_db/__main__.py) module of the [query_db](../src/lstm_adversarial_attack/query_db/\\_\\_init__.py) sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/icustay_detail.sql\n",
      "Done. Query time = 0.23 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/icustay_detail.csv\n",
      "Done. csv write time = 0.18 seconds\n",
      "\n",
      "Query 2 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_bg.sql\n",
      "Done. Query time = 7.92 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/pivoted_bg.csv\n",
      "Done. csv write time = 1.48 seconds\n",
      "\n",
      "Query 3 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_lab.sql\n",
      "Done. Query time = 10.25 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/pivoted_lab.csv\n",
      "Done. csv write time = 2.44 seconds\n",
      "\n",
      "Query 4 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_vital.sql\n",
      "Done. Query time = 34.51 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/pivoted_vital.csv\n",
      "Done. csv write time = 10.30 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m query_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lstm_adversarial_attack.query_db.__main__ as query_db\n",
    "# query_db.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of each `.sql` query is saved to a `.csv` file. The path to each of these files is shown in the terminal output above. The output path of the queries is defined by variable `DB_OUTPUT_DIR` in [config_settings](../src/lstm_adversarial_attack/config_settings.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Implementation Details\n",
    "\n",
    "We will use the [`preprocess`](../src/lstm_adversarial_attack/preprocess/__init__.py) sub-package's [`\\_\\_main__`](../src/lstm_adversarial_attack/preprocess/__main__.py) module to transform information from the `.csv` files output by the `.sql` queries into numpy arrays (which can then be asily converted into PyTorch tensors). Examining the code of [`preprocess.\\_\\_main__.main()`](../src/lstm_adversarial_attack/preprocess/__main__.py), we see that it instantiates a `Preprocessor` object. Looking at the implementation of [`Preprocessor`](../src/lstm_adversarial_attack/preprocess/preprocessor.py), we see that this class has a `.preprocess_modules` attribute assigned by the following code:\n",
    "\n",
    "```\n",
    "self.preprocess_modules = [\n",
    "            prf.Prefilter(),\n",
    "            imc.ICUStayMeasurementCombiner(),\n",
    "            slb.FullAdmissionListBuilder(),\n",
    "            fb.FeatureBuilder(),\n",
    "            ff.FeatureFinalizer(),\n",
    "        ]\n",
    "```\n",
    "Each element of the `.preprocess_modules` attribute is a subclass of [`PreprocessModule`](../src/lstm_adversarial_attack/preprocess/preprocess_module.py) and performs performs a portion the preprocessing tasks.\n",
    "\n",
    "* [`Prefilter`](../src/lstm_adversarial_attack/preprocess/prefilter.py) reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* [`ICUStayMeasurementCombiner`](../src/lstm_adversarial_attack/preprocess/icustay_measurement_combiner.py) performs various joins (aka \"merges\" in the language of Pandas) to combine lab and vital sign measurement data with ICU stay data.\n",
    "* [`FullAdmissionListBuilder`](../src/lstm_adversarial_attack/preprocess/sample_list_builder.py) generates a list consisting of one FullAdmissionData object per ICU stay. The attributes of a FullAdmissionData object include ICU stay info, and a dataframe containing the measurement and timestamp data for all vital sign and lab data associated with the ICU stay.\n",
    "* [`FeatureBuilder`](../src/lstm_adversarial_attack/preprocess/feature_builder.py) resamples the time series datafame to one-hour intervals, imputes missing data, winsorizes measurement values (with cutoffs at the 5th and 95th global percentiles), and normalizes the measuremnt values so all data are between 0 and 1.\n",
    "* [`FeatureFinalizer`](../src/lstm_adversarial_attack/preprocess/feature_finalizer.py) selects the data observation time window (default starts at hospital admission time and ends 48 hours after admission). This module outputs the entire dataset features as a list of numpy arrays, and the mortality labels as a list of integers. These data structures (saved as .pickle files) will be convenient starting points when the `tune_train` and `attack` sub-packages need to create PyTorch Datasets.\n",
    "\n",
    "Files output by [`Prefilter`](../src/lstm_adversarial_attack/preprocess/prefilter.py), [`ICUStayMeasurementCombiner`](../src/lstm_adversarial_attack/preprocess/icustay_measurement_combiner.py), [`FullAdmissionListBuilder`](../src/lstm_adversarial_attack/preprocess/sample_list_builder.py), and [`FeatureBuilder`](../src/lstm_adversarial_attack/preprocess/feature_builder.py) are saved under subdirectories of `data/preprocess/checkpoints/`, and the output of [`FeatureFinalizer`](../src/lstm_adversarial_attack/preprocess/feature_finalizer.py) is saved in `data/preprocess/final_output/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Run the Preprocess Modules\n",
    "\n",
    "We run the preprocess code using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prefilter\n",
      "Prefilter init time = 5.7509918212890625\n",
      "Prefilter process time = 1.7072343826293945\n",
      "Prefilter export time = 0.2999382019042969\n",
      "\n",
      "Running ICUStayMeasurementMerger\n",
      "ICUStayMeasurementMerger init time = 0.014623641967773438\n",
      "ICUStayMeasurementMerger process time = 8.70536994934082\n",
      "ICUStayMeasurementMerger export time = 1.3995847702026367\n",
      "\n",
      "Running AdmissionListBuilder\n",
      "AdmissionListBuilder init time = 0.003213167190551758\n",
      "AdmissionListBuilder process time = 16.93038034439087\n",
      "AdmissionListBuilder export time = 16.186893224716187\n",
      "\n",
      "Running FeatureBuilder\n",
      "FeatureBuilder init time = 0.002311229705810547\n",
      "Done building features for sample 5000/41960\n",
      "Done building features for sample 10000/41960\n",
      "Done building features for sample 15000/41960\n",
      "Done building features for sample 20000/41960\n",
      "Done building features for sample 25000/41960\n",
      "Done building features for sample 30000/41960\n",
      "Done building features for sample 35000/41960\n",
      "Done building features for sample 40000/41960\n",
      "FeatureBuilder process time = 125.31809449195862\n",
      "FeatureBuilder export time = 23.86540699005127\n",
      "\n",
      "Running FeatureFinalizer\n",
      "FeatureFinalizer init time = 2.3603439331054688e-05\n",
      "FeatureFinalizer process time = 11.41321325302124\n",
      "FeatureFinalizer export time = 1.6451268196105957\n",
      "\n",
      "total time = 213.24269342422485\n"
     ]
    }
   ],
   "source": [
    "!python -m preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lstm_adversarial_attack.preprocess.__main__ as preprocess\n",
    "# preprocess.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Performance\n",
    "\n",
    "On an Intel i7-13700K CPU, the above preprocessing work takes approximately 3.9 minutes. The same data transformations on the same machine with preprocessing code from [] approximately 45 minutes. This time difference is largely due to the fact that the current project preprocess subpackage avoids the use of `for` loops and relies heavily vectorized Pandas and Numpy operations.\n",
    "\n",
    "Additional time reduction could be achieved by parellelizing the preprocess computations with tools such as [pandaparallel](https://github.com/nalepae/pandarallel) or [pyspark](https://spark.apache.org/docs/3.3.1/api/python/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Create the Pytorch Dataset object\n",
    "We import module `x19_mort_general_dataset` and use it along with files saved by the `preprocessor.feature_finalizer` to insantiate a Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import x19_mort_general_dataset as xmd\n",
    "dataset = xmd.X19MGeneralDataset.from_feature_finalizer_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Examine the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate a DatasetInspector from the `x19_mort_general_dataset` module and use its methods to display some basic information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41951 samples in the Dataset.\n",
      "Calling `__getitem__` on the Dataset returns a tuple of length 2.\n",
      "The first element of this tuple is a 2-D Tensor with 19 columns and data type torch.float32.\n",
      "The second element is a 0-D Tensor with data type torch.int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>seq_length</th>\n",
       "      <th>6</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_samples</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>84</td>\n",
       "      <td>144</td>\n",
       "      <td>126</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>113</td>\n",
       "      <td>148</td>\n",
       "      <td>152</td>\n",
       "      <td>189</td>\n",
       "      <td>199</td>\n",
       "      <td>220</td>\n",
       "      <td>178</td>\n",
       "      <td>231</td>\n",
       "      <td>203</td>\n",
       "      <td>211</td>\n",
       "      <td>191</td>\n",
       "      <td>185</td>\n",
       "      <td>221</td>\n",
       "      <td>474</td>\n",
       "      <td>37832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nunm_samples</th>\n",
       "      <td>37338</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_inspector = xmd.DatasetInspector(dataset=dataset)\n",
    "dataset_inspector.view_basic_info()\n",
    "dataset_inspector.view_seq_length_summary()\n",
    "dataset_inspector.view_label_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dataset is from a unique ICU stay. The input features for a single sample are represented by a 2D tensor where the column corresponds to a particular lab or vital sign measurement, and the row corresponds to time in hours after hospital admission. All samples' input feature tensors have the same number of columns, but the number of rows can vary from sample-to-sample. In LSTM lingo, the number of time steps assiciated with a sample is called the *sequence length*. In the current analysis, the Preprocessor removed all measuremens > 48 hours post-admission, so the maximum sequence length is 48. Samples ICU stays with < 48 hours of observations have smaller sequence lengths.\n",
    "\n",
    "A class label of 1 corresponds to an in-hospital mortality event. Less than 15% of samples belong this class. We will need to take the class imabalance into account when tuning and training predictive models with this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Architecture\n",
    "\n",
    "The starting point for our predictive model is based on the model in [1] and consists of the following layers:\n",
    "\n",
    "| Layer # | Description        | Input Shape                            | Parameters          | Output Shape           | Activation       |\n",
    "| ------- | ------------------ | -------------------------------------- | ------------------- | ---------------------- | ---------------- |\n",
    "| 1       | Bidirectional LSTM | (b, t<sub>max</sub> = 48, n<sub>meas</sub> = 19) | n<sub>LSTM</sub>    | (b, 2n<sub>LSTM</sub>) | a<sub>LSTM</sub> |\n",
    "| 2       | Dropoout           | (b, 2n<sub>LSTM</sub>)                 | P<sub>dropout</sub> | (b, 2n<sub>LSTM</sub>) | -                |\n",
    "| 3       | Fully Connected    | (b, 2n<sub>LSTM</sub>)                 | n<sub>FC</sub>      | (b, n<sub>FC</sub>)    | a<sub>FC</sub>   |\n",
    "| 4       | Output             | (b, n<sub>FC</sub>)                    | n<sub>out</sub> = 2 | (b, n<sub>out</sub>    | a<sub>out</sub>  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from the above table are defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter           | Description                                             |\n",
    "| ------------------- | ------------------------------------------------------- |\n",
    "| b                   | Batch size                                              |\n",
    "| t<sub>max</sub>     | Maximum input sequence length                           |\n",
    "| n<sub>meas</sub>    | Number of patient measurement types                     |\n",
    "| n<sub>LSTM</sub>    | Number of features in a LSTM hidden state               |\n",
    "| a<sub>LSTM</sub>    | Activation function for the LSTM output                 |\n",
    "| P<sub>dropout</sub> | Dropout probablity                                      |\n",
    "| n<sub>FC</sub>      | Numbef of nodes in the fully connected layer            |\n",
    "| a<sub>FC</sub>      | Activation function for the fully connected layer ouput |\n",
    "| n<sub>out</sub>     | Number of nodes in the output layer                     |\n",
    "| a<sub>out</sub>     | Activation function for the output layer                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that n<sub>meas</sub>, n<sub>out</sub>, abd s<sub>max</sub> are fixed. We have chosen to always use all 19 patient measurement types, and our classification problem always has two classes. In our current data pipeline, data collected outside of a specified time window are removed during the final preprocessing phase. If we want the observation window to be tunable, it would be helpful to move the `preprocess.feature_finalizer` module into the `tune_attack` sub-package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning\n",
    "\n",
    "### 9.1 Architectural hyperparameters\n",
    "\n",
    "The following table lists the ranges architectural parameters to be explored during hyperparameter tuning.\n",
    "\n",
    "| Parameter           | Tuning Type  | Values                            |\n",
    "| ------------------- | ------------ | --------------------------------- |\n",
    "| b                   | Discrete     | 2<sup>k</sup> , k = 5, 6, 7, 8    |                    \n",
    "| h<sub>LSTM</sub>    | Discrete     | 2<sup>k</sup> , k = 5, 6, 7       |\n",
    "| a<sub>LSTM</sub>    | Discrete     | ReLU, Tanh                        |\n",
    "| P<sub>dropout</sub> | Continuous   | 0.000 $\\textemdash$ 0.5000        |\n",
    "| h<sub>FC</sub>      | Discrete     | 2<sup>k</sup> , k = 4, 5, 6, 7, 8 |\n",
    "| a<sub>FC</sub>      | Discrete     | ReLU, Tanh                        |\n",
    "\n",
    "\n",
    "### 9.2 Trainer hyperparameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During hyperparameter tuning, we also explore different training optimization algorithms and learning rates.\n",
    "\n",
    "| Parameter     | Tuning Type | Values             |\n",
    "| ------------- | ----------- | ------------------ |\n",
    "| Optimizer     | Discrete    | SGD, RMSprop, Adam |\n",
    "| Learning Rate | Continuous  | 1e-5 - 1e-1        |\n",
    "\n",
    "When using the Adam optimizer, we always use the Pytorch default values of $\\beta_1 = 0.9, \\beta_2 = 0.999, \\epsilon = 10^{-8}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Implementation Details\n",
    "The [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py) class in the [`tune_train`](../src/lstm_adversarial_attack/tune_train/__init__.py) sub-package implements a cross-validation tuning scheme that utilizes the [Optuna](https://optuna.org/) framework. The boundaries of hyperparameter space to explore during tuning are passed to the [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py) constructor in a [`X19MLSTMTuningRanges`](../src/lstm_adversarial_attack/tune_train/tuner_helpers.py) object. The default attribute of a [`X19MLSTMTuningRanges`](../src/lstm_adversarial_attack/tune_train/tuner_helpers.py) object are stored in the following config variables in [`config_settings`](../src/lstm_adversarial_attack/config_settings.py):\n",
    "```\n",
    "    TUNING_LOG_LSTM_HIDDEN_SIZE\n",
    "    TUNING_LSTM_ACT_OPTIONS\n",
    "    TUNING_DROPOUT\n",
    "    TUNING_LOG_FC_HIDDEN_SIZE\n",
    "    TUNING_FC_ACT_OPTIONS\n",
    "    TUNING_OPTIMIZER_OPTIONS\n",
    "    TUNING_LEARNING_RATE\n",
    "    TUNING_LOG_BATCH_SIZE\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) generator is used to assign samples to each fold. When selecting samples for each training batch, we use a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) with a [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler) to oversample from the minority class (label = 1). For a given set of hyperparameters, the [`HyperParameterTuner.objective_fn`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) method returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna [`TPESampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html) to select new sets of hyperparameters for additional trials. [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) also uses an Optuna [`MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html) to stop unpromising trials early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Starting a New Hyperparameter Tuning Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, a few things to note:\n",
    "* Depending your GPU compute power, running the full 30 trials could take 2 - 20 hours.\n",
    "* Results will be saved to a newly created directory (with a timestamp-based name) under `data/tune_train/hyperparameter_tuning`. \n",
    "* If the study is stopped early (via CTRL-C or the Jupyter Stop button), learning from whatever trials have completed up to that point will be saved.\n",
    "* While the tuning trials are running, look ahead to the next Markdown cell for instructions on how to monitor progress in Tensorboard (depending on your notebook output settings you may need to scroll down to see that cell)\n",
    "\n",
    "We can start a new hyperparaemter tuning study using the [`tune_new`](../src/lstm_adversarial_attack/tune_train/tune_new.py) module from the [`tune_train`](../src/lstm_adversarial_attack/tune_train/__init__.py) subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lstm_adversarial_attack.tune_train import tune_new\n",
    "my_completed_study = tune_new.main(num_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-13 21:12:45,802]\u001b[0m A new study created in RDB with name: model_tuning_20231213211245732172\u001b[0m\n",
      "Starting hyperparameter tuning.\n",
      "\n",
      "Data for Tensorboard will be written to:\n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231213211245732172/tensorboard\n",
      "\n",
      "CV mean logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231213211245732172/cv_mean_logs\n",
      "\n",
      "Individual trainer logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231213211245732172/trainer_output\n",
      "fold_0, epoch_1, Loss: 0.6946\n",
      "fold_0, epoch_2, Loss: 0.6946\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6943\n",
      "Accuracy:\t0.5031\n",
      "AUC:\t\t0.3675\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6925\n",
      "fold_1, epoch_2, Loss: 0.6924\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6925\n",
      "Accuracy:\t0.5219\n",
      "AUC:\t\t0.5946\n",
      "Precision:\t0.5095\n",
      "Recall:\t\t0.7459\n",
      "F1:\t\t\t0.6054\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6951\n",
      "fold_2, epoch_2, Loss: 0.6946\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6949\n",
      "Accuracy:\t0.5011\n",
      "AUC:\t\t0.3469\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.6945\n",
      "fold_0, epoch_4, Loss: 0.6943\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6944\n",
      "Accuracy:\t0.5006\n",
      "AUC:\t\t0.3739\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.6925\n",
      "fold_1, epoch_4, Loss: 0.6925\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6925\n",
      "Accuracy:\t0.5233\n",
      "AUC:\t\t0.5955\n",
      "Precision:\t0.5159\n",
      "Recall:\t\t0.7428\n",
      "F1:\t\t\t0.6089\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.6954\n",
      "fold_2, epoch_4, Loss: 0.6952\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6954\n",
      "Accuracy:\t0.4953\n",
      "AUC:\t\t0.3463\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "\u001b[32m[I 2023-12-13 21:13:02,422]\u001b[0m Trial 0 finished with value: 0.6939130268313668 and parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'Tanh', 'dropout': 0.0056406475882083695, 'log_fc_hidden_size': 7, 'fc_act_name': 'Tanh', 'optimizer_name': 'SGD', 'learning_rate': 0.0001195454679142409, 'log_batch_size': 8}. Best is trial 0 with value: 0.6939130268313668.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.5889\n",
      "fold_0, epoch_2, Loss: 0.5542\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5400\n",
      "Accuracy:\t0.7568\n",
      "AUC:\t\t0.8357\n",
      "Precision:\t0.7451\n",
      "Recall:\t\t0.7821\n",
      "F1:\t\t\t0.7631\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6543\n",
      "fold_1, epoch_2, Loss: 0.5630\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5503\n",
      "Accuracy:\t0.7439\n",
      "AUC:\t\t0.8224\n",
      "Precision:\t0.7602\n",
      "Recall:\t\t0.7041\n",
      "F1:\t\t\t0.7311\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.5959\n",
      "fold_2, epoch_2, Loss: 0.5591\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5687\n",
      "Accuracy:\t0.7264\n",
      "AUC:\t\t0.8274\n",
      "Precision:\t0.8177\n",
      "Recall:\t\t0.5787\n",
      "F1:\t\t\t0.6778\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.5461\n",
      "fold_0, epoch_4, Loss: 0.5479\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5368\n",
      "Accuracy:\t0.7627\n",
      "AUC:\t\t0.8408\n",
      "Precision:\t0.7904\n",
      "Recall:\t\t0.7126\n",
      "F1:\t\t\t0.7495\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.5493\n",
      "fold_1, epoch_4, Loss: 0.5456\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5299\n",
      "Accuracy:\t0.7680\n",
      "AUC:\t\t0.8447\n",
      "Precision:\t0.7531\n",
      "Recall:\t\t0.7984\n",
      "F1:\t\t\t0.7751\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.5517\n",
      "fold_2, epoch_4, Loss: 0.5421\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5480\n",
      "Accuracy:\t0.7458\n",
      "AUC:\t\t0.8384\n",
      "Precision:\t0.7012\n",
      "Recall:\t\t0.8624\n",
      "F1:\t\t\t0.7735\n",
      "\n",
      "\u001b[32m[I 2023-12-13 21:13:21,535]\u001b[0m Trial 1 finished with value: 0.5382056341958735 and parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'Tanh', 'dropout': 0.2597555277621354, 'log_fc_hidden_size': 5, 'fc_act_name': 'ReLU', 'optimizer_name': 'RMSprop', 'learning_rate': 0.012669323960864566, 'log_batch_size': 7}. Best is trial 1 with value: 0.5382056341958735.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.5871\n",
      "fold_0, epoch_2, Loss: 0.5667\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5586\n",
      "Accuracy:\t0.7344\n",
      "AUC:\t\t0.8204\n",
      "Precision:\t0.8087\n",
      "Recall:\t\t0.6193\n",
      "F1:\t\t\t0.7015\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.5874\n",
      "^C\n",
      "\u001b[33m[W 2023-12-13 21:13:27,719]\u001b[0m Trial 2 failed with parameters: {'log_lstm_hidden_size': 7, 'lstm_act_name': 'ReLU', 'dropout': 0.3487365908067882, 'log_fc_hidden_size': 4, 'fc_act_name': 'Tanh', 'optimizer_name': 'Adam', 'learning_rate': 0.0342188086967941, 'log_batch_size': 7} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 321, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 194, in train_model\n",
      "    loss.backward()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-12-13 21:13:27,719]\u001b[0m Trial 2 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_new.py\", line 54, in <module>\n",
      "    completed_study = main(**args_namespace.__dict__)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_new.py\", line 37, in main\n",
      "    study = tuner_driver(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 239, in __call__\n",
      "    completed_study = self.run(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 235, in run\n",
      "    completed_study = tuner.tune(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 405, in tune\n",
      "    self.study.optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 321, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 194, in train_model\n",
      "    loss.backward()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python tune_train/tune_new.py --num_trials 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Monitor Tuning Progress with Tensorboard\n",
    "\n",
    "While we are tuning hyperparameters, we can monitor results in Tensorboard. One (relatively straightforward) way to start Tensorboard is to first launch a `zsh` shell inside the project container:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app_dev /bin/zsh\n",
    "```\n",
    "Next, at the container `zsh` prompt, run the following command to start a Tensorboard server:\n",
    "\n",
    "```\n",
    "> tensorboard --logdir=/home/devspace/project/data/hyperparameter_tuning/continued_trials/tensorboard --host=0.0.0.0\n",
    "```\n",
    "Then, in your browser, go to: `http://localhost:6006/` You should see something like the screenshot below.  The x-axis for all plots is epoch number. (Unfortunately, there is no good way to add axis labels in Tensorboard.) In this example we are in the middle of running trial #21. Trial #20 completed the default number of epochs per fold (100). Trial #19 only ran 20 epochs because it was pruned by the Optuna `MeadianPruner`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard_image](images/tensorboard_hyperparameter_tuning.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6 Run Additional Trials on an Exiting Tuning Study\n",
    "\n",
    "If we want to run additional trials using the results saved from a tuning study that previously ran, we can use the [`tune_train.tune_resume`](../src/lstm_adversarial_attack/tune_train/tune_resume.py) module.  When we resume an existing study, the Optuna framework can use learning from earlier trials in the study to choose conditios for the new trials. The new trial results are saved to the same directory and `optuna.Study` filepath containing results from the study's previous trials.\n",
    "\n",
    "We use the next code cell to resume tuning with an existing Study. When we do not provide an argument for tune_resume.main study_dir parameter (as is the case below), we default to the directory under `data/tune_train/hyperparameter_tuning` that contains the most recently modified `optuna_study.pickle` file.\n",
    "\n",
    ">**Note** If we want to use a study other than the most recently modified one, our call to `tune_resume.main` would look something like this:\n",
    "\n",
    ">`tune_resume.main(study_dir=/home/devspace/project/data/tune_train/hyperparameter_tuning/2023-07-27_17_04_20.069961/checkpoints_tuner,\n",
    "> num_trials=30)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lstm_adversarial_attack.tune_train import tune_resume\n",
    "tune_resume.main(num_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_resume.py [-h] [-s [STUDY_NAME]] [-n [NUM_TRIALS]]\n",
      "\n",
      "Runs additional hyperparameter tuning trials using previously saved\n",
      "TunerDriver and optuna.Study as startingpoints. New trial results are added to\n",
      "the existing Study.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -s [STUDY_NAME], --study_name [STUDY_NAME]\n",
      "                        Name (as saved in RDB) of study to resume\n",
      "  -n [NUM_TRIALS], --num_trials [NUM_TRIALS]\n",
      "                        Number of additional trials to run for the study in\n",
      "                        study_dir. Defaults to value stored in\n",
      "                        config_settings.TUNER_NUM_TRIALS.\n"
     ]
    }
   ],
   "source": [
    "!python tune_train/tune_resume.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_set.TUNER_NUM_TRIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-13 21:14:32,796]\u001b[0m Using an existing study with name 'model_tuning_20231212145059484285' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,799]\u001b[0m Using an existing study with name 'model_tuning_20231212145403542782' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,801]\u001b[0m Using an existing study with name 'model_tuning_20231212145658762150' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,803]\u001b[0m Using an existing study with name 'model_tuning_20231212145945456284' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,805]\u001b[0m Using an existing study with name 'model_tuning_20231212150617988279' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,806]\u001b[0m Using an existing study with name 'model_tuning_20231212163145594546' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,809]\u001b[0m Using an existing study with name 'model_tuning_20231212163921995927' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,810]\u001b[0m Using an existing study with name 'model_tuning_20231213091504341520' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,812]\u001b[0m Using an existing study with name 'model_tuning_20231213211245732172' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-13 21:14:32,896]\u001b[0m Using an existing study with name 'model_tuning_20231213211245732172' instead of creating a new one.\u001b[0m\n",
      "Starting hyperparameter tuning.\n",
      "\n",
      "Data for Tensorboard will be written to:\n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231213211245732172/tensorboard\n",
      "\n",
      "CV mean logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231213211245732172/cv_mean_logs\n",
      "\n",
      "Individual trainer logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231213211245732172/trainer_output\n",
      "fold_0, epoch_1, Loss: 0.6126\n",
      "fold_0, epoch_2, Loss: 0.5610\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5461\n",
      "Accuracy:\t0.7521\n",
      "AUC:\t\t0.8345\n",
      "Precision:\t0.7909\n",
      "Recall:\t\t0.6836\n",
      "F1:\t\t\t0.7334\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.5879\n",
      "fold_1, epoch_2, Loss: 0.5556\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5511\n",
      "Accuracy:\t0.7383\n",
      "AUC:\t\t0.8317\n",
      "Precision:\t0.7934\n",
      "Recall:\t\t0.6446\n",
      "F1:\t\t\t0.7113\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.5984\n",
      "fold_2, epoch_2, Loss: 0.5575\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5498\n",
      "Accuracy:\t0.7481\n",
      "AUC:\t\t0.8239\n",
      "Precision:\t0.7340\n",
      "Recall:\t\t0.7832\n",
      "F1:\t\t\t0.7578\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.5421\n",
      "fold_0, epoch_4, Loss: 0.5352\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5316\n",
      "Accuracy:\t0.7682\n",
      "AUC:\t\t0.8490\n",
      "Precision:\t0.8064\n",
      "Recall:\t\t0.7082\n",
      "F1:\t\t\t0.7541\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.5441\n",
      "fold_1, epoch_4, Loss: 0.5355\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5368\n",
      "Accuracy:\t0.7605\n",
      "AUC:\t\t0.8437\n",
      "Precision:\t0.7957\n",
      "Recall:\t\t0.6984\n",
      "F1:\t\t\t0.7439\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.5471\n",
      "fold_2, epoch_4, Loss: 0.5446\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5297\n",
      "Accuracy:\t0.7674\n",
      "AUC:\t\t0.8467\n",
      "Precision:\t0.7528\n",
      "Recall:\t\t0.7943\n",
      "F1:\t\t\t0.7730\n",
      "\n",
      "\u001b[32m[I 2023-12-13 21:15:02,528]\u001b[0m Trial 3 finished with value: 0.5326972316004319 and parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'Tanh', 'dropout': 0.1271512688872587, 'log_fc_hidden_size': 4, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 0.010032506623661742, 'log_batch_size': 6}. Best is trial 3 with value: 0.5326972316004319.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.6737\n",
      "fold_0, epoch_2, Loss: 0.6072\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5874\n",
      "Accuracy:\t0.7139\n",
      "AUC:\t\t0.7758\n",
      "Precision:\t0.7440\n",
      "Recall:\t\t0.6600\n",
      "F1:\t\t\t0.6995\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6789\n",
      "fold_1, epoch_2, Loss: 0.6157\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6002\n",
      "Accuracy:\t0.6994\n",
      "AUC:\t\t0.7585\n",
      "Precision:\t0.7321\n",
      "Recall:\t\t0.6264\n",
      "F1:\t\t\t0.6751\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6761\n",
      "fold_2, epoch_2, Loss: 0.6099\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6005\n",
      "Accuracy:\t0.7008\n",
      "AUC:\t\t0.7575\n",
      "Precision:\t0.7099\n",
      "Recall:\t\t0.6756\n",
      "F1:\t\t\t0.6923\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.5820\n",
      "fold_0, epoch_4, Loss: 0.5724\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5730\n",
      "Accuracy:\t0.7247\n",
      "AUC:\t\t0.7913\n",
      "Precision:\t0.7430\n",
      "Recall:\t\t0.6920\n",
      "F1:\t\t\t0.7166\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.5914\n",
      "fold_1, epoch_4, Loss: 0.5840\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5795\n",
      "Accuracy:\t0.7159\n",
      "AUC:\t\t0.7862\n",
      "Precision:\t0.7503\n",
      "Recall:\t\t0.6498\n",
      "F1:\t\t\t0.6964\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.5932\n",
      "fold_2, epoch_4, Loss: 0.5831\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5775\n",
      "Accuracy:\t0.7210\n",
      "AUC:\t\t0.7870\n",
      "Precision:\t0.7384\n",
      "Recall:\t\t0.6759\n",
      "F1:\t\t\t0.7057\n",
      "\n",
      "\u001b[32m[I 2023-12-13 21:15:21,676]\u001b[0m Trial 4 finished with value: 0.5766490901986213 and parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'ReLU', 'dropout': 0.0997139702527936, 'log_fc_hidden_size': 8, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 3.6450878991100194e-05, 'log_batch_size': 7}. Best is trial 3 with value: 0.5326972316004319.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.6947\n",
      "fold_0, epoch_2, Loss: 0.6938\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6929\n",
      "Accuracy:\t0.5012\n",
      "AUC:\t\t0.7225\n",
      "Precision:\t0.5012\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6678\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6940\n",
      "fold_1, epoch_2, Loss: 0.6933\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6923\n",
      "Accuracy:\t0.5017\n",
      "AUC:\t\t0.7363\n",
      "Precision:\t0.5017\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6682\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6928\n",
      "fold_2, epoch_2, Loss: 0.6908\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6898\n",
      "Accuracy:\t0.5040\n",
      "AUC:\t\t0.7390\n",
      "Precision:\t0.5040\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6702\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.6920\n",
      "fold_0, epoch_4, Loss: 0.6889\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6844\n",
      "Accuracy:\t0.5062\n",
      "AUC:\t\t0.7416\n",
      "Precision:\t0.5062\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6721\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.6918\n",
      "fold_1, epoch_4, Loss: 0.6892\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6856\n",
      "Accuracy:\t0.4965\n",
      "AUC:\t\t0.7614\n",
      "Precision:\t0.4965\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6636\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.6886\n",
      "^C\n",
      "\u001b[33m[W 2023-12-13 21:15:34,918]\u001b[0m Trial 5 failed with parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'ReLU', 'dropout': 0.1506319581109385, 'log_fc_hidden_size': 4, 'fc_act_name': 'ReLU', 'optimizer_name': 'Adam', 'learning_rate': 2.6781227037436828e-05, 'log_batch_size': 8} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 321, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 194, in train_model\n",
      "    loss.backward()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-12-13 21:15:34,919]\u001b[0m Trial 5 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_resume.py\", line 89, in <module>\n",
      "    completed_study = main(**args_namespace.__dict__)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_resume.py\", line 56, in main\n",
      "    study = tuner_driver(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 239, in __call__\n",
      "    completed_study = self.run(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 235, in run\n",
      "    completed_study = tuner.tune(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 405, in tune\n",
      "    self.study.optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 321, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 194, in train_model\n",
      "    loss.backward()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python tune_train/tune_resume.py --num_trials 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.7 Select Final Hyperparameters\n",
    "When we are done tuning, we can view our best set of hyperparameters by examining the `Optuna.Study` object from our above tuning run(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_ParzenEstimatorParameters.__new__() missing 1 required positional argument: 'categorical_distance_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlstm_adversarial_attack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresource_io\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrio\u001b[39;00m\n\u001b[1;32m      3\u001b[0m study_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/devspace/project/data/tune_train/hyperparameter_tuning/continued_trials/checkpoints_tuner/optuna_study.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceImporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_pickle_to_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_path\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best trial result is from trial # \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe set of hyperparameters from this trial are:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/resource_io.py:58\u001b[0m, in \u001b[0;36mResourceImporter.import_pickle_to_object\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_path(path\u001b[38;5;241m=\u001b[39mpath, file_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m path\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/custom_unpickler.py:14\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file_obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file_obj):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCustomUnpickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/dill/_dill.py:442\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mStockUnpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_main_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore:\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;66;03m# point obj class to main\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: _ParzenEstimatorParameters.__new__() missing 1 required positional argument: 'categorical_distance_func'"
     ]
    }
   ],
   "source": [
    "import lstm_adversarial_attack.resource_io as rio\n",
    "\n",
    "study_path = Path(\"/home/devspace/project/data/tune_train/hyperparameter_tuning/continued_trials/checkpoints_tuner/optuna_study.pickle\")\n",
    "\n",
    "study = rio.ResourceImporter().import_pickle_to_object(\n",
    "    path=study_path\n",
    ")\n",
    "\n",
    "print(f\"The best trial result is from trial # {study.best_trial.number}.\\n\")\n",
    "print(\"The set of hyperparameters from this trial are:\")\n",
    "pprint.pprint(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.8 Run K-Fold Cross Validation with \"Best\" Hyperparameters and Extended Training (More Epochs)\n",
    "In the above tuning runs, we only run 100 epochs per fold (in the interest of reducing compute requirements). Based on the validation loss and AUC curves, it appears that we could improve our predictive performance (i.e. decrease validation loss, and increase AUC) by training longer. We now run another round of Stratified K-fold cross-validation with our best set of parameters with a larger number of epochs.\n",
    "\n",
    "#### 9.8.1 Notes on our Method\n",
    "Some caveats about our methodology:\n",
    "* We are using \"flat\" cross-validation (as was done in previous studies on this dataset). This method computationally less expensive than nested cross-validation. Flat cross-validation has the potential to overestimate of model performance. In many cases the magnitude of overestimation is small. We also mitigate this effect by using a different set of (randomly generated) fold assignments than was used for hyperparameter tuning. \n",
    "* By selecting our hyperparameters based on the smaller number of epochs (100), we favor models that are faster to to train. It is possible that using a larger number of epochs in the tuning runs would have yielded a different (and better) set of \"best\" hyperparameters, but would also be computationally more expensive.\n",
    "\n",
    "\n",
    "#### 9.8.2 Instantiate a CrossValidatorDriver\n",
    "We use a CrossValidatorDriver object to run cross-validation with a single set of hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validator_driver as cvd\n",
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "\n",
    "cv_driver = cvd.CrossValidatorDriver.from_study_path(\n",
    "        device=cur_device,\n",
    "        dataset=dataset,\n",
    "        study_path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data members of `cv_driver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(cv_driver.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run 5-fold cross-validation using 1000 epochs per fold. We will evaluate performance and save a checkpoint once every 10 epochs. These settings are determined by the values of `CV_DRIVER_EPOCHS_PER_FOLD`, `CV_DRIVER_NUM_FOLDS`, `CV_DRIVER_EVAL_INTERVAL`, and `CV_DRIVER_EVALS_PER_CHECKPOINT` in `lstm_adversarial_attacker.config_settings`. The `.from_study_path()` class method we used to construct `cv_driver` extracts the best set of hyperparameters from `study_path` and passes them to the CrossValidationDriver constructor.\n",
    "\n",
    "#### 9.8.3 Run Cross-Validation\n",
    "We now call `cv_driver`'s `.run()` method to start the cross-validation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "collapsed"
    ]
   },
   "outputs": [],
   "source": [
    "cv_driver.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.8.4 Monitor Cross-Validation Progress in Tensorbard\n",
    "Near the start of the terminal output from the previous code cell, look for the lines:\n",
    "```\n",
    "Checkpoints will be saved in:\n",
    "/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard\n",
    "```\n",
    "Then, start a zsh shell inside the app container, and launch tensorboard server:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app /bin/zsh\n",
    "$ tensorboard --logdir=/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "The Tensorboard output can now be viewed in your browswer at http://localhost:6006\n",
    "\n",
    "This Tensorboard screenshot was taken at the end of a 5-fold, 1000 epoch per fold cross-validation run.\n",
    "![tensorboard_image](images/tensorboard_5fold_cv_best_params_1000epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.8.5 Why Do We See Continued (Slow) Increase in Predictive Performance Up To Such High (1000) Epoch Counts?\n",
    "\n",
    "The above AUC and validation loss curves show continued (though diminishing) improvement in predictive performance during the entire 1000 epochs. The fact that we do not observe any sign of overfitting at such a large number of epochs is somewhat unusual. A likely cause of this behavior is the `WeightedRandomSampler` used in our training `DataLoaders`. Samples with our minority class label (`mortality = 1`) only represent ~15% of the total dataset. To deal with this imbalanced dataset, we oversample from the minority class and undersample from the majority class when creating batches of samples for training. In our current implementation, some samples from the majority class go unseen by the `StandardModelTrainer` for a large number of epochs. The number of unseen samples slowly dwindles (and the amount of information available for training slowly increases), even at very high epoch counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.8.6 Summarize Results\n",
    "We can use a CrossValidationSummarizer to identify and summarize each fold's best-performing checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validation_summarizer as cvs\n",
    "cv_summarizer = cvs.CrossValidationSummarizer.from_cv_checkpoints_dir()\n",
    "optimal_results_df = cv_summarizer.get_optimal_results_df(\n",
    "        metric=cvs.EvalMetric.VALIDATION_LOSS,\n",
    "        optimize_direction=cvs.OptimizeDirection.MIN,\n",
    "    )\n",
    "\n",
    "optimal_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the mean and standard deviation of each performance metric using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_results_df.describe().loc[[\"mean\", \"std\"], (optimal_results_df.columns != \"epoch\") & (optimal_results_df.columns != \"fold\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.9 Comparison with Prior Work\n",
    "\n",
    "The table below compares the predictive performance of the LSTM model in this work with other LSTM-based models using the same dataset. The current model shows the best predictive performance among all models in the table based on AUC and F1 scores. \n",
    "\n",
    "\n",
    "|  | Authors       | Model      | Input Features | AUC             | F1              | Precision       | Recall          |\n",
    "|-|------------|------------|----------------|-----------------|-----------------|-----------------|-----------------|\n",
    "|1 |Sun et al.  | LSTM-128 + FC-32 + FC-2 | [13 labs, 6 vitals] x 48 hr  | 0.9094 (0.0053) | 0.5429 (0.0194) | 0.4100 (0.0272) | 0.8071 (0.0269) |\n",
    "|2 |Tang et al. | LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr + demographic data  | 0.949 (0.003) | 0.623 (0.012) | \n",
    "| 3|Tang et al. | CNN + LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr + demographic data | 0.940 (0.0071) | 0.633 (0.031) | \n",
    "|4 |Tang et al. | CNN + LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr | 0.933 (0.006) | 0.587 (0.025) |\n",
    "|5 |Tang et al. | LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr | 0.907 (0.006) | 0.526 (0.013) |\n",
    "|6 |This work   | LSTM-128 + FC-16 + FC-2 | [13 labs, 6 vitals] x 48 hr  | 0.9657 (0.0035) | 0.9669 (0.0038) | 0.9888 (0.0009) | 0.9459 (0.0072) |\n",
    "\n",
    "> **Notes** LSTM-X indicates an LSTM with X hidden layers. FC-X indicates a fully connected layer with an output size of X. All LSTMs are bidirectional. The demographic data used in studies #2 and #3 was obtained from MIMIC-III.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Adversarial Attack Algorithm on the Trained Model\n",
    "\n",
    "### 10.1 Adversarial Loss and Regularization\n",
    "Our method of adversarial attack is similar to Chen et al.'s approach that uses an adversarial loss function and L1 regularization. When attacking a binary classification model with trained parameters $\\theta$, we start with the input feature matrix $X$ of a sample that the model correctly predicts to be in class $t_{c}$, so  $M(X) = t_{c}$ where $M$ is the model's prediction function. We then search for a perturbation matrix $P$ that meets the condition:\n",
    "$$\n",
    "M(X + P) \\ne t_{c}\n",
    "$$\n",
    "Since we are dealing with binary classification, this condition is equivalent to:\n",
    "$$\n",
    "M(X + P) = \\neg{t_{c}}\n",
    "$$\n",
    "where $\\neg{t_c}$ is the negation of $t_c$. Defining a perturbed feature matrix $\\widetilde{X} = X + P$ , an adversarial loss function can be written as:\n",
    "$$\n",
    "max\\{[Logit(\\widetilde{X})]_{t_c} - [Logit(\\widetilde{X})]_{\\neg{t_c}}, - \\kappa \\}\n",
    "$$\n",
    "\n",
    "When running perturbed input $\\widetilde{X}$ through a forward pass, $[Logit(\\widetilde{X})]_{t_c}$ and $[Logit(\\widetilde{X})]_{\\neg{t_c}}$ are the **pre-activation** values at the nodes corresponding to $t_c$ and $\\neg{t_c}$ the in 2-node final layer. A value $\\ge 0$ is chosen for $\\kappa$. Using a small non-zero value of $\\kappa$ will prevent an attack algorithm from optimizing toward an infinitesimally small gap between $[Logit(\\widetilde{X})]_{t_c}$ and $[Logit(\\widetilde{X})]_{\\neg{t_c}}$ while still targeting the small difference we want for an adversarial example.\n",
    "\n",
    "To encourage an attack algorithm to find sparse perturbations, the following regularized version of Equation  () is used  \n",
    "\n",
    "$$\n",
    "max\\{[Logit(\\widetilde{X})]_{y_\\theta} - [Logit(X)]_{\\widetilde{y}_\\theta}, - \\kappa \\} + \\lambda||\\widetilde{X}-X||_1\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is the L1 regularization constant. Equation () can be minimized by subgradient descent or by an Iterative Soft-Thresholding Algorithm (ISTA). The latter approach typically converges faster. \n",
    "\n",
    "\n",
    "### 10.2 Attack Algorithm and Regularization\n",
    "\n",
    "Adversarial attacks on a particular model and dataset input features are managed by an `AdversarialAttackTrainer`. In the procedure outlined below, we discover an adversarial example any time we find $[Logit(\\widetilde{X})]_{\\neg{t_c}} > [Logit(\\widetilde{X})]_{t_c}$, even if we have not converged near a minimum value of Equation (). We attack each batch of samples for a fixed number of iterations, regardless of how many (if any) adversarial examples are found.\n",
    "\n",
    "1. A `LogitNoDropoutModelBuiler` creates a modified version of the target model. The modified model has all dropout probabilities set to zero, and does not have an activation function on the output layer.\n",
    "2. Batches of input features are run through a `FeaturePerturber` (implemented in `attack.feature_perturber`) that generates slightly modified versions of original features\n",
    "3. The perturbed features are run through the modified model that was built by the `LogitNoDropoutModelBuiler` to obtain values for $[Logit(\\widetilde{X})]_{t_c}$ and $[Logit(\\widetilde{X})]_{\\neg{t_c}}$\n",
    "4. An instance of custom PyTorch loss function ` AdversarialLoss`, which implements Equation (), calculates a loss tensor\n",
    "5. The Pytorch `.backward()`  method of the loss tensor finds the gradient of the loss with respect to the elements of the `FeaturePerturber.perturbation` tensor\n",
    "\n",
    "6. If the current $Logit$ values resulting from a sample's perturbed input features represent an adversarial example, and the example is either the first or lowest loss example for that sample, the perturbations and other details are stored in a `BatchResult` object.\n",
    "\n",
    "7. A Pytorch optimizer uses the loss gradient to calculate and apply adjustments to the perturbations\n",
    "\n",
    "8. The `AdversarialAttackTrainer.apply_soft_bounded_threshold()` method performs ISTA thresholding on the perturbations\n",
    "\n",
    "9. The perturbations (which have been adjusted by the optimizer *and* ISTA thresholding, are used in step 1 of the next attack iteration.\n",
    "\n",
    "Two key points from above procedure are: (1) Unlike the method used in [], we do not stop attacking an example upon finding a single adversarial perturbation for it.  (2) We use a combination of subgradient descent (in step 7), and ISTA (in step 8) to minimize (or at least reduce) the value of equation (). We do not know if this approach is guaranteed to converge to a minimum in the adversarial loss function, but empirically, we find this subgradient descent + ISTA more effective at finding sparse adversarial examples than either method is on its own.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Attack Hyperparameter Tuning\n",
    "\n",
    "Before running an attack on the entire dataset, we tune attack hyperparameters with help from `optuna`. Our approach here is not as rigourous as the one we used for predictive model tuning. We just use small fraction of the total dataset for tuning, and no cross-validation is involved.\n",
    "\n",
    "#### 10.3.1 Viewing / Setting the Tuning Ranges\n",
    "\n",
    "First, let's look at the current values of the project config variables that determine how an attack hyperparameter tuning session will run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kappa: min = {cfg_set.ATTACK_TUNING_KAPPA[0]}, max = {cfg_set.ATTACK_TUNING_KAPPA[1]}\")\n",
    "print(f\"Lambda: min = {cfg_set.ATTACK_TUNING_LAMBDA_1[0]}, max = {cfg_set.ATTACK_TUNING_LAMBDA_1[1]}\")\n",
    "print(f\"Optimizer: {cfg_set.ATTACK_TUNING_OPTIMIZER_OPTIONS}\")\n",
    "print(f\"Learning rate: min = {cfg_set.ATTACK_TUNING_LEARNING_RATE[0]}, max = {cfg_set.ATTACK_TUNING_LEARNING_RATE[1]}\")\n",
    "print(f\"Batch size: min = {2 ** cfg_set.ATTACK_TUNING_LOG_BATCH_SIZE[0]}, max = {2 ** cfg_set.ATTACK_TUNING_LOG_BATCH_SIZE[1]}\")\n",
    "print(f\"Attack iterations per batch: {cfg_set.ATTACK_TUNING_EPOCHS}\")\n",
    "print(f\"Max number of samples: {cfg_set.ATTACK_TUNING_MAX_NUM_SAMPLES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are stored as variables in `src/lstm_adversarial_attack/config_settings.py` and can be modified as needed to customize a tuning session.\n",
    "\n",
    ">**Note** The `ATTACK_TUNING_MAX_NUM_SAMPLES` specifies the number of samples to be considered for attack. However, samples that are misclassified by the target model are not attacked, so the actual number of samples used for tuning will be slightly lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2 Running an AttackHyperParameterTuner\n",
    "\n",
    "We can run a new attack hyperparameter tunin session with function `initiate_attack_tuning_study()` from the `attack.tune_attacks` module. The `target_mode_assessment_type` determines whether we use a model trained by cross-validation or single-fold training. The default behavior is to choose the most recent result of whichever assessment type is specified. We can influence the type of adversarial perturbation our tuned algorithm will produce through the argument passed to the `objective` parameter. We use the return value of any method of class `AttackTunerObjectivesBuilder`. Current options are:\n",
    "\n",
    "| Objective                                                   | Maximizes                                                    |\n",
    "| ----------------------------------------------------------- | ------------------------------------------------------------ |\n",
    "| `sparsity()`        | Sum of the perturbation sparsities of the lowest loss adversarial example of each sample |\n",
    "| `max_num_nonzero_perts()` | Number of adversarial perturbations with only one non-zero element |\n",
    "| `sparse_small()`           | Sum of (sparsity / L1 norm) of the lowest loss adversarial example of each sample |\n",
    "| `sparse_small_max()`       | Sum of (sparsity / largest magnitude of any perturbation element) of lowest loss adversarial example of each sample |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.attack.attack_hyperparameter_tuner as aht\n",
    "import lstm_adversarial_attack.attack.tune_attacks as tua\n",
    "\n",
    "# initial_attack_tuning_study = tua.main()\n",
    "help(tua.main)\n",
    "\n",
    "# initial_attack_tuning_study = tua.start_new_tuning(\n",
    "#         num_trials=50,\n",
    "#         # target_model_assessment_type=amr.ModelAssessmentType.KFOLD,\n",
    "#         objective=aht.AttackTunerObjectivesBuilder.sparse_small_max(),\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will be saved in a subdirectory of `/home/devspace/project/data/attack/attack_hyperparameter_tuning`. If we want to run additional trials for an existing study, we can use the following code. Again, the default behavior is to use the newest existing study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "continued_study = tua.resume_tuning(num_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3 Attacking the full dataset\n",
    "\n",
    "Next we use function  `attack_with_tuned_params()` to attack all correctly classified samples using the results of our latest hyperparamter tuning session. Results will be saved in a subdirectory of /home/devspace/project/data/attack/frozen_hyperparameter_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.attack.attack as atk\n",
    "atk.attack_with_tuned_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Attack Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.attack_analysis.attack_analysis as ata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_adversarial_attack.attack_analysis import attack_analysis_driver as aad\n",
    "aad.plot_latest_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
