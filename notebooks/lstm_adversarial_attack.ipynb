{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About this Notebook\n",
    "\n",
    "See the project [README](https://github.com/duanegoodner/lstm_adversarial_attack) for general information on the dataset and approach used in this notebook.\n",
    "\n",
    "The implementation details for this project are encapsulated in various classes and methods defined in modules under the project `src` directory, and various intermediate data structures and logs are saved in the project `data` directory. Most of the code in this notebook simply instantiates top-level classes and makes calls to their methods without revealing implementation details. Please look to code in the `src` and `data` directories if you interested in lower level details. The import paths as well as the terminal output shown in this notebook will provide some guidance on where to look within those directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, review the project README at https://github.com/duanegoodner/lstm_adversarial_attack, and complete all steps in the \"How to run this project\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports\n",
    "Most of the necessary standard library imports and external package imports are handled modules in the `src` directory, but we need to import a few here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Standard Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 External Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Internal Project Modules and Sub-packages\n",
    "To help gain a sense of project structure, we will import internal packages and modules as-needed (i.e. immediately before the notebook code cells where they are first used). For now, we import the project `src` path defined in `lstm_adversarial_attack/notebooks/src_path`, add it to sys.path (so we can easily import project code), and we import project config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src_paths\n",
    "sys.path.append(str(src_paths.lstm_adversarial_attack_pkg))\n",
    "import lstm_adversarial_attack.config_paths as cfg_paths\n",
    "import lstm_adversarial_attack.config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Queries\n",
    "We need to run four queries on the MIMIC-III PostgreSQL database. The paths to files containing the queries are stored in a list as `DB_QUERIES` in the project `config_paths` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/devspace/project/src/mimiciii_queries/icustay_detail.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_bg.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_lab.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_vital.sql')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_paths.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database, and execute the queries, we instantiate a `MimiciiiDatabaseAccess` object from module `mimiciii_database` of project sub-package `query_db` and use its .connect(), .run_sql_queries() and .close_connection() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.query_db.mimiciii_database as mdb\n",
    "\n",
    "db_access = mdb.MimiciiiDatabaseAccess(\n",
    "    dotenv_path=cfg_paths.DB_DOTENV_PATH, output_dir=cfg_paths.DB_OUTPUT_DIR\n",
    ")\n",
    "db_access.connect()\n",
    "db_query_results = db_access.run_sql_queries(\n",
    "    sql_query_paths=cfg_paths.DB_QUERIES\n",
    ")\n",
    "db_access.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of each `.sql` query is saved to a `.csv` file. The path to each of these files is shown in the terminal output above. The output path of the queries is defined by variable `DB_OUTPUT_DIR` in the project `config_settings` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instantiate a Preprocessor object\n",
    "We import the `preprocessor` module from internal sub-package `preprocess`, instantiate a `Preprocessor` object, and examine its .preprocess_modules data member. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.preprocess.preprocessor as pre\n",
    "preprocessor = pre.Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a general idea of how the `lstm_adversarial_attack.preprocess` sub-package works by looking at the `Preprocessor` object's `.preprocessor_modules` data member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'lstm_adversarial_attack.preprocess.prefilter.Prefilter'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.icustay_measurement_combiner.ICUStayMeasurementCombiner'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.sample_list_builder.FullAdmissionListBuilder'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.feature_builder.FeatureBuilder'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.feature_finalizer.FeatureFinalizer'>]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint([item.__class__ for item in preprocessor.preprocess_modules])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prefilter reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* ICUStayMeasurementCombiner performs various joins (aka \"merges\" in the language of Pandas) to combine lab and vital sign measurement data with ICU stay data.\n",
    "* FullAdmissionListBuilder generates a list consisting of one FullAdmissionData object per ICU stay. The attributes of a FullAdmissionData object include ICU stay info, and a dataframe containing the measurement and timestamp data for all vital sign and lab data associated with the ICU stay.\n",
    "* FeatureBuilder resamples the time series datafame to one-hour intervals, imputes missing data, winsorizes measurement values (with cutoffs at the 5th and 95th global percentiles), and normalizes the measuremnt values so all data are between 0 and 1.\n",
    "* FeatureFinalizer selects the data observation time window (default starts at hospital admission time and ends 48 hours after admission). This module outputs the entire dataset features as a list of numpy arrays, and the mortality labels as a list of integers. These data structures (saved as .pickle files) will be convenient starting points when the `tune_train` and `attack` sub-packages need to create PyTorch Datasets.\n",
    "\n",
    "Now that we have a some background info, we are ready to run the Preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_resources = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pytorch Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create the Dataset\n",
    "We import module `x19_mort_general_dataset` and use it along with files saved by the Preprocessor's Feature Finalizer module to insantiate a Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "dataset = xmd.X19MGeneralDataset.from_feature_finalizer_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Examine the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Dataset size, tensor shapes, and data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset = 41951\n",
      "\n",
      "Type returned by dataset.__getitem__ = <class 'tuple'>\n",
      "\n",
      "Length of each tuple returned by dataset.__getitem__ = 2\n",
      "\n",
      "Object type, dimensionality, and datatype of each element in a tuple returned by dataset.__getitem__:\n",
      "((<class 'torch.Tensor'>, 2, torch.float32), (<class 'torch.Tensor'>, 0, torch.int64))\n",
      "\n",
      "input size (# columns) of each feature matrix is:\n",
      "19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in dataset = {len(dataset)}\\n\")\n",
    "print(f\"Type returned by dataset.__getitem__ = {type(dataset[0])}\\n\")\n",
    "print(\n",
    "    f\"Length of each tuple returned by dataset.__getitem__ = {len(dataset[0])}\"\n",
    ")\n",
    "print(\n",
    "    \"\\nObject type, dimensionality, and datatype of each element in a tuple\"\n",
    "    \" returned by dataset.__getitem__:\"\n",
    ")\n",
    "print(tuple([(type(item), item.dim(), item.dtype) for item in dataset[0]]))\n",
    "print(f\"\\ninput size (# columns) of each feature matrix is:\\n\"\n",
    "     f\"{np.unique([item.shape[1] for item in dataset[:][0]]).item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Distributions of feature sequence lengths and label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of input sequence lengths (# rows):\n",
      "length\tcounts\n",
      "[[    6     1]\n",
      " [   13     1]\n",
      " [   14     1]\n",
      " [   16     2]\n",
      " [   17     4]\n",
      " [   18     3]\n",
      " [   19     8]\n",
      " [   20    12]\n",
      " [   21    25]\n",
      " [   22    49]\n",
      " [   23    84]\n",
      " [   24   144]\n",
      " [   25   126]\n",
      " [   26   110]\n",
      " [   27    93]\n",
      " [   28    95]\n",
      " [   29    84]\n",
      " [   30    90]\n",
      " [   31    75]\n",
      " [   32    99]\n",
      " [   33    98]\n",
      " [   34   113]\n",
      " [   35   148]\n",
      " [   36   152]\n",
      " [   37   189]\n",
      " [   38   199]\n",
      " [   39   220]\n",
      " [   40   178]\n",
      " [   41   231]\n",
      " [   42   203]\n",
      " [   43   211]\n",
      " [   44   191]\n",
      " [   45   185]\n",
      " [   46   221]\n",
      " [   47   474]\n",
      " [   48 37832]]\n",
      "\n",
      "Label counts:\n",
      "value\tcounts\n",
      "[[    0 37338]\n",
      " [    1  4613]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of input sequence lengths (# rows):\")\n",
    "print(\"length\\tcounts\")\n",
    "unique_sequence_lengths, sequence_length_counts = np.unique(\n",
    "    [item.shape[0] for item in dataset[:][0]], return_counts=True\n",
    ")\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            unique_sequence_lengths.reshape(-1, 1),\n",
    "            sequence_length_counts.reshape(-1, 1),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nLabel counts:\")\n",
    "print(\"value\\tcounts\")\n",
    "unique_labels, label_counts = np.unique([dataset[:][1]], return_counts=True)\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (unique_labels.reshape(-1, 1), label_counts.reshape(-1, 1)), axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Tuning Parameters\n",
    "\n",
    "We define the following architecture for our LSTM predictive model\n",
    "\n",
    "| Item  | Detail #1 | Detail #2| Detail #3 |\n",
    "| :-------------- | :---------| :---------| :---------\n",
    "| Bidirectional LSTM | input size = 19 | # hidden states per direction = *x<sub>1</sub>* | activation = ReLU or Tanh  |\n",
    "| Dropout | P<sub>dropout</sub> = *x<sub>2</sub>* | -  | -  |\n",
    "| Fully Connected Layer #1 | input size = *2x<sub>1</sub>*| output size = *x<sub>3</sub>* | activation = ReLU or Tanh |\n",
    "| Fully Connected Layer #2 | input size = *x<sub>3</sub>* | output size = 2 | activation = Softmax |\n",
    "| Optimizer | type = SGD or RMSProp or Adam | learning rate = *x<sub>4</sub>* | - |\n",
    "\n",
    "*x<sub>1</sub>*, *x<sub>2</sub>*, *x<sub>3</sub>*, *x<sub>4</sub>*, activation functions for the LSTM and FC #1, the optimizer type, and learning rate will be determined through hyperparameter tuning.\n",
    "\n",
    "The `HyperParameterTuner` class in the `lstm_adversarial_attack.tune_train` sub-package implements a K-fold (default K = 5) cross-validation tuning scheme that utilizes the Optuna framework. For a given set of hyperparameters, the `HyperParameterTUner.objective_fn()` returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna `TPESampler` to select new sets of hyperparameters for additional trials. `HyperParameterTuner` also uses an Optuna `MedianPruner` to stop unpromising trials early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 General Approach\n",
    "The `HyperParameterTuner` class in the `lstm_adversarial_attack.tune_train` sub-package implements a Stratified K-fold (default K = 5) cross-validation tuning scheme that utilizes the Optuna framework. When defining the dataset indices for each fold, we oversample from samples in the minority class (label = 1) using a For a given set of hyperparameters, the `HyperParameterTUner.objective_fn()` returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna `TPESampler` to select new sets of hyperparameters for additional trials. `HyperParameterTuner` also uses an Optuna `MedianPruner` to stop unpromising trials early.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Check for GPU\n",
    "Model hyperparameter tuning (along with training, and model attacks) is implemented in PyTorch, and we really need a GPU to run things in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cur_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    cur_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"cur_device is {cur_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Instantiate and Examine TunerDriver\n",
    "We then instantiate a TunerDriver object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.tuner_driver as td\n",
    "tuner_driver = td.TunerDriver(\n",
    "    device=cur_device,\n",
    "    dataset=dataset,\n",
    "    continue_study_path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE,\n",
    "    output_dir=cfg_paths.ONGOING_TUNING_STUDY_DIR,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `continue_study_path` and `output_dir` arguments passed to the `TunerDriver` constructor will allow us to build upon an existing Optuna study that contains learning from previously run trials. Model hyperparameter tuning is the most time-consuming part of the overall project pipeline, so we usually do not want to start from scratch. (But if you really want to start from scratch, just don't pass either of these path arguments to the `TuneDriver` constructor). For reference, the values of the two path variables we passed to the TunerDriver constructor are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue_study_path = /home/devspace/project/data/hyperparameter_tuning/continued_trials/checkpoints_tuner/optuna_study.pickle\n",
      "output_dir = /home/devspace/project/data/hyperparameter_tuning/continued_trials\n"
     ]
    }
   ],
   "source": [
    "print(f\"continue_study_path = {cfg_paths.ONGOING_TUNING_STUDY_PICKLE}\")\n",
    "print(f\"output_dir = {cfg_paths.ONGOING_TUNING_STUDY_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TunerDriver object has many default parameters/attributes set by values in `cfg_paths` and `cfg_settings`. Note that its `.tuner` attribute is a `HyperParameterTuner` which in turn has a `.tuning_ranges` attribute that specifies our hyperparameter search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuner_driver.tuner is a <class 'lstm_adversarial_attack.tune_train.hyperparameter_tuner.HyperParameterTuner'>\n",
      "\n",
      "tuner_driver.tuner.tuning_ranges:\n",
      "X19MLSTMTuningRanges(log_lstm_hidden_size=(5, 7),\n",
      "                     lstm_act_options=('ReLU', 'Tanh'),\n",
      "                     dropout=(0, 0.5),\n",
      "                     log_fc_hidden_size=(4, 8),\n",
      "                     fc_act_options=('ReLU', 'Tanh'),\n",
      "                     optimizer_options=('Adam', 'RMSprop', 'SGD'),\n",
      "                     learning_rate=(1e-05, 0.1),\n",
      "                     log_batch_size=(5, 8))\n"
     ]
    }
   ],
   "source": [
    "print(f\"The tuner_driver.tuner is a {type(tuner_driver.tuner)}\\n\")\n",
    "print(\"tuner_driver.tuner.tuning_ranges:\")\n",
    "pprint.pprint(tuner_driver.tuner.tuning_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Run the TunerDriver\n",
    "The code in the next cell will run the Tuner Driver (and its associated HyperParameterTuner). Before starting, a few things to note:\n",
    "* Depending your GPU compute power, running the full 30 trials could take 2 - 20 hours.\n",
    "* If the study is stopped early (via CTRL-C or the Jupyter Stop button), learning from whatever trials have completed up to that point will be saved.\n",
    "* While the tuning trials are running, look ahead to the next Markdown cell for instructions on how to monitor progress in Tensorboard (depending on your notebook output settings you may need to scroll down to see that cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completed_study = tuner_driver.run(num_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Monitor Tuning Progress with Tensorboard\n",
    "\n",
    "While we are tuning hyperparameters, we can monitor results in Tensorboard. We can run tensorboard by starting a zsh session inside the project app container, and launching the tensorboard server from there:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app_dev /bin/zsh\n",
    "> tensorboard --logdir=/home/devspace/project/data/hyperparameter_tuning/continued_trials/tensorboard --host=0.0.0.0\n",
    "```\n",
    "Then, in your browser, go to: `http://localhost:6006/`\n",
    "\n",
    "You should see something like the screenshot below.  The x-axis for all plots is epoch number. (Unfortunately, there is no good way to add axis labels in Tensorboard.)\n",
    "\n",
    "In this example we are in the middle of running trial #21. Trial #20 completed the default number of epochs per fold (100). Trial #19 only ran 20 epochs because it was pruned by the Optuna `MeadianPruner`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard_image](images/tensorboard_hyperparameter_tuning.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Select Final Hyperparameters\n",
    "When we are done tuning, we can view our best set of hyperparameters by examining the `Optuna.Study` object from our above tuning run(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best trial result is from trial # 20.\n",
      "\n",
      "The set of hyperparameters from this trial are:\n",
      "{'dropout': 0.029018875280141854,\n",
      " 'fc_act_name': 'Tanh',\n",
      " 'learning_rate': 0.0002784280532512521,\n",
      " 'log_batch_size': 5,\n",
      " 'log_fc_hidden_size': 4,\n",
      " 'log_lstm_hidden_size': 7,\n",
      " 'lstm_act_name': 'Tanh',\n",
      " 'optimizer_name': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "import lstm_adversarial_attack.resource_io as rio\n",
    "study = rio.ResourceImporter().import_pickle_to_object(\n",
    "    path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE\n",
    ")\n",
    "\n",
    "print(f\"The best trial result is from trial # {study.best_trial.number}.\\n\")\n",
    "print(\"The set of hyperparameters from this trial are:\")\n",
    "pprint.pprint(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Run K-Fold Cross Validation with \"Best\" Hyperparameters and Extended Training (More Epochs)\n",
    "In the above tuning runs, we only run 100 epochs per fold (in the interest of reducing compute requirements). Based on the validation loss and AUC curves, it appears that we could improve our predictive performance (i.e. decrease validation loss, and increase AUC) by training longer. We now run another round of Stratified K-fold cross-validation with our best set of parameters with a larger number of epochs.\n",
    "\n",
    "#### 6.7.1 Notes on our Method\n",
    "Some caveats about our methodology:\n",
    "* We are using \"flat\" cross-validation (as was done in previous studies on this dataset). This method computationally less expensive than nested cross-validation. Flat cross-validation has the potential to overestimate of model performance. In many cases the magnitude of overestimation is small. We also mitigate this effect by using a different set of (randomly generated) fold assignments than was used for hyperparameter tuning. \n",
    "* By selecting our hyperparameters based on the smaller number of epochs (100), we favor models that are faster to to train. It is possible that using a larger number of epochs in the tuning runs would have yielded a different (and better) set of \"best\" hyperparameters, but would also be computationally more expensive.\n",
    "\n",
    "\n",
    "#### 6.7.2 Instantiate a CrossValidatorDriver\n",
    "We use a CrossValidatorDriver object to run cross-validation with a single set of hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validator_driver as cvd\n",
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "\n",
    "cv_driver = cvd.CrossValidatorDriver.from_study_path(\n",
    "        device=cur_device,\n",
    "        dataset=dataset,\n",
    "        study_path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data members of `cv_driver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': <lstm_adversarial_attack.x19_mort_general_dataset.X19MGeneralDataset object at 0x7f274f5b4ca0>,\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'epochs_per_fold': 1000,\n",
      " 'eval_interval': 10,\n",
      " 'evals_per_checkpoint': 1,\n",
      " 'hyperparameters': X19LSTMHyperParameterSettings(log_lstm_hidden_size=7,\n",
      "                                                  lstm_act_name='Tanh',\n",
      "                                                  dropout=0.029018875280141854,\n",
      "                                                  log_fc_hidden_size=4,\n",
      "                                                  fc_act_name='Tanh',\n",
      "                                                  optimizer_name='Adam',\n",
      "                                                  learning_rate=0.0002784280532512521,\n",
      "                                                  log_batch_size=5),\n",
      " 'num_folds': 5}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cv_driver.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run 5-fold cross-validation using 1000 epochs per fold. We will evaluate performance (using a fold's validation set) and save a checkpoint once every 10 epochs. These settings are determined by the values of `CV_DRIVER_EPOCHS_PER_FOLD`, `CV_DRIVER_NUM_FOLDS`, `CV_DRIVER_EVAL_INTERVAL`, and `CV_DRIVER_EVALS_PER_CHECKPOINT` in `lstm_adversarial_attacker.config_settings`. The `.from_study_path()` class method we used to construct `cv_driver` extracts the best set of hyperparameters from `study_path` and passes them to the CrossValidationDriver constructor.\n",
    "\n",
    "#### 6.7.3 Run Cross-Validation\n",
    "We now call `cv_driver`'s `.run()` method to start the cross-validation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/checkpoints/fold_0\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/tensorboard\n",
      "\n",
      "\n",
      "fold_0, epoch_1, Loss: 0.5809\n",
      "fold_0, epoch_2, Loss: 0.5482\n",
      "fold_0, epoch_3, Loss: 0.5539\n",
      "fold_0, epoch_4, Loss: 0.5446\n",
      "fold_0, epoch_5, Loss: 0.5327\n",
      "fold_0, epoch_6, Loss: 0.5328\n",
      "fold_0, epoch_7, Loss: 0.5265\n",
      "fold_0, epoch_8, Loss: 0.5267\n",
      "fold_0, epoch_9, Loss: 0.5188\n",
      "fold_0, epoch_10, Loss: 0.5096\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5205\n",
      "Accuracy:\t0.7805\n",
      "AUC:\t\t0.8674\n",
      "Precision:\t0.8303\n",
      "Recall:\t\t0.7065\n",
      "F1:\t\t\t0.7634\n",
      "\n",
      "fold_0, epoch_11, Loss: 0.5153\n",
      "fold_0, epoch_12, Loss: 0.5072\n",
      "fold_0, epoch_13, Loss: 0.5015\n",
      "fold_0, epoch_14, Loss: 0.4993\n",
      "fold_0, epoch_15, Loss: 0.4998\n",
      "fold_0, epoch_16, Loss: 0.4964\n",
      "fold_0, epoch_17, Loss: 0.4916\n",
      "fold_0, epoch_18, Loss: 0.4931\n",
      "fold_0, epoch_19, Loss: 0.4902\n",
      "fold_0, epoch_20, Loss: 0.4894\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4866\n",
      "Accuracy:\t0.8191\n",
      "AUC:\t\t0.8873\n",
      "Precision:\t0.8330\n",
      "Recall:\t\t0.7981\n",
      "F1:\t\t\t0.8152\n",
      "\n",
      "fold_0, epoch_21, Loss: 0.4838\n",
      "fold_0, epoch_22, Loss: 0.4810\n",
      "fold_0, epoch_23, Loss: 0.4801\n",
      "fold_0, epoch_24, Loss: 0.4757\n",
      "fold_0, epoch_25, Loss: 0.4733\n",
      "fold_0, epoch_26, Loss: 0.4756\n",
      "fold_0, epoch_27, Loss: 0.4746\n",
      "fold_0, epoch_28, Loss: 0.4668\n",
      "fold_0, epoch_29, Loss: 0.4681\n",
      "fold_0, epoch_30, Loss: 0.4610\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4609\n",
      "Accuracy:\t0.8471\n",
      "AUC:\t\t0.8979\n",
      "Precision:\t0.8469\n",
      "Recall:\t\t0.8491\n",
      "F1:\t\t\t0.8480\n",
      "\n",
      "fold_0, epoch_31, Loss: 0.4637\n",
      "fold_0, epoch_32, Loss: 0.4592\n",
      "fold_0, epoch_33, Loss: 0.4553\n",
      "fold_0, epoch_34, Loss: 0.4592\n",
      "fold_0, epoch_35, Loss: 0.4540\n",
      "fold_0, epoch_36, Loss: 0.4542\n",
      "fold_0, epoch_37, Loss: 0.4504\n",
      "fold_0, epoch_38, Loss: 0.4461\n",
      "fold_0, epoch_39, Loss: 0.4452\n",
      "fold_0, epoch_40, Loss: 0.4447\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4523\n",
      "Accuracy:\t0.8586\n",
      "AUC:\t\t0.8961\n",
      "Precision:\t0.8614\n",
      "Recall:\t\t0.8558\n",
      "F1:\t\t\t0.8586\n",
      "\n",
      "fold_0, epoch_41, Loss: 0.4424\n",
      "fold_0, epoch_42, Loss: 0.4458\n",
      "fold_0, epoch_43, Loss: 0.4469\n",
      "fold_0, epoch_44, Loss: 0.4457\n",
      "fold_0, epoch_45, Loss: 0.4430\n",
      "fold_0, epoch_46, Loss: 0.4381\n",
      "fold_0, epoch_47, Loss: 0.4354\n",
      "fold_0, epoch_48, Loss: 0.4358\n",
      "fold_0, epoch_49, Loss: 0.4350\n",
      "fold_0, epoch_50, Loss: 0.4323\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4316\n",
      "Accuracy:\t0.8795\n",
      "AUC:\t\t0.9081\n",
      "Precision:\t0.8669\n",
      "Recall:\t\t0.8973\n",
      "F1:\t\t\t0.8818\n",
      "\n",
      "fold_0, epoch_51, Loss: 0.4334\n",
      "fold_0, epoch_52, Loss: 0.4268\n",
      "fold_0, epoch_53, Loss: 0.4315\n",
      "fold_0, epoch_54, Loss: 0.4258\n",
      "fold_0, epoch_55, Loss: 0.4247\n",
      "fold_0, epoch_56, Loss: 0.4269\n",
      "fold_0, epoch_57, Loss: 0.4245\n",
      "fold_0, epoch_58, Loss: 0.4269\n",
      "fold_0, epoch_59, Loss: 0.4233\n",
      "fold_0, epoch_60, Loss: 0.4263\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4313\n",
      "Accuracy:\t0.8796\n",
      "AUC:\t\t0.9146\n",
      "Precision:\t0.8479\n",
      "Recall:\t\t0.9251\n",
      "F1:\t\t\t0.8848\n",
      "\n",
      "fold_0, epoch_61, Loss: 0.4313\n",
      "fold_0, epoch_62, Loss: 0.4257\n",
      "fold_0, epoch_63, Loss: 0.4201\n",
      "fold_0, epoch_64, Loss: 0.4195\n",
      "fold_0, epoch_65, Loss: 0.4172\n",
      "fold_0, epoch_66, Loss: 0.4188\n",
      "fold_0, epoch_67, Loss: 0.4216\n",
      "fold_0, epoch_68, Loss: 0.4246\n",
      "fold_0, epoch_69, Loss: 0.4151\n",
      "fold_0, epoch_70, Loss: 0.4190\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4123\n",
      "Accuracy:\t0.9001\n",
      "AUC:\t\t0.9161\n",
      "Precision:\t0.8924\n",
      "Recall:\t\t0.9102\n",
      "F1:\t\t\t0.9012\n",
      "\n",
      "fold_0, epoch_71, Loss: 0.4176\n",
      "fold_0, epoch_72, Loss: 0.4240\n",
      "fold_0, epoch_73, Loss: 0.4142\n",
      "fold_0, epoch_74, Loss: 0.4095\n",
      "fold_0, epoch_75, Loss: 0.4112\n",
      "fold_0, epoch_76, Loss: 0.4129\n",
      "fold_0, epoch_77, Loss: 0.4150\n",
      "fold_0, epoch_78, Loss: 0.4126\n",
      "fold_0, epoch_79, Loss: 0.4147\n",
      "fold_0, epoch_80, Loss: 0.4119\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4083\n",
      "Accuracy:\t0.9045\n",
      "AUC:\t\t0.9185\n",
      "Precision:\t0.8905\n",
      "Recall:\t\t0.9222\n",
      "F1:\t\t\t0.9060\n",
      "\n",
      "fold_0, epoch_81, Loss: 0.4057\n",
      "fold_0, epoch_82, Loss: 0.4133\n",
      "fold_0, epoch_83, Loss: 0.4072\n",
      "fold_0, epoch_84, Loss: 0.4103\n",
      "fold_0, epoch_85, Loss: 0.4063\n",
      "fold_0, epoch_86, Loss: 0.4128\n",
      "fold_0, epoch_87, Loss: 0.4065\n",
      "fold_0, epoch_88, Loss: 0.4065\n",
      "fold_0, epoch_89, Loss: 0.4075\n",
      "fold_0, epoch_90, Loss: 0.4069\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3986\n",
      "Accuracy:\t0.9145\n",
      "AUC:\t\t0.9258\n",
      "Precision:\t0.9139\n",
      "Recall:\t\t0.9145\n",
      "F1:\t\t\t0.9142\n",
      "\n",
      "fold_0, epoch_91, Loss: 0.4039\n",
      "fold_0, epoch_92, Loss: 0.4001\n",
      "fold_0, epoch_93, Loss: 0.4044\n",
      "fold_0, epoch_94, Loss: 0.3971\n",
      "fold_0, epoch_95, Loss: 0.4060\n",
      "fold_0, epoch_96, Loss: 0.4029\n",
      "fold_0, epoch_97, Loss: 0.3994\n",
      "fold_0, epoch_98, Loss: 0.4020\n",
      "fold_0, epoch_99, Loss: 0.4002\n",
      "fold_0, epoch_100, Loss: 0.4027\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3936\n",
      "Accuracy:\t0.9191\n",
      "AUC:\t\t0.9293\n",
      "Precision:\t0.9138\n",
      "Recall:\t\t0.9270\n",
      "F1:\t\t\t0.9203\n",
      "\n",
      "fold_0, epoch_101, Loss: 0.3947\n",
      "fold_0, epoch_102, Loss: 0.4018\n",
      "fold_0, epoch_103, Loss: 0.3999\n",
      "fold_0, epoch_104, Loss: 0.3948\n",
      "fold_0, epoch_105, Loss: 0.3986\n",
      "fold_0, epoch_106, Loss: 0.4020\n",
      "fold_0, epoch_107, Loss: 0.3986\n",
      "fold_0, epoch_108, Loss: 0.3984\n",
      "fold_0, epoch_109, Loss: 0.3902\n",
      "fold_0, epoch_110, Loss: 0.3937\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3961\n",
      "Accuracy:\t0.9163\n",
      "AUC:\t\t0.9286\n",
      "Precision:\t0.9248\n",
      "Recall:\t\t0.9047\n",
      "F1:\t\t\t0.9147\n",
      "\n",
      "fold_0, epoch_111, Loss: 0.3932\n",
      "fold_0, epoch_112, Loss: 0.3950\n",
      "fold_0, epoch_113, Loss: 0.3934\n",
      "fold_0, epoch_114, Loss: 0.3952\n",
      "fold_0, epoch_115, Loss: 0.3945\n",
      "fold_0, epoch_116, Loss: 0.3935\n",
      "fold_0, epoch_117, Loss: 0.4005\n",
      "fold_0, epoch_118, Loss: 0.4016\n",
      "fold_0, epoch_119, Loss: 0.3972\n",
      "fold_0, epoch_120, Loss: 0.3929\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3929\n",
      "Accuracy:\t0.9202\n",
      "AUC:\t\t0.9282\n",
      "Precision:\t0.9124\n",
      "Recall:\t\t0.9282\n",
      "F1:\t\t\t0.9202\n",
      "\n",
      "fold_0, epoch_121, Loss: 0.3953\n",
      "fold_0, epoch_122, Loss: 0.3978\n",
      "fold_0, epoch_123, Loss: 0.3958\n",
      "fold_0, epoch_124, Loss: 0.3899\n",
      "fold_0, epoch_125, Loss: 0.3916\n",
      "fold_0, epoch_126, Loss: 0.3907\n",
      "fold_0, epoch_127, Loss: 0.3912\n",
      "fold_0, epoch_128, Loss: 0.3909\n",
      "fold_0, epoch_129, Loss: 0.3949\n",
      "fold_0, epoch_130, Loss: 0.3897\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3897\n",
      "Accuracy:\t0.9234\n",
      "AUC:\t\t0.9319\n",
      "Precision:\t0.9309\n",
      "Recall:\t\t0.9146\n",
      "F1:\t\t\t0.9227\n",
      "\n",
      "fold_0, epoch_131, Loss: 0.3905\n",
      "fold_0, epoch_132, Loss: 0.3905\n",
      "fold_0, epoch_133, Loss: 0.3872\n",
      "fold_0, epoch_134, Loss: 0.3872\n",
      "fold_0, epoch_135, Loss: 0.3911\n",
      "fold_0, epoch_136, Loss: 0.3844\n",
      "fold_0, epoch_137, Loss: 0.3866\n",
      "fold_0, epoch_138, Loss: 0.3872\n",
      "fold_0, epoch_139, Loss: 0.3910\n",
      "fold_0, epoch_140, Loss: 0.3827\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3838\n",
      "Accuracy:\t0.9293\n",
      "AUC:\t\t0.9346\n",
      "Precision:\t0.9376\n",
      "Recall:\t\t0.9192\n",
      "F1:\t\t\t0.9283\n",
      "\n",
      "fold_0, epoch_141, Loss: 0.3882\n",
      "fold_0, epoch_142, Loss: 0.3850\n",
      "fold_0, epoch_143, Loss: 0.3966\n",
      "fold_0, epoch_144, Loss: 0.3824\n",
      "fold_0, epoch_145, Loss: 0.3873\n",
      "fold_0, epoch_146, Loss: 0.3943\n",
      "fold_0, epoch_147, Loss: 0.3865\n",
      "fold_0, epoch_148, Loss: 0.3837\n",
      "fold_0, epoch_149, Loss: 0.3854\n",
      "fold_0, epoch_150, Loss: 0.3877\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3836\n",
      "Accuracy:\t0.9292\n",
      "AUC:\t\t0.9357\n",
      "Precision:\t0.9298\n",
      "Recall:\t\t0.9276\n",
      "F1:\t\t\t0.9287\n",
      "\n",
      "fold_0, epoch_151, Loss: 0.3845\n",
      "fold_0, epoch_152, Loss: 0.3874\n",
      "fold_0, epoch_153, Loss: 0.3865\n",
      "fold_0, epoch_154, Loss: 0.3814\n",
      "fold_0, epoch_155, Loss: 0.3875\n",
      "fold_0, epoch_156, Loss: 0.3877\n",
      "fold_0, epoch_157, Loss: 0.3829\n",
      "fold_0, epoch_158, Loss: 0.3838\n",
      "fold_0, epoch_159, Loss: 0.3798\n",
      "fold_0, epoch_160, Loss: 0.3812\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3831\n",
      "Accuracy:\t0.9297\n",
      "AUC:\t\t0.9372\n",
      "Precision:\t0.9315\n",
      "Recall:\t\t0.9274\n",
      "F1:\t\t\t0.9294\n",
      "\n",
      "fold_0, epoch_161, Loss: 0.3829\n",
      "fold_0, epoch_162, Loss: 0.3798\n",
      "fold_0, epoch_163, Loss: 0.3814\n",
      "fold_0, epoch_164, Loss: 0.3828\n",
      "fold_0, epoch_165, Loss: 0.3793\n",
      "fold_0, epoch_166, Loss: 0.3828\n",
      "fold_0, epoch_167, Loss: 0.3821\n",
      "fold_0, epoch_168, Loss: 0.3816\n",
      "fold_0, epoch_169, Loss: 0.3832\n",
      "fold_0, epoch_170, Loss: 0.3830\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3881\n",
      "Accuracy:\t0.9247\n",
      "AUC:\t\t0.9348\n",
      "Precision:\t0.9285\n",
      "Recall:\t\t0.9210\n",
      "F1:\t\t\t0.9247\n",
      "\n",
      "fold_0, epoch_171, Loss: 0.3816\n",
      "fold_0, epoch_172, Loss: 0.3810\n",
      "fold_0, epoch_173, Loss: 0.3759\n",
      "fold_0, epoch_174, Loss: 0.3786\n",
      "fold_0, epoch_175, Loss: 0.3831\n",
      "fold_0, epoch_176, Loss: 0.3820\n",
      "fold_0, epoch_177, Loss: 0.3795\n",
      "fold_0, epoch_178, Loss: 0.3808\n",
      "fold_0, epoch_179, Loss: 0.3882\n",
      "fold_0, epoch_180, Loss: 0.3854\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3826\n",
      "Accuracy:\t0.9301\n",
      "AUC:\t\t0.9378\n",
      "Precision:\t0.9408\n",
      "Recall:\t\t0.9170\n",
      "F1:\t\t\t0.9287\n",
      "\n",
      "fold_0, epoch_181, Loss: 0.3787\n",
      "fold_0, epoch_182, Loss: 0.3830\n",
      "fold_0, epoch_183, Loss: 0.3745\n",
      "fold_0, epoch_184, Loss: 0.3809\n",
      "fold_0, epoch_185, Loss: 0.3845\n",
      "fold_0, epoch_186, Loss: 0.3811\n",
      "fold_0, epoch_187, Loss: 0.3805\n",
      "fold_0, epoch_188, Loss: 0.3805\n",
      "fold_0, epoch_189, Loss: 0.3810\n",
      "fold_0, epoch_190, Loss: 0.3869\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3811\n",
      "Accuracy:\t0.9318\n",
      "AUC:\t\t0.9396\n",
      "Precision:\t0.9505\n",
      "Recall:\t\t0.9108\n",
      "F1:\t\t\t0.9302\n",
      "\n",
      "fold_0, epoch_191, Loss: 0.3800\n",
      "fold_0, epoch_192, Loss: 0.3789\n",
      "fold_0, epoch_193, Loss: 0.3747\n",
      "fold_0, epoch_194, Loss: 0.3796\n",
      "fold_0, epoch_195, Loss: 0.3808\n",
      "fold_0, epoch_196, Loss: 0.3791\n",
      "fold_0, epoch_197, Loss: 0.3779\n",
      "fold_0, epoch_198, Loss: 0.3742\n",
      "fold_0, epoch_199, Loss: 0.3750\n",
      "fold_0, epoch_200, Loss: 0.3794\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3739\n",
      "Accuracy:\t0.9390\n",
      "AUC:\t\t0.9426\n",
      "Precision:\t0.9447\n",
      "Recall:\t\t0.9317\n",
      "F1:\t\t\t0.9381\n",
      "\n",
      "fold_0, epoch_201, Loss: 0.3750\n",
      "fold_0, epoch_202, Loss: 0.3748\n",
      "fold_0, epoch_203, Loss: 0.3767\n",
      "fold_0, epoch_204, Loss: 0.3755\n",
      "fold_0, epoch_205, Loss: 0.3761\n",
      "fold_0, epoch_206, Loss: 0.3720\n",
      "fold_0, epoch_207, Loss: 0.3760\n",
      "fold_0, epoch_208, Loss: 0.3774\n",
      "fold_0, epoch_209, Loss: 0.3733\n",
      "fold_0, epoch_210, Loss: 0.3734\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3703\n",
      "Accuracy:\t0.9427\n",
      "AUC:\t\t0.9468\n",
      "Precision:\t0.9571\n",
      "Recall:\t\t0.9278\n",
      "F1:\t\t\t0.9422\n",
      "\n",
      "fold_0, epoch_211, Loss: 0.3763\n",
      "fold_0, epoch_212, Loss: 0.3790\n",
      "fold_0, epoch_213, Loss: 0.3778\n",
      "fold_0, epoch_214, Loss: 0.3743\n",
      "fold_0, epoch_215, Loss: 0.3697\n",
      "fold_0, epoch_216, Loss: 0.3725\n",
      "fold_0, epoch_217, Loss: 0.3772\n",
      "fold_0, epoch_218, Loss: 0.3735\n",
      "fold_0, epoch_219, Loss: 0.3857\n",
      "fold_0, epoch_220, Loss: 0.3761\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3710\n",
      "Accuracy:\t0.9423\n",
      "AUC:\t\t0.9448\n",
      "Precision:\t0.9507\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9424\n",
      "\n",
      "fold_0, epoch_221, Loss: 0.3758\n",
      "fold_0, epoch_222, Loss: 0.3782\n",
      "fold_0, epoch_223, Loss: 0.3724\n",
      "fold_0, epoch_224, Loss: 0.3753\n",
      "fold_0, epoch_225, Loss: 0.3736\n",
      "fold_0, epoch_226, Loss: 0.3766\n",
      "fold_0, epoch_227, Loss: 0.3774\n",
      "fold_0, epoch_228, Loss: 0.3740\n",
      "fold_0, epoch_229, Loss: 0.3710\n",
      "fold_0, epoch_230, Loss: 0.3732\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3754\n",
      "Accuracy:\t0.9373\n",
      "AUC:\t\t0.9414\n",
      "Precision:\t0.9458\n",
      "Recall:\t\t0.9288\n",
      "F1:\t\t\t0.9372\n",
      "\n",
      "fold_0, epoch_231, Loss: 0.3698\n",
      "fold_0, epoch_232, Loss: 0.3724\n",
      "fold_0, epoch_233, Loss: 0.3717\n",
      "fold_0, epoch_234, Loss: 0.3734\n",
      "fold_0, epoch_235, Loss: 0.3742\n",
      "fold_0, epoch_236, Loss: 0.3771\n",
      "fold_0, epoch_237, Loss: 0.3769\n",
      "fold_0, epoch_238, Loss: 0.3784\n",
      "fold_0, epoch_239, Loss: 0.3707\n",
      "fold_0, epoch_240, Loss: 0.3688\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3678\n",
      "Accuracy:\t0.9451\n",
      "AUC:\t\t0.9468\n",
      "Precision:\t0.9543\n",
      "Recall:\t\t0.9348\n",
      "F1:\t\t\t0.9444\n",
      "\n",
      "fold_0, epoch_241, Loss: 0.3751\n",
      "fold_0, epoch_242, Loss: 0.3729\n",
      "fold_0, epoch_243, Loss: 0.3695\n",
      "fold_0, epoch_244, Loss: 0.3770\n",
      "fold_0, epoch_245, Loss: 0.3716\n",
      "fold_0, epoch_246, Loss: 0.3707\n",
      "fold_0, epoch_247, Loss: 0.3712\n",
      "fold_0, epoch_248, Loss: 0.3710\n",
      "fold_0, epoch_249, Loss: 0.3687\n",
      "fold_0, epoch_250, Loss: 0.3733\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3695\n",
      "Accuracy:\t0.9435\n",
      "AUC:\t\t0.9494\n",
      "Precision:\t0.9554\n",
      "Recall:\t\t0.9302\n",
      "F1:\t\t\t0.9426\n",
      "\n",
      "fold_0, epoch_251, Loss: 0.3659\n",
      "fold_0, epoch_252, Loss: 0.3690\n",
      "fold_0, epoch_253, Loss: 0.3687\n",
      "fold_0, epoch_254, Loss: 0.3695\n",
      "fold_0, epoch_255, Loss: 0.3665\n",
      "fold_0, epoch_256, Loss: 0.3739\n",
      "fold_0, epoch_257, Loss: 0.3695\n",
      "fold_0, epoch_258, Loss: 0.3722\n",
      "fold_0, epoch_259, Loss: 0.3685\n",
      "fold_0, epoch_260, Loss: 0.3699\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3693\n",
      "Accuracy:\t0.9436\n",
      "AUC:\t\t0.9472\n",
      "Precision:\t0.9618\n",
      "Recall:\t\t0.9247\n",
      "F1:\t\t\t0.9429\n",
      "\n",
      "fold_0, epoch_261, Loss: 0.3747\n",
      "fold_0, epoch_262, Loss: 0.3692\n",
      "fold_0, epoch_263, Loss: 0.3635\n",
      "fold_0, epoch_264, Loss: 0.3695\n",
      "fold_0, epoch_265, Loss: 0.3686\n",
      "fold_0, epoch_266, Loss: 0.3710\n",
      "fold_0, epoch_267, Loss: 0.3683\n",
      "fold_0, epoch_268, Loss: 0.3729\n",
      "fold_0, epoch_269, Loss: 0.3681\n",
      "fold_0, epoch_270, Loss: 0.3672\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3684\n",
      "Accuracy:\t0.9443\n",
      "AUC:\t\t0.9493\n",
      "Precision:\t0.9543\n",
      "Recall:\t\t0.9335\n",
      "F1:\t\t\t0.9438\n",
      "\n",
      "fold_0, epoch_271, Loss: 0.3678\n",
      "fold_0, epoch_272, Loss: 0.3685\n",
      "fold_0, epoch_273, Loss: 0.3729\n",
      "fold_0, epoch_274, Loss: 0.3680\n",
      "fold_0, epoch_275, Loss: 0.3686\n",
      "fold_0, epoch_276, Loss: 0.3740\n",
      "fold_0, epoch_277, Loss: 0.3702\n",
      "fold_0, epoch_278, Loss: 0.3708\n",
      "fold_0, epoch_279, Loss: 0.3694\n",
      "fold_0, epoch_280, Loss: 0.3690\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3666\n",
      "Accuracy:\t0.9463\n",
      "AUC:\t\t0.9483\n",
      "Precision:\t0.9579\n",
      "Recall:\t\t0.9338\n",
      "F1:\t\t\t0.9457\n",
      "\n",
      "fold_0, epoch_281, Loss: 0.3666\n",
      "fold_0, epoch_282, Loss: 0.3780\n",
      "fold_0, epoch_283, Loss: 0.3664\n",
      "fold_0, epoch_284, Loss: 0.3704\n",
      "fold_0, epoch_285, Loss: 0.3706\n",
      "fold_0, epoch_286, Loss: 0.3741\n",
      "fold_0, epoch_287, Loss: 0.3682\n",
      "fold_0, epoch_288, Loss: 0.3738\n",
      "fold_0, epoch_289, Loss: 0.3668\n",
      "fold_0, epoch_290, Loss: 0.3656\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3626\n",
      "Accuracy:\t0.9505\n",
      "AUC:\t\t0.9528\n",
      "Precision:\t0.9618\n",
      "Recall:\t\t0.9378\n",
      "F1:\t\t\t0.9496\n",
      "\n",
      "fold_0, epoch_291, Loss: 0.3679\n",
      "fold_0, epoch_292, Loss: 0.3664\n",
      "fold_0, epoch_293, Loss: 0.3662\n",
      "fold_0, epoch_294, Loss: 0.3666\n",
      "fold_0, epoch_295, Loss: 0.3712\n",
      "fold_0, epoch_296, Loss: 0.3658\n",
      "fold_0, epoch_297, Loss: 0.3637\n",
      "fold_0, epoch_298, Loss: 0.3661\n",
      "fold_0, epoch_299, Loss: 0.3678\n",
      "fold_0, epoch_300, Loss: 0.3672\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3673\n",
      "Accuracy:\t0.9454\n",
      "AUC:\t\t0.9486\n",
      "Precision:\t0.9550\n",
      "Recall:\t\t0.9348\n",
      "F1:\t\t\t0.9448\n",
      "\n",
      "fold_0, epoch_301, Loss: 0.3674\n",
      "fold_0, epoch_302, Loss: 0.3675\n",
      "fold_0, epoch_303, Loss: 0.3663\n",
      "fold_0, epoch_304, Loss: 0.3641\n",
      "fold_0, epoch_305, Loss: 0.3652\n",
      "fold_0, epoch_306, Loss: 0.3681\n",
      "fold_0, epoch_307, Loss: 0.3667\n",
      "fold_0, epoch_308, Loss: 0.3674\n",
      "fold_0, epoch_309, Loss: 0.3661\n",
      "fold_0, epoch_310, Loss: 0.3675\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3671\n",
      "Accuracy:\t0.9461\n",
      "AUC:\t\t0.9493\n",
      "Precision:\t0.9615\n",
      "Recall:\t\t0.9299\n",
      "F1:\t\t\t0.9454\n",
      "\n",
      "fold_0, epoch_311, Loss: 0.3652\n",
      "fold_0, epoch_312, Loss: 0.3648\n",
      "fold_0, epoch_313, Loss: 0.3676\n",
      "fold_0, epoch_314, Loss: 0.3653\n",
      "fold_0, epoch_315, Loss: 0.3666\n",
      "fold_0, epoch_316, Loss: 0.3641\n",
      "fold_0, epoch_317, Loss: 0.3654\n",
      "fold_0, epoch_318, Loss: 0.3701\n",
      "fold_0, epoch_319, Loss: 0.3622\n",
      "fold_0, epoch_320, Loss: 0.3668\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3670\n",
      "Accuracy:\t0.9457\n",
      "AUC:\t\t0.9493\n",
      "Precision:\t0.9562\n",
      "Recall:\t\t0.9348\n",
      "F1:\t\t\t0.9454\n",
      "\n",
      "fold_0, epoch_321, Loss: 0.3688\n",
      "fold_0, epoch_322, Loss: 0.3653\n",
      "fold_0, epoch_323, Loss: 0.3667\n",
      "fold_0, epoch_324, Loss: 0.3637\n",
      "fold_0, epoch_325, Loss: 0.3625\n",
      "fold_0, epoch_326, Loss: 0.3672\n",
      "fold_0, epoch_327, Loss: 0.3689\n",
      "fold_0, epoch_328, Loss: 0.3646\n",
      "fold_0, epoch_329, Loss: 0.3622\n",
      "fold_0, epoch_330, Loss: 0.3663\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3681\n",
      "Accuracy:\t0.9446\n",
      "AUC:\t\t0.9490\n",
      "Precision:\t0.9526\n",
      "Recall:\t\t0.9353\n",
      "F1:\t\t\t0.9438\n",
      "\n",
      "fold_0, epoch_331, Loss: 0.3650\n",
      "fold_0, epoch_332, Loss: 0.3656\n",
      "fold_0, epoch_333, Loss: 0.3601\n",
      "fold_0, epoch_334, Loss: 0.3683\n",
      "fold_0, epoch_335, Loss: 0.3610\n",
      "fold_0, epoch_336, Loss: 0.3668\n",
      "fold_0, epoch_337, Loss: 0.3670\n",
      "fold_0, epoch_338, Loss: 0.3656\n",
      "fold_0, epoch_339, Loss: 0.3643\n",
      "fold_0, epoch_340, Loss: 0.3652\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3616\n",
      "Accuracy:\t0.9518\n",
      "AUC:\t\t0.9513\n",
      "Precision:\t0.9682\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9510\n",
      "\n",
      "fold_0, epoch_341, Loss: 0.3606\n",
      "fold_0, epoch_342, Loss: 0.3617\n",
      "fold_0, epoch_343, Loss: 0.3604\n",
      "fold_0, epoch_344, Loss: 0.3609\n",
      "fold_0, epoch_345, Loss: 0.3652\n",
      "fold_0, epoch_346, Loss: 0.3641\n",
      "fold_0, epoch_347, Loss: 0.3640\n",
      "fold_0, epoch_348, Loss: 0.3631\n",
      "fold_0, epoch_349, Loss: 0.3629\n",
      "fold_0, epoch_350, Loss: 0.3616\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3616\n",
      "Accuracy:\t0.9516\n",
      "AUC:\t\t0.9527\n",
      "Precision:\t0.9700\n",
      "Recall:\t\t0.9322\n",
      "F1:\t\t\t0.9507\n",
      "\n",
      "fold_0, epoch_351, Loss: 0.3606\n",
      "fold_0, epoch_352, Loss: 0.3634\n",
      "fold_0, epoch_353, Loss: 0.3629\n",
      "fold_0, epoch_354, Loss: 0.3697\n",
      "fold_0, epoch_355, Loss: 0.3609\n",
      "fold_0, epoch_356, Loss: 0.3599\n",
      "fold_0, epoch_357, Loss: 0.3619\n",
      "fold_0, epoch_358, Loss: 0.3614\n",
      "fold_0, epoch_359, Loss: 0.3637\n",
      "fold_0, epoch_360, Loss: 0.3645\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3633\n",
      "Accuracy:\t0.9496\n",
      "AUC:\t\t0.9533\n",
      "Precision:\t0.9642\n",
      "Recall:\t\t0.9340\n",
      "F1:\t\t\t0.9488\n",
      "\n",
      "fold_0, epoch_361, Loss: 0.3617\n",
      "fold_0, epoch_362, Loss: 0.3640\n",
      "fold_0, epoch_363, Loss: 0.3615\n",
      "fold_0, epoch_364, Loss: 0.3610\n",
      "fold_0, epoch_365, Loss: 0.3589\n",
      "fold_0, epoch_366, Loss: 0.3626\n",
      "fold_0, epoch_367, Loss: 0.3604\n",
      "fold_0, epoch_368, Loss: 0.3597\n",
      "fold_0, epoch_369, Loss: 0.3592\n",
      "fold_0, epoch_370, Loss: 0.3610\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3608\n",
      "Accuracy:\t0.9522\n",
      "AUC:\t\t0.9544\n",
      "Precision:\t0.9639\n",
      "Recall:\t\t0.9392\n",
      "F1:\t\t\t0.9514\n",
      "\n",
      "fold_0, epoch_371, Loss: 0.3621\n",
      "fold_0, epoch_372, Loss: 0.3599\n",
      "fold_0, epoch_373, Loss: 0.3615\n",
      "fold_0, epoch_374, Loss: 0.3584\n",
      "fold_0, epoch_375, Loss: 0.3631\n",
      "fold_0, epoch_376, Loss: 0.3615\n",
      "fold_0, epoch_377, Loss: 0.3620\n",
      "fold_0, epoch_378, Loss: 0.3608\n",
      "fold_0, epoch_379, Loss: 0.3595\n",
      "fold_0, epoch_380, Loss: 0.3628\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3571\n",
      "Accuracy:\t0.9562\n",
      "AUC:\t\t0.9529\n",
      "Precision:\t0.9744\n",
      "Recall:\t\t0.9373\n",
      "F1:\t\t\t0.9555\n",
      "\n",
      "fold_0, epoch_381, Loss: 0.3626\n",
      "fold_0, epoch_382, Loss: 0.3630\n",
      "fold_0, epoch_383, Loss: 0.3603\n",
      "fold_0, epoch_384, Loss: 0.3651\n",
      "fold_0, epoch_385, Loss: 0.3586\n",
      "fold_0, epoch_386, Loss: 0.3612\n",
      "fold_0, epoch_387, Loss: 0.3615\n",
      "fold_0, epoch_388, Loss: 0.3627\n",
      "fold_0, epoch_389, Loss: 0.3624\n",
      "fold_0, epoch_390, Loss: 0.3590\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3634\n",
      "Accuracy:\t0.9497\n",
      "AUC:\t\t0.9506\n",
      "Precision:\t0.9685\n",
      "Recall:\t\t0.9291\n",
      "F1:\t\t\t0.9484\n",
      "\n",
      "fold_0, epoch_391, Loss: 0.3567\n",
      "fold_0, epoch_392, Loss: 0.3622\n",
      "fold_0, epoch_393, Loss: 0.3602\n",
      "fold_0, epoch_394, Loss: 0.3683\n",
      "fold_0, epoch_395, Loss: 0.3608\n",
      "fold_0, epoch_396, Loss: 0.3592\n",
      "fold_0, epoch_397, Loss: 0.3573\n",
      "fold_0, epoch_398, Loss: 0.3620\n",
      "fold_0, epoch_399, Loss: 0.3614\n",
      "fold_0, epoch_400, Loss: 0.3603\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3603\n",
      "Accuracy:\t0.9529\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9701\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9519\n",
      "\n",
      "fold_0, epoch_401, Loss: 0.3605\n",
      "fold_0, epoch_402, Loss: 0.3614\n",
      "fold_0, epoch_403, Loss: 0.3618\n",
      "fold_0, epoch_404, Loss: 0.3605\n",
      "fold_0, epoch_405, Loss: 0.3589\n",
      "fold_0, epoch_406, Loss: 0.3578\n",
      "fold_0, epoch_407, Loss: 0.3574\n",
      "fold_0, epoch_408, Loss: 0.3645\n",
      "fold_0, epoch_409, Loss: 0.3609\n",
      "fold_0, epoch_410, Loss: 0.3593\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3579\n",
      "Accuracy:\t0.9552\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9695\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9543\n",
      "\n",
      "fold_0, epoch_411, Loss: 0.3589\n",
      "fold_0, epoch_412, Loss: 0.3582\n",
      "fold_0, epoch_413, Loss: 0.3570\n",
      "fold_0, epoch_414, Loss: 0.3570\n",
      "fold_0, epoch_415, Loss: 0.3592\n",
      "fold_0, epoch_416, Loss: 0.3578\n",
      "fold_0, epoch_417, Loss: 0.3686\n",
      "fold_0, epoch_418, Loss: 0.3641\n",
      "fold_0, epoch_419, Loss: 0.3566\n",
      "fold_0, epoch_420, Loss: 0.3618\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3589\n",
      "Accuracy:\t0.9544\n",
      "AUC:\t\t0.9547\n",
      "Precision:\t0.9696\n",
      "Recall:\t\t0.9374\n",
      "F1:\t\t\t0.9532\n",
      "\n",
      "fold_0, epoch_421, Loss: 0.3595\n",
      "fold_0, epoch_422, Loss: 0.3609\n",
      "fold_0, epoch_423, Loss: 0.3558\n",
      "fold_0, epoch_424, Loss: 0.3637\n",
      "fold_0, epoch_425, Loss: 0.3588\n",
      "fold_0, epoch_426, Loss: 0.3570\n",
      "fold_0, epoch_427, Loss: 0.3599\n",
      "fold_0, epoch_428, Loss: 0.3577\n",
      "fold_0, epoch_429, Loss: 0.3602\n",
      "fold_0, epoch_430, Loss: 0.3650\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3592\n",
      "Accuracy:\t0.9539\n",
      "AUC:\t\t0.9535\n",
      "Precision:\t0.9714\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9525\n",
      "\n",
      "fold_0, epoch_431, Loss: 0.3645\n",
      "fold_0, epoch_432, Loss: 0.3567\n",
      "fold_0, epoch_433, Loss: 0.3555\n",
      "fold_0, epoch_434, Loss: 0.3564\n",
      "fold_0, epoch_435, Loss: 0.3574\n",
      "fold_0, epoch_436, Loss: 0.3609\n",
      "fold_0, epoch_437, Loss: 0.3594\n",
      "fold_0, epoch_438, Loss: 0.3596\n",
      "fold_0, epoch_439, Loss: 0.3586\n",
      "fold_0, epoch_440, Loss: 0.3610\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3619\n",
      "Accuracy:\t0.9513\n",
      "AUC:\t\t0.9534\n",
      "Precision:\t0.9769\n",
      "Recall:\t\t0.9242\n",
      "F1:\t\t\t0.9498\n",
      "\n",
      "fold_0, epoch_441, Loss: 0.3639\n",
      "fold_0, epoch_442, Loss: 0.3599\n",
      "fold_0, epoch_443, Loss: 0.3548\n",
      "fold_0, epoch_444, Loss: 0.3591\n",
      "fold_0, epoch_445, Loss: 0.3558\n",
      "fold_0, epoch_446, Loss: 0.3596\n",
      "fold_0, epoch_447, Loss: 0.3568\n",
      "fold_0, epoch_448, Loss: 0.3584\n",
      "fold_0, epoch_449, Loss: 0.3592\n",
      "fold_0, epoch_450, Loss: 0.3567\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3555\n",
      "Accuracy:\t0.9575\n",
      "AUC:\t\t0.9564\n",
      "Precision:\t0.9739\n",
      "Recall:\t\t0.9399\n",
      "F1:\t\t\t0.9566\n",
      "\n",
      "fold_0, epoch_451, Loss: 0.3564\n",
      "fold_0, epoch_452, Loss: 0.3572\n",
      "fold_0, epoch_453, Loss: 0.3582\n",
      "fold_0, epoch_454, Loss: 0.3574\n",
      "fold_0, epoch_455, Loss: 0.3596\n",
      "fold_0, epoch_456, Loss: 0.3585\n",
      "fold_0, epoch_457, Loss: 0.3580\n",
      "fold_0, epoch_458, Loss: 0.3574\n",
      "fold_0, epoch_459, Loss: 0.3552\n",
      "fold_0, epoch_460, Loss: 0.3564\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3536\n",
      "Accuracy:\t0.9593\n",
      "AUC:\t\t0.9583\n",
      "Precision:\t0.9779\n",
      "Recall:\t\t0.9392\n",
      "F1:\t\t\t0.9581\n",
      "\n",
      "fold_0, epoch_461, Loss: 0.3579\n",
      "fold_0, epoch_462, Loss: 0.3611\n",
      "fold_0, epoch_463, Loss: 0.3571\n",
      "fold_0, epoch_464, Loss: 0.3576\n",
      "fold_0, epoch_465, Loss: 0.3560\n",
      "fold_0, epoch_466, Loss: 0.3550\n",
      "fold_0, epoch_467, Loss: 0.3563\n",
      "fold_0, epoch_468, Loss: 0.3576\n",
      "fold_0, epoch_469, Loss: 0.3597\n",
      "fold_0, epoch_470, Loss: 0.3594\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3567\n",
      "Accuracy:\t0.9565\n",
      "AUC:\t\t0.9569\n",
      "Precision:\t0.9771\n",
      "Recall:\t\t0.9345\n",
      "F1:\t\t\t0.9553\n",
      "\n",
      "fold_0, epoch_471, Loss: 0.3572\n",
      "fold_0, epoch_472, Loss: 0.3611\n",
      "fold_0, epoch_473, Loss: 0.3562\n",
      "fold_0, epoch_474, Loss: 0.3579\n",
      "fold_0, epoch_475, Loss: 0.3595\n",
      "fold_0, epoch_476, Loss: 0.3593\n",
      "fold_0, epoch_477, Loss: 0.3581\n",
      "fold_0, epoch_478, Loss: 0.3572\n",
      "fold_0, epoch_479, Loss: 0.3622\n",
      "fold_0, epoch_480, Loss: 0.3583\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3549\n",
      "Accuracy:\t0.9585\n",
      "AUC:\t\t0.9567\n",
      "Precision:\t0.9760\n",
      "Recall:\t\t0.9401\n",
      "F1:\t\t\t0.9577\n",
      "\n",
      "fold_0, epoch_481, Loss: 0.3591\n",
      "fold_0, epoch_482, Loss: 0.3586\n",
      "fold_0, epoch_483, Loss: 0.3559\n",
      "fold_0, epoch_484, Loss: 0.3602\n",
      "fold_0, epoch_485, Loss: 0.3562\n",
      "fold_0, epoch_486, Loss: 0.3533\n",
      "fold_0, epoch_487, Loss: 0.3559\n",
      "fold_0, epoch_488, Loss: 0.3573\n",
      "fold_0, epoch_489, Loss: 0.3566\n",
      "fold_0, epoch_490, Loss: 0.3592\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3568\n",
      "Accuracy:\t0.9564\n",
      "AUC:\t\t0.9571\n",
      "Precision:\t0.9756\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_0, epoch_491, Loss: 0.3565\n",
      "fold_0, epoch_492, Loss: 0.3555\n",
      "fold_0, epoch_493, Loss: 0.3580\n",
      "fold_0, epoch_494, Loss: 0.3569\n",
      "fold_0, epoch_495, Loss: 0.3565\n",
      "fold_0, epoch_496, Loss: 0.3591\n",
      "fold_0, epoch_497, Loss: 0.3586\n",
      "fold_0, epoch_498, Loss: 0.3581\n",
      "fold_0, epoch_499, Loss: 0.3547\n",
      "fold_0, epoch_500, Loss: 0.3561\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3545\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9583\n",
      "Precision:\t0.9790\n",
      "Recall:\t\t0.9381\n",
      "F1:\t\t\t0.9581\n",
      "\n",
      "fold_0, epoch_501, Loss: 0.3558\n",
      "fold_0, epoch_502, Loss: 0.3594\n",
      "fold_0, epoch_503, Loss: 0.3547\n",
      "fold_0, epoch_504, Loss: 0.3563\n",
      "fold_0, epoch_505, Loss: 0.3556\n",
      "fold_0, epoch_506, Loss: 0.3567\n",
      "fold_0, epoch_507, Loss: 0.3565\n",
      "fold_0, epoch_508, Loss: 0.3565\n",
      "fold_0, epoch_509, Loss: 0.3580\n",
      "fold_0, epoch_510, Loss: 0.3551\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3554\n",
      "Accuracy:\t0.9578\n",
      "AUC:\t\t0.9572\n",
      "Precision:\t0.9753\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9571\n",
      "\n",
      "fold_0, epoch_511, Loss: 0.3549\n",
      "fold_0, epoch_512, Loss: 0.3587\n",
      "fold_0, epoch_513, Loss: 0.3548\n",
      "fold_0, epoch_514, Loss: 0.3536\n",
      "fold_0, epoch_515, Loss: 0.3548\n",
      "fold_0, epoch_516, Loss: 0.3551\n",
      "fold_0, epoch_517, Loss: 0.3546\n",
      "fold_0, epoch_518, Loss: 0.3559\n",
      "fold_0, epoch_519, Loss: 0.3575\n",
      "fold_0, epoch_520, Loss: 0.3525\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3563\n",
      "Accuracy:\t0.9566\n",
      "AUC:\t\t0.9573\n",
      "Precision:\t0.9736\n",
      "Recall:\t\t0.9389\n",
      "F1:\t\t\t0.9559\n",
      "\n",
      "fold_0, epoch_521, Loss: 0.3572\n",
      "fold_0, epoch_522, Loss: 0.3559\n",
      "fold_0, epoch_523, Loss: 0.3582\n",
      "fold_0, epoch_524, Loss: 0.3579\n",
      "fold_0, epoch_525, Loss: 0.3527\n",
      "fold_0, epoch_526, Loss: 0.3562\n",
      "fold_0, epoch_527, Loss: 0.3570\n",
      "fold_0, epoch_528, Loss: 0.3572\n",
      "fold_0, epoch_529, Loss: 0.3540\n",
      "fold_0, epoch_530, Loss: 0.3551\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9605\n",
      "AUC:\t\t0.9594\n",
      "Precision:\t0.9812\n",
      "Recall:\t\t0.9390\n",
      "F1:\t\t\t0.9597\n",
      "\n",
      "fold_0, epoch_531, Loss: 0.3570\n",
      "fold_0, epoch_532, Loss: 0.3568\n",
      "fold_0, epoch_533, Loss: 0.3546\n",
      "fold_0, epoch_534, Loss: 0.3560\n",
      "fold_0, epoch_535, Loss: 0.3552\n",
      "fold_0, epoch_536, Loss: 0.3540\n",
      "fold_0, epoch_537, Loss: 0.3562\n",
      "fold_0, epoch_538, Loss: 0.3534\n",
      "fold_0, epoch_539, Loss: 0.3543\n",
      "fold_0, epoch_540, Loss: 0.3553\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3530\n",
      "Accuracy:\t0.9602\n",
      "AUC:\t\t0.9591\n",
      "Precision:\t0.9827\n",
      "Recall:\t\t0.9373\n",
      "F1:\t\t\t0.9594\n",
      "\n",
      "fold_0, epoch_541, Loss: 0.3562\n",
      "fold_0, epoch_542, Loss: 0.3547\n",
      "fold_0, epoch_543, Loss: 0.3545\n",
      "fold_0, epoch_544, Loss: 0.3534\n",
      "fold_0, epoch_545, Loss: 0.3562\n",
      "fold_0, epoch_546, Loss: 0.3535\n",
      "fold_0, epoch_547, Loss: 0.3598\n",
      "fold_0, epoch_548, Loss: 0.3554\n",
      "fold_0, epoch_549, Loss: 0.3540\n",
      "fold_0, epoch_550, Loss: 0.3541\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3546\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9768\n",
      "Recall:\t\t0.9390\n",
      "F1:\t\t\t0.9575\n",
      "\n",
      "fold_0, epoch_551, Loss: 0.3560\n",
      "fold_0, epoch_552, Loss: 0.3555\n",
      "fold_0, epoch_553, Loss: 0.3547\n",
      "fold_0, epoch_554, Loss: 0.3535\n",
      "fold_0, epoch_555, Loss: 0.3517\n",
      "fold_0, epoch_556, Loss: 0.3541\n",
      "fold_0, epoch_557, Loss: 0.3567\n",
      "fold_0, epoch_558, Loss: 0.3537\n",
      "fold_0, epoch_559, Loss: 0.3563\n",
      "fold_0, epoch_560, Loss: 0.3550\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3580\n",
      "Accuracy:\t0.9553\n",
      "AUC:\t\t0.9556\n",
      "Precision:\t0.9782\n",
      "Recall:\t\t0.9321\n",
      "F1:\t\t\t0.9546\n",
      "\n",
      "fold_0, epoch_561, Loss: 0.3575\n",
      "fold_0, epoch_562, Loss: 0.3553\n",
      "fold_0, epoch_563, Loss: 0.3571\n",
      "fold_0, epoch_564, Loss: 0.3542\n",
      "fold_0, epoch_565, Loss: 0.3545\n",
      "fold_0, epoch_566, Loss: 0.3541\n",
      "fold_0, epoch_567, Loss: 0.3551\n",
      "fold_0, epoch_568, Loss: 0.3558\n",
      "fold_0, epoch_569, Loss: 0.3530\n",
      "fold_0, epoch_570, Loss: 0.3550\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9597\n",
      "AUC:\t\t0.9572\n",
      "Precision:\t0.9823\n",
      "Recall:\t\t0.9362\n",
      "F1:\t\t\t0.9587\n",
      "\n",
      "fold_0, epoch_571, Loss: 0.3509\n",
      "fold_0, epoch_572, Loss: 0.3542\n",
      "fold_0, epoch_573, Loss: 0.3526\n",
      "fold_0, epoch_574, Loss: 0.3528\n",
      "fold_0, epoch_575, Loss: 0.3531\n",
      "fold_0, epoch_576, Loss: 0.3552\n",
      "fold_0, epoch_577, Loss: 0.3562\n",
      "fold_0, epoch_578, Loss: 0.3539\n",
      "fold_0, epoch_579, Loss: 0.3561\n",
      "fold_0, epoch_580, Loss: 0.3599\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3550\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9798\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9568\n",
      "\n",
      "fold_0, epoch_581, Loss: 0.3554\n",
      "fold_0, epoch_582, Loss: 0.3508\n",
      "fold_0, epoch_583, Loss: 0.3575\n",
      "fold_0, epoch_584, Loss: 0.3545\n",
      "fold_0, epoch_585, Loss: 0.3572\n",
      "fold_0, epoch_586, Loss: 0.3572\n",
      "fold_0, epoch_587, Loss: 0.3574\n",
      "fold_0, epoch_588, Loss: 0.3526\n",
      "fold_0, epoch_589, Loss: 0.3555\n",
      "fold_0, epoch_590, Loss: 0.3553\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3517\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9598\n",
      "Precision:\t0.9794\n",
      "Recall:\t\t0.9427\n",
      "F1:\t\t\t0.9607\n",
      "\n",
      "fold_0, epoch_591, Loss: 0.3531\n",
      "fold_0, epoch_592, Loss: 0.3551\n",
      "fold_0, epoch_593, Loss: 0.3527\n",
      "fold_0, epoch_594, Loss: 0.3533\n",
      "fold_0, epoch_595, Loss: 0.3563\n",
      "fold_0, epoch_596, Loss: 0.3544\n",
      "fold_0, epoch_597, Loss: 0.3518\n",
      "fold_0, epoch_598, Loss: 0.3531\n",
      "fold_0, epoch_599, Loss: 0.3534\n",
      "fold_0, epoch_600, Loss: 0.3518\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3535\n",
      "Accuracy:\t0.9595\n",
      "AUC:\t\t0.9599\n",
      "Precision:\t0.9837\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9584\n",
      "\n",
      "fold_0, epoch_601, Loss: 0.3556\n",
      "fold_0, epoch_602, Loss: 0.3557\n",
      "fold_0, epoch_603, Loss: 0.3552\n",
      "fold_0, epoch_604, Loss: 0.3533\n",
      "fold_0, epoch_605, Loss: 0.3525\n",
      "fold_0, epoch_606, Loss: 0.3566\n",
      "fold_0, epoch_607, Loss: 0.3565\n",
      "fold_0, epoch_608, Loss: 0.3551\n",
      "fold_0, epoch_609, Loss: 0.3529\n",
      "fold_0, epoch_610, Loss: 0.3551\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3535\n",
      "Accuracy:\t0.9595\n",
      "AUC:\t\t0.9592\n",
      "Precision:\t0.9797\n",
      "Recall:\t\t0.9383\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_0, epoch_611, Loss: 0.3505\n",
      "fold_0, epoch_612, Loss: 0.3540\n",
      "fold_0, epoch_613, Loss: 0.3524\n",
      "fold_0, epoch_614, Loss: 0.3533\n",
      "fold_0, epoch_615, Loss: 0.3518\n",
      "fold_0, epoch_616, Loss: 0.3535\n",
      "fold_0, epoch_617, Loss: 0.3519\n",
      "fold_0, epoch_618, Loss: 0.3559\n",
      "fold_0, epoch_619, Loss: 0.3546\n",
      "fold_0, epoch_620, Loss: 0.3507\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9621\n",
      "Precision:\t0.9820\n",
      "Recall:\t\t0.9418\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_0, epoch_621, Loss: 0.3543\n",
      "fold_0, epoch_622, Loss: 0.3528\n",
      "fold_0, epoch_623, Loss: 0.3525\n",
      "fold_0, epoch_624, Loss: 0.3526\n",
      "fold_0, epoch_625, Loss: 0.3556\n",
      "fold_0, epoch_626, Loss: 0.3526\n",
      "fold_0, epoch_627, Loss: 0.3510\n",
      "fold_0, epoch_628, Loss: 0.3523\n",
      "fold_0, epoch_629, Loss: 0.3538\n",
      "fold_0, epoch_630, Loss: 0.3535\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3524\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9597\n",
      "Precision:\t0.9842\n",
      "Recall:\t\t0.9367\n",
      "F1:\t\t\t0.9598\n",
      "\n",
      "fold_0, epoch_631, Loss: 0.3533\n",
      "fold_0, epoch_632, Loss: 0.3552\n",
      "fold_0, epoch_633, Loss: 0.3546\n",
      "fold_0, epoch_634, Loss: 0.3544\n",
      "fold_0, epoch_635, Loss: 0.3549\n",
      "fold_0, epoch_636, Loss: 0.3498\n",
      "fold_0, epoch_637, Loss: 0.3520\n",
      "fold_0, epoch_638, Loss: 0.3536\n",
      "fold_0, epoch_639, Loss: 0.3545\n",
      "fold_0, epoch_640, Loss: 0.3519\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3519\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9607\n",
      "Precision:\t0.9803\n",
      "Recall:\t\t0.9405\n",
      "F1:\t\t\t0.9600\n",
      "\n",
      "fold_0, epoch_641, Loss: 0.3530\n",
      "fold_0, epoch_642, Loss: 0.3529\n",
      "fold_0, epoch_643, Loss: 0.3507\n",
      "fold_0, epoch_644, Loss: 0.3521\n",
      "fold_0, epoch_645, Loss: 0.3534\n",
      "fold_0, epoch_646, Loss: 0.3543\n",
      "fold_0, epoch_647, Loss: 0.3524\n",
      "fold_0, epoch_648, Loss: 0.3502\n",
      "fold_0, epoch_649, Loss: 0.3539\n",
      "fold_0, epoch_650, Loss: 0.3547\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3495\n",
      "Accuracy:\t0.9638\n",
      "AUC:\t\t0.9623\n",
      "Precision:\t0.9829\n",
      "Recall:\t\t0.9447\n",
      "F1:\t\t\t0.9635\n",
      "\n",
      "fold_0, epoch_651, Loss: 0.3538\n",
      "fold_0, epoch_652, Loss: 0.3609\n",
      "fold_0, epoch_653, Loss: 0.3608\n",
      "fold_0, epoch_654, Loss: 0.3510\n",
      "fold_0, epoch_655, Loss: 0.3518\n",
      "fold_0, epoch_656, Loss: 0.3516\n",
      "fold_0, epoch_657, Loss: 0.3511\n",
      "fold_0, epoch_658, Loss: 0.3515\n",
      "fold_0, epoch_659, Loss: 0.3556\n",
      "fold_0, epoch_660, Loss: 0.3535\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9616\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9810\n",
      "Recall:\t\t0.9407\n",
      "F1:\t\t\t0.9605\n",
      "\n",
      "fold_0, epoch_661, Loss: 0.3523\n",
      "fold_0, epoch_662, Loss: 0.3540\n",
      "fold_0, epoch_663, Loss: 0.3511\n",
      "fold_0, epoch_664, Loss: 0.3537\n",
      "fold_0, epoch_665, Loss: 0.3521\n",
      "fold_0, epoch_666, Loss: 0.3563\n",
      "fold_0, epoch_667, Loss: 0.3553\n",
      "fold_0, epoch_668, Loss: 0.3491\n",
      "fold_0, epoch_669, Loss: 0.3510\n",
      "fold_0, epoch_670, Loss: 0.3542\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9590\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9835\n",
      "Recall:\t\t0.9337\n",
      "F1:\t\t\t0.9580\n",
      "\n",
      "fold_0, epoch_671, Loss: 0.3524\n",
      "fold_0, epoch_672, Loss: 0.3558\n",
      "fold_0, epoch_673, Loss: 0.3519\n",
      "fold_0, epoch_674, Loss: 0.3513\n",
      "fold_0, epoch_675, Loss: 0.3505\n",
      "fold_0, epoch_676, Loss: 0.3514\n",
      "fold_0, epoch_677, Loss: 0.3512\n",
      "fold_0, epoch_678, Loss: 0.3541\n",
      "fold_0, epoch_679, Loss: 0.3551\n",
      "fold_0, epoch_680, Loss: 0.3537\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3572\n",
      "Accuracy:\t0.9555\n",
      "AUC:\t\t0.9595\n",
      "Precision:\t0.9826\n",
      "Recall:\t\t0.9275\n",
      "F1:\t\t\t0.9543\n",
      "\n",
      "fold_0, epoch_681, Loss: 0.3514\n",
      "fold_0, epoch_682, Loss: 0.3534\n",
      "fold_0, epoch_683, Loss: 0.3516\n",
      "fold_0, epoch_684, Loss: 0.3521\n",
      "fold_0, epoch_685, Loss: 0.3530\n",
      "fold_0, epoch_686, Loss: 0.3512\n",
      "fold_0, epoch_687, Loss: 0.3511\n",
      "fold_0, epoch_688, Loss: 0.3530\n",
      "fold_0, epoch_689, Loss: 0.3520\n",
      "fold_0, epoch_690, Loss: 0.3505\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3498\n",
      "Accuracy:\t0.9635\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9840\n",
      "Recall:\t\t0.9422\n",
      "F1:\t\t\t0.9627\n",
      "\n",
      "fold_0, epoch_691, Loss: 0.3534\n",
      "fold_0, epoch_692, Loss: 0.3552\n",
      "fold_0, epoch_693, Loss: 0.3493\n",
      "fold_0, epoch_694, Loss: 0.3532\n",
      "fold_0, epoch_695, Loss: 0.3545\n",
      "fold_0, epoch_696, Loss: 0.3526\n",
      "fold_0, epoch_697, Loss: 0.3528\n",
      "fold_0, epoch_698, Loss: 0.3539\n",
      "fold_0, epoch_699, Loss: 0.3512\n",
      "fold_0, epoch_700, Loss: 0.3495\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3491\n",
      "Accuracy:\t0.9641\n",
      "AUC:\t\t0.9626\n",
      "Precision:\t0.9845\n",
      "Recall:\t\t0.9428\n",
      "F1:\t\t\t0.9632\n",
      "\n",
      "fold_0, epoch_701, Loss: 0.3508\n",
      "fold_0, epoch_702, Loss: 0.3518\n",
      "fold_0, epoch_703, Loss: 0.3535\n",
      "fold_0, epoch_704, Loss: 0.3504\n",
      "fold_0, epoch_705, Loss: 0.3506\n",
      "fold_0, epoch_706, Loss: 0.3515\n",
      "fold_0, epoch_707, Loss: 0.3522\n",
      "fold_0, epoch_708, Loss: 0.3526\n",
      "fold_0, epoch_709, Loss: 0.3512\n",
      "fold_0, epoch_710, Loss: 0.3498\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3529\n",
      "Accuracy:\t0.9602\n",
      "AUC:\t\t0.9596\n",
      "Precision:\t0.9806\n",
      "Recall:\t\t0.9399\n",
      "F1:\t\t\t0.9598\n",
      "\n",
      "fold_0, epoch_711, Loss: 0.3495\n",
      "fold_0, epoch_712, Loss: 0.3512\n",
      "fold_0, epoch_713, Loss: 0.3535\n",
      "fold_0, epoch_714, Loss: 0.3519\n",
      "fold_0, epoch_715, Loss: 0.3487\n",
      "fold_0, epoch_716, Loss: 0.3508\n",
      "fold_0, epoch_717, Loss: 0.3538\n",
      "fold_0, epoch_718, Loss: 0.3518\n",
      "fold_0, epoch_719, Loss: 0.3493\n",
      "fold_0, epoch_720, Loss: 0.3514\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3497\n",
      "Accuracy:\t0.9634\n",
      "AUC:\t\t0.9619\n",
      "Precision:\t0.9820\n",
      "Recall:\t\t0.9439\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_0, epoch_721, Loss: 0.3509\n",
      "fold_0, epoch_722, Loss: 0.3518\n",
      "fold_0, epoch_723, Loss: 0.3510\n",
      "fold_0, epoch_724, Loss: 0.3530\n",
      "fold_0, epoch_725, Loss: 0.3521\n",
      "fold_0, epoch_726, Loss: 0.3528\n",
      "fold_0, epoch_727, Loss: 0.3554\n",
      "fold_0, epoch_728, Loss: 0.3516\n",
      "fold_0, epoch_729, Loss: 0.3485\n",
      "fold_0, epoch_730, Loss: 0.3504\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3511\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9614\n",
      "Precision:\t0.9857\n",
      "Recall:\t\t0.9379\n",
      "F1:\t\t\t0.9612\n",
      "\n",
      "fold_0, epoch_731, Loss: 0.3515\n",
      "fold_0, epoch_732, Loss: 0.3523\n",
      "fold_0, epoch_733, Loss: 0.3508\n",
      "fold_0, epoch_734, Loss: 0.3509\n",
      "fold_0, epoch_735, Loss: 0.3507\n",
      "fold_0, epoch_736, Loss: 0.3521\n",
      "fold_0, epoch_737, Loss: 0.3503\n",
      "fold_0, epoch_738, Loss: 0.3490\n",
      "fold_0, epoch_739, Loss: 0.3517\n",
      "fold_0, epoch_740, Loss: 0.3530\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9623\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9398\n",
      "F1:\t\t\t0.9613\n",
      "\n",
      "fold_0, epoch_741, Loss: 0.3523\n",
      "fold_0, epoch_742, Loss: 0.3525\n",
      "fold_0, epoch_743, Loss: 0.3524\n",
      "fold_0, epoch_744, Loss: 0.3520\n",
      "fold_0, epoch_745, Loss: 0.3506\n",
      "fold_0, epoch_746, Loss: 0.3498\n",
      "fold_0, epoch_747, Loss: 0.3530\n",
      "fold_0, epoch_748, Loss: 0.3519\n",
      "fold_0, epoch_749, Loss: 0.3524\n",
      "fold_0, epoch_750, Loss: 0.3518\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3498\n",
      "Accuracy:\t0.9633\n",
      "AUC:\t\t0.9618\n",
      "Precision:\t0.9845\n",
      "Recall:\t\t0.9410\n",
      "F1:\t\t\t0.9623\n",
      "\n",
      "fold_0, epoch_751, Loss: 0.3489\n",
      "fold_0, epoch_752, Loss: 0.3502\n",
      "fold_0, epoch_753, Loss: 0.3519\n",
      "fold_0, epoch_754, Loss: 0.3528\n",
      "fold_0, epoch_755, Loss: 0.3503\n",
      "fold_0, epoch_756, Loss: 0.3530\n",
      "fold_0, epoch_757, Loss: 0.3539\n",
      "fold_0, epoch_758, Loss: 0.3491\n",
      "fold_0, epoch_759, Loss: 0.3488\n",
      "fold_0, epoch_760, Loss: 0.3515\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3498\n",
      "Accuracy:\t0.9633\n",
      "AUC:\t\t0.9622\n",
      "Precision:\t0.9857\n",
      "Recall:\t\t0.9408\n",
      "F1:\t\t\t0.9627\n",
      "\n",
      "fold_0, epoch_761, Loss: 0.3522\n",
      "fold_0, epoch_762, Loss: 0.3499\n",
      "fold_0, epoch_763, Loss: 0.3505\n",
      "fold_0, epoch_764, Loss: 0.3518\n",
      "fold_0, epoch_765, Loss: 0.3512\n",
      "fold_0, epoch_766, Loss: 0.3501\n",
      "fold_0, epoch_767, Loss: 0.3511\n",
      "fold_0, epoch_768, Loss: 0.3506\n",
      "fold_0, epoch_769, Loss: 0.3518\n",
      "fold_0, epoch_770, Loss: 0.3510\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3495\n",
      "Accuracy:\t0.9638\n",
      "AUC:\t\t0.9616\n",
      "Precision:\t0.9855\n",
      "Recall:\t\t0.9413\n",
      "F1:\t\t\t0.9629\n",
      "\n",
      "fold_0, epoch_771, Loss: 0.3479\n",
      "fold_0, epoch_772, Loss: 0.3517\n",
      "fold_0, epoch_773, Loss: 0.3478\n",
      "fold_0, epoch_774, Loss: 0.3505\n",
      "fold_0, epoch_775, Loss: 0.3508\n",
      "fold_0, epoch_776, Loss: 0.3500\n",
      "fold_0, epoch_777, Loss: 0.3484\n",
      "fold_0, epoch_778, Loss: 0.3519\n",
      "fold_0, epoch_779, Loss: 0.3498\n",
      "fold_0, epoch_780, Loss: 0.3508\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3523\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9802\n",
      "Recall:\t\t0.9409\n",
      "F1:\t\t\t0.9601\n",
      "\n",
      "fold_0, epoch_781, Loss: 0.3501\n",
      "fold_0, epoch_782, Loss: 0.3518\n",
      "fold_0, epoch_783, Loss: 0.3527\n",
      "fold_0, epoch_784, Loss: 0.3517\n",
      "fold_0, epoch_785, Loss: 0.3505\n",
      "fold_0, epoch_786, Loss: 0.3490\n",
      "fold_0, epoch_787, Loss: 0.3501\n",
      "fold_0, epoch_788, Loss: 0.3489\n",
      "fold_0, epoch_789, Loss: 0.3518\n",
      "fold_0, epoch_790, Loss: 0.3507\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3486\n",
      "Accuracy:\t0.9645\n",
      "AUC:\t\t0.9643\n",
      "Precision:\t0.9850\n",
      "Recall:\t\t0.9428\n",
      "F1:\t\t\t0.9635\n",
      "\n",
      "fold_0, epoch_791, Loss: 0.3471\n",
      "fold_0, epoch_792, Loss: 0.3507\n",
      "fold_0, epoch_793, Loss: 0.3521\n",
      "fold_0, epoch_794, Loss: 0.3512\n",
      "fold_0, epoch_795, Loss: 0.3489\n",
      "fold_0, epoch_796, Loss: 0.3488\n",
      "fold_0, epoch_797, Loss: 0.3493\n",
      "fold_0, epoch_798, Loss: 0.3482\n",
      "fold_0, epoch_799, Loss: 0.3484\n",
      "fold_0, epoch_800, Loss: 0.3483\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3478\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9635\n",
      "Precision:\t0.9858\n",
      "Recall:\t\t0.9443\n",
      "F1:\t\t\t0.9646\n",
      "\n",
      "fold_0, epoch_801, Loss: 0.3539\n",
      "fold_0, epoch_802, Loss: 0.3483\n",
      "fold_0, epoch_803, Loss: 0.3479\n",
      "fold_0, epoch_804, Loss: 0.3489\n",
      "fold_0, epoch_805, Loss: 0.3487\n",
      "fold_0, epoch_806, Loss: 0.3491\n",
      "fold_0, epoch_807, Loss: 0.3506\n",
      "fold_0, epoch_808, Loss: 0.3506\n",
      "fold_0, epoch_809, Loss: 0.3506\n",
      "fold_0, epoch_810, Loss: 0.3499\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3512\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9400\n",
      "F1:\t\t\t0.9614\n",
      "\n",
      "fold_0, epoch_811, Loss: 0.3517\n",
      "fold_0, epoch_812, Loss: 0.3489\n",
      "fold_0, epoch_813, Loss: 0.3500\n",
      "fold_0, epoch_814, Loss: 0.3507\n",
      "fold_0, epoch_815, Loss: 0.3480\n",
      "fold_0, epoch_816, Loss: 0.3481\n",
      "fold_0, epoch_817, Loss: 0.3491\n",
      "fold_0, epoch_818, Loss: 0.3483\n",
      "fold_0, epoch_819, Loss: 0.3520\n",
      "fold_0, epoch_820, Loss: 0.3500\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3522\n",
      "Accuracy:\t0.9610\n",
      "AUC:\t\t0.9602\n",
      "Precision:\t0.9805\n",
      "Recall:\t\t0.9413\n",
      "F1:\t\t\t0.9605\n",
      "\n",
      "fold_0, epoch_821, Loss: 0.3506\n",
      "fold_0, epoch_822, Loss: 0.3518\n",
      "fold_0, epoch_823, Loss: 0.3495\n",
      "fold_0, epoch_824, Loss: 0.3506\n",
      "fold_0, epoch_825, Loss: 0.3509\n",
      "fold_0, epoch_826, Loss: 0.3479\n",
      "fold_0, epoch_827, Loss: 0.3515\n",
      "fold_0, epoch_828, Loss: 0.3493\n",
      "fold_0, epoch_829, Loss: 0.3510\n",
      "fold_0, epoch_830, Loss: 0.3514\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3491\n",
      "Accuracy:\t0.9641\n",
      "AUC:\t\t0.9630\n",
      "Precision:\t0.9850\n",
      "Recall:\t\t0.9419\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_0, epoch_831, Loss: 0.3481\n",
      "fold_0, epoch_832, Loss: 0.3509\n",
      "fold_0, epoch_833, Loss: 0.3525\n",
      "fold_0, epoch_834, Loss: 0.3494\n",
      "fold_0, epoch_835, Loss: 0.3522\n",
      "fold_0, epoch_836, Loss: 0.3508\n",
      "fold_0, epoch_837, Loss: 0.3476\n",
      "fold_0, epoch_838, Loss: 0.3499\n",
      "fold_0, epoch_839, Loss: 0.3502\n",
      "fold_0, epoch_840, Loss: 0.3457\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9631\n",
      "Precision:\t0.9895\n",
      "Recall:\t\t0.9413\n",
      "F1:\t\t\t0.9648\n",
      "\n",
      "fold_0, epoch_841, Loss: 0.3463\n",
      "fold_0, epoch_842, Loss: 0.3469\n",
      "fold_0, epoch_843, Loss: 0.3517\n",
      "fold_0, epoch_844, Loss: 0.3502\n",
      "fold_0, epoch_845, Loss: 0.3508\n",
      "fold_0, epoch_846, Loss: 0.3507\n",
      "fold_0, epoch_847, Loss: 0.3480\n",
      "fold_0, epoch_848, Loss: 0.3491\n",
      "fold_0, epoch_849, Loss: 0.3507\n",
      "fold_0, epoch_850, Loss: 0.3497\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9624\n",
      "AUC:\t\t0.9619\n",
      "Precision:\t0.9862\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_0, epoch_851, Loss: 0.3471\n",
      "fold_0, epoch_852, Loss: 0.3509\n",
      "fold_0, epoch_853, Loss: 0.3520\n",
      "fold_0, epoch_854, Loss: 0.3482\n",
      "fold_0, epoch_855, Loss: 0.3519\n",
      "fold_0, epoch_856, Loss: 0.3490\n",
      "fold_0, epoch_857, Loss: 0.3509\n",
      "fold_0, epoch_858, Loss: 0.3477\n",
      "fold_0, epoch_859, Loss: 0.3493\n",
      "fold_0, epoch_860, Loss: 0.3514\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3480\n",
      "Accuracy:\t0.9652\n",
      "AUC:\t\t0.9631\n",
      "Precision:\t0.9876\n",
      "Recall:\t\t0.9417\n",
      "F1:\t\t\t0.9641\n",
      "\n",
      "fold_0, epoch_861, Loss: 0.3477\n",
      "fold_0, epoch_862, Loss: 0.3461\n",
      "fold_0, epoch_863, Loss: 0.3510\n",
      "fold_0, epoch_864, Loss: 0.3485\n",
      "fold_0, epoch_865, Loss: 0.3508\n",
      "fold_0, epoch_866, Loss: 0.3507\n",
      "fold_0, epoch_867, Loss: 0.3487\n",
      "fold_0, epoch_868, Loss: 0.3499\n",
      "fold_0, epoch_869, Loss: 0.3499\n",
      "fold_0, epoch_870, Loss: 0.3494\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3512\n",
      "Accuracy:\t0.9620\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9884\n",
      "Recall:\t\t0.9355\n",
      "F1:\t\t\t0.9612\n",
      "\n",
      "fold_0, epoch_871, Loss: 0.3492\n",
      "fold_0, epoch_872, Loss: 0.3480\n",
      "fold_0, epoch_873, Loss: 0.3498\n",
      "fold_0, epoch_874, Loss: 0.3478\n",
      "fold_0, epoch_875, Loss: 0.3490\n",
      "fold_0, epoch_876, Loss: 0.3475\n",
      "fold_0, epoch_877, Loss: 0.3494\n",
      "fold_0, epoch_878, Loss: 0.3476\n",
      "fold_0, epoch_879, Loss: 0.3484\n",
      "fold_0, epoch_880, Loss: 0.3460\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3489\n",
      "Accuracy:\t0.9643\n",
      "AUC:\t\t0.9625\n",
      "Precision:\t0.9882\n",
      "Recall:\t\t0.9402\n",
      "F1:\t\t\t0.9636\n",
      "\n",
      "fold_0, epoch_881, Loss: 0.3499\n",
      "fold_0, epoch_882, Loss: 0.3492\n",
      "fold_0, epoch_883, Loss: 0.3490\n",
      "fold_0, epoch_884, Loss: 0.3487\n",
      "fold_0, epoch_885, Loss: 0.3469\n",
      "fold_0, epoch_886, Loss: 0.3487\n",
      "fold_0, epoch_887, Loss: 0.3477\n",
      "fold_0, epoch_888, Loss: 0.3513\n",
      "fold_0, epoch_889, Loss: 0.3486\n",
      "fold_0, epoch_890, Loss: 0.3493\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3472\n",
      "Accuracy:\t0.9660\n",
      "AUC:\t\t0.9647\n",
      "Precision:\t0.9885\n",
      "Recall:\t\t0.9428\n",
      "F1:\t\t\t0.9651\n",
      "\n",
      "fold_0, epoch_891, Loss: 0.3488\n",
      "fold_0, epoch_892, Loss: 0.3490\n",
      "fold_0, epoch_893, Loss: 0.3487\n",
      "fold_0, epoch_894, Loss: 0.3500\n",
      "fold_0, epoch_895, Loss: 0.3487\n",
      "fold_0, epoch_896, Loss: 0.3469\n",
      "fold_0, epoch_897, Loss: 0.3492\n",
      "fold_0, epoch_898, Loss: 0.3512\n",
      "fold_0, epoch_899, Loss: 0.3484\n",
      "fold_0, epoch_900, Loss: 0.3510\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3468\n",
      "Accuracy:\t0.9664\n",
      "AUC:\t\t0.9642\n",
      "Precision:\t0.9877\n",
      "Recall:\t\t0.9443\n",
      "F1:\t\t\t0.9655\n",
      "\n",
      "fold_0, epoch_901, Loss: 0.3491\n",
      "fold_0, epoch_902, Loss: 0.3475\n",
      "fold_0, epoch_903, Loss: 0.3481\n",
      "fold_0, epoch_904, Loss: 0.3514\n",
      "fold_0, epoch_905, Loss: 0.3485\n",
      "fold_0, epoch_906, Loss: 0.3481\n",
      "fold_0, epoch_907, Loss: 0.3478\n",
      "fold_0, epoch_908, Loss: 0.3528\n",
      "fold_0, epoch_909, Loss: 0.3499\n",
      "fold_0, epoch_910, Loss: 0.3474\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3494\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9876\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_0, epoch_911, Loss: 0.3514\n",
      "fold_0, epoch_912, Loss: 0.3475\n",
      "fold_0, epoch_913, Loss: 0.3507\n",
      "fold_0, epoch_914, Loss: 0.3482\n",
      "fold_0, epoch_915, Loss: 0.3479\n",
      "fold_0, epoch_916, Loss: 0.3484\n",
      "fold_0, epoch_917, Loss: 0.3498\n",
      "fold_0, epoch_918, Loss: 0.3486\n",
      "fold_0, epoch_919, Loss: 0.3492\n",
      "fold_0, epoch_920, Loss: 0.3480\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3520\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9618\n",
      "Precision:\t0.9874\n",
      "Recall:\t\t0.9339\n",
      "F1:\t\t\t0.9599\n",
      "\n",
      "fold_0, epoch_921, Loss: 0.3496\n",
      "fold_0, epoch_922, Loss: 0.3482\n",
      "fold_0, epoch_923, Loss: 0.3511\n",
      "fold_0, epoch_924, Loss: 0.3476\n",
      "fold_0, epoch_925, Loss: 0.3500\n",
      "fold_0, epoch_926, Loss: 0.3532\n",
      "fold_0, epoch_927, Loss: 0.3495\n",
      "fold_0, epoch_928, Loss: 0.3479\n",
      "fold_0, epoch_929, Loss: 0.3474\n",
      "fold_0, epoch_930, Loss: 0.3509\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9594\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9853\n",
      "Recall:\t\t0.9332\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_0, epoch_931, Loss: 0.3516\n",
      "fold_0, epoch_932, Loss: 0.3495\n",
      "fold_0, epoch_933, Loss: 0.3487\n",
      "fold_0, epoch_934, Loss: 0.3498\n",
      "fold_0, epoch_935, Loss: 0.3518\n",
      "fold_0, epoch_936, Loss: 0.3507\n",
      "fold_0, epoch_937, Loss: 0.3476\n",
      "fold_0, epoch_938, Loss: 0.3481\n",
      "fold_0, epoch_939, Loss: 0.3490\n",
      "fold_0, epoch_940, Loss: 0.3511\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3473\n",
      "Accuracy:\t0.9659\n",
      "AUC:\t\t0.9639\n",
      "Precision:\t0.9888\n",
      "Recall:\t\t0.9422\n",
      "F1:\t\t\t0.9649\n",
      "\n",
      "fold_0, epoch_941, Loss: 0.3492\n",
      "fold_0, epoch_942, Loss: 0.3473\n",
      "fold_0, epoch_943, Loss: 0.3480\n",
      "fold_0, epoch_944, Loss: 0.3544\n",
      "fold_0, epoch_945, Loss: 0.3484\n",
      "fold_0, epoch_946, Loss: 0.3486\n",
      "fold_0, epoch_947, Loss: 0.3482\n",
      "fold_0, epoch_948, Loss: 0.3486\n",
      "fold_0, epoch_949, Loss: 0.3505\n",
      "fold_0, epoch_950, Loss: 0.3460\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9653\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9881\n",
      "Recall:\t\t0.9424\n",
      "F1:\t\t\t0.9647\n",
      "\n",
      "fold_0, epoch_951, Loss: 0.3470\n",
      "fold_0, epoch_952, Loss: 0.3502\n",
      "fold_0, epoch_953, Loss: 0.3489\n",
      "fold_0, epoch_954, Loss: 0.3503\n",
      "fold_0, epoch_955, Loss: 0.3512\n",
      "fold_0, epoch_956, Loss: 0.3485\n",
      "fold_0, epoch_957, Loss: 0.3474\n",
      "fold_0, epoch_958, Loss: 0.3499\n",
      "fold_0, epoch_959, Loss: 0.3498\n",
      "fold_0, epoch_960, Loss: 0.3490\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3469\n",
      "Accuracy:\t0.9663\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9894\n",
      "Recall:\t\t0.9422\n",
      "F1:\t\t\t0.9652\n",
      "\n",
      "fold_0, epoch_961, Loss: 0.3474\n",
      "fold_0, epoch_962, Loss: 0.3501\n",
      "fold_0, epoch_963, Loss: 0.3502\n",
      "fold_0, epoch_964, Loss: 0.3486\n",
      "fold_0, epoch_965, Loss: 0.3490\n",
      "fold_0, epoch_966, Loss: 0.3486\n",
      "fold_0, epoch_967, Loss: 0.3490\n",
      "fold_0, epoch_968, Loss: 0.3501\n",
      "fold_0, epoch_969, Loss: 0.3483\n",
      "fold_0, epoch_970, Loss: 0.3473\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3477\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9639\n",
      "Precision:\t0.9888\n",
      "Recall:\t\t0.9418\n",
      "F1:\t\t\t0.9647\n",
      "\n",
      "fold_0, epoch_971, Loss: 0.3506\n",
      "fold_0, epoch_972, Loss: 0.3503\n",
      "fold_0, epoch_973, Loss: 0.3493\n",
      "fold_0, epoch_974, Loss: 0.3509\n",
      "fold_0, epoch_975, Loss: 0.3499\n",
      "fold_0, epoch_976, Loss: 0.3474\n",
      "fold_0, epoch_977, Loss: 0.3499\n",
      "fold_0, epoch_978, Loss: 0.3488\n",
      "fold_0, epoch_979, Loss: 0.3468\n",
      "fold_0, epoch_980, Loss: 0.3489\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3472\n",
      "Accuracy:\t0.9659\n",
      "AUC:\t\t0.9654\n",
      "Precision:\t0.9872\n",
      "Recall:\t\t0.9436\n",
      "F1:\t\t\t0.9649\n",
      "\n",
      "fold_0, epoch_981, Loss: 0.3498\n",
      "fold_0, epoch_982, Loss: 0.3494\n",
      "fold_0, epoch_983, Loss: 0.3482\n",
      "fold_0, epoch_984, Loss: 0.3488\n",
      "fold_0, epoch_985, Loss: 0.3502\n",
      "fold_0, epoch_986, Loss: 0.3478\n",
      "fold_0, epoch_987, Loss: 0.3522\n",
      "fold_0, epoch_988, Loss: 0.3476\n",
      "fold_0, epoch_989, Loss: 0.3495\n",
      "fold_0, epoch_990, Loss: 0.3480\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3503\n",
      "Accuracy:\t0.9632\n",
      "AUC:\t\t0.9629\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9412\n",
      "F1:\t\t\t0.9621\n",
      "\n",
      "fold_0, epoch_991, Loss: 0.3464\n",
      "fold_0, epoch_992, Loss: 0.3507\n",
      "fold_0, epoch_993, Loss: 0.3499\n",
      "fold_0, epoch_994, Loss: 0.3472\n",
      "fold_0, epoch_995, Loss: 0.3475\n",
      "fold_0, epoch_996, Loss: 0.3483\n",
      "fold_0, epoch_997, Loss: 0.3481\n",
      "fold_0, epoch_998, Loss: 0.3490\n",
      "fold_0, epoch_999, Loss: 0.3498\n",
      "fold_0, epoch_1000, Loss: 0.3498\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3455\n",
      "Accuracy:\t0.9678\n",
      "AUC:\t\t0.9655\n",
      "Precision:\t0.9899\n",
      "Recall:\t\t0.9456\n",
      "F1:\t\t\t0.9673\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/checkpoints/fold_1\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/tensorboard\n",
      "\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.5731\n",
      "fold_1, epoch_2, Loss: 0.5437\n",
      "fold_1, epoch_3, Loss: 0.5305\n",
      "fold_1, epoch_4, Loss: 0.5239\n",
      "fold_1, epoch_5, Loss: 0.5198\n",
      "fold_1, epoch_6, Loss: 0.5189\n",
      "fold_1, epoch_7, Loss: 0.5113\n",
      "fold_1, epoch_8, Loss: 0.5066\n",
      "fold_1, epoch_9, Loss: 0.5062\n",
      "fold_1, epoch_10, Loss: 0.5009\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4935\n",
      "Accuracy:\t0.8102\n",
      "AUC:\t\t0.8790\n",
      "Precision:\t0.8030\n",
      "Recall:\t\t0.8209\n",
      "F1:\t\t\t0.8118\n",
      "\n",
      "fold_1, epoch_11, Loss: 0.5009\n",
      "fold_1, epoch_12, Loss: 0.4976\n",
      "fold_1, epoch_13, Loss: 0.4952\n",
      "fold_1, epoch_14, Loss: 0.4937\n",
      "fold_1, epoch_15, Loss: 0.4924\n",
      "fold_1, epoch_16, Loss: 0.4863\n",
      "fold_1, epoch_17, Loss: 0.4849\n",
      "fold_1, epoch_18, Loss: 0.4822\n",
      "fold_1, epoch_19, Loss: 0.4848\n",
      "fold_1, epoch_20, Loss: 0.4817\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4859\n",
      "Accuracy:\t0.8205\n",
      "AUC:\t\t0.8827\n",
      "Precision:\t0.7983\n",
      "Recall:\t\t0.8602\n",
      "F1:\t\t\t0.8281\n",
      "\n",
      "fold_1, epoch_21, Loss: 0.4776\n",
      "fold_1, epoch_22, Loss: 0.4741\n",
      "fold_1, epoch_23, Loss: 0.4743\n",
      "fold_1, epoch_24, Loss: 0.4709\n",
      "fold_1, epoch_25, Loss: 0.4684\n",
      "fold_1, epoch_26, Loss: 0.4698\n",
      "fold_1, epoch_27, Loss: 0.4617\n",
      "fold_1, epoch_28, Loss: 0.4637\n",
      "fold_1, epoch_29, Loss: 0.4622\n",
      "fold_1, epoch_30, Loss: 0.4598\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4605\n",
      "Accuracy:\t0.8509\n",
      "AUC:\t\t0.8963\n",
      "Precision:\t0.8351\n",
      "Recall:\t\t0.8752\n",
      "F1:\t\t\t0.8547\n",
      "\n",
      "fold_1, epoch_31, Loss: 0.4544\n",
      "fold_1, epoch_32, Loss: 0.4539\n",
      "fold_1, epoch_33, Loss: 0.4577\n",
      "fold_1, epoch_34, Loss: 0.4524\n",
      "fold_1, epoch_35, Loss: 0.4501\n",
      "fold_1, epoch_36, Loss: 0.4462\n",
      "fold_1, epoch_37, Loss: 0.4477\n",
      "fold_1, epoch_38, Loss: 0.4406\n",
      "fold_1, epoch_39, Loss: 0.4465\n",
      "fold_1, epoch_40, Loss: 0.4412\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4402\n",
      "Accuracy:\t0.8717\n",
      "AUC:\t\t0.9043\n",
      "Precision:\t0.8642\n",
      "Recall:\t\t0.8811\n",
      "F1:\t\t\t0.8726\n",
      "\n",
      "fold_1, epoch_41, Loss: 0.4437\n",
      "fold_1, epoch_42, Loss: 0.4382\n",
      "fold_1, epoch_43, Loss: 0.4384\n",
      "fold_1, epoch_44, Loss: 0.4347\n",
      "fold_1, epoch_45, Loss: 0.4382\n",
      "fold_1, epoch_46, Loss: 0.4340\n",
      "fold_1, epoch_47, Loss: 0.4347\n",
      "fold_1, epoch_48, Loss: 0.4362\n",
      "fold_1, epoch_49, Loss: 0.4324\n",
      "fold_1, epoch_50, Loss: 0.4288\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4249\n",
      "Accuracy:\t0.8874\n",
      "AUC:\t\t0.9150\n",
      "Precision:\t0.8780\n",
      "Recall:\t\t0.9007\n",
      "F1:\t\t\t0.8892\n",
      "\n",
      "fold_1, epoch_51, Loss: 0.4316\n",
      "fold_1, epoch_52, Loss: 0.4257\n",
      "fold_1, epoch_53, Loss: 0.4286\n",
      "fold_1, epoch_54, Loss: 0.4298\n",
      "fold_1, epoch_55, Loss: 0.4321\n",
      "fold_1, epoch_56, Loss: 0.4285\n",
      "fold_1, epoch_57, Loss: 0.4276\n",
      "fold_1, epoch_58, Loss: 0.4274\n",
      "fold_1, epoch_59, Loss: 0.4229\n",
      "fold_1, epoch_60, Loss: 0.4213\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4447\n",
      "Accuracy:\t0.8667\n",
      "AUC:\t\t0.9034\n",
      "Precision:\t0.8511\n",
      "Recall:\t\t0.8859\n",
      "F1:\t\t\t0.8682\n",
      "\n",
      "fold_1, epoch_61, Loss: 0.4199\n",
      "fold_1, epoch_62, Loss: 0.4209\n",
      "fold_1, epoch_63, Loss: 0.4235\n",
      "fold_1, epoch_64, Loss: 0.4161\n",
      "fold_1, epoch_65, Loss: 0.4185\n",
      "fold_1, epoch_66, Loss: 0.4155\n",
      "fold_1, epoch_67, Loss: 0.4152\n",
      "fold_1, epoch_68, Loss: 0.4122\n",
      "fold_1, epoch_69, Loss: 0.4246\n",
      "fold_1, epoch_70, Loss: 0.4157\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4278\n",
      "Accuracy:\t0.8840\n",
      "AUC:\t\t0.9117\n",
      "Precision:\t0.8600\n",
      "Recall:\t\t0.9151\n",
      "F1:\t\t\t0.8867\n",
      "\n",
      "fold_1, epoch_71, Loss: 0.4206\n",
      "fold_1, epoch_72, Loss: 0.4152\n",
      "fold_1, epoch_73, Loss: 0.4106\n",
      "fold_1, epoch_74, Loss: 0.4140\n",
      "fold_1, epoch_75, Loss: 0.4080\n",
      "fold_1, epoch_76, Loss: 0.4090\n",
      "fold_1, epoch_77, Loss: 0.4093\n",
      "fold_1, epoch_78, Loss: 0.4182\n",
      "fold_1, epoch_79, Loss: 0.4203\n",
      "fold_1, epoch_80, Loss: 0.4070\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4009\n",
      "Accuracy:\t0.9114\n",
      "AUC:\t\t0.9250\n",
      "Precision:\t0.9017\n",
      "Recall:\t\t0.9250\n",
      "F1:\t\t\t0.9132\n",
      "\n",
      "fold_1, epoch_81, Loss: 0.4096\n",
      "fold_1, epoch_82, Loss: 0.4076\n",
      "fold_1, epoch_83, Loss: 0.4094\n",
      "fold_1, epoch_84, Loss: 0.4075\n",
      "fold_1, epoch_85, Loss: 0.4131\n",
      "fold_1, epoch_86, Loss: 0.4237\n",
      "fold_1, epoch_87, Loss: 0.4115\n",
      "fold_1, epoch_88, Loss: 0.4070\n",
      "fold_1, epoch_89, Loss: 0.4010\n",
      "fold_1, epoch_90, Loss: 0.4046\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4020\n",
      "Accuracy:\t0.9107\n",
      "AUC:\t\t0.9223\n",
      "Precision:\t0.9008\n",
      "Recall:\t\t0.9219\n",
      "F1:\t\t\t0.9113\n",
      "\n",
      "fold_1, epoch_91, Loss: 0.4010\n",
      "fold_1, epoch_92, Loss: 0.4058\n",
      "fold_1, epoch_93, Loss: 0.4017\n",
      "fold_1, epoch_94, Loss: 0.3986\n",
      "fold_1, epoch_95, Loss: 0.4076\n",
      "fold_1, epoch_96, Loss: 0.4126\n",
      "fold_1, epoch_97, Loss: 0.4006\n",
      "fold_1, epoch_98, Loss: 0.4003\n",
      "fold_1, epoch_99, Loss: 0.3989\n",
      "fold_1, epoch_100, Loss: 0.3968\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3996\n",
      "Accuracy:\t0.9120\n",
      "AUC:\t\t0.9299\n",
      "Precision:\t0.9164\n",
      "Recall:\t\t0.9059\n",
      "F1:\t\t\t0.9111\n",
      "\n",
      "fold_1, epoch_101, Loss: 0.4010\n",
      "fold_1, epoch_102, Loss: 0.3958\n",
      "fold_1, epoch_103, Loss: 0.3994\n",
      "fold_1, epoch_104, Loss: 0.3972\n",
      "fold_1, epoch_105, Loss: 0.4004\n",
      "fold_1, epoch_106, Loss: 0.4043\n",
      "fold_1, epoch_107, Loss: 0.3918\n",
      "fold_1, epoch_108, Loss: 0.3912\n",
      "fold_1, epoch_109, Loss: 0.3910\n",
      "fold_1, epoch_110, Loss: 0.3950\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3908\n",
      "Accuracy:\t0.9223\n",
      "AUC:\t\t0.9339\n",
      "Precision:\t0.9216\n",
      "Recall:\t\t0.9244\n",
      "F1:\t\t\t0.9230\n",
      "\n",
      "fold_1, epoch_111, Loss: 0.4116\n",
      "fold_1, epoch_112, Loss: 0.3984\n",
      "fold_1, epoch_113, Loss: 0.3965\n",
      "fold_1, epoch_114, Loss: 0.3971\n",
      "fold_1, epoch_115, Loss: 0.3908\n",
      "fold_1, epoch_116, Loss: 0.3923\n",
      "fold_1, epoch_117, Loss: 0.3911\n",
      "fold_1, epoch_118, Loss: 0.3882\n",
      "fold_1, epoch_119, Loss: 0.3950\n",
      "fold_1, epoch_120, Loss: 0.3918\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3927\n",
      "Accuracy:\t0.9191\n",
      "AUC:\t\t0.9332\n",
      "Precision:\t0.9153\n",
      "Recall:\t\t0.9241\n",
      "F1:\t\t\t0.9197\n",
      "\n",
      "fold_1, epoch_121, Loss: 0.3953\n",
      "fold_1, epoch_122, Loss: 0.3899\n",
      "fold_1, epoch_123, Loss: 0.3906\n",
      "fold_1, epoch_124, Loss: 0.3864\n",
      "fold_1, epoch_125, Loss: 0.3891\n",
      "fold_1, epoch_126, Loss: 0.3856\n",
      "fold_1, epoch_127, Loss: 0.3897\n",
      "fold_1, epoch_128, Loss: 0.3890\n",
      "fold_1, epoch_129, Loss: 0.3921\n",
      "fold_1, epoch_130, Loss: 0.3882\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3878\n",
      "Accuracy:\t0.9247\n",
      "AUC:\t\t0.9367\n",
      "Precision:\t0.9187\n",
      "Recall:\t\t0.9325\n",
      "F1:\t\t\t0.9255\n",
      "\n",
      "fold_1, epoch_131, Loss: 0.3913\n",
      "fold_1, epoch_132, Loss: 0.3835\n",
      "fold_1, epoch_133, Loss: 0.3850\n",
      "fold_1, epoch_134, Loss: 0.3855\n",
      "fold_1, epoch_135, Loss: 0.3946\n",
      "fold_1, epoch_136, Loss: 0.3882\n",
      "fold_1, epoch_137, Loss: 0.3883\n",
      "fold_1, epoch_138, Loss: 0.3899\n",
      "fold_1, epoch_139, Loss: 0.3865\n",
      "fold_1, epoch_140, Loss: 0.3839\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3835\n",
      "Accuracy:\t0.9290\n",
      "AUC:\t\t0.9404\n",
      "Precision:\t0.9293\n",
      "Recall:\t\t0.9271\n",
      "F1:\t\t\t0.9282\n",
      "\n",
      "fold_1, epoch_141, Loss: 0.3840\n",
      "fold_1, epoch_142, Loss: 0.3824\n",
      "fold_1, epoch_143, Loss: 0.3823\n",
      "fold_1, epoch_144, Loss: 0.3881\n",
      "fold_1, epoch_145, Loss: 0.3831\n",
      "fold_1, epoch_146, Loss: 0.3827\n",
      "fold_1, epoch_147, Loss: 0.3801\n",
      "fold_1, epoch_148, Loss: 0.3812\n",
      "fold_1, epoch_149, Loss: 0.3837\n",
      "fold_1, epoch_150, Loss: 0.3838\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3767\n",
      "Accuracy:\t0.9364\n",
      "AUC:\t\t0.9416\n",
      "Precision:\t0.9381\n",
      "Recall:\t\t0.9337\n",
      "F1:\t\t\t0.9359\n",
      "\n",
      "fold_1, epoch_151, Loss: 0.3849\n",
      "fold_1, epoch_152, Loss: 0.3894\n",
      "fold_1, epoch_153, Loss: 0.3795\n",
      "fold_1, epoch_154, Loss: 0.3832\n",
      "fold_1, epoch_155, Loss: 0.3840\n",
      "fold_1, epoch_156, Loss: 0.3795\n",
      "fold_1, epoch_157, Loss: 0.3875\n",
      "fold_1, epoch_158, Loss: 0.3823\n",
      "fold_1, epoch_159, Loss: 0.3805\n",
      "fold_1, epoch_160, Loss: 0.3815\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3813\n",
      "Accuracy:\t0.9311\n",
      "AUC:\t\t0.9414\n",
      "Precision:\t0.9340\n",
      "Recall:\t\t0.9274\n",
      "F1:\t\t\t0.9307\n",
      "\n",
      "fold_1, epoch_161, Loss: 0.3787\n",
      "fold_1, epoch_162, Loss: 0.3780\n",
      "fold_1, epoch_163, Loss: 0.3825\n",
      "fold_1, epoch_164, Loss: 0.3794\n",
      "fold_1, epoch_165, Loss: 0.3814\n",
      "fold_1, epoch_166, Loss: 0.3799\n",
      "fold_1, epoch_167, Loss: 0.3804\n",
      "fold_1, epoch_168, Loss: 0.3889\n",
      "fold_1, epoch_169, Loss: 0.3776\n",
      "fold_1, epoch_170, Loss: 0.3744\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3743\n",
      "Accuracy:\t0.9380\n",
      "AUC:\t\t0.9460\n",
      "Precision:\t0.9455\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9377\n",
      "\n",
      "fold_1, epoch_171, Loss: 0.3794\n",
      "fold_1, epoch_172, Loss: 0.3773\n",
      "fold_1, epoch_173, Loss: 0.3833\n",
      "fold_1, epoch_174, Loss: 0.3769\n",
      "fold_1, epoch_175, Loss: 0.3765\n",
      "fold_1, epoch_176, Loss: 0.3779\n",
      "fold_1, epoch_177, Loss: 0.3738\n",
      "fold_1, epoch_178, Loss: 0.3808\n",
      "fold_1, epoch_179, Loss: 0.3802\n",
      "fold_1, epoch_180, Loss: 0.3840\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3853\n",
      "Accuracy:\t0.9272\n",
      "AUC:\t\t0.9429\n",
      "Precision:\t0.9495\n",
      "Recall:\t\t0.9016\n",
      "F1:\t\t\t0.9249\n",
      "\n",
      "fold_1, epoch_181, Loss: 0.3794\n",
      "fold_1, epoch_182, Loss: 0.3757\n",
      "fold_1, epoch_183, Loss: 0.3757\n",
      "fold_1, epoch_184, Loss: 0.3777\n",
      "fold_1, epoch_185, Loss: 0.3839\n",
      "fold_1, epoch_186, Loss: 0.3767\n",
      "fold_1, epoch_187, Loss: 0.3759\n",
      "fold_1, epoch_188, Loss: 0.3740\n",
      "fold_1, epoch_189, Loss: 0.3815\n",
      "fold_1, epoch_190, Loss: 0.3756\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3776\n",
      "Accuracy:\t0.9351\n",
      "AUC:\t\t0.9446\n",
      "Precision:\t0.9348\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9346\n",
      "\n",
      "fold_1, epoch_191, Loss: 0.3792\n",
      "fold_1, epoch_192, Loss: 0.3823\n",
      "fold_1, epoch_193, Loss: 0.3733\n",
      "fold_1, epoch_194, Loss: 0.3777\n",
      "fold_1, epoch_195, Loss: 0.3768\n",
      "fold_1, epoch_196, Loss: 0.3737\n",
      "fold_1, epoch_197, Loss: 0.3747\n",
      "fold_1, epoch_198, Loss: 0.3732\n",
      "fold_1, epoch_199, Loss: 0.3744\n",
      "fold_1, epoch_200, Loss: 0.3747\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3759\n",
      "Accuracy:\t0.9363\n",
      "AUC:\t\t0.9461\n",
      "Precision:\t0.9424\n",
      "Recall:\t\t0.9286\n",
      "F1:\t\t\t0.9355\n",
      "\n",
      "fold_1, epoch_201, Loss: 0.3717\n",
      "fold_1, epoch_202, Loss: 0.3705\n",
      "fold_1, epoch_203, Loss: 0.3748\n",
      "fold_1, epoch_204, Loss: 0.3723\n",
      "fold_1, epoch_205, Loss: 0.3731\n",
      "fold_1, epoch_206, Loss: 0.3700\n",
      "fold_1, epoch_207, Loss: 0.3720\n",
      "fold_1, epoch_208, Loss: 0.3765\n",
      "fold_1, epoch_209, Loss: 0.3734\n",
      "fold_1, epoch_210, Loss: 0.3695\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3671\n",
      "Accuracy:\t0.9460\n",
      "AUC:\t\t0.9503\n",
      "Precision:\t0.9471\n",
      "Recall:\t\t0.9445\n",
      "F1:\t\t\t0.9458\n",
      "\n",
      "fold_1, epoch_211, Loss: 0.3722\n",
      "fold_1, epoch_212, Loss: 0.3735\n",
      "fold_1, epoch_213, Loss: 0.3698\n",
      "fold_1, epoch_214, Loss: 0.3723\n",
      "fold_1, epoch_215, Loss: 0.3748\n",
      "fold_1, epoch_216, Loss: 0.3760\n",
      "fold_1, epoch_217, Loss: 0.3674\n",
      "fold_1, epoch_218, Loss: 0.3686\n",
      "fold_1, epoch_219, Loss: 0.3731\n",
      "fold_1, epoch_220, Loss: 0.3701\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3680\n",
      "Accuracy:\t0.9450\n",
      "AUC:\t\t0.9482\n",
      "Precision:\t0.9520\n",
      "Recall:\t\t0.9371\n",
      "F1:\t\t\t0.9445\n",
      "\n",
      "fold_1, epoch_221, Loss: 0.3717\n",
      "fold_1, epoch_222, Loss: 0.3681\n",
      "fold_1, epoch_223, Loss: 0.3717\n",
      "fold_1, epoch_224, Loss: 0.3710\n",
      "fold_1, epoch_225, Loss: 0.3696\n",
      "fold_1, epoch_226, Loss: 0.3659\n",
      "fold_1, epoch_227, Loss: 0.3660\n",
      "fold_1, epoch_228, Loss: 0.3738\n",
      "fold_1, epoch_229, Loss: 0.3709\n",
      "fold_1, epoch_230, Loss: 0.3673\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3686\n",
      "Accuracy:\t0.9443\n",
      "AUC:\t\t0.9484\n",
      "Precision:\t0.9470\n",
      "Recall:\t\t0.9411\n",
      "F1:\t\t\t0.9440\n",
      "\n",
      "fold_1, epoch_231, Loss: 0.3656\n",
      "fold_1, epoch_232, Loss: 0.3680\n",
      "fold_1, epoch_233, Loss: 0.3691\n",
      "fold_1, epoch_234, Loss: 0.3686\n",
      "fold_1, epoch_235, Loss: 0.3726\n",
      "fold_1, epoch_236, Loss: 0.3688\n",
      "fold_1, epoch_237, Loss: 0.3662\n",
      "fold_1, epoch_238, Loss: 0.3708\n",
      "fold_1, epoch_239, Loss: 0.3689\n",
      "fold_1, epoch_240, Loss: 0.3696\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3657\n",
      "Accuracy:\t0.9474\n",
      "AUC:\t\t0.9524\n",
      "Precision:\t0.9546\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9470\n",
      "\n",
      "fold_1, epoch_241, Loss: 0.3680\n",
      "fold_1, epoch_242, Loss: 0.3711\n",
      "fold_1, epoch_243, Loss: 0.3709\n",
      "fold_1, epoch_244, Loss: 0.3670\n",
      "fold_1, epoch_245, Loss: 0.3676\n",
      "fold_1, epoch_246, Loss: 0.3643\n",
      "fold_1, epoch_247, Loss: 0.3693\n",
      "fold_1, epoch_248, Loss: 0.3672\n",
      "fold_1, epoch_249, Loss: 0.3666\n",
      "fold_1, epoch_250, Loss: 0.3659\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3636\n",
      "Accuracy:\t0.9493\n",
      "AUC:\t\t0.9539\n",
      "Precision:\t0.9542\n",
      "Recall:\t\t0.9435\n",
      "F1:\t\t\t0.9488\n",
      "\n",
      "fold_1, epoch_251, Loss: 0.3696\n",
      "fold_1, epoch_252, Loss: 0.3696\n",
      "fold_1, epoch_253, Loss: 0.3655\n",
      "fold_1, epoch_254, Loss: 0.3664\n",
      "fold_1, epoch_255, Loss: 0.3637\n",
      "fold_1, epoch_256, Loss: 0.3623\n",
      "fold_1, epoch_257, Loss: 0.3660\n",
      "fold_1, epoch_258, Loss: 0.3674\n",
      "fold_1, epoch_259, Loss: 0.3682\n",
      "fold_1, epoch_260, Loss: 0.3671\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3639\n",
      "Accuracy:\t0.9495\n",
      "AUC:\t\t0.9522\n",
      "Precision:\t0.9582\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9488\n",
      "\n",
      "fold_1, epoch_261, Loss: 0.3653\n",
      "fold_1, epoch_262, Loss: 0.3696\n",
      "fold_1, epoch_263, Loss: 0.3639\n",
      "fold_1, epoch_264, Loss: 0.3711\n",
      "fold_1, epoch_265, Loss: 0.3614\n",
      "fold_1, epoch_266, Loss: 0.3630\n",
      "fold_1, epoch_267, Loss: 0.3659\n",
      "fold_1, epoch_268, Loss: 0.3627\n",
      "fold_1, epoch_269, Loss: 0.3656\n",
      "fold_1, epoch_270, Loss: 0.3671\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3654\n",
      "Accuracy:\t0.9477\n",
      "AUC:\t\t0.9534\n",
      "Precision:\t0.9563\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9471\n",
      "\n",
      "fold_1, epoch_271, Loss: 0.3665\n",
      "fold_1, epoch_272, Loss: 0.3625\n",
      "fold_1, epoch_273, Loss: 0.3628\n",
      "fold_1, epoch_274, Loss: 0.3655\n",
      "fold_1, epoch_275, Loss: 0.3655\n",
      "fold_1, epoch_276, Loss: 0.3650\n",
      "fold_1, epoch_277, Loss: 0.3636\n",
      "fold_1, epoch_278, Loss: 0.3647\n",
      "fold_1, epoch_279, Loss: 0.3612\n",
      "fold_1, epoch_280, Loss: 0.3629\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3646\n",
      "Accuracy:\t0.9481\n",
      "AUC:\t\t0.9548\n",
      "Precision:\t0.9533\n",
      "Recall:\t\t0.9433\n",
      "F1:\t\t\t0.9483\n",
      "\n",
      "fold_1, epoch_281, Loss: 0.3620\n",
      "fold_1, epoch_282, Loss: 0.3629\n",
      "fold_1, epoch_283, Loss: 0.3620\n",
      "fold_1, epoch_284, Loss: 0.3627\n",
      "fold_1, epoch_285, Loss: 0.3623\n",
      "fold_1, epoch_286, Loss: 0.3616\n",
      "fold_1, epoch_287, Loss: 0.3599\n",
      "fold_1, epoch_288, Loss: 0.3657\n",
      "fold_1, epoch_289, Loss: 0.3644\n",
      "fold_1, epoch_290, Loss: 0.3650\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3661\n",
      "Accuracy:\t0.9468\n",
      "AUC:\t\t0.9545\n",
      "Precision:\t0.9582\n",
      "Recall:\t\t0.9330\n",
      "F1:\t\t\t0.9455\n",
      "\n",
      "fold_1, epoch_291, Loss: 0.3617\n",
      "fold_1, epoch_292, Loss: 0.3652\n",
      "fold_1, epoch_293, Loss: 0.3618\n",
      "fold_1, epoch_294, Loss: 0.3609\n",
      "fold_1, epoch_295, Loss: 0.3621\n",
      "fold_1, epoch_296, Loss: 0.3610\n",
      "fold_1, epoch_297, Loss: 0.3606\n",
      "fold_1, epoch_298, Loss: 0.3649\n",
      "fold_1, epoch_299, Loss: 0.3611\n",
      "fold_1, epoch_300, Loss: 0.3616\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3563\n",
      "Accuracy:\t0.9569\n",
      "AUC:\t\t0.9574\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9453\n",
      "F1:\t\t\t0.9567\n",
      "\n",
      "fold_1, epoch_301, Loss: 0.3594\n",
      "fold_1, epoch_302, Loss: 0.3618\n",
      "fold_1, epoch_303, Loss: 0.3614\n",
      "fold_1, epoch_304, Loss: 0.3636\n",
      "fold_1, epoch_305, Loss: 0.3622\n",
      "fold_1, epoch_306, Loss: 0.3578\n",
      "fold_1, epoch_307, Loss: 0.3590\n",
      "fold_1, epoch_308, Loss: 0.3595\n",
      "fold_1, epoch_309, Loss: 0.3610\n",
      "fold_1, epoch_310, Loss: 0.3597\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3583\n",
      "Accuracy:\t0.9547\n",
      "AUC:\t\t0.9572\n",
      "Precision:\t0.9687\n",
      "Recall:\t\t0.9395\n",
      "F1:\t\t\t0.9539\n",
      "\n",
      "fold_1, epoch_311, Loss: 0.3586\n",
      "fold_1, epoch_312, Loss: 0.3664\n",
      "fold_1, epoch_313, Loss: 0.3632\n",
      "fold_1, epoch_314, Loss: 0.3609\n",
      "fold_1, epoch_315, Loss: 0.3598\n",
      "fold_1, epoch_316, Loss: 0.3612\n",
      "fold_1, epoch_317, Loss: 0.3627\n",
      "fold_1, epoch_318, Loss: 0.3635\n",
      "fold_1, epoch_319, Loss: 0.3600\n",
      "fold_1, epoch_320, Loss: 0.3647\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3653\n",
      "Accuracy:\t0.9479\n",
      "AUC:\t\t0.9534\n",
      "Precision:\t0.9600\n",
      "Recall:\t\t0.9340\n",
      "F1:\t\t\t0.9468\n",
      "\n",
      "fold_1, epoch_321, Loss: 0.3635\n",
      "fold_1, epoch_322, Loss: 0.3579\n",
      "fold_1, epoch_323, Loss: 0.3591\n",
      "fold_1, epoch_324, Loss: 0.3637\n",
      "fold_1, epoch_325, Loss: 0.3641\n",
      "fold_1, epoch_326, Loss: 0.3600\n",
      "fold_1, epoch_327, Loss: 0.3603\n",
      "fold_1, epoch_328, Loss: 0.3647\n",
      "fold_1, epoch_329, Loss: 0.3598\n",
      "fold_1, epoch_330, Loss: 0.3574\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3581\n",
      "Accuracy:\t0.9551\n",
      "AUC:\t\t0.9577\n",
      "Precision:\t0.9642\n",
      "Recall:\t\t0.9454\n",
      "F1:\t\t\t0.9547\n",
      "\n",
      "fold_1, epoch_331, Loss: 0.3619\n",
      "fold_1, epoch_332, Loss: 0.3632\n",
      "fold_1, epoch_333, Loss: 0.3622\n",
      "fold_1, epoch_334, Loss: 0.3594\n",
      "fold_1, epoch_335, Loss: 0.3579\n",
      "fold_1, epoch_336, Loss: 0.3628\n",
      "fold_1, epoch_337, Loss: 0.3593\n",
      "fold_1, epoch_338, Loss: 0.3554\n",
      "fold_1, epoch_339, Loss: 0.3597\n",
      "fold_1, epoch_340, Loss: 0.3614\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3602\n",
      "Accuracy:\t0.9529\n",
      "AUC:\t\t0.9573\n",
      "Precision:\t0.9657\n",
      "Recall:\t\t0.9388\n",
      "F1:\t\t\t0.9521\n",
      "\n",
      "fold_1, epoch_341, Loss: 0.3582\n",
      "fold_1, epoch_342, Loss: 0.3570\n",
      "fold_1, epoch_343, Loss: 0.3567\n",
      "fold_1, epoch_344, Loss: 0.3599\n",
      "fold_1, epoch_345, Loss: 0.3600\n",
      "fold_1, epoch_346, Loss: 0.3598\n",
      "fold_1, epoch_347, Loss: 0.3591\n",
      "fold_1, epoch_348, Loss: 0.3561\n",
      "fold_1, epoch_349, Loss: 0.3565\n",
      "fold_1, epoch_350, Loss: 0.3588\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3652\n",
      "Accuracy:\t0.9475\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9628\n",
      "Recall:\t\t0.9307\n",
      "F1:\t\t\t0.9465\n",
      "\n",
      "fold_1, epoch_351, Loss: 0.3618\n",
      "fold_1, epoch_352, Loss: 0.3597\n",
      "fold_1, epoch_353, Loss: 0.3621\n",
      "fold_1, epoch_354, Loss: 0.3627\n",
      "fold_1, epoch_355, Loss: 0.3598\n",
      "fold_1, epoch_356, Loss: 0.3566\n",
      "fold_1, epoch_357, Loss: 0.3591\n",
      "fold_1, epoch_358, Loss: 0.3576\n",
      "fold_1, epoch_359, Loss: 0.3549\n",
      "fold_1, epoch_360, Loss: 0.3576\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3550\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9591\n",
      "Precision:\t0.9723\n",
      "Recall:\t\t0.9438\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_1, epoch_361, Loss: 0.3549\n",
      "fold_1, epoch_362, Loss: 0.3650\n",
      "fold_1, epoch_363, Loss: 0.3567\n",
      "fold_1, epoch_364, Loss: 0.3598\n",
      "fold_1, epoch_365, Loss: 0.3564\n",
      "fold_1, epoch_366, Loss: 0.3589\n",
      "fold_1, epoch_367, Loss: 0.3571\n",
      "fold_1, epoch_368, Loss: 0.3577\n",
      "fold_1, epoch_369, Loss: 0.3598\n",
      "fold_1, epoch_370, Loss: 0.3623\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3584\n",
      "Accuracy:\t0.9548\n",
      "AUC:\t\t0.9569\n",
      "Precision:\t0.9680\n",
      "Recall:\t\t0.9408\n",
      "F1:\t\t\t0.9542\n",
      "\n",
      "fold_1, epoch_371, Loss: 0.3568\n",
      "fold_1, epoch_372, Loss: 0.3547\n",
      "fold_1, epoch_373, Loss: 0.3546\n",
      "fold_1, epoch_374, Loss: 0.3559\n",
      "fold_1, epoch_375, Loss: 0.3595\n",
      "fold_1, epoch_376, Loss: 0.3563\n",
      "fold_1, epoch_377, Loss: 0.3553\n",
      "fold_1, epoch_378, Loss: 0.3550\n",
      "fold_1, epoch_379, Loss: 0.3557\n",
      "fold_1, epoch_380, Loss: 0.3565\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3547\n",
      "Accuracy:\t0.9585\n",
      "AUC:\t\t0.9609\n",
      "Precision:\t0.9721\n",
      "Recall:\t\t0.9447\n",
      "F1:\t\t\t0.9582\n",
      "\n",
      "fold_1, epoch_381, Loss: 0.3601\n",
      "fold_1, epoch_382, Loss: 0.3574\n",
      "fold_1, epoch_383, Loss: 0.3520\n",
      "fold_1, epoch_384, Loss: 0.3555\n",
      "fold_1, epoch_385, Loss: 0.3598\n",
      "fold_1, epoch_386, Loss: 0.3584\n",
      "fold_1, epoch_387, Loss: 0.3561\n",
      "fold_1, epoch_388, Loss: 0.3562\n",
      "fold_1, epoch_389, Loss: 0.3553\n",
      "fold_1, epoch_390, Loss: 0.3534\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3549\n",
      "Accuracy:\t0.9579\n",
      "AUC:\t\t0.9598\n",
      "Precision:\t0.9746\n",
      "Recall:\t\t0.9402\n",
      "F1:\t\t\t0.9571\n",
      "\n",
      "fold_1, epoch_391, Loss: 0.3569\n",
      "fold_1, epoch_392, Loss: 0.3537\n",
      "fold_1, epoch_393, Loss: 0.3578\n",
      "fold_1, epoch_394, Loss: 0.3554\n",
      "fold_1, epoch_395, Loss: 0.3560\n",
      "fold_1, epoch_396, Loss: 0.3607\n",
      "fold_1, epoch_397, Loss: 0.3568\n",
      "fold_1, epoch_398, Loss: 0.3557\n",
      "fold_1, epoch_399, Loss: 0.3582\n",
      "fold_1, epoch_400, Loss: 0.3589\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3543\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9708\n",
      "Recall:\t\t0.9464\n",
      "F1:\t\t\t0.9584\n",
      "\n",
      "fold_1, epoch_401, Loss: 0.3570\n",
      "fold_1, epoch_402, Loss: 0.3575\n",
      "fold_1, epoch_403, Loss: 0.3558\n",
      "fold_1, epoch_404, Loss: 0.3547\n",
      "fold_1, epoch_405, Loss: 0.3548\n",
      "fold_1, epoch_406, Loss: 0.3579\n",
      "fold_1, epoch_407, Loss: 0.3556\n",
      "fold_1, epoch_408, Loss: 0.3579\n",
      "fold_1, epoch_409, Loss: 0.3552\n",
      "fold_1, epoch_410, Loss: 0.3587\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3590\n",
      "Accuracy:\t0.9543\n",
      "AUC:\t\t0.9567\n",
      "Precision:\t0.9671\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9536\n",
      "\n",
      "fold_1, epoch_411, Loss: 0.3564\n",
      "fold_1, epoch_412, Loss: 0.3557\n",
      "fold_1, epoch_413, Loss: 0.3536\n",
      "fold_1, epoch_414, Loss: 0.3524\n",
      "fold_1, epoch_415, Loss: 0.3568\n",
      "fold_1, epoch_416, Loss: 0.3525\n",
      "fold_1, epoch_417, Loss: 0.3544\n",
      "fold_1, epoch_418, Loss: 0.3522\n",
      "fold_1, epoch_419, Loss: 0.3589\n",
      "fold_1, epoch_420, Loss: 0.3556\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3531\n",
      "Accuracy:\t0.9600\n",
      "AUC:\t\t0.9620\n",
      "Precision:\t0.9737\n",
      "Recall:\t\t0.9457\n",
      "F1:\t\t\t0.9595\n",
      "\n",
      "fold_1, epoch_421, Loss: 0.3555\n",
      "fold_1, epoch_422, Loss: 0.3560\n",
      "fold_1, epoch_423, Loss: 0.3550\n",
      "fold_1, epoch_424, Loss: 0.3530\n",
      "fold_1, epoch_425, Loss: 0.3572\n",
      "fold_1, epoch_426, Loss: 0.3540\n",
      "fold_1, epoch_427, Loss: 0.3539\n",
      "fold_1, epoch_428, Loss: 0.3561\n",
      "fold_1, epoch_429, Loss: 0.3529\n",
      "fold_1, epoch_430, Loss: 0.3527\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3512\n",
      "Accuracy:\t0.9620\n",
      "AUC:\t\t0.9624\n",
      "Precision:\t0.9759\n",
      "Recall:\t\t0.9478\n",
      "F1:\t\t\t0.9616\n",
      "\n",
      "fold_1, epoch_431, Loss: 0.3534\n",
      "fold_1, epoch_432, Loss: 0.3564\n",
      "fold_1, epoch_433, Loss: 0.3557\n",
      "fold_1, epoch_434, Loss: 0.3575\n",
      "fold_1, epoch_435, Loss: 0.3534\n",
      "fold_1, epoch_436, Loss: 0.3523\n",
      "fold_1, epoch_437, Loss: 0.3503\n",
      "fold_1, epoch_438, Loss: 0.3556\n",
      "fold_1, epoch_439, Loss: 0.3546\n",
      "fold_1, epoch_440, Loss: 0.3514\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3534\n",
      "Accuracy:\t0.9597\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9719\n",
      "Recall:\t\t0.9467\n",
      "F1:\t\t\t0.9591\n",
      "\n",
      "fold_1, epoch_441, Loss: 0.3527\n",
      "fold_1, epoch_442, Loss: 0.3520\n",
      "fold_1, epoch_443, Loss: 0.3597\n",
      "fold_1, epoch_444, Loss: 0.3527\n",
      "fold_1, epoch_445, Loss: 0.3564\n",
      "fold_1, epoch_446, Loss: 0.3513\n",
      "fold_1, epoch_447, Loss: 0.3535\n",
      "fold_1, epoch_448, Loss: 0.3526\n",
      "fold_1, epoch_449, Loss: 0.3526\n",
      "fold_1, epoch_450, Loss: 0.3512\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3505\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9624\n",
      "Precision:\t0.9765\n",
      "Recall:\t\t0.9491\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_1, epoch_451, Loss: 0.3526\n",
      "fold_1, epoch_452, Loss: 0.3550\n",
      "fold_1, epoch_453, Loss: 0.3559\n",
      "fold_1, epoch_454, Loss: 0.3540\n",
      "fold_1, epoch_455, Loss: 0.3568\n",
      "fold_1, epoch_456, Loss: 0.3519\n",
      "fold_1, epoch_457, Loss: 0.3537\n",
      "fold_1, epoch_458, Loss: 0.3544\n",
      "fold_1, epoch_459, Loss: 0.3559\n",
      "fold_1, epoch_460, Loss: 0.3547\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9616\n",
      "Precision:\t0.9716\n",
      "Recall:\t\t0.9464\n",
      "F1:\t\t\t0.9588\n",
      "\n",
      "fold_1, epoch_461, Loss: 0.3535\n",
      "fold_1, epoch_462, Loss: 0.3523\n",
      "fold_1, epoch_463, Loss: 0.3509\n",
      "fold_1, epoch_464, Loss: 0.3532\n",
      "fold_1, epoch_465, Loss: 0.3542\n",
      "fold_1, epoch_466, Loss: 0.3522\n",
      "fold_1, epoch_467, Loss: 0.3534\n",
      "fold_1, epoch_468, Loss: 0.3539\n",
      "fold_1, epoch_469, Loss: 0.3517\n",
      "fold_1, epoch_470, Loss: 0.3537\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3519\n",
      "Accuracy:\t0.9612\n",
      "AUC:\t\t0.9625\n",
      "Precision:\t0.9747\n",
      "Recall:\t\t0.9467\n",
      "F1:\t\t\t0.9605\n",
      "\n",
      "fold_1, epoch_471, Loss: 0.3543\n",
      "fold_1, epoch_472, Loss: 0.3524\n",
      "fold_1, epoch_473, Loss: 0.3523\n",
      "fold_1, epoch_474, Loss: 0.3508\n",
      "fold_1, epoch_475, Loss: 0.3536\n",
      "fold_1, epoch_476, Loss: 0.3510\n",
      "fold_1, epoch_477, Loss: 0.3535\n",
      "fold_1, epoch_478, Loss: 0.3537\n",
      "fold_1, epoch_479, Loss: 0.3539\n",
      "fold_1, epoch_480, Loss: 0.3507\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9625\n",
      "AUC:\t\t0.9631\n",
      "Precision:\t0.9768\n",
      "Recall:\t\t0.9475\n",
      "F1:\t\t\t0.9619\n",
      "\n",
      "fold_1, epoch_481, Loss: 0.3549\n",
      "fold_1, epoch_482, Loss: 0.3514\n",
      "fold_1, epoch_483, Loss: 0.3537\n",
      "fold_1, epoch_484, Loss: 0.3512\n",
      "fold_1, epoch_485, Loss: 0.3550\n",
      "fold_1, epoch_486, Loss: 0.3554\n",
      "fold_1, epoch_487, Loss: 0.3538\n",
      "fold_1, epoch_488, Loss: 0.3516\n",
      "fold_1, epoch_489, Loss: 0.3522\n",
      "fold_1, epoch_490, Loss: 0.3514\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3676\n",
      "Accuracy:\t0.9451\n",
      "AUC:\t\t0.9559\n",
      "Precision:\t0.9668\n",
      "Recall:\t\t0.9220\n",
      "F1:\t\t\t0.9439\n",
      "\n",
      "fold_1, epoch_491, Loss: 0.3546\n",
      "fold_1, epoch_492, Loss: 0.3527\n",
      "fold_1, epoch_493, Loss: 0.3503\n",
      "fold_1, epoch_494, Loss: 0.3542\n",
      "fold_1, epoch_495, Loss: 0.3533\n",
      "fold_1, epoch_496, Loss: 0.3518\n",
      "fold_1, epoch_497, Loss: 0.3513\n",
      "fold_1, epoch_498, Loss: 0.3502\n",
      "fold_1, epoch_499, Loss: 0.3476\n",
      "fold_1, epoch_500, Loss: 0.3516\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3568\n",
      "Accuracy:\t0.9559\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9724\n",
      "Recall:\t\t0.9390\n",
      "F1:\t\t\t0.9554\n",
      "\n",
      "fold_1, epoch_501, Loss: 0.3563\n",
      "fold_1, epoch_502, Loss: 0.3536\n",
      "fold_1, epoch_503, Loss: 0.3546\n",
      "fold_1, epoch_504, Loss: 0.3499\n",
      "fold_1, epoch_505, Loss: 0.3486\n",
      "fold_1, epoch_506, Loss: 0.3553\n",
      "fold_1, epoch_507, Loss: 0.3519\n",
      "fold_1, epoch_508, Loss: 0.3539\n",
      "fold_1, epoch_509, Loss: 0.3482\n",
      "fold_1, epoch_510, Loss: 0.3491\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3484\n",
      "Accuracy:\t0.9649\n",
      "AUC:\t\t0.9646\n",
      "Precision:\t0.9790\n",
      "Recall:\t\t0.9505\n",
      "F1:\t\t\t0.9645\n",
      "\n",
      "fold_1, epoch_511, Loss: 0.3521\n",
      "fold_1, epoch_512, Loss: 0.3520\n",
      "fold_1, epoch_513, Loss: 0.3516\n",
      "fold_1, epoch_514, Loss: 0.3516\n",
      "fold_1, epoch_515, Loss: 0.3490\n",
      "fold_1, epoch_516, Loss: 0.3516\n",
      "fold_1, epoch_517, Loss: 0.3483\n",
      "fold_1, epoch_518, Loss: 0.3511\n",
      "fold_1, epoch_519, Loss: 0.3522\n",
      "fold_1, epoch_520, Loss: 0.3522\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3488\n",
      "Accuracy:\t0.9646\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9791\n",
      "Recall:\t\t0.9496\n",
      "F1:\t\t\t0.9642\n",
      "\n",
      "fold_1, epoch_521, Loss: 0.3510\n",
      "fold_1, epoch_522, Loss: 0.3531\n",
      "fold_1, epoch_523, Loss: 0.3516\n",
      "fold_1, epoch_524, Loss: 0.3505\n",
      "fold_1, epoch_525, Loss: 0.3531\n",
      "fold_1, epoch_526, Loss: 0.3537\n",
      "fold_1, epoch_527, Loss: 0.3502\n",
      "fold_1, epoch_528, Loss: 0.3522\n",
      "fold_1, epoch_529, Loss: 0.3506\n",
      "fold_1, epoch_530, Loss: 0.3558\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3535\n",
      "Accuracy:\t0.9594\n",
      "AUC:\t\t0.9616\n",
      "Precision:\t0.9796\n",
      "Recall:\t\t0.9394\n",
      "F1:\t\t\t0.9591\n",
      "\n",
      "fold_1, epoch_531, Loss: 0.3526\n",
      "fold_1, epoch_532, Loss: 0.3516\n",
      "fold_1, epoch_533, Loss: 0.3494\n",
      "fold_1, epoch_534, Loss: 0.3487\n",
      "fold_1, epoch_535, Loss: 0.3488\n",
      "fold_1, epoch_536, Loss: 0.3499\n",
      "fold_1, epoch_537, Loss: 0.3547\n",
      "fold_1, epoch_538, Loss: 0.3522\n",
      "fold_1, epoch_539, Loss: 0.3456\n",
      "fold_1, epoch_540, Loss: 0.3499\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3481\n",
      "Accuracy:\t0.9652\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9835\n",
      "Recall:\t\t0.9470\n",
      "F1:\t\t\t0.9649\n",
      "\n",
      "fold_1, epoch_541, Loss: 0.3493\n",
      "fold_1, epoch_542, Loss: 0.3503\n",
      "fold_1, epoch_543, Loss: 0.3511\n",
      "fold_1, epoch_544, Loss: 0.3510\n",
      "fold_1, epoch_545, Loss: 0.3485\n",
      "fold_1, epoch_546, Loss: 0.3513\n",
      "fold_1, epoch_547, Loss: 0.3523\n",
      "fold_1, epoch_548, Loss: 0.3555\n",
      "fold_1, epoch_549, Loss: 0.3514\n",
      "fold_1, epoch_550, Loss: 0.3500\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3483\n",
      "Accuracy:\t0.9647\n",
      "AUC:\t\t0.9657\n",
      "Precision:\t0.9802\n",
      "Recall:\t\t0.9484\n",
      "F1:\t\t\t0.9641\n",
      "\n",
      "fold_1, epoch_551, Loss: 0.3522\n",
      "fold_1, epoch_552, Loss: 0.3519\n",
      "fold_1, epoch_553, Loss: 0.3552\n",
      "fold_1, epoch_554, Loss: 0.3530\n",
      "fold_1, epoch_555, Loss: 0.3504\n",
      "fold_1, epoch_556, Loss: 0.3476\n",
      "fold_1, epoch_557, Loss: 0.3494\n",
      "fold_1, epoch_558, Loss: 0.3498\n",
      "fold_1, epoch_559, Loss: 0.3510\n",
      "fold_1, epoch_560, Loss: 0.3496\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3534\n",
      "Accuracy:\t0.9596\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9759\n",
      "Recall:\t\t0.9427\n",
      "F1:\t\t\t0.9590\n",
      "\n",
      "fold_1, epoch_561, Loss: 0.3507\n",
      "fold_1, epoch_562, Loss: 0.3485\n",
      "fold_1, epoch_563, Loss: 0.3504\n",
      "fold_1, epoch_564, Loss: 0.3492\n",
      "fold_1, epoch_565, Loss: 0.3499\n",
      "fold_1, epoch_566, Loss: 0.3500\n",
      "fold_1, epoch_567, Loss: 0.3477\n",
      "fold_1, epoch_568, Loss: 0.3499\n",
      "fold_1, epoch_569, Loss: 0.3514\n",
      "fold_1, epoch_570, Loss: 0.3496\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3474\n",
      "Accuracy:\t0.9658\n",
      "AUC:\t\t0.9647\n",
      "Precision:\t0.9824\n",
      "Recall:\t\t0.9483\n",
      "F1:\t\t\t0.9650\n",
      "\n",
      "fold_1, epoch_571, Loss: 0.3480\n",
      "fold_1, epoch_572, Loss: 0.3478\n",
      "fold_1, epoch_573, Loss: 0.3501\n",
      "fold_1, epoch_574, Loss: 0.3507\n",
      "fold_1, epoch_575, Loss: 0.3490\n",
      "fold_1, epoch_576, Loss: 0.3453\n",
      "fold_1, epoch_577, Loss: 0.3503\n",
      "fold_1, epoch_578, Loss: 0.3477\n",
      "fold_1, epoch_579, Loss: 0.3489\n",
      "fold_1, epoch_580, Loss: 0.3490\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9652\n",
      "AUC:\t\t0.9648\n",
      "Precision:\t0.9814\n",
      "Recall:\t\t0.9474\n",
      "F1:\t\t\t0.9641\n",
      "\n",
      "fold_1, epoch_581, Loss: 0.3485\n",
      "fold_1, epoch_582, Loss: 0.3478\n",
      "fold_1, epoch_583, Loss: 0.3498\n",
      "fold_1, epoch_584, Loss: 0.3491\n",
      "fold_1, epoch_585, Loss: 0.3518\n",
      "fold_1, epoch_586, Loss: 0.3490\n",
      "fold_1, epoch_587, Loss: 0.3494\n",
      "fold_1, epoch_588, Loss: 0.3501\n",
      "fold_1, epoch_589, Loss: 0.3493\n",
      "fold_1, epoch_590, Loss: 0.3495\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9620\n",
      "AUC:\t\t0.9651\n",
      "Precision:\t0.9786\n",
      "Recall:\t\t0.9449\n",
      "F1:\t\t\t0.9614\n",
      "\n",
      "fold_1, epoch_591, Loss: 0.3498\n",
      "fold_1, epoch_592, Loss: 0.3499\n",
      "fold_1, epoch_593, Loss: 0.3499\n",
      "fold_1, epoch_594, Loss: 0.3467\n",
      "fold_1, epoch_595, Loss: 0.3498\n",
      "fold_1, epoch_596, Loss: 0.3495\n",
      "fold_1, epoch_597, Loss: 0.3486\n",
      "fold_1, epoch_598, Loss: 0.3486\n",
      "fold_1, epoch_599, Loss: 0.3484\n",
      "fold_1, epoch_600, Loss: 0.3501\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3522\n",
      "Accuracy:\t0.9604\n",
      "AUC:\t\t0.9652\n",
      "Precision:\t0.9779\n",
      "Recall:\t\t0.9416\n",
      "F1:\t\t\t0.9594\n",
      "\n",
      "fold_1, epoch_601, Loss: 0.3459\n",
      "fold_1, epoch_602, Loss: 0.3486\n",
      "fold_1, epoch_603, Loss: 0.3460\n",
      "fold_1, epoch_604, Loss: 0.3494\n",
      "fold_1, epoch_605, Loss: 0.3499\n",
      "fold_1, epoch_606, Loss: 0.3496\n",
      "fold_1, epoch_607, Loss: 0.3508\n",
      "fold_1, epoch_608, Loss: 0.3484\n",
      "fold_1, epoch_609, Loss: 0.3489\n",
      "fold_1, epoch_610, Loss: 0.3477\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3452\n",
      "Accuracy:\t0.9681\n",
      "AUC:\t\t0.9673\n",
      "Precision:\t0.9846\n",
      "Recall:\t\t0.9509\n",
      "F1:\t\t\t0.9674\n",
      "\n",
      "fold_1, epoch_611, Loss: 0.3473\n",
      "fold_1, epoch_612, Loss: 0.3504\n",
      "fold_1, epoch_613, Loss: 0.3487\n",
      "fold_1, epoch_614, Loss: 0.3474\n",
      "fold_1, epoch_615, Loss: 0.3498\n",
      "fold_1, epoch_616, Loss: 0.3474\n",
      "fold_1, epoch_617, Loss: 0.3491\n",
      "fold_1, epoch_618, Loss: 0.3519\n",
      "fold_1, epoch_619, Loss: 0.3503\n",
      "fold_1, epoch_620, Loss: 0.3473\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3492\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9649\n",
      "Precision:\t0.9769\n",
      "Recall:\t\t0.9495\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_1, epoch_621, Loss: 0.3507\n",
      "fold_1, epoch_622, Loss: 0.3484\n",
      "fold_1, epoch_623, Loss: 0.3507\n",
      "fold_1, epoch_624, Loss: 0.3484\n",
      "fold_1, epoch_625, Loss: 0.3518\n",
      "fold_1, epoch_626, Loss: 0.3460\n",
      "fold_1, epoch_627, Loss: 0.3482\n",
      "fold_1, epoch_628, Loss: 0.3459\n",
      "fold_1, epoch_629, Loss: 0.3518\n",
      "fold_1, epoch_630, Loss: 0.3500\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3471\n",
      "Accuracy:\t0.9661\n",
      "AUC:\t\t0.9667\n",
      "Precision:\t0.9837\n",
      "Recall:\t\t0.9481\n",
      "F1:\t\t\t0.9656\n",
      "\n",
      "fold_1, epoch_631, Loss: 0.3479\n",
      "fold_1, epoch_632, Loss: 0.3462\n",
      "fold_1, epoch_633, Loss: 0.3490\n",
      "fold_1, epoch_634, Loss: 0.3508\n",
      "fold_1, epoch_635, Loss: 0.3475\n",
      "fold_1, epoch_636, Loss: 0.3489\n",
      "fold_1, epoch_637, Loss: 0.3499\n",
      "fold_1, epoch_638, Loss: 0.3499\n",
      "fold_1, epoch_639, Loss: 0.3482\n",
      "fold_1, epoch_640, Loss: 0.3488\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3470\n",
      "Accuracy:\t0.9662\n",
      "AUC:\t\t0.9650\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9479\n",
      "F1:\t\t\t0.9655\n",
      "\n",
      "fold_1, epoch_641, Loss: 0.3469\n",
      "fold_1, epoch_642, Loss: 0.3504\n",
      "fold_1, epoch_643, Loss: 0.3466\n",
      "fold_1, epoch_644, Loss: 0.3476\n",
      "fold_1, epoch_645, Loss: 0.3489\n",
      "fold_1, epoch_646, Loss: 0.3491\n",
      "fold_1, epoch_647, Loss: 0.3500\n",
      "fold_1, epoch_648, Loss: 0.3517\n",
      "fold_1, epoch_649, Loss: 0.3522\n",
      "fold_1, epoch_650, Loss: 0.3484\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3521\n",
      "Accuracy:\t0.9605\n",
      "AUC:\t\t0.9650\n",
      "Precision:\t0.9791\n",
      "Recall:\t\t0.9415\n",
      "F1:\t\t\t0.9599\n",
      "\n",
      "fold_1, epoch_651, Loss: 0.3483\n",
      "fold_1, epoch_652, Loss: 0.3463\n",
      "fold_1, epoch_653, Loss: 0.3478\n",
      "fold_1, epoch_654, Loss: 0.3491\n",
      "fold_1, epoch_655, Loss: 0.3495\n",
      "fold_1, epoch_656, Loss: 0.3484\n",
      "fold_1, epoch_657, Loss: 0.3476\n",
      "fold_1, epoch_658, Loss: 0.3490\n",
      "fold_1, epoch_659, Loss: 0.3472\n",
      "fold_1, epoch_660, Loss: 0.3478\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3470\n",
      "Accuracy:\t0.9664\n",
      "AUC:\t\t0.9666\n",
      "Precision:\t0.9833\n",
      "Recall:\t\t0.9487\n",
      "F1:\t\t\t0.9657\n",
      "\n",
      "fold_1, epoch_661, Loss: 0.3490\n",
      "fold_1, epoch_662, Loss: 0.3513\n",
      "fold_1, epoch_663, Loss: 0.3469\n",
      "fold_1, epoch_664, Loss: 0.3473\n",
      "fold_1, epoch_665, Loss: 0.3500\n",
      "fold_1, epoch_666, Loss: 0.3452\n",
      "fold_1, epoch_667, Loss: 0.3455\n",
      "fold_1, epoch_668, Loss: 0.3471\n",
      "fold_1, epoch_669, Loss: 0.3469\n",
      "fold_1, epoch_670, Loss: 0.3469\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3493\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9665\n",
      "Precision:\t0.9842\n",
      "Recall:\t\t0.9423\n",
      "F1:\t\t\t0.9628\n",
      "\n",
      "fold_1, epoch_671, Loss: 0.3487\n",
      "fold_1, epoch_672, Loss: 0.3482\n",
      "fold_1, epoch_673, Loss: 0.3488\n",
      "fold_1, epoch_674, Loss: 0.3477\n",
      "fold_1, epoch_675, Loss: 0.3470\n",
      "fold_1, epoch_676, Loss: 0.3469\n",
      "fold_1, epoch_677, Loss: 0.3506\n",
      "fold_1, epoch_678, Loss: 0.3491\n",
      "fold_1, epoch_679, Loss: 0.3491\n",
      "fold_1, epoch_680, Loss: 0.3482\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3478\n",
      "Accuracy:\t0.9652\n",
      "AUC:\t\t0.9653\n",
      "Precision:\t0.9802\n",
      "Recall:\t\t0.9491\n",
      "F1:\t\t\t0.9644\n",
      "\n",
      "fold_1, epoch_681, Loss: 0.3491\n",
      "fold_1, epoch_682, Loss: 0.3467\n",
      "fold_1, epoch_683, Loss: 0.3493\n",
      "fold_1, epoch_684, Loss: 0.3455\n",
      "fold_1, epoch_685, Loss: 0.3472\n",
      "fold_1, epoch_686, Loss: 0.3522\n",
      "fold_1, epoch_687, Loss: 0.3490\n",
      "fold_1, epoch_688, Loss: 0.3467\n",
      "fold_1, epoch_689, Loss: 0.3466\n",
      "fold_1, epoch_690, Loss: 0.3439\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3476\n",
      "Accuracy:\t0.9653\n",
      "AUC:\t\t0.9661\n",
      "Precision:\t0.9849\n",
      "Recall:\t\t0.9461\n",
      "F1:\t\t\t0.9651\n",
      "\n",
      "fold_1, epoch_691, Loss: 0.3477\n",
      "fold_1, epoch_692, Loss: 0.3471\n",
      "fold_1, epoch_693, Loss: 0.3464\n",
      "fold_1, epoch_694, Loss: 0.3486\n",
      "fold_1, epoch_695, Loss: 0.3498\n",
      "fold_1, epoch_696, Loss: 0.3469\n",
      "fold_1, epoch_697, Loss: 0.3467\n",
      "fold_1, epoch_698, Loss: 0.3496\n",
      "fold_1, epoch_699, Loss: 0.3463\n",
      "fold_1, epoch_700, Loss: 0.3451\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3480\n",
      "Accuracy:\t0.9650\n",
      "AUC:\t\t0.9670\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9453\n",
      "F1:\t\t\t0.9642\n",
      "\n",
      "fold_1, epoch_701, Loss: 0.3470\n",
      "fold_1, epoch_702, Loss: 0.3457\n",
      "fold_1, epoch_703, Loss: 0.3461\n",
      "fold_1, epoch_704, Loss: 0.3464\n",
      "fold_1, epoch_705, Loss: 0.3470\n",
      "fold_1, epoch_706, Loss: 0.3489\n",
      "fold_1, epoch_707, Loss: 0.3464\n",
      "fold_1, epoch_708, Loss: 0.3476\n",
      "fold_1, epoch_709, Loss: 0.3503\n",
      "fold_1, epoch_710, Loss: 0.3446\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3458\n",
      "Accuracy:\t0.9675\n",
      "AUC:\t\t0.9660\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9503\n",
      "F1:\t\t\t0.9668\n",
      "\n",
      "fold_1, epoch_711, Loss: 0.3461\n",
      "fold_1, epoch_712, Loss: 0.3503\n",
      "fold_1, epoch_713, Loss: 0.3487\n",
      "fold_1, epoch_714, Loss: 0.3493\n",
      "fold_1, epoch_715, Loss: 0.3490\n",
      "fold_1, epoch_716, Loss: 0.3463\n",
      "fold_1, epoch_717, Loss: 0.3481\n",
      "fold_1, epoch_718, Loss: 0.3458\n",
      "fold_1, epoch_719, Loss: 0.3483\n",
      "fold_1, epoch_720, Loss: 0.3466\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3468\n",
      "Accuracy:\t0.9662\n",
      "AUC:\t\t0.9656\n",
      "Precision:\t0.9843\n",
      "Recall:\t\t0.9474\n",
      "F1:\t\t\t0.9655\n",
      "\n",
      "fold_1, epoch_721, Loss: 0.3450\n",
      "fold_1, epoch_722, Loss: 0.3475\n",
      "fold_1, epoch_723, Loss: 0.3461\n",
      "fold_1, epoch_724, Loss: 0.3459\n",
      "fold_1, epoch_725, Loss: 0.3464\n",
      "fold_1, epoch_726, Loss: 0.3488\n",
      "fold_1, epoch_727, Loss: 0.3464\n",
      "fold_1, epoch_728, Loss: 0.3474\n",
      "fold_1, epoch_729, Loss: 0.3471\n",
      "fold_1, epoch_730, Loss: 0.3453\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3490\n",
      "Accuracy:\t0.9641\n",
      "AUC:\t\t0.9657\n",
      "Precision:\t0.9842\n",
      "Recall:\t\t0.9434\n",
      "F1:\t\t\t0.9634\n",
      "\n",
      "fold_1, epoch_731, Loss: 0.3502\n",
      "fold_1, epoch_732, Loss: 0.3458\n",
      "fold_1, epoch_733, Loss: 0.3467\n",
      "fold_1, epoch_734, Loss: 0.3469\n",
      "fold_1, epoch_735, Loss: 0.3465\n",
      "fold_1, epoch_736, Loss: 0.3455\n",
      "fold_1, epoch_737, Loss: 0.3447\n",
      "fold_1, epoch_738, Loss: 0.3441\n",
      "fold_1, epoch_739, Loss: 0.3461\n",
      "fold_1, epoch_740, Loss: 0.3466\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3485\n",
      "Accuracy:\t0.9646\n",
      "AUC:\t\t0.9651\n",
      "Precision:\t0.9833\n",
      "Recall:\t\t0.9451\n",
      "F1:\t\t\t0.9638\n",
      "\n",
      "fold_1, epoch_741, Loss: 0.3447\n",
      "fold_1, epoch_742, Loss: 0.3464\n",
      "fold_1, epoch_743, Loss: 0.3486\n",
      "fold_1, epoch_744, Loss: 0.3486\n",
      "fold_1, epoch_745, Loss: 0.3462\n",
      "fold_1, epoch_746, Loss: 0.3449\n",
      "fold_1, epoch_747, Loss: 0.3476\n",
      "fold_1, epoch_748, Loss: 0.3489\n",
      "fold_1, epoch_749, Loss: 0.3479\n",
      "fold_1, epoch_750, Loss: 0.3468\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3467\n",
      "Accuracy:\t0.9665\n",
      "AUC:\t\t0.9670\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9458\n",
      "F1:\t\t\t0.9658\n",
      "\n",
      "fold_1, epoch_751, Loss: 0.3450\n",
      "fold_1, epoch_752, Loss: 0.3422\n",
      "fold_1, epoch_753, Loss: 0.3462\n",
      "fold_1, epoch_754, Loss: 0.3470\n",
      "fold_1, epoch_755, Loss: 0.3491\n",
      "fold_1, epoch_756, Loss: 0.3479\n",
      "fold_1, epoch_757, Loss: 0.3470\n",
      "fold_1, epoch_758, Loss: 0.3460\n",
      "fold_1, epoch_759, Loss: 0.3478\n",
      "fold_1, epoch_760, Loss: 0.3457\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3440\n",
      "Accuracy:\t0.9691\n",
      "AUC:\t\t0.9693\n",
      "Precision:\t0.9846\n",
      "Recall:\t\t0.9532\n",
      "F1:\t\t\t0.9687\n",
      "\n",
      "fold_1, epoch_761, Loss: 0.3447\n",
      "fold_1, epoch_762, Loss: 0.3449\n",
      "fold_1, epoch_763, Loss: 0.3460\n",
      "fold_1, epoch_764, Loss: 0.3463\n",
      "fold_1, epoch_765, Loss: 0.3446\n",
      "fold_1, epoch_766, Loss: 0.3457\n",
      "fold_1, epoch_767, Loss: 0.3485\n",
      "fold_1, epoch_768, Loss: 0.3460\n",
      "fold_1, epoch_769, Loss: 0.3434\n",
      "fold_1, epoch_770, Loss: 0.3452\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3458\n",
      "Accuracy:\t0.9670\n",
      "AUC:\t\t0.9671\n",
      "Precision:\t0.9853\n",
      "Recall:\t\t0.9481\n",
      "F1:\t\t\t0.9664\n",
      "\n",
      "fold_1, epoch_771, Loss: 0.3453\n",
      "fold_1, epoch_772, Loss: 0.3477\n",
      "fold_1, epoch_773, Loss: 0.3457\n",
      "fold_1, epoch_774, Loss: 0.3458\n",
      "fold_1, epoch_775, Loss: 0.3462\n",
      "fold_1, epoch_776, Loss: 0.3440\n",
      "fold_1, epoch_777, Loss: 0.3445\n",
      "fold_1, epoch_778, Loss: 0.3452\n",
      "fold_1, epoch_779, Loss: 0.3452\n",
      "fold_1, epoch_780, Loss: 0.3450\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3442\n",
      "Accuracy:\t0.9691\n",
      "AUC:\t\t0.9683\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9506\n",
      "F1:\t\t\t0.9683\n",
      "\n",
      "fold_1, epoch_781, Loss: 0.3462\n",
      "fold_1, epoch_782, Loss: 0.3490\n",
      "fold_1, epoch_783, Loss: 0.3485\n",
      "fold_1, epoch_784, Loss: 0.3438\n",
      "fold_1, epoch_785, Loss: 0.3453\n",
      "fold_1, epoch_786, Loss: 0.3455\n",
      "fold_1, epoch_787, Loss: 0.3480\n",
      "fold_1, epoch_788, Loss: 0.3502\n",
      "fold_1, epoch_789, Loss: 0.3460\n",
      "fold_1, epoch_790, Loss: 0.3457\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3469\n",
      "Accuracy:\t0.9663\n",
      "AUC:\t\t0.9655\n",
      "Precision:\t0.9861\n",
      "Recall:\t\t0.9457\n",
      "F1:\t\t\t0.9655\n",
      "\n",
      "fold_1, epoch_791, Loss: 0.3459\n",
      "fold_1, epoch_792, Loss: 0.3470\n",
      "fold_1, epoch_793, Loss: 0.3458\n",
      "fold_1, epoch_794, Loss: 0.3491\n",
      "fold_1, epoch_795, Loss: 0.3458\n",
      "fold_1, epoch_796, Loss: 0.3452\n",
      "fold_1, epoch_797, Loss: 0.3461\n",
      "fold_1, epoch_798, Loss: 0.3443\n",
      "fold_1, epoch_799, Loss: 0.3455\n",
      "fold_1, epoch_800, Loss: 0.3468\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3442\n",
      "Accuracy:\t0.9691\n",
      "AUC:\t\t0.9679\n",
      "Precision:\t0.9887\n",
      "Recall:\t\t0.9489\n",
      "F1:\t\t\t0.9684\n",
      "\n",
      "fold_1, epoch_801, Loss: 0.3470\n",
      "fold_1, epoch_802, Loss: 0.3448\n",
      "fold_1, epoch_803, Loss: 0.3461\n",
      "fold_1, epoch_804, Loss: 0.3437\n",
      "fold_1, epoch_805, Loss: 0.3459\n",
      "fold_1, epoch_806, Loss: 0.3474\n",
      "fold_1, epoch_807, Loss: 0.3455\n",
      "fold_1, epoch_808, Loss: 0.3441\n",
      "fold_1, epoch_809, Loss: 0.3468\n",
      "fold_1, epoch_810, Loss: 0.3470\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3483\n",
      "Accuracy:\t0.9646\n",
      "AUC:\t\t0.9638\n",
      "Precision:\t0.9856\n",
      "Recall:\t\t0.9432\n",
      "F1:\t\t\t0.9640\n",
      "\n",
      "fold_1, epoch_811, Loss: 0.3474\n",
      "fold_1, epoch_812, Loss: 0.3462\n",
      "fold_1, epoch_813, Loss: 0.3445\n",
      "fold_1, epoch_814, Loss: 0.3463\n",
      "fold_1, epoch_815, Loss: 0.3439\n",
      "fold_1, epoch_816, Loss: 0.3460\n",
      "fold_1, epoch_817, Loss: 0.3431\n",
      "fold_1, epoch_818, Loss: 0.3456\n",
      "fold_1, epoch_819, Loss: 0.3464\n",
      "fold_1, epoch_820, Loss: 0.3441\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3426\n",
      "Accuracy:\t0.9707\n",
      "AUC:\t\t0.9696\n",
      "Precision:\t0.9880\n",
      "Recall:\t\t0.9531\n",
      "F1:\t\t\t0.9703\n",
      "\n",
      "fold_1, epoch_821, Loss: 0.3452\n",
      "fold_1, epoch_822, Loss: 0.3469\n",
      "fold_1, epoch_823, Loss: 0.3444\n",
      "fold_1, epoch_824, Loss: 0.3434\n",
      "fold_1, epoch_825, Loss: 0.3462\n",
      "fold_1, epoch_826, Loss: 0.3453\n",
      "fold_1, epoch_827, Loss: 0.3460\n",
      "fold_1, epoch_828, Loss: 0.3460\n",
      "fold_1, epoch_829, Loss: 0.3437\n",
      "fold_1, epoch_830, Loss: 0.3441\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3451\n",
      "Accuracy:\t0.9679\n",
      "AUC:\t\t0.9674\n",
      "Precision:\t0.9884\n",
      "Recall:\t\t0.9469\n",
      "F1:\t\t\t0.9672\n",
      "\n",
      "fold_1, epoch_831, Loss: 0.3459\n",
      "fold_1, epoch_832, Loss: 0.3479\n",
      "fold_1, epoch_833, Loss: 0.3435\n",
      "fold_1, epoch_834, Loss: 0.3467\n",
      "fold_1, epoch_835, Loss: 0.3470\n",
      "fold_1, epoch_836, Loss: 0.3428\n",
      "fold_1, epoch_837, Loss: 0.3459\n",
      "fold_1, epoch_838, Loss: 0.3436\n",
      "fold_1, epoch_839, Loss: 0.3448\n",
      "fold_1, epoch_840, Loss: 0.3450\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3462\n",
      "Accuracy:\t0.9669\n",
      "AUC:\t\t0.9683\n",
      "Precision:\t0.9819\n",
      "Recall:\t\t0.9513\n",
      "F1:\t\t\t0.9664\n",
      "\n",
      "fold_1, epoch_841, Loss: 0.3439\n",
      "fold_1, epoch_842, Loss: 0.3457\n",
      "fold_1, epoch_843, Loss: 0.3463\n",
      "fold_1, epoch_844, Loss: 0.3464\n",
      "fold_1, epoch_845, Loss: 0.3475\n",
      "fold_1, epoch_846, Loss: 0.3465\n",
      "fold_1, epoch_847, Loss: 0.3451\n",
      "fold_1, epoch_848, Loss: 0.3441\n",
      "fold_1, epoch_849, Loss: 0.3442\n",
      "fold_1, epoch_850, Loss: 0.3469\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3463\n",
      "Accuracy:\t0.9668\n",
      "AUC:\t\t0.9691\n",
      "Precision:\t0.9843\n",
      "Recall:\t\t0.9487\n",
      "F1:\t\t\t0.9662\n",
      "\n",
      "fold_1, epoch_851, Loss: 0.3452\n",
      "fold_1, epoch_852, Loss: 0.3446\n",
      "fold_1, epoch_853, Loss: 0.3451\n",
      "fold_1, epoch_854, Loss: 0.3434\n",
      "fold_1, epoch_855, Loss: 0.3416\n",
      "fold_1, epoch_856, Loss: 0.3445\n",
      "fold_1, epoch_857, Loss: 0.3461\n",
      "fold_1, epoch_858, Loss: 0.3445\n",
      "fold_1, epoch_859, Loss: 0.3460\n",
      "fold_1, epoch_860, Loss: 0.3446\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3455\n",
      "Accuracy:\t0.9676\n",
      "AUC:\t\t0.9668\n",
      "Precision:\t0.9888\n",
      "Recall:\t\t0.9462\n",
      "F1:\t\t\t0.9670\n",
      "\n",
      "fold_1, epoch_861, Loss: 0.3442\n",
      "fold_1, epoch_862, Loss: 0.3442\n",
      "fold_1, epoch_863, Loss: 0.3453\n",
      "fold_1, epoch_864, Loss: 0.3425\n",
      "fold_1, epoch_865, Loss: 0.3451\n",
      "fold_1, epoch_866, Loss: 0.3431\n",
      "fold_1, epoch_867, Loss: 0.3447\n",
      "fold_1, epoch_868, Loss: 0.3446\n",
      "fold_1, epoch_869, Loss: 0.3431\n",
      "fold_1, epoch_870, Loss: 0.3435\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3410\n",
      "Accuracy:\t0.9723\n",
      "AUC:\t\t0.9699\n",
      "Precision:\t0.9891\n",
      "Recall:\t\t0.9555\n",
      "F1:\t\t\t0.9720\n",
      "\n",
      "fold_1, epoch_871, Loss: 0.3438\n",
      "fold_1, epoch_872, Loss: 0.3426\n",
      "fold_1, epoch_873, Loss: 0.3435\n",
      "fold_1, epoch_874, Loss: 0.3461\n",
      "fold_1, epoch_875, Loss: 0.3455\n",
      "fold_1, epoch_876, Loss: 0.3461\n",
      "fold_1, epoch_877, Loss: 0.3460\n",
      "fold_1, epoch_878, Loss: 0.3439\n",
      "fold_1, epoch_879, Loss: 0.3416\n",
      "fold_1, epoch_880, Loss: 0.3433\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3439\n",
      "Accuracy:\t0.9693\n",
      "AUC:\t\t0.9698\n",
      "Precision:\t0.9879\n",
      "Recall:\t\t0.9505\n",
      "F1:\t\t\t0.9688\n",
      "\n",
      "fold_1, epoch_881, Loss: 0.3435\n",
      "fold_1, epoch_882, Loss: 0.3447\n",
      "fold_1, epoch_883, Loss: 0.3442\n",
      "fold_1, epoch_884, Loss: 0.3450\n",
      "fold_1, epoch_885, Loss: 0.3443\n",
      "fold_1, epoch_886, Loss: 0.3428\n",
      "fold_1, epoch_887, Loss: 0.3436\n",
      "fold_1, epoch_888, Loss: 0.3446\n",
      "fold_1, epoch_889, Loss: 0.3422\n",
      "fold_1, epoch_890, Loss: 0.3417\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3427\n",
      "Accuracy:\t0.9705\n",
      "AUC:\t\t0.9694\n",
      "Precision:\t0.9882\n",
      "Recall:\t\t0.9522\n",
      "F1:\t\t\t0.9699\n",
      "\n",
      "fold_1, epoch_891, Loss: 0.3425\n",
      "fold_1, epoch_892, Loss: 0.3462\n",
      "fold_1, epoch_893, Loss: 0.3432\n",
      "fold_1, epoch_894, Loss: 0.3427\n",
      "fold_1, epoch_895, Loss: 0.3423\n",
      "fold_1, epoch_896, Loss: 0.3437\n",
      "fold_1, epoch_897, Loss: 0.3445\n",
      "fold_1, epoch_898, Loss: 0.3423\n",
      "fold_1, epoch_899, Loss: 0.3428\n",
      "fold_1, epoch_900, Loss: 0.3421\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3423\n",
      "Accuracy:\t0.9710\n",
      "AUC:\t\t0.9690\n",
      "Precision:\t0.9890\n",
      "Recall:\t\t0.9528\n",
      "F1:\t\t\t0.9706\n",
      "\n",
      "fold_1, epoch_901, Loss: 0.3445\n",
      "fold_1, epoch_902, Loss: 0.3414\n",
      "fold_1, epoch_903, Loss: 0.3440\n",
      "fold_1, epoch_904, Loss: 0.3433\n",
      "fold_1, epoch_905, Loss: 0.3434\n",
      "fold_1, epoch_906, Loss: 0.3434\n",
      "fold_1, epoch_907, Loss: 0.3443\n",
      "fold_1, epoch_908, Loss: 0.3438\n",
      "fold_1, epoch_909, Loss: 0.3422\n",
      "fold_1, epoch_910, Loss: 0.3467\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3474\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9677\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9466\n",
      "F1:\t\t\t0.9650\n",
      "\n",
      "fold_1, epoch_911, Loss: 0.3441\n",
      "fold_1, epoch_912, Loss: 0.3423\n",
      "fold_1, epoch_913, Loss: 0.3433\n",
      "fold_1, epoch_914, Loss: 0.3436\n",
      "fold_1, epoch_915, Loss: 0.3458\n",
      "fold_1, epoch_916, Loss: 0.3439\n",
      "fold_1, epoch_917, Loss: 0.3423\n",
      "fold_1, epoch_918, Loss: 0.3428\n",
      "fold_1, epoch_919, Loss: 0.3429\n",
      "fold_1, epoch_920, Loss: 0.3457\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3407\n",
      "Accuracy:\t0.9725\n",
      "AUC:\t\t0.9707\n",
      "Precision:\t0.9888\n",
      "Recall:\t\t0.9556\n",
      "F1:\t\t\t0.9719\n",
      "\n",
      "fold_1, epoch_921, Loss: 0.3423\n",
      "fold_1, epoch_922, Loss: 0.3430\n",
      "fold_1, epoch_923, Loss: 0.3434\n",
      "fold_1, epoch_924, Loss: 0.3410\n",
      "fold_1, epoch_925, Loss: 0.3461\n",
      "fold_1, epoch_926, Loss: 0.3449\n",
      "fold_1, epoch_927, Loss: 0.3439\n",
      "fold_1, epoch_928, Loss: 0.3432\n",
      "fold_1, epoch_929, Loss: 0.3432\n",
      "fold_1, epoch_930, Loss: 0.3445\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3432\n",
      "Accuracy:\t0.9701\n",
      "AUC:\t\t0.9688\n",
      "Precision:\t0.9885\n",
      "Recall:\t\t0.9515\n",
      "F1:\t\t\t0.9697\n",
      "\n",
      "fold_1, epoch_931, Loss: 0.3428\n",
      "fold_1, epoch_932, Loss: 0.3438\n",
      "fold_1, epoch_933, Loss: 0.3434\n",
      "fold_1, epoch_934, Loss: 0.3441\n",
      "fold_1, epoch_935, Loss: 0.3459\n",
      "fold_1, epoch_936, Loss: 0.3432\n",
      "fold_1, epoch_937, Loss: 0.3448\n",
      "fold_1, epoch_938, Loss: 0.3448\n",
      "fold_1, epoch_939, Loss: 0.3444\n",
      "fold_1, epoch_940, Loss: 0.3433\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3448\n",
      "Accuracy:\t0.9683\n",
      "AUC:\t\t0.9680\n",
      "Precision:\t0.9848\n",
      "Recall:\t\t0.9513\n",
      "F1:\t\t\t0.9678\n",
      "\n",
      "fold_1, epoch_941, Loss: 0.3452\n",
      "fold_1, epoch_942, Loss: 0.3434\n",
      "fold_1, epoch_943, Loss: 0.3411\n",
      "fold_1, epoch_944, Loss: 0.3462\n",
      "fold_1, epoch_945, Loss: 0.3461\n",
      "fold_1, epoch_946, Loss: 0.3414\n",
      "fold_1, epoch_947, Loss: 0.3427\n",
      "fold_1, epoch_948, Loss: 0.3423\n",
      "fold_1, epoch_949, Loss: 0.3439\n",
      "fold_1, epoch_950, Loss: 0.3466\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3453\n",
      "Accuracy:\t0.9678\n",
      "AUC:\t\t0.9675\n",
      "Precision:\t0.9890\n",
      "Recall:\t\t0.9460\n",
      "F1:\t\t\t0.9670\n",
      "\n",
      "fold_1, epoch_951, Loss: 0.3453\n",
      "fold_1, epoch_952, Loss: 0.3444\n",
      "fold_1, epoch_953, Loss: 0.3415\n",
      "fold_1, epoch_954, Loss: 0.3449\n",
      "fold_1, epoch_955, Loss: 0.3427\n",
      "fold_1, epoch_956, Loss: 0.3431\n",
      "fold_1, epoch_957, Loss: 0.3422\n",
      "fold_1, epoch_958, Loss: 0.3428\n",
      "fold_1, epoch_959, Loss: 0.3443\n",
      "fold_1, epoch_960, Loss: 0.3450\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3426\n",
      "Accuracy:\t0.9707\n",
      "AUC:\t\t0.9686\n",
      "Precision:\t0.9899\n",
      "Recall:\t\t0.9514\n",
      "F1:\t\t\t0.9702\n",
      "\n",
      "fold_1, epoch_961, Loss: 0.3428\n",
      "fold_1, epoch_962, Loss: 0.3434\n",
      "fold_1, epoch_963, Loss: 0.3436\n",
      "fold_1, epoch_964, Loss: 0.3444\n",
      "fold_1, epoch_965, Loss: 0.3444\n",
      "fold_1, epoch_966, Loss: 0.3435\n",
      "fold_1, epoch_967, Loss: 0.3424\n",
      "fold_1, epoch_968, Loss: 0.3443\n",
      "fold_1, epoch_969, Loss: 0.3427\n",
      "fold_1, epoch_970, Loss: 0.3426\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3447\n",
      "Accuracy:\t0.9682\n",
      "AUC:\t\t0.9685\n",
      "Precision:\t0.9896\n",
      "Recall:\t\t0.9457\n",
      "F1:\t\t\t0.9671\n",
      "\n",
      "fold_1, epoch_971, Loss: 0.3439\n",
      "fold_1, epoch_972, Loss: 0.3452\n",
      "fold_1, epoch_973, Loss: 0.3403\n",
      "fold_1, epoch_974, Loss: 0.3418\n",
      "fold_1, epoch_975, Loss: 0.3411\n",
      "fold_1, epoch_976, Loss: 0.3458\n",
      "fold_1, epoch_977, Loss: 0.3429\n",
      "fold_1, epoch_978, Loss: 0.3427\n",
      "fold_1, epoch_979, Loss: 0.3431\n",
      "fold_1, epoch_980, Loss: 0.3445\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3421\n",
      "Accuracy:\t0.9710\n",
      "AUC:\t\t0.9709\n",
      "Precision:\t0.9873\n",
      "Recall:\t\t0.9546\n",
      "F1:\t\t\t0.9707\n",
      "\n",
      "fold_1, epoch_981, Loss: 0.3425\n",
      "fold_1, epoch_982, Loss: 0.3416\n",
      "fold_1, epoch_983, Loss: 0.3424\n",
      "fold_1, epoch_984, Loss: 0.3433\n",
      "fold_1, epoch_985, Loss: 0.3431\n",
      "fold_1, epoch_986, Loss: 0.3424\n",
      "fold_1, epoch_987, Loss: 0.3440\n",
      "fold_1, epoch_988, Loss: 0.3412\n",
      "fold_1, epoch_989, Loss: 0.3425\n",
      "fold_1, epoch_990, Loss: 0.3432\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3416\n",
      "Accuracy:\t0.9717\n",
      "AUC:\t\t0.9707\n",
      "Precision:\t0.9898\n",
      "Recall:\t\t0.9534\n",
      "F1:\t\t\t0.9713\n",
      "\n",
      "fold_1, epoch_991, Loss: 0.3420\n",
      "fold_1, epoch_992, Loss: 0.3442\n",
      "fold_1, epoch_993, Loss: 0.3443\n",
      "fold_1, epoch_994, Loss: 0.3432\n",
      "fold_1, epoch_995, Loss: 0.3445\n",
      "fold_1, epoch_996, Loss: 0.3419\n",
      "fold_1, epoch_997, Loss: 0.3440\n",
      "fold_1, epoch_998, Loss: 0.3451\n",
      "fold_1, epoch_999, Loss: 0.3429\n",
      "fold_1, epoch_1000, Loss: 0.3430\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3417\n",
      "Accuracy:\t0.9716\n",
      "AUC:\t\t0.9687\n",
      "Precision:\t0.9885\n",
      "Recall:\t\t0.9538\n",
      "F1:\t\t\t0.9708\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/checkpoints/fold_2\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/tensorboard\n",
      "\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.5884\n",
      "fold_2, epoch_2, Loss: 0.5503\n",
      "fold_2, epoch_3, Loss: 0.5391\n",
      "fold_2, epoch_4, Loss: 0.5319\n",
      "fold_2, epoch_5, Loss: 0.5266\n",
      "fold_2, epoch_6, Loss: 0.5208\n",
      "fold_2, epoch_7, Loss: 0.5132\n",
      "fold_2, epoch_8, Loss: 0.5169\n",
      "fold_2, epoch_9, Loss: 0.5095\n",
      "fold_2, epoch_10, Loss: 0.5034\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4994\n",
      "Accuracy:\t0.8052\n",
      "AUC:\t\t0.8718\n",
      "Precision:\t0.7946\n",
      "Recall:\t\t0.8181\n",
      "F1:\t\t\t0.8061\n",
      "\n",
      "fold_2, epoch_11, Loss: 0.5047\n",
      "fold_2, epoch_12, Loss: 0.5010\n",
      "fold_2, epoch_13, Loss: 0.4954\n",
      "fold_2, epoch_14, Loss: 0.4924\n",
      "fold_2, epoch_15, Loss: 0.4959\n",
      "fold_2, epoch_16, Loss: 0.4902\n",
      "fold_2, epoch_17, Loss: 0.4853\n",
      "fold_2, epoch_18, Loss: 0.4846\n",
      "fold_2, epoch_19, Loss: 0.4832\n",
      "fold_2, epoch_20, Loss: 0.4829\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4748\n",
      "Accuracy:\t0.8354\n",
      "AUC:\t\t0.8831\n",
      "Precision:\t0.8180\n",
      "Recall:\t\t0.8682\n",
      "F1:\t\t\t0.8424\n",
      "\n",
      "fold_2, epoch_21, Loss: 0.4767\n",
      "fold_2, epoch_22, Loss: 0.4765\n",
      "fold_2, epoch_23, Loss: 0.4721\n",
      "fold_2, epoch_24, Loss: 0.4705\n",
      "fold_2, epoch_25, Loss: 0.4699\n",
      "fold_2, epoch_26, Loss: 0.4673\n",
      "fold_2, epoch_27, Loss: 0.4663\n",
      "fold_2, epoch_28, Loss: 0.4590\n",
      "fold_2, epoch_29, Loss: 0.4524\n",
      "fold_2, epoch_30, Loss: 0.4547\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4635\n",
      "Accuracy:\t0.8467\n",
      "AUC:\t\t0.8931\n",
      "Precision:\t0.8325\n",
      "Recall:\t\t0.8639\n",
      "F1:\t\t\t0.8479\n",
      "\n",
      "fold_2, epoch_31, Loss: 0.4559\n",
      "fold_2, epoch_32, Loss: 0.4538\n",
      "fold_2, epoch_33, Loss: 0.4484\n",
      "fold_2, epoch_34, Loss: 0.4469\n",
      "fold_2, epoch_35, Loss: 0.4435\n",
      "fold_2, epoch_36, Loss: 0.4478\n",
      "fold_2, epoch_37, Loss: 0.4454\n",
      "fold_2, epoch_38, Loss: 0.4433\n",
      "fold_2, epoch_39, Loss: 0.4495\n",
      "fold_2, epoch_40, Loss: 0.4419\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4391\n",
      "Accuracy:\t0.8718\n",
      "AUC:\t\t0.9032\n",
      "Precision:\t0.8726\n",
      "Recall:\t\t0.8726\n",
      "F1:\t\t\t0.8726\n",
      "\n",
      "fold_2, epoch_41, Loss: 0.4380\n",
      "fold_2, epoch_42, Loss: 0.4366\n",
      "fold_2, epoch_43, Loss: 0.4395\n",
      "fold_2, epoch_44, Loss: 0.4335\n",
      "fold_2, epoch_45, Loss: 0.4347\n",
      "fold_2, epoch_46, Loss: 0.4342\n",
      "fold_2, epoch_47, Loss: 0.4328\n",
      "fold_2, epoch_48, Loss: 0.4328\n",
      "fold_2, epoch_49, Loss: 0.4322\n",
      "fold_2, epoch_50, Loss: 0.4346\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4258\n",
      "Accuracy:\t0.8854\n",
      "AUC:\t\t0.9083\n",
      "Precision:\t0.8766\n",
      "Recall:\t\t0.8967\n",
      "F1:\t\t\t0.8865\n",
      "\n",
      "fold_2, epoch_51, Loss: 0.4295\n",
      "fold_2, epoch_52, Loss: 0.4298\n",
      "fold_2, epoch_53, Loss: 0.4217\n",
      "fold_2, epoch_54, Loss: 0.4224\n",
      "fold_2, epoch_55, Loss: 0.4225\n",
      "fold_2, epoch_56, Loss: 0.4199\n",
      "fold_2, epoch_57, Loss: 0.4209\n",
      "fold_2, epoch_58, Loss: 0.4216\n",
      "fold_2, epoch_59, Loss: 0.4210\n",
      "fold_2, epoch_60, Loss: 0.4198\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4222\n",
      "Accuracy:\t0.8898\n",
      "AUC:\t\t0.9109\n",
      "Precision:\t0.8821\n",
      "Recall:\t\t0.9000\n",
      "F1:\t\t\t0.8910\n",
      "\n",
      "fold_2, epoch_61, Loss: 0.4223\n",
      "fold_2, epoch_62, Loss: 0.4184\n",
      "fold_2, epoch_63, Loss: 0.4217\n",
      "fold_2, epoch_64, Loss: 0.4166\n",
      "fold_2, epoch_65, Loss: 0.4129\n",
      "fold_2, epoch_66, Loss: 0.4222\n",
      "fold_2, epoch_67, Loss: 0.4163\n",
      "fold_2, epoch_68, Loss: 0.4130\n",
      "fold_2, epoch_69, Loss: 0.4208\n",
      "fold_2, epoch_70, Loss: 0.4183\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4118\n",
      "Accuracy:\t0.9003\n",
      "AUC:\t\t0.9174\n",
      "Precision:\t0.8899\n",
      "Recall:\t\t0.9129\n",
      "F1:\t\t\t0.9013\n",
      "\n",
      "fold_2, epoch_71, Loss: 0.4161\n",
      "fold_2, epoch_72, Loss: 0.4095\n",
      "fold_2, epoch_73, Loss: 0.4094\n",
      "fold_2, epoch_74, Loss: 0.4119\n",
      "fold_2, epoch_75, Loss: 0.4091\n",
      "fold_2, epoch_76, Loss: 0.4111\n",
      "fold_2, epoch_77, Loss: 0.4094\n",
      "fold_2, epoch_78, Loss: 0.4075\n",
      "fold_2, epoch_79, Loss: 0.4054\n",
      "fold_2, epoch_80, Loss: 0.4038\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4108\n",
      "Accuracy:\t0.9016\n",
      "AUC:\t\t0.9203\n",
      "Precision:\t0.9072\n",
      "Recall:\t\t0.8949\n",
      "F1:\t\t\t0.9010\n",
      "\n",
      "fold_2, epoch_81, Loss: 0.4063\n",
      "fold_2, epoch_82, Loss: 0.4050\n",
      "fold_2, epoch_83, Loss: 0.4013\n",
      "fold_2, epoch_84, Loss: 0.4075\n",
      "fold_2, epoch_85, Loss: 0.4011\n",
      "fold_2, epoch_86, Loss: 0.4043\n",
      "fold_2, epoch_87, Loss: 0.4018\n",
      "fold_2, epoch_88, Loss: 0.4062\n",
      "fold_2, epoch_89, Loss: 0.4070\n",
      "fold_2, epoch_90, Loss: 0.4003\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3990\n",
      "Accuracy:\t0.9139\n",
      "AUC:\t\t0.9234\n",
      "Precision:\t0.9165\n",
      "Recall:\t\t0.9114\n",
      "F1:\t\t\t0.9139\n",
      "\n",
      "fold_2, epoch_91, Loss: 0.3975\n",
      "fold_2, epoch_92, Loss: 0.3990\n",
      "fold_2, epoch_93, Loss: 0.3989\n",
      "fold_2, epoch_94, Loss: 0.3978\n",
      "fold_2, epoch_95, Loss: 0.4007\n",
      "fold_2, epoch_96, Loss: 0.3988\n",
      "fold_2, epoch_97, Loss: 0.3941\n",
      "fold_2, epoch_98, Loss: 0.4002\n",
      "fold_2, epoch_99, Loss: 0.3957\n",
      "fold_2, epoch_100, Loss: 0.3985\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3977\n",
      "Accuracy:\t0.9148\n",
      "AUC:\t\t0.9273\n",
      "Precision:\t0.9207\n",
      "Recall:\t\t0.9066\n",
      "F1:\t\t\t0.9136\n",
      "\n",
      "fold_2, epoch_101, Loss: 0.4009\n",
      "fold_2, epoch_102, Loss: 0.4004\n",
      "fold_2, epoch_103, Loss: 0.3959\n",
      "fold_2, epoch_104, Loss: 0.3984\n",
      "fold_2, epoch_105, Loss: 0.3898\n",
      "fold_2, epoch_106, Loss: 0.3945\n",
      "fold_2, epoch_107, Loss: 0.3918\n",
      "fold_2, epoch_108, Loss: 0.3977\n",
      "fold_2, epoch_109, Loss: 0.3936\n",
      "fold_2, epoch_110, Loss: 0.3989\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3889\n",
      "Accuracy:\t0.9238\n",
      "AUC:\t\t0.9303\n",
      "Precision:\t0.9289\n",
      "Recall:\t\t0.9184\n",
      "F1:\t\t\t0.9237\n",
      "\n",
      "fold_2, epoch_111, Loss: 0.3954\n",
      "fold_2, epoch_112, Loss: 0.3907\n",
      "fold_2, epoch_113, Loss: 0.3905\n",
      "fold_2, epoch_114, Loss: 0.3928\n",
      "fold_2, epoch_115, Loss: 0.3940\n",
      "fold_2, epoch_116, Loss: 0.3926\n",
      "fold_2, epoch_117, Loss: 0.3936\n",
      "fold_2, epoch_118, Loss: 0.3935\n",
      "fold_2, epoch_119, Loss: 0.3901\n",
      "fold_2, epoch_120, Loss: 0.3879\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3875\n",
      "Accuracy:\t0.9251\n",
      "AUC:\t\t0.9322\n",
      "Precision:\t0.9246\n",
      "Recall:\t\t0.9252\n",
      "F1:\t\t\t0.9249\n",
      "\n",
      "fold_2, epoch_121, Loss: 0.3880\n",
      "fold_2, epoch_122, Loss: 0.3888\n",
      "fold_2, epoch_123, Loss: 0.3927\n",
      "fold_2, epoch_124, Loss: 0.3873\n",
      "fold_2, epoch_125, Loss: 0.3938\n",
      "fold_2, epoch_126, Loss: 0.3900\n",
      "fold_2, epoch_127, Loss: 0.3884\n",
      "fold_2, epoch_128, Loss: 0.3897\n",
      "fold_2, epoch_129, Loss: 0.3907\n",
      "fold_2, epoch_130, Loss: 0.3881\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3925\n",
      "Accuracy:\t0.9201\n",
      "AUC:\t\t0.9307\n",
      "Precision:\t0.9368\n",
      "Recall:\t\t0.9007\n",
      "F1:\t\t\t0.9184\n",
      "\n",
      "fold_2, epoch_131, Loss: 0.3911\n",
      "fold_2, epoch_132, Loss: 0.3867\n",
      "fold_2, epoch_133, Loss: 0.3831\n",
      "fold_2, epoch_134, Loss: 0.3898\n",
      "fold_2, epoch_135, Loss: 0.3934\n",
      "fold_2, epoch_136, Loss: 0.3849\n",
      "fold_2, epoch_137, Loss: 0.3818\n",
      "fold_2, epoch_138, Loss: 0.3889\n",
      "fold_2, epoch_139, Loss: 0.3831\n",
      "fold_2, epoch_140, Loss: 0.3883\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3949\n",
      "Accuracy:\t0.9171\n",
      "AUC:\t\t0.9300\n",
      "Precision:\t0.9114\n",
      "Recall:\t\t0.9240\n",
      "F1:\t\t\t0.9177\n",
      "\n",
      "fold_2, epoch_141, Loss: 0.3831\n",
      "fold_2, epoch_142, Loss: 0.3841\n",
      "fold_2, epoch_143, Loss: 0.3851\n",
      "fold_2, epoch_144, Loss: 0.3865\n",
      "fold_2, epoch_145, Loss: 0.3830\n",
      "fold_2, epoch_146, Loss: 0.3866\n",
      "fold_2, epoch_147, Loss: 0.3847\n",
      "fold_2, epoch_148, Loss: 0.3818\n",
      "fold_2, epoch_149, Loss: 0.3880\n",
      "fold_2, epoch_150, Loss: 0.3865\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3796\n",
      "Accuracy:\t0.9336\n",
      "AUC:\t\t0.9381\n",
      "Precision:\t0.9445\n",
      "Recall:\t\t0.9212\n",
      "F1:\t\t\t0.9327\n",
      "\n",
      "fold_2, epoch_151, Loss: 0.3843\n",
      "fold_2, epoch_152, Loss: 0.3852\n",
      "fold_2, epoch_153, Loss: 0.3824\n",
      "fold_2, epoch_154, Loss: 0.3826\n",
      "fold_2, epoch_155, Loss: 0.3857\n",
      "fold_2, epoch_156, Loss: 0.3822\n",
      "fold_2, epoch_157, Loss: 0.3839\n",
      "fold_2, epoch_158, Loss: 0.3818\n",
      "fold_2, epoch_159, Loss: 0.3823\n",
      "fold_2, epoch_160, Loss: 0.3856\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3777\n",
      "Accuracy:\t0.9350\n",
      "AUC:\t\t0.9384\n",
      "Precision:\t0.9444\n",
      "Recall:\t\t0.9251\n",
      "F1:\t\t\t0.9347\n",
      "\n",
      "fold_2, epoch_161, Loss: 0.3816\n",
      "fold_2, epoch_162, Loss: 0.3804\n",
      "fold_2, epoch_163, Loss: 0.3853\n",
      "fold_2, epoch_164, Loss: 0.3777\n",
      "fold_2, epoch_165, Loss: 0.3805\n",
      "fold_2, epoch_166, Loss: 0.3837\n",
      "fold_2, epoch_167, Loss: 0.3820\n",
      "fold_2, epoch_168, Loss: 0.3803\n",
      "fold_2, epoch_169, Loss: 0.3807\n",
      "fold_2, epoch_170, Loss: 0.3786\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3787\n",
      "Accuracy:\t0.9348\n",
      "AUC:\t\t0.9385\n",
      "Precision:\t0.9459\n",
      "Recall:\t\t0.9231\n",
      "F1:\t\t\t0.9344\n",
      "\n",
      "fold_2, epoch_171, Loss: 0.3796\n",
      "fold_2, epoch_172, Loss: 0.3809\n",
      "fold_2, epoch_173, Loss: 0.3783\n",
      "fold_2, epoch_174, Loss: 0.3770\n",
      "fold_2, epoch_175, Loss: 0.3818\n",
      "fold_2, epoch_176, Loss: 0.3813\n",
      "fold_2, epoch_177, Loss: 0.3762\n",
      "fold_2, epoch_178, Loss: 0.3777\n",
      "fold_2, epoch_179, Loss: 0.3816\n",
      "fold_2, epoch_180, Loss: 0.3790\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3845\n",
      "Accuracy:\t0.9274\n",
      "AUC:\t\t0.9409\n",
      "Precision:\t0.9560\n",
      "Recall:\t\t0.8955\n",
      "F1:\t\t\t0.9247\n",
      "\n",
      "fold_2, epoch_181, Loss: 0.3869\n",
      "fold_2, epoch_182, Loss: 0.3820\n",
      "fold_2, epoch_183, Loss: 0.3745\n",
      "fold_2, epoch_184, Loss: 0.3766\n",
      "fold_2, epoch_185, Loss: 0.3792\n",
      "fold_2, epoch_186, Loss: 0.3779\n",
      "fold_2, epoch_187, Loss: 0.3739\n",
      "fold_2, epoch_188, Loss: 0.3780\n",
      "fold_2, epoch_189, Loss: 0.3778\n",
      "fold_2, epoch_190, Loss: 0.3735\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3766\n",
      "Accuracy:\t0.9364\n",
      "AUC:\t\t0.9410\n",
      "Precision:\t0.9498\n",
      "Recall:\t\t0.9206\n",
      "F1:\t\t\t0.9350\n",
      "\n",
      "fold_2, epoch_191, Loss: 0.3780\n",
      "fold_2, epoch_192, Loss: 0.3776\n",
      "fold_2, epoch_193, Loss: 0.3771\n",
      "fold_2, epoch_194, Loss: 0.3759\n",
      "fold_2, epoch_195, Loss: 0.3799\n",
      "fold_2, epoch_196, Loss: 0.3744\n",
      "fold_2, epoch_197, Loss: 0.3731\n",
      "fold_2, epoch_198, Loss: 0.3769\n",
      "fold_2, epoch_199, Loss: 0.3776\n",
      "fold_2, epoch_200, Loss: 0.3733\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3785\n",
      "Accuracy:\t0.9342\n",
      "AUC:\t\t0.9415\n",
      "Precision:\t0.9449\n",
      "Recall:\t\t0.9217\n",
      "F1:\t\t\t0.9331\n",
      "\n",
      "fold_2, epoch_201, Loss: 0.3727\n",
      "fold_2, epoch_202, Loss: 0.3794\n",
      "fold_2, epoch_203, Loss: 0.3768\n",
      "fold_2, epoch_204, Loss: 0.3768\n",
      "fold_2, epoch_205, Loss: 0.3725\n",
      "fold_2, epoch_206, Loss: 0.3766\n",
      "fold_2, epoch_207, Loss: 0.3775\n",
      "fold_2, epoch_208, Loss: 0.3714\n",
      "fold_2, epoch_209, Loss: 0.3748\n",
      "fold_2, epoch_210, Loss: 0.3711\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3719\n",
      "Accuracy:\t0.9411\n",
      "AUC:\t\t0.9429\n",
      "Precision:\t0.9507\n",
      "Recall:\t\t0.9302\n",
      "F1:\t\t\t0.9403\n",
      "\n",
      "fold_2, epoch_211, Loss: 0.3737\n",
      "fold_2, epoch_212, Loss: 0.3746\n",
      "fold_2, epoch_213, Loss: 0.3762\n",
      "fold_2, epoch_214, Loss: 0.3747\n",
      "fold_2, epoch_215, Loss: 0.3758\n",
      "fold_2, epoch_216, Loss: 0.3750\n",
      "fold_2, epoch_217, Loss: 0.3712\n",
      "fold_2, epoch_218, Loss: 0.3747\n",
      "fold_2, epoch_219, Loss: 0.3776\n",
      "fold_2, epoch_220, Loss: 0.3723\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3749\n",
      "Accuracy:\t0.9380\n",
      "AUC:\t\t0.9419\n",
      "Precision:\t0.9557\n",
      "Recall:\t\t0.9197\n",
      "F1:\t\t\t0.9373\n",
      "\n",
      "fold_2, epoch_221, Loss: 0.3755\n",
      "fold_2, epoch_222, Loss: 0.3733\n",
      "fold_2, epoch_223, Loss: 0.3692\n",
      "fold_2, epoch_224, Loss: 0.3738\n",
      "fold_2, epoch_225, Loss: 0.3712\n",
      "fold_2, epoch_226, Loss: 0.3743\n",
      "fold_2, epoch_227, Loss: 0.3697\n",
      "fold_2, epoch_228, Loss: 0.3744\n",
      "fold_2, epoch_229, Loss: 0.3723\n",
      "fold_2, epoch_230, Loss: 0.3748\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3727\n",
      "Accuracy:\t0.9400\n",
      "AUC:\t\t0.9440\n",
      "Precision:\t0.9517\n",
      "Recall:\t\t0.9265\n",
      "F1:\t\t\t0.9389\n",
      "\n",
      "fold_2, epoch_231, Loss: 0.3750\n",
      "fold_2, epoch_232, Loss: 0.3694\n",
      "fold_2, epoch_233, Loss: 0.3691\n",
      "fold_2, epoch_234, Loss: 0.3718\n",
      "fold_2, epoch_235, Loss: 0.3737\n",
      "fold_2, epoch_236, Loss: 0.3726\n",
      "fold_2, epoch_237, Loss: 0.3697\n",
      "fold_2, epoch_238, Loss: 0.3709\n",
      "fold_2, epoch_239, Loss: 0.3705\n",
      "fold_2, epoch_240, Loss: 0.3739\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3711\n",
      "Accuracy:\t0.9421\n",
      "AUC:\t\t0.9443\n",
      "Precision:\t0.9607\n",
      "Recall:\t\t0.9219\n",
      "F1:\t\t\t0.9409\n",
      "\n",
      "fold_2, epoch_241, Loss: 0.3701\n",
      "fold_2, epoch_242, Loss: 0.3712\n",
      "fold_2, epoch_243, Loss: 0.3763\n",
      "fold_2, epoch_244, Loss: 0.3767\n",
      "fold_2, epoch_245, Loss: 0.3729\n",
      "fold_2, epoch_246, Loss: 0.3694\n",
      "fold_2, epoch_247, Loss: 0.3718\n",
      "fold_2, epoch_248, Loss: 0.3690\n",
      "fold_2, epoch_249, Loss: 0.3689\n",
      "fold_2, epoch_250, Loss: 0.3692\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3692\n",
      "Accuracy:\t0.9438\n",
      "AUC:\t\t0.9466\n",
      "Precision:\t0.9619\n",
      "Recall:\t\t0.9234\n",
      "F1:\t\t\t0.9422\n",
      "\n",
      "fold_2, epoch_251, Loss: 0.3727\n",
      "fold_2, epoch_252, Loss: 0.3708\n",
      "fold_2, epoch_253, Loss: 0.3670\n",
      "fold_2, epoch_254, Loss: 0.3686\n",
      "fold_2, epoch_255, Loss: 0.3673\n",
      "fold_2, epoch_256, Loss: 0.3724\n",
      "fold_2, epoch_257, Loss: 0.3699\n",
      "fold_2, epoch_258, Loss: 0.3717\n",
      "fold_2, epoch_259, Loss: 0.3727\n",
      "fold_2, epoch_260, Loss: 0.3697\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3653\n",
      "Accuracy:\t0.9477\n",
      "AUC:\t\t0.9483\n",
      "Precision:\t0.9649\n",
      "Recall:\t\t0.9293\n",
      "F1:\t\t\t0.9468\n",
      "\n",
      "fold_2, epoch_261, Loss: 0.3695\n",
      "fold_2, epoch_262, Loss: 0.3667\n",
      "fold_2, epoch_263, Loss: 0.3704\n",
      "fold_2, epoch_264, Loss: 0.3725\n",
      "fold_2, epoch_265, Loss: 0.3668\n",
      "fold_2, epoch_266, Loss: 0.3692\n",
      "fold_2, epoch_267, Loss: 0.3705\n",
      "fold_2, epoch_268, Loss: 0.3649\n",
      "fold_2, epoch_269, Loss: 0.3669\n",
      "fold_2, epoch_270, Loss: 0.3703\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3652\n",
      "Accuracy:\t0.9479\n",
      "AUC:\t\t0.9484\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9259\n",
      "F1:\t\t\t0.9466\n",
      "\n",
      "fold_2, epoch_271, Loss: 0.3696\n",
      "fold_2, epoch_272, Loss: 0.3685\n",
      "fold_2, epoch_273, Loss: 0.3659\n",
      "fold_2, epoch_274, Loss: 0.3685\n",
      "fold_2, epoch_275, Loss: 0.3713\n",
      "fold_2, epoch_276, Loss: 0.3693\n",
      "fold_2, epoch_277, Loss: 0.3698\n",
      "fold_2, epoch_278, Loss: 0.3677\n",
      "fold_2, epoch_279, Loss: 0.3657\n",
      "fold_2, epoch_280, Loss: 0.3679\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3655\n",
      "Accuracy:\t0.9477\n",
      "AUC:\t\t0.9485\n",
      "Precision:\t0.9688\n",
      "Recall:\t\t0.9254\n",
      "F1:\t\t\t0.9466\n",
      "\n",
      "fold_2, epoch_281, Loss: 0.3685\n",
      "fold_2, epoch_282, Loss: 0.3705\n",
      "fold_2, epoch_283, Loss: 0.3684\n",
      "fold_2, epoch_284, Loss: 0.3680\n",
      "fold_2, epoch_285, Loss: 0.3671\n",
      "fold_2, epoch_286, Loss: 0.3689\n",
      "fold_2, epoch_287, Loss: 0.3661\n",
      "fold_2, epoch_288, Loss: 0.3673\n",
      "fold_2, epoch_289, Loss: 0.3680\n",
      "fold_2, epoch_290, Loss: 0.3643\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3700\n",
      "Accuracy:\t0.9431\n",
      "AUC:\t\t0.9448\n",
      "Precision:\t0.9612\n",
      "Recall:\t\t0.9237\n",
      "F1:\t\t\t0.9421\n",
      "\n",
      "fold_2, epoch_291, Loss: 0.3692\n",
      "fold_2, epoch_292, Loss: 0.3656\n",
      "fold_2, epoch_293, Loss: 0.3640\n",
      "fold_2, epoch_294, Loss: 0.3659\n",
      "fold_2, epoch_295, Loss: 0.3652\n",
      "fold_2, epoch_296, Loss: 0.3681\n",
      "fold_2, epoch_297, Loss: 0.3657\n",
      "fold_2, epoch_298, Loss: 0.3649\n",
      "fold_2, epoch_299, Loss: 0.3675\n",
      "fold_2, epoch_300, Loss: 0.3668\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3647\n",
      "Accuracy:\t0.9485\n",
      "AUC:\t\t0.9500\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9274\n",
      "F1:\t\t\t0.9474\n",
      "\n",
      "fold_2, epoch_301, Loss: 0.3656\n",
      "fold_2, epoch_302, Loss: 0.3678\n",
      "fold_2, epoch_303, Loss: 0.3645\n",
      "fold_2, epoch_304, Loss: 0.3653\n",
      "fold_2, epoch_305, Loss: 0.3635\n",
      "fold_2, epoch_306, Loss: 0.3649\n",
      "fold_2, epoch_307, Loss: 0.3654\n",
      "fold_2, epoch_308, Loss: 0.3664\n",
      "fold_2, epoch_309, Loss: 0.3681\n",
      "fold_2, epoch_310, Loss: 0.3649\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3612\n",
      "Accuracy:\t0.9520\n",
      "AUC:\t\t0.9526\n",
      "Precision:\t0.9693\n",
      "Recall:\t\t0.9334\n",
      "F1:\t\t\t0.9510\n",
      "\n",
      "fold_2, epoch_311, Loss: 0.3656\n",
      "fold_2, epoch_312, Loss: 0.3679\n",
      "fold_2, epoch_313, Loss: 0.3636\n",
      "fold_2, epoch_314, Loss: 0.3633\n",
      "fold_2, epoch_315, Loss: 0.3659\n",
      "fold_2, epoch_316, Loss: 0.3646\n",
      "fold_2, epoch_317, Loss: 0.3644\n",
      "fold_2, epoch_318, Loss: 0.3683\n",
      "fold_2, epoch_319, Loss: 0.3682\n",
      "fold_2, epoch_320, Loss: 0.3619\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3638\n",
      "Accuracy:\t0.9492\n",
      "AUC:\t\t0.9500\n",
      "Precision:\t0.9685\n",
      "Recall:\t\t0.9286\n",
      "F1:\t\t\t0.9481\n",
      "\n",
      "fold_2, epoch_321, Loss: 0.3591\n",
      "fold_2, epoch_322, Loss: 0.3636\n",
      "fold_2, epoch_323, Loss: 0.3683\n",
      "fold_2, epoch_324, Loss: 0.3658\n",
      "fold_2, epoch_325, Loss: 0.3655\n",
      "fold_2, epoch_326, Loss: 0.3670\n",
      "fold_2, epoch_327, Loss: 0.3665\n",
      "fold_2, epoch_328, Loss: 0.3621\n",
      "fold_2, epoch_329, Loss: 0.3653\n",
      "fold_2, epoch_330, Loss: 0.3623\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3619\n",
      "Accuracy:\t0.9513\n",
      "AUC:\t\t0.9491\n",
      "Precision:\t0.9717\n",
      "Recall:\t\t0.9291\n",
      "F1:\t\t\t0.9499\n",
      "\n",
      "fold_2, epoch_331, Loss: 0.3684\n",
      "fold_2, epoch_332, Loss: 0.3684\n",
      "fold_2, epoch_333, Loss: 0.3642\n",
      "fold_2, epoch_334, Loss: 0.3682\n",
      "fold_2, epoch_335, Loss: 0.3635\n",
      "fold_2, epoch_336, Loss: 0.3627\n",
      "fold_2, epoch_337, Loss: 0.3653\n",
      "fold_2, epoch_338, Loss: 0.3629\n",
      "fold_2, epoch_339, Loss: 0.3624\n",
      "fold_2, epoch_340, Loss: 0.3624\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3647\n",
      "Accuracy:\t0.9482\n",
      "AUC:\t\t0.9497\n",
      "Precision:\t0.9694\n",
      "Recall:\t\t0.9266\n",
      "F1:\t\t\t0.9475\n",
      "\n",
      "fold_2, epoch_341, Loss: 0.3650\n",
      "fold_2, epoch_342, Loss: 0.3661\n",
      "fold_2, epoch_343, Loss: 0.3626\n",
      "fold_2, epoch_344, Loss: 0.3652\n",
      "fold_2, epoch_345, Loss: 0.3657\n",
      "fold_2, epoch_346, Loss: 0.3638\n",
      "fold_2, epoch_347, Loss: 0.3643\n",
      "fold_2, epoch_348, Loss: 0.3642\n",
      "fold_2, epoch_349, Loss: 0.3608\n",
      "fold_2, epoch_350, Loss: 0.3635\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3602\n",
      "Accuracy:\t0.9529\n",
      "AUC:\t\t0.9533\n",
      "Precision:\t0.9761\n",
      "Recall:\t\t0.9289\n",
      "F1:\t\t\t0.9519\n",
      "\n",
      "fold_2, epoch_351, Loss: 0.3618\n",
      "fold_2, epoch_352, Loss: 0.3633\n",
      "fold_2, epoch_353, Loss: 0.3639\n",
      "fold_2, epoch_354, Loss: 0.3636\n",
      "fold_2, epoch_355, Loss: 0.3643\n",
      "fold_2, epoch_356, Loss: 0.3619\n",
      "fold_2, epoch_357, Loss: 0.3651\n",
      "fold_2, epoch_358, Loss: 0.3624\n",
      "fold_2, epoch_359, Loss: 0.3632\n",
      "fold_2, epoch_360, Loss: 0.3606\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3675\n",
      "Accuracy:\t0.9451\n",
      "AUC:\t\t0.9515\n",
      "Precision:\t0.9718\n",
      "Recall:\t\t0.9173\n",
      "F1:\t\t\t0.9438\n",
      "\n",
      "fold_2, epoch_361, Loss: 0.3652\n",
      "fold_2, epoch_362, Loss: 0.3662\n",
      "fold_2, epoch_363, Loss: 0.3652\n",
      "fold_2, epoch_364, Loss: 0.3614\n",
      "fold_2, epoch_365, Loss: 0.3625\n",
      "fold_2, epoch_366, Loss: 0.3609\n",
      "fold_2, epoch_367, Loss: 0.3638\n",
      "fold_2, epoch_368, Loss: 0.3607\n",
      "fold_2, epoch_369, Loss: 0.3618\n",
      "fold_2, epoch_370, Loss: 0.3626\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3607\n",
      "Accuracy:\t0.9523\n",
      "AUC:\t\t0.9533\n",
      "Precision:\t0.9729\n",
      "Recall:\t\t0.9304\n",
      "F1:\t\t\t0.9512\n",
      "\n",
      "fold_2, epoch_371, Loss: 0.3601\n",
      "fold_2, epoch_372, Loss: 0.3650\n",
      "fold_2, epoch_373, Loss: 0.3640\n",
      "fold_2, epoch_374, Loss: 0.3612\n",
      "fold_2, epoch_375, Loss: 0.3631\n",
      "fold_2, epoch_376, Loss: 0.3588\n",
      "fold_2, epoch_377, Loss: 0.3621\n",
      "fold_2, epoch_378, Loss: 0.3641\n",
      "fold_2, epoch_379, Loss: 0.3633\n",
      "fold_2, epoch_380, Loss: 0.3629\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3583\n",
      "Accuracy:\t0.9549\n",
      "AUC:\t\t0.9538\n",
      "Precision:\t0.9767\n",
      "Recall:\t\t0.9319\n",
      "F1:\t\t\t0.9538\n",
      "\n",
      "fold_2, epoch_381, Loss: 0.3585\n",
      "fold_2, epoch_382, Loss: 0.3635\n",
      "fold_2, epoch_383, Loss: 0.3664\n",
      "fold_2, epoch_384, Loss: 0.3627\n",
      "fold_2, epoch_385, Loss: 0.3598\n",
      "fold_2, epoch_386, Loss: 0.3626\n",
      "fold_2, epoch_387, Loss: 0.3617\n",
      "fold_2, epoch_388, Loss: 0.3630\n",
      "fold_2, epoch_389, Loss: 0.3636\n",
      "fold_2, epoch_390, Loss: 0.3630\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3698\n",
      "Accuracy:\t0.9435\n",
      "AUC:\t\t0.9466\n",
      "Precision:\t0.9678\n",
      "Recall:\t\t0.9182\n",
      "F1:\t\t\t0.9423\n",
      "\n",
      "fold_2, epoch_391, Loss: 0.3615\n",
      "fold_2, epoch_392, Loss: 0.3620\n",
      "fold_2, epoch_393, Loss: 0.3626\n",
      "fold_2, epoch_394, Loss: 0.3609\n",
      "fold_2, epoch_395, Loss: 0.3624\n",
      "fold_2, epoch_396, Loss: 0.3616\n",
      "fold_2, epoch_397, Loss: 0.3623\n",
      "fold_2, epoch_398, Loss: 0.3646\n",
      "fold_2, epoch_399, Loss: 0.3606\n",
      "fold_2, epoch_400, Loss: 0.3635\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3622\n",
      "Accuracy:\t0.9510\n",
      "AUC:\t\t0.9517\n",
      "Precision:\t0.9704\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9498\n",
      "\n",
      "fold_2, epoch_401, Loss: 0.3615\n",
      "fold_2, epoch_402, Loss: 0.3592\n",
      "fold_2, epoch_403, Loss: 0.3621\n",
      "fold_2, epoch_404, Loss: 0.3597\n",
      "fold_2, epoch_405, Loss: 0.3601\n",
      "fold_2, epoch_406, Loss: 0.3620\n",
      "fold_2, epoch_407, Loss: 0.3656\n",
      "fold_2, epoch_408, Loss: 0.3597\n",
      "fold_2, epoch_409, Loss: 0.3610\n",
      "fold_2, epoch_410, Loss: 0.3607\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3585\n",
      "Accuracy:\t0.9546\n",
      "AUC:\t\t0.9529\n",
      "Precision:\t0.9764\n",
      "Recall:\t\t0.9321\n",
      "F1:\t\t\t0.9537\n",
      "\n",
      "fold_2, epoch_411, Loss: 0.3587\n",
      "fold_2, epoch_412, Loss: 0.3613\n",
      "fold_2, epoch_413, Loss: 0.3612\n",
      "fold_2, epoch_414, Loss: 0.3589\n",
      "fold_2, epoch_415, Loss: 0.3607\n",
      "fold_2, epoch_416, Loss: 0.3628\n",
      "fold_2, epoch_417, Loss: 0.3577\n",
      "fold_2, epoch_418, Loss: 0.3618\n",
      "fold_2, epoch_419, Loss: 0.3587\n",
      "fold_2, epoch_420, Loss: 0.3625\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3607\n",
      "Accuracy:\t0.9524\n",
      "AUC:\t\t0.9533\n",
      "Precision:\t0.9745\n",
      "Recall:\t\t0.9293\n",
      "F1:\t\t\t0.9514\n",
      "\n",
      "fold_2, epoch_421, Loss: 0.3642\n",
      "fold_2, epoch_422, Loss: 0.3597\n",
      "fold_2, epoch_423, Loss: 0.3598\n",
      "fold_2, epoch_424, Loss: 0.3633\n",
      "fold_2, epoch_425, Loss: 0.3592\n",
      "fold_2, epoch_426, Loss: 0.3609\n",
      "fold_2, epoch_427, Loss: 0.3621\n",
      "fold_2, epoch_428, Loss: 0.3606\n",
      "fold_2, epoch_429, Loss: 0.3640\n",
      "fold_2, epoch_430, Loss: 0.3600\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3567\n",
      "Accuracy:\t0.9563\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9814\n",
      "Recall:\t\t0.9295\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_2, epoch_431, Loss: 0.3592\n",
      "fold_2, epoch_432, Loss: 0.3604\n",
      "fold_2, epoch_433, Loss: 0.3599\n",
      "fold_2, epoch_434, Loss: 0.3572\n",
      "fold_2, epoch_435, Loss: 0.3610\n",
      "fold_2, epoch_436, Loss: 0.3578\n",
      "fold_2, epoch_437, Loss: 0.3572\n",
      "fold_2, epoch_438, Loss: 0.3624\n",
      "fold_2, epoch_439, Loss: 0.3584\n",
      "fold_2, epoch_440, Loss: 0.3586\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3578\n",
      "Accuracy:\t0.9552\n",
      "AUC:\t\t0.9557\n",
      "Precision:\t0.9771\n",
      "Recall:\t\t0.9317\n",
      "F1:\t\t\t0.9539\n",
      "\n",
      "fold_2, epoch_441, Loss: 0.3601\n",
      "fold_2, epoch_442, Loss: 0.3595\n",
      "fold_2, epoch_443, Loss: 0.3585\n",
      "fold_2, epoch_444, Loss: 0.3572\n",
      "fold_2, epoch_445, Loss: 0.3610\n",
      "fold_2, epoch_446, Loss: 0.3565\n",
      "fold_2, epoch_447, Loss: 0.3578\n",
      "fold_2, epoch_448, Loss: 0.3645\n",
      "fold_2, epoch_449, Loss: 0.3614\n",
      "fold_2, epoch_450, Loss: 0.3597\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3583\n",
      "Accuracy:\t0.9549\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9773\n",
      "Recall:\t\t0.9320\n",
      "F1:\t\t\t0.9541\n",
      "\n",
      "fold_2, epoch_451, Loss: 0.3603\n",
      "fold_2, epoch_452, Loss: 0.3602\n",
      "fold_2, epoch_453, Loss: 0.3605\n",
      "fold_2, epoch_454, Loss: 0.3599\n",
      "fold_2, epoch_455, Loss: 0.3581\n",
      "fold_2, epoch_456, Loss: 0.3588\n",
      "fold_2, epoch_457, Loss: 0.3589\n",
      "fold_2, epoch_458, Loss: 0.3600\n",
      "fold_2, epoch_459, Loss: 0.3615\n",
      "fold_2, epoch_460, Loss: 0.3604\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3577\n",
      "Accuracy:\t0.9556\n",
      "AUC:\t\t0.9547\n",
      "Precision:\t0.9778\n",
      "Recall:\t\t0.9328\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_2, epoch_461, Loss: 0.3587\n",
      "fold_2, epoch_462, Loss: 0.3610\n",
      "fold_2, epoch_463, Loss: 0.3585\n",
      "fold_2, epoch_464, Loss: 0.3577\n",
      "fold_2, epoch_465, Loss: 0.3602\n",
      "fold_2, epoch_466, Loss: 0.3604\n",
      "fold_2, epoch_467, Loss: 0.3593\n",
      "fold_2, epoch_468, Loss: 0.3587\n",
      "fold_2, epoch_469, Loss: 0.3548\n",
      "fold_2, epoch_470, Loss: 0.3601\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3572\n",
      "Accuracy:\t0.9561\n",
      "AUC:\t\t0.9541\n",
      "Precision:\t0.9794\n",
      "Recall:\t\t0.9314\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_2, epoch_471, Loss: 0.3590\n",
      "fold_2, epoch_472, Loss: 0.3568\n",
      "fold_2, epoch_473, Loss: 0.3608\n",
      "fold_2, epoch_474, Loss: 0.3612\n",
      "fold_2, epoch_475, Loss: 0.3583\n",
      "fold_2, epoch_476, Loss: 0.3582\n",
      "fold_2, epoch_477, Loss: 0.3557\n",
      "fold_2, epoch_478, Loss: 0.3572\n",
      "fold_2, epoch_479, Loss: 0.3580\n",
      "fold_2, epoch_480, Loss: 0.3581\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3572\n",
      "Accuracy:\t0.9559\n",
      "AUC:\t\t0.9559\n",
      "Precision:\t0.9807\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_2, epoch_481, Loss: 0.3601\n",
      "fold_2, epoch_482, Loss: 0.3558\n",
      "fold_2, epoch_483, Loss: 0.3595\n",
      "fold_2, epoch_484, Loss: 0.3571\n",
      "fold_2, epoch_485, Loss: 0.3595\n",
      "fold_2, epoch_486, Loss: 0.3604\n",
      "fold_2, epoch_487, Loss: 0.3584\n",
      "fold_2, epoch_488, Loss: 0.3582\n",
      "fold_2, epoch_489, Loss: 0.3571\n",
      "fold_2, epoch_490, Loss: 0.3605\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3567\n",
      "Accuracy:\t0.9563\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9789\n",
      "Recall:\t\t0.9326\n",
      "F1:\t\t\t0.9552\n",
      "\n",
      "fold_2, epoch_491, Loss: 0.3565\n",
      "fold_2, epoch_492, Loss: 0.3554\n",
      "fold_2, epoch_493, Loss: 0.3558\n",
      "fold_2, epoch_494, Loss: 0.3599\n",
      "fold_2, epoch_495, Loss: 0.3579\n",
      "fold_2, epoch_496, Loss: 0.3608\n",
      "fold_2, epoch_497, Loss: 0.3608\n",
      "fold_2, epoch_498, Loss: 0.3576\n",
      "fold_2, epoch_499, Loss: 0.3566\n",
      "fold_2, epoch_500, Loss: 0.3602\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3583\n",
      "Accuracy:\t0.9549\n",
      "AUC:\t\t0.9568\n",
      "Precision:\t0.9755\n",
      "Recall:\t\t0.9329\n",
      "F1:\t\t\t0.9537\n",
      "\n",
      "fold_2, epoch_501, Loss: 0.3573\n",
      "fold_2, epoch_502, Loss: 0.3589\n",
      "fold_2, epoch_503, Loss: 0.3576\n",
      "fold_2, epoch_504, Loss: 0.3571\n",
      "fold_2, epoch_505, Loss: 0.3572\n",
      "fold_2, epoch_506, Loss: 0.3560\n",
      "fold_2, epoch_507, Loss: 0.3557\n",
      "fold_2, epoch_508, Loss: 0.3564\n",
      "fold_2, epoch_509, Loss: 0.3552\n",
      "fold_2, epoch_510, Loss: 0.3572\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3570\n",
      "Accuracy:\t0.9561\n",
      "AUC:\t\t0.9553\n",
      "Precision:\t0.9783\n",
      "Recall:\t\t0.9326\n",
      "F1:\t\t\t0.9549\n",
      "\n",
      "fold_2, epoch_511, Loss: 0.3588\n",
      "fold_2, epoch_512, Loss: 0.3559\n",
      "fold_2, epoch_513, Loss: 0.3617\n",
      "fold_2, epoch_514, Loss: 0.3571\n",
      "fold_2, epoch_515, Loss: 0.3605\n",
      "fold_2, epoch_516, Loss: 0.3559\n",
      "fold_2, epoch_517, Loss: 0.3584\n",
      "fold_2, epoch_518, Loss: 0.3586\n",
      "fold_2, epoch_519, Loss: 0.3559\n",
      "fold_2, epoch_520, Loss: 0.3576\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3635\n",
      "Accuracy:\t0.9492\n",
      "AUC:\t\t0.9534\n",
      "Precision:\t0.9753\n",
      "Recall:\t\t0.9220\n",
      "F1:\t\t\t0.9479\n",
      "\n",
      "fold_2, epoch_521, Loss: 0.3610\n",
      "fold_2, epoch_522, Loss: 0.3577\n",
      "fold_2, epoch_523, Loss: 0.3557\n",
      "fold_2, epoch_524, Loss: 0.3573\n",
      "fold_2, epoch_525, Loss: 0.3561\n",
      "fold_2, epoch_526, Loss: 0.3548\n",
      "fold_2, epoch_527, Loss: 0.3571\n",
      "fold_2, epoch_528, Loss: 0.3589\n",
      "fold_2, epoch_529, Loss: 0.3576\n",
      "fold_2, epoch_530, Loss: 0.3574\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3553\n",
      "Accuracy:\t0.9579\n",
      "AUC:\t\t0.9573\n",
      "Precision:\t0.9810\n",
      "Recall:\t\t0.9336\n",
      "F1:\t\t\t0.9567\n",
      "\n",
      "fold_2, epoch_531, Loss: 0.3570\n",
      "fold_2, epoch_532, Loss: 0.3565\n",
      "fold_2, epoch_533, Loss: 0.3570\n",
      "fold_2, epoch_534, Loss: 0.3567\n",
      "fold_2, epoch_535, Loss: 0.3576\n",
      "fold_2, epoch_536, Loss: 0.3544\n",
      "fold_2, epoch_537, Loss: 0.3581\n",
      "fold_2, epoch_538, Loss: 0.3551\n",
      "fold_2, epoch_539, Loss: 0.3594\n",
      "fold_2, epoch_540, Loss: 0.3548\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3550\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9565\n",
      "Precision:\t0.9834\n",
      "Recall:\t\t0.9323\n",
      "F1:\t\t\t0.9572\n",
      "\n",
      "fold_2, epoch_541, Loss: 0.3571\n",
      "fold_2, epoch_542, Loss: 0.3574\n",
      "fold_2, epoch_543, Loss: 0.3579\n",
      "fold_2, epoch_544, Loss: 0.3549\n",
      "fold_2, epoch_545, Loss: 0.3545\n",
      "fold_2, epoch_546, Loss: 0.3564\n",
      "fold_2, epoch_547, Loss: 0.3554\n",
      "fold_2, epoch_548, Loss: 0.3593\n",
      "fold_2, epoch_549, Loss: 0.3547\n",
      "fold_2, epoch_550, Loss: 0.3525\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3592\n",
      "Accuracy:\t0.9538\n",
      "AUC:\t\t0.9550\n",
      "Precision:\t0.9756\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9523\n",
      "\n",
      "fold_2, epoch_551, Loss: 0.3550\n",
      "fold_2, epoch_552, Loss: 0.3562\n",
      "fold_2, epoch_553, Loss: 0.3549\n",
      "fold_2, epoch_554, Loss: 0.3570\n",
      "fold_2, epoch_555, Loss: 0.3567\n",
      "fold_2, epoch_556, Loss: 0.3553\n",
      "fold_2, epoch_557, Loss: 0.3569\n",
      "fold_2, epoch_558, Loss: 0.3573\n",
      "fold_2, epoch_559, Loss: 0.3552\n",
      "fold_2, epoch_560, Loss: 0.3583\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9578\n",
      "Precision:\t0.9824\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_2, epoch_561, Loss: 0.3568\n",
      "fold_2, epoch_562, Loss: 0.3563\n",
      "fold_2, epoch_563, Loss: 0.3552\n",
      "fold_2, epoch_564, Loss: 0.3555\n",
      "fold_2, epoch_565, Loss: 0.3567\n",
      "fold_2, epoch_566, Loss: 0.3559\n",
      "fold_2, epoch_567, Loss: 0.3545\n",
      "fold_2, epoch_568, Loss: 0.3562\n",
      "fold_2, epoch_569, Loss: 0.3564\n",
      "fold_2, epoch_570, Loss: 0.3552\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9595\n",
      "AUC:\t\t0.9592\n",
      "Precision:\t0.9807\n",
      "Recall:\t\t0.9370\n",
      "F1:\t\t\t0.9584\n",
      "\n",
      "fold_2, epoch_571, Loss: 0.3568\n",
      "fold_2, epoch_572, Loss: 0.3553\n",
      "fold_2, epoch_573, Loss: 0.3537\n",
      "fold_2, epoch_574, Loss: 0.3580\n",
      "fold_2, epoch_575, Loss: 0.3574\n",
      "fold_2, epoch_576, Loss: 0.3543\n",
      "fold_2, epoch_577, Loss: 0.3539\n",
      "fold_2, epoch_578, Loss: 0.3534\n",
      "fold_2, epoch_579, Loss: 0.3549\n",
      "fold_2, epoch_580, Loss: 0.3552\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3649\n",
      "Accuracy:\t0.9479\n",
      "AUC:\t\t0.9568\n",
      "Precision:\t0.9747\n",
      "Recall:\t\t0.9197\n",
      "F1:\t\t\t0.9464\n",
      "\n",
      "fold_2, epoch_581, Loss: 0.3574\n",
      "fold_2, epoch_582, Loss: 0.3538\n",
      "fold_2, epoch_583, Loss: 0.3556\n",
      "fold_2, epoch_584, Loss: 0.3525\n",
      "fold_2, epoch_585, Loss: 0.3555\n",
      "fold_2, epoch_586, Loss: 0.3591\n",
      "fold_2, epoch_587, Loss: 0.3548\n",
      "fold_2, epoch_588, Loss: 0.3567\n",
      "fold_2, epoch_589, Loss: 0.3550\n",
      "fold_2, epoch_590, Loss: 0.3546\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3520\n",
      "Accuracy:\t0.9612\n",
      "AUC:\t\t0.9597\n",
      "Precision:\t0.9847\n",
      "Recall:\t\t0.9373\n",
      "F1:\t\t\t0.9604\n",
      "\n",
      "fold_2, epoch_591, Loss: 0.3547\n",
      "fold_2, epoch_592, Loss: 0.3542\n",
      "fold_2, epoch_593, Loss: 0.3552\n",
      "fold_2, epoch_594, Loss: 0.3565\n",
      "fold_2, epoch_595, Loss: 0.3551\n",
      "fold_2, epoch_596, Loss: 0.3546\n",
      "fold_2, epoch_597, Loss: 0.3537\n",
      "fold_2, epoch_598, Loss: 0.3583\n",
      "fold_2, epoch_599, Loss: 0.3549\n",
      "fold_2, epoch_600, Loss: 0.3542\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3554\n",
      "Accuracy:\t0.9577\n",
      "AUC:\t\t0.9574\n",
      "Precision:\t0.9828\n",
      "Recall:\t\t0.9314\n",
      "F1:\t\t\t0.9564\n",
      "\n",
      "fold_2, epoch_601, Loss: 0.3560\n",
      "fold_2, epoch_602, Loss: 0.3532\n",
      "fold_2, epoch_603, Loss: 0.3557\n",
      "fold_2, epoch_604, Loss: 0.3545\n",
      "fold_2, epoch_605, Loss: 0.3536\n",
      "fold_2, epoch_606, Loss: 0.3551\n",
      "fold_2, epoch_607, Loss: 0.3543\n",
      "fold_2, epoch_608, Loss: 0.3533\n",
      "fold_2, epoch_609, Loss: 0.3565\n",
      "fold_2, epoch_610, Loss: 0.3562\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9587\n",
      "AUC:\t\t0.9591\n",
      "Precision:\t0.9798\n",
      "Recall:\t\t0.9369\n",
      "F1:\t\t\t0.9579\n",
      "\n",
      "fold_2, epoch_611, Loss: 0.3554\n",
      "fold_2, epoch_612, Loss: 0.3535\n",
      "fold_2, epoch_613, Loss: 0.3545\n",
      "fold_2, epoch_614, Loss: 0.3536\n",
      "fold_2, epoch_615, Loss: 0.3547\n",
      "fold_2, epoch_616, Loss: 0.3545\n",
      "fold_2, epoch_617, Loss: 0.3561\n",
      "fold_2, epoch_618, Loss: 0.3542\n",
      "fold_2, epoch_619, Loss: 0.3548\n",
      "fold_2, epoch_620, Loss: 0.3558\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3534\n",
      "Accuracy:\t0.9598\n",
      "AUC:\t\t0.9596\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9353\n",
      "F1:\t\t\t0.9591\n",
      "\n",
      "fold_2, epoch_621, Loss: 0.3548\n",
      "fold_2, epoch_622, Loss: 0.3555\n",
      "fold_2, epoch_623, Loss: 0.3572\n",
      "fold_2, epoch_624, Loss: 0.3531\n",
      "fold_2, epoch_625, Loss: 0.3546\n",
      "fold_2, epoch_626, Loss: 0.3556\n",
      "fold_2, epoch_627, Loss: 0.3553\n",
      "fold_2, epoch_628, Loss: 0.3543\n",
      "fold_2, epoch_629, Loss: 0.3533\n",
      "fold_2, epoch_630, Loss: 0.3531\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3535\n",
      "Accuracy:\t0.9597\n",
      "AUC:\t\t0.9581\n",
      "Precision:\t0.9836\n",
      "Recall:\t\t0.9350\n",
      "F1:\t\t\t0.9587\n",
      "\n",
      "fold_2, epoch_631, Loss: 0.3562\n",
      "fold_2, epoch_632, Loss: 0.3556\n",
      "fold_2, epoch_633, Loss: 0.3561\n",
      "fold_2, epoch_634, Loss: 0.3544\n",
      "fold_2, epoch_635, Loss: 0.3556\n",
      "fold_2, epoch_636, Loss: 0.3548\n",
      "fold_2, epoch_637, Loss: 0.3553\n",
      "fold_2, epoch_638, Loss: 0.3537\n",
      "fold_2, epoch_639, Loss: 0.3540\n",
      "fold_2, epoch_640, Loss: 0.3552\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3570\n",
      "Accuracy:\t0.9559\n",
      "AUC:\t\t0.9581\n",
      "Precision:\t0.9858\n",
      "Recall:\t\t0.9251\n",
      "F1:\t\t\t0.9545\n",
      "\n",
      "fold_2, epoch_641, Loss: 0.3551\n",
      "fold_2, epoch_642, Loss: 0.3561\n",
      "fold_2, epoch_643, Loss: 0.3536\n",
      "fold_2, epoch_644, Loss: 0.3541\n",
      "fold_2, epoch_645, Loss: 0.3540\n",
      "fold_2, epoch_646, Loss: 0.3546\n",
      "fold_2, epoch_647, Loss: 0.3533\n",
      "fold_2, epoch_648, Loss: 0.3553\n",
      "fold_2, epoch_649, Loss: 0.3550\n",
      "fold_2, epoch_650, Loss: 0.3525\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3540\n",
      "Accuracy:\t0.9592\n",
      "AUC:\t\t0.9578\n",
      "Precision:\t0.9838\n",
      "Recall:\t\t0.9330\n",
      "F1:\t\t\t0.9577\n",
      "\n",
      "fold_2, epoch_651, Loss: 0.3532\n",
      "fold_2, epoch_652, Loss: 0.3556\n",
      "fold_2, epoch_653, Loss: 0.3548\n",
      "fold_2, epoch_654, Loss: 0.3549\n",
      "fold_2, epoch_655, Loss: 0.3560\n",
      "fold_2, epoch_656, Loss: 0.3542\n",
      "fold_2, epoch_657, Loss: 0.3543\n",
      "fold_2, epoch_658, Loss: 0.3554\n",
      "fold_2, epoch_659, Loss: 0.3521\n",
      "fold_2, epoch_660, Loss: 0.3525\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3551\n",
      "Accuracy:\t0.9580\n",
      "AUC:\t\t0.9571\n",
      "Precision:\t0.9820\n",
      "Recall:\t\t0.9328\n",
      "F1:\t\t\t0.9568\n",
      "\n",
      "fold_2, epoch_661, Loss: 0.3537\n",
      "fold_2, epoch_662, Loss: 0.3525\n",
      "fold_2, epoch_663, Loss: 0.3562\n",
      "fold_2, epoch_664, Loss: 0.3547\n",
      "fold_2, epoch_665, Loss: 0.3535\n",
      "fold_2, epoch_666, Loss: 0.3527\n",
      "fold_2, epoch_667, Loss: 0.3517\n",
      "fold_2, epoch_668, Loss: 0.3549\n",
      "fold_2, epoch_669, Loss: 0.3508\n",
      "fold_2, epoch_670, Loss: 0.3525\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9586\n",
      "Precision:\t0.9840\n",
      "Recall:\t\t0.9332\n",
      "F1:\t\t\t0.9579\n",
      "\n",
      "fold_2, epoch_671, Loss: 0.3527\n",
      "fold_2, epoch_672, Loss: 0.3558\n",
      "fold_2, epoch_673, Loss: 0.3537\n",
      "fold_2, epoch_674, Loss: 0.3528\n",
      "fold_2, epoch_675, Loss: 0.3515\n",
      "fold_2, epoch_676, Loss: 0.3516\n",
      "fold_2, epoch_677, Loss: 0.3542\n",
      "fold_2, epoch_678, Loss: 0.3547\n",
      "fold_2, epoch_679, Loss: 0.3551\n",
      "fold_2, epoch_680, Loss: 0.3527\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3542\n",
      "Accuracy:\t0.9589\n",
      "AUC:\t\t0.9592\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9334\n",
      "F1:\t\t\t0.9581\n",
      "\n",
      "fold_2, epoch_681, Loss: 0.3552\n",
      "fold_2, epoch_682, Loss: 0.3533\n",
      "fold_2, epoch_683, Loss: 0.3537\n",
      "fold_2, epoch_684, Loss: 0.3567\n",
      "fold_2, epoch_685, Loss: 0.3549\n",
      "fold_2, epoch_686, Loss: 0.3529\n",
      "fold_2, epoch_687, Loss: 0.3525\n",
      "fold_2, epoch_688, Loss: 0.3515\n",
      "fold_2, epoch_689, Loss: 0.3554\n",
      "fold_2, epoch_690, Loss: 0.3530\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3497\n",
      "Accuracy:\t0.9636\n",
      "AUC:\t\t0.9616\n",
      "Precision:\t0.9881\n",
      "Recall:\t\t0.9383\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_2, epoch_691, Loss: 0.3531\n",
      "fold_2, epoch_692, Loss: 0.3543\n",
      "fold_2, epoch_693, Loss: 0.3533\n",
      "fold_2, epoch_694, Loss: 0.3540\n",
      "fold_2, epoch_695, Loss: 0.3538\n",
      "fold_2, epoch_696, Loss: 0.3515\n",
      "fold_2, epoch_697, Loss: 0.3527\n",
      "fold_2, epoch_698, Loss: 0.3560\n",
      "fold_2, epoch_699, Loss: 0.3534\n",
      "fold_2, epoch_700, Loss: 0.3546\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9594\n",
      "AUC:\t\t0.9589\n",
      "Precision:\t0.9819\n",
      "Recall:\t\t0.9362\n",
      "F1:\t\t\t0.9585\n",
      "\n",
      "fold_2, epoch_701, Loss: 0.3559\n",
      "fold_2, epoch_702, Loss: 0.3555\n",
      "fold_2, epoch_703, Loss: 0.3546\n",
      "fold_2, epoch_704, Loss: 0.3519\n",
      "fold_2, epoch_705, Loss: 0.3514\n",
      "fold_2, epoch_706, Loss: 0.3532\n",
      "fold_2, epoch_707, Loss: 0.3541\n",
      "fold_2, epoch_708, Loss: 0.3544\n",
      "fold_2, epoch_709, Loss: 0.3554\n",
      "fold_2, epoch_710, Loss: 0.3547\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3543\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9815\n",
      "Recall:\t\t0.9352\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_2, epoch_711, Loss: 0.3519\n",
      "fold_2, epoch_712, Loss: 0.3534\n",
      "fold_2, epoch_713, Loss: 0.3545\n",
      "fold_2, epoch_714, Loss: 0.3534\n",
      "fold_2, epoch_715, Loss: 0.3541\n",
      "fold_2, epoch_716, Loss: 0.3533\n",
      "fold_2, epoch_717, Loss: 0.3535\n",
      "fold_2, epoch_718, Loss: 0.3513\n",
      "fold_2, epoch_719, Loss: 0.3550\n",
      "fold_2, epoch_720, Loss: 0.3526\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3515\n",
      "Accuracy:\t0.9619\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9865\n",
      "Recall:\t\t0.9368\n",
      "F1:\t\t\t0.9610\n",
      "\n",
      "fold_2, epoch_721, Loss: 0.3557\n",
      "fold_2, epoch_722, Loss: 0.3538\n",
      "fold_2, epoch_723, Loss: 0.3537\n",
      "fold_2, epoch_724, Loss: 0.3532\n",
      "fold_2, epoch_725, Loss: 0.3545\n",
      "fold_2, epoch_726, Loss: 0.3500\n",
      "fold_2, epoch_727, Loss: 0.3560\n",
      "fold_2, epoch_728, Loss: 0.3514\n",
      "fold_2, epoch_729, Loss: 0.3518\n",
      "fold_2, epoch_730, Loss: 0.3523\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3556\n",
      "Accuracy:\t0.9574\n",
      "AUC:\t\t0.9580\n",
      "Precision:\t0.9847\n",
      "Recall:\t\t0.9289\n",
      "F1:\t\t\t0.9560\n",
      "\n",
      "fold_2, epoch_731, Loss: 0.3566\n",
      "fold_2, epoch_732, Loss: 0.3512\n",
      "fold_2, epoch_733, Loss: 0.3516\n",
      "fold_2, epoch_734, Loss: 0.3526\n",
      "fold_2, epoch_735, Loss: 0.3555\n",
      "fold_2, epoch_736, Loss: 0.3532\n",
      "fold_2, epoch_737, Loss: 0.3506\n",
      "fold_2, epoch_738, Loss: 0.3528\n",
      "fold_2, epoch_739, Loss: 0.3534\n",
      "fold_2, epoch_740, Loss: 0.3505\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3511\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9601\n",
      "Precision:\t0.9874\n",
      "Recall:\t\t0.9359\n",
      "F1:\t\t\t0.9610\n",
      "\n",
      "fold_2, epoch_741, Loss: 0.3500\n",
      "fold_2, epoch_742, Loss: 0.3549\n",
      "fold_2, epoch_743, Loss: 0.3543\n",
      "fold_2, epoch_744, Loss: 0.3505\n",
      "fold_2, epoch_745, Loss: 0.3530\n",
      "fold_2, epoch_746, Loss: 0.3515\n",
      "fold_2, epoch_747, Loss: 0.3517\n",
      "fold_2, epoch_748, Loss: 0.3524\n",
      "fold_2, epoch_749, Loss: 0.3543\n",
      "fold_2, epoch_750, Loss: 0.3553\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9604\n",
      "AUC:\t\t0.9602\n",
      "Precision:\t0.9864\n",
      "Recall:\t\t0.9342\n",
      "F1:\t\t\t0.9596\n",
      "\n",
      "fold_2, epoch_751, Loss: 0.3531\n",
      "fold_2, epoch_752, Loss: 0.3512\n",
      "fold_2, epoch_753, Loss: 0.3526\n",
      "fold_2, epoch_754, Loss: 0.3518\n",
      "fold_2, epoch_755, Loss: 0.3536\n",
      "fold_2, epoch_756, Loss: 0.3556\n",
      "fold_2, epoch_757, Loss: 0.3525\n",
      "fold_2, epoch_758, Loss: 0.3509\n",
      "fold_2, epoch_759, Loss: 0.3505\n",
      "fold_2, epoch_760, Loss: 0.3527\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3529\n",
      "Accuracy:\t0.9603\n",
      "AUC:\t\t0.9591\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9340\n",
      "F1:\t\t\t0.9596\n",
      "\n",
      "fold_2, epoch_761, Loss: 0.3540\n",
      "fold_2, epoch_762, Loss: 0.3517\n",
      "fold_2, epoch_763, Loss: 0.3531\n",
      "fold_2, epoch_764, Loss: 0.3521\n",
      "fold_2, epoch_765, Loss: 0.3537\n",
      "fold_2, epoch_766, Loss: 0.3509\n",
      "fold_2, epoch_767, Loss: 0.3525\n",
      "fold_2, epoch_768, Loss: 0.3538\n",
      "fold_2, epoch_769, Loss: 0.3525\n",
      "fold_2, epoch_770, Loss: 0.3517\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3503\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9884\n",
      "Recall:\t\t0.9370\n",
      "F1:\t\t\t0.9620\n",
      "\n",
      "fold_2, epoch_771, Loss: 0.3526\n",
      "fold_2, epoch_772, Loss: 0.3524\n",
      "fold_2, epoch_773, Loss: 0.3545\n",
      "fold_2, epoch_774, Loss: 0.3522\n",
      "fold_2, epoch_775, Loss: 0.3535\n",
      "fold_2, epoch_776, Loss: 0.3531\n",
      "fold_2, epoch_777, Loss: 0.3527\n",
      "fold_2, epoch_778, Loss: 0.3528\n",
      "fold_2, epoch_779, Loss: 0.3526\n",
      "fold_2, epoch_780, Loss: 0.3524\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9606\n",
      "AUC:\t\t0.9607\n",
      "Precision:\t0.9880\n",
      "Recall:\t\t0.9329\n",
      "F1:\t\t\t0.9596\n",
      "\n",
      "fold_2, epoch_781, Loss: 0.3534\n",
      "fold_2, epoch_782, Loss: 0.3517\n",
      "fold_2, epoch_783, Loss: 0.3523\n",
      "fold_2, epoch_784, Loss: 0.3501\n",
      "fold_2, epoch_785, Loss: 0.3504\n",
      "fold_2, epoch_786, Loss: 0.3502\n",
      "fold_2, epoch_787, Loss: 0.3525\n",
      "fold_2, epoch_788, Loss: 0.3547\n",
      "fold_2, epoch_789, Loss: 0.3540\n",
      "fold_2, epoch_790, Loss: 0.3512\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3547\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9588\n",
      "Precision:\t0.9863\n",
      "Recall:\t\t0.9295\n",
      "F1:\t\t\t0.9571\n",
      "\n",
      "fold_2, epoch_791, Loss: 0.3532\n",
      "fold_2, epoch_792, Loss: 0.3553\n",
      "fold_2, epoch_793, Loss: 0.3528\n",
      "fold_2, epoch_794, Loss: 0.3517\n",
      "fold_2, epoch_795, Loss: 0.3533\n",
      "fold_2, epoch_796, Loss: 0.3518\n",
      "fold_2, epoch_797, Loss: 0.3530\n",
      "fold_2, epoch_798, Loss: 0.3507\n",
      "fold_2, epoch_799, Loss: 0.3510\n",
      "fold_2, epoch_800, Loss: 0.3531\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3522\n",
      "Accuracy:\t0.9610\n",
      "AUC:\t\t0.9603\n",
      "Precision:\t0.9868\n",
      "Recall:\t\t0.9338\n",
      "F1:\t\t\t0.9595\n",
      "\n",
      "fold_2, epoch_801, Loss: 0.3516\n",
      "fold_2, epoch_802, Loss: 0.3537\n",
      "fold_2, epoch_803, Loss: 0.3521\n",
      "fold_2, epoch_804, Loss: 0.3527\n",
      "fold_2, epoch_805, Loss: 0.3521\n",
      "fold_2, epoch_806, Loss: 0.3516\n",
      "fold_2, epoch_807, Loss: 0.3557\n",
      "fold_2, epoch_808, Loss: 0.3524\n",
      "fold_2, epoch_809, Loss: 0.3525\n",
      "fold_2, epoch_810, Loss: 0.3521\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9615\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9870\n",
      "Recall:\t\t0.9359\n",
      "F1:\t\t\t0.9608\n",
      "\n",
      "fold_2, epoch_811, Loss: 0.3517\n",
      "fold_2, epoch_812, Loss: 0.3522\n",
      "fold_2, epoch_813, Loss: 0.3526\n",
      "fold_2, epoch_814, Loss: 0.3535\n",
      "fold_2, epoch_815, Loss: 0.3527\n",
      "fold_2, epoch_816, Loss: 0.3536\n",
      "fold_2, epoch_817, Loss: 0.3515\n",
      "fold_2, epoch_818, Loss: 0.3508\n",
      "fold_2, epoch_819, Loss: 0.3499\n",
      "fold_2, epoch_820, Loss: 0.3541\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3546\n",
      "Accuracy:\t0.9585\n",
      "AUC:\t\t0.9587\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9323\n",
      "F1:\t\t\t0.9575\n",
      "\n",
      "fold_2, epoch_821, Loss: 0.3526\n",
      "fold_2, epoch_822, Loss: 0.3523\n",
      "fold_2, epoch_823, Loss: 0.3510\n",
      "fold_2, epoch_824, Loss: 0.3523\n",
      "fold_2, epoch_825, Loss: 0.3533\n",
      "fold_2, epoch_826, Loss: 0.3512\n",
      "fold_2, epoch_827, Loss: 0.3515\n",
      "fold_2, epoch_828, Loss: 0.3525\n",
      "fold_2, epoch_829, Loss: 0.3530\n",
      "fold_2, epoch_830, Loss: 0.3517\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3517\n",
      "Accuracy:\t0.9615\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9903\n",
      "Recall:\t\t0.9330\n",
      "F1:\t\t\t0.9608\n",
      "\n",
      "fold_2, epoch_831, Loss: 0.3495\n",
      "fold_2, epoch_832, Loss: 0.3540\n",
      "fold_2, epoch_833, Loss: 0.3542\n",
      "fold_2, epoch_834, Loss: 0.3524\n",
      "fold_2, epoch_835, Loss: 0.3525\n",
      "fold_2, epoch_836, Loss: 0.3510\n",
      "fold_2, epoch_837, Loss: 0.3496\n",
      "fold_2, epoch_838, Loss: 0.3503\n",
      "fold_2, epoch_839, Loss: 0.3524\n",
      "fold_2, epoch_840, Loss: 0.3507\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3503\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9619\n",
      "Precision:\t0.9901\n",
      "Recall:\t\t0.9354\n",
      "F1:\t\t\t0.9620\n",
      "\n",
      "fold_2, epoch_841, Loss: 0.3505\n",
      "fold_2, epoch_842, Loss: 0.3508\n",
      "fold_2, epoch_843, Loss: 0.3510\n",
      "fold_2, epoch_844, Loss: 0.3515\n",
      "fold_2, epoch_845, Loss: 0.3520\n",
      "fold_2, epoch_846, Loss: 0.3527\n",
      "fold_2, epoch_847, Loss: 0.3539\n",
      "fold_2, epoch_848, Loss: 0.3531\n",
      "fold_2, epoch_849, Loss: 0.3554\n",
      "fold_2, epoch_850, Loss: 0.3505\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3513\n",
      "Accuracy:\t0.9619\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9856\n",
      "Recall:\t\t0.9372\n",
      "F1:\t\t\t0.9608\n",
      "\n",
      "fold_2, epoch_851, Loss: 0.3525\n",
      "fold_2, epoch_852, Loss: 0.3504\n",
      "fold_2, epoch_853, Loss: 0.3509\n",
      "fold_2, epoch_854, Loss: 0.3533\n",
      "fold_2, epoch_855, Loss: 0.3499\n",
      "fold_2, epoch_856, Loss: 0.3490\n",
      "fold_2, epoch_857, Loss: 0.3531\n",
      "fold_2, epoch_858, Loss: 0.3525\n",
      "fold_2, epoch_859, Loss: 0.3538\n",
      "fold_2, epoch_860, Loss: 0.3538\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3521\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9584\n",
      "Precision:\t0.9888\n",
      "Recall:\t\t0.9324\n",
      "F1:\t\t\t0.9598\n",
      "\n",
      "fold_2, epoch_861, Loss: 0.3508\n",
      "fold_2, epoch_862, Loss: 0.3500\n",
      "fold_2, epoch_863, Loss: 0.3526\n",
      "fold_2, epoch_864, Loss: 0.3515\n",
      "fold_2, epoch_865, Loss: 0.3509\n",
      "fold_2, epoch_866, Loss: 0.3517\n",
      "fold_2, epoch_867, Loss: 0.3534\n",
      "fold_2, epoch_868, Loss: 0.3498\n",
      "fold_2, epoch_869, Loss: 0.3506\n",
      "fold_2, epoch_870, Loss: 0.3537\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3534\n",
      "Accuracy:\t0.9598\n",
      "AUC:\t\t0.9587\n",
      "Precision:\t0.9869\n",
      "Recall:\t\t0.9319\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_2, epoch_871, Loss: 0.3508\n",
      "fold_2, epoch_872, Loss: 0.3518\n",
      "fold_2, epoch_873, Loss: 0.3523\n",
      "fold_2, epoch_874, Loss: 0.3506\n",
      "fold_2, epoch_875, Loss: 0.3536\n",
      "fold_2, epoch_876, Loss: 0.3521\n",
      "fold_2, epoch_877, Loss: 0.3513\n",
      "fold_2, epoch_878, Loss: 0.3511\n",
      "fold_2, epoch_879, Loss: 0.3503\n",
      "fold_2, epoch_880, Loss: 0.3534\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9626\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9880\n",
      "Recall:\t\t0.9372\n",
      "F1:\t\t\t0.9620\n",
      "\n",
      "fold_2, epoch_881, Loss: 0.3514\n",
      "fold_2, epoch_882, Loss: 0.3525\n",
      "fold_2, epoch_883, Loss: 0.3536\n",
      "fold_2, epoch_884, Loss: 0.3504\n",
      "fold_2, epoch_885, Loss: 0.3523\n",
      "fold_2, epoch_886, Loss: 0.3482\n",
      "fold_2, epoch_887, Loss: 0.3530\n",
      "fold_2, epoch_888, Loss: 0.3527\n",
      "fold_2, epoch_889, Loss: 0.3527\n",
      "fold_2, epoch_890, Loss: 0.3515\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9623\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9877\n",
      "Recall:\t\t0.9361\n",
      "F1:\t\t\t0.9612\n",
      "\n",
      "fold_2, epoch_891, Loss: 0.3507\n",
      "fold_2, epoch_892, Loss: 0.3523\n",
      "fold_2, epoch_893, Loss: 0.3517\n",
      "fold_2, epoch_894, Loss: 0.3511\n",
      "fold_2, epoch_895, Loss: 0.3512\n",
      "fold_2, epoch_896, Loss: 0.3513\n",
      "fold_2, epoch_897, Loss: 0.3521\n",
      "fold_2, epoch_898, Loss: 0.3516\n",
      "fold_2, epoch_899, Loss: 0.3511\n",
      "fold_2, epoch_900, Loss: 0.3514\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9616\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9870\n",
      "Recall:\t\t0.9358\n",
      "F1:\t\t\t0.9607\n",
      "\n",
      "fold_2, epoch_901, Loss: 0.3525\n",
      "fold_2, epoch_902, Loss: 0.3533\n",
      "fold_2, epoch_903, Loss: 0.3510\n",
      "fold_2, epoch_904, Loss: 0.3518\n",
      "fold_2, epoch_905, Loss: 0.3506\n",
      "fold_2, epoch_906, Loss: 0.3527\n",
      "fold_2, epoch_907, Loss: 0.3533\n",
      "fold_2, epoch_908, Loss: 0.3508\n",
      "fold_2, epoch_909, Loss: 0.3516\n",
      "fold_2, epoch_910, Loss: 0.3521\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9595\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9892\n",
      "Recall:\t\t0.9297\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_2, epoch_911, Loss: 0.3523\n",
      "fold_2, epoch_912, Loss: 0.3534\n",
      "fold_2, epoch_913, Loss: 0.3514\n",
      "fold_2, epoch_914, Loss: 0.3492\n",
      "fold_2, epoch_915, Loss: 0.3536\n",
      "fold_2, epoch_916, Loss: 0.3520\n",
      "fold_2, epoch_917, Loss: 0.3499\n",
      "fold_2, epoch_918, Loss: 0.3524\n",
      "fold_2, epoch_919, Loss: 0.3519\n",
      "fold_2, epoch_920, Loss: 0.3526\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3512\n",
      "Accuracy:\t0.9620\n",
      "AUC:\t\t0.9601\n",
      "Precision:\t0.9886\n",
      "Recall:\t\t0.9348\n",
      "F1:\t\t\t0.9609\n",
      "\n",
      "fold_2, epoch_921, Loss: 0.3507\n",
      "fold_2, epoch_922, Loss: 0.3535\n",
      "fold_2, epoch_923, Loss: 0.3510\n",
      "fold_2, epoch_924, Loss: 0.3513\n",
      "fold_2, epoch_925, Loss: 0.3496\n",
      "fold_2, epoch_926, Loss: 0.3513\n",
      "fold_2, epoch_927, Loss: 0.3497\n",
      "fold_2, epoch_928, Loss: 0.3510\n",
      "fold_2, epoch_929, Loss: 0.3522\n",
      "fold_2, epoch_930, Loss: 0.3508\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3504\n",
      "Accuracy:\t0.9628\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9888\n",
      "Recall:\t\t0.9356\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_2, epoch_931, Loss: 0.3489\n",
      "fold_2, epoch_932, Loss: 0.3511\n",
      "fold_2, epoch_933, Loss: 0.3514\n",
      "fold_2, epoch_934, Loss: 0.3508\n",
      "fold_2, epoch_935, Loss: 0.3527\n",
      "fold_2, epoch_936, Loss: 0.3529\n",
      "fold_2, epoch_937, Loss: 0.3503\n",
      "fold_2, epoch_938, Loss: 0.3492\n",
      "fold_2, epoch_939, Loss: 0.3504\n",
      "fold_2, epoch_940, Loss: 0.3526\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3497\n",
      "Accuracy:\t0.9634\n",
      "AUC:\t\t0.9642\n",
      "Precision:\t0.9901\n",
      "Recall:\t\t0.9369\n",
      "F1:\t\t\t0.9627\n",
      "\n",
      "fold_2, epoch_941, Loss: 0.3518\n",
      "fold_2, epoch_942, Loss: 0.3532\n",
      "fold_2, epoch_943, Loss: 0.3521\n",
      "fold_2, epoch_944, Loss: 0.3541\n",
      "fold_2, epoch_945, Loss: 0.3522\n",
      "fold_2, epoch_946, Loss: 0.3519\n",
      "fold_2, epoch_947, Loss: 0.3520\n",
      "fold_2, epoch_948, Loss: 0.3507\n",
      "fold_2, epoch_949, Loss: 0.3506\n",
      "fold_2, epoch_950, Loss: 0.3505\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9604\n",
      "AUC:\t\t0.9597\n",
      "Precision:\t0.9891\n",
      "Recall:\t\t0.9316\n",
      "F1:\t\t\t0.9595\n",
      "\n",
      "fold_2, epoch_951, Loss: 0.3504\n",
      "fold_2, epoch_952, Loss: 0.3512\n",
      "fold_2, epoch_953, Loss: 0.3511\n",
      "fold_2, epoch_954, Loss: 0.3505\n",
      "fold_2, epoch_955, Loss: 0.3505\n",
      "fold_2, epoch_956, Loss: 0.3507\n",
      "fold_2, epoch_957, Loss: 0.3527\n",
      "fold_2, epoch_958, Loss: 0.3516\n",
      "fold_2, epoch_959, Loss: 0.3501\n",
      "fold_2, epoch_960, Loss: 0.3499\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3495\n",
      "Accuracy:\t0.9637\n",
      "AUC:\t\t0.9620\n",
      "Precision:\t0.9894\n",
      "Recall:\t\t0.9372\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_2, epoch_961, Loss: 0.3519\n",
      "fold_2, epoch_962, Loss: 0.3515\n",
      "fold_2, epoch_963, Loss: 0.3533\n",
      "fold_2, epoch_964, Loss: 0.3516\n",
      "fold_2, epoch_965, Loss: 0.3508\n",
      "fold_2, epoch_966, Loss: 0.3512\n",
      "fold_2, epoch_967, Loss: 0.3517\n",
      "fold_2, epoch_968, Loss: 0.3513\n",
      "fold_2, epoch_969, Loss: 0.3504\n",
      "fold_2, epoch_970, Loss: 0.3522\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3498\n",
      "Accuracy:\t0.9634\n",
      "AUC:\t\t0.9626\n",
      "Precision:\t0.9882\n",
      "Recall:\t\t0.9379\n",
      "F1:\t\t\t0.9624\n",
      "\n",
      "fold_2, epoch_971, Loss: 0.3538\n",
      "fold_2, epoch_972, Loss: 0.3519\n",
      "fold_2, epoch_973, Loss: 0.3522\n",
      "fold_2, epoch_974, Loss: 0.3497\n",
      "fold_2, epoch_975, Loss: 0.3505\n",
      "fold_2, epoch_976, Loss: 0.3524\n",
      "fold_2, epoch_977, Loss: 0.3500\n",
      "fold_2, epoch_978, Loss: 0.3513\n",
      "fold_2, epoch_979, Loss: 0.3498\n",
      "fold_2, epoch_980, Loss: 0.3539\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3500\n",
      "Accuracy:\t0.9632\n",
      "AUC:\t\t0.9622\n",
      "Precision:\t0.9897\n",
      "Recall:\t\t0.9365\n",
      "F1:\t\t\t0.9623\n",
      "\n",
      "fold_2, epoch_981, Loss: 0.3516\n",
      "fold_2, epoch_982, Loss: 0.3498\n",
      "fold_2, epoch_983, Loss: 0.3521\n",
      "fold_2, epoch_984, Loss: 0.3534\n",
      "fold_2, epoch_985, Loss: 0.3521\n",
      "fold_2, epoch_986, Loss: 0.3511\n",
      "fold_2, epoch_987, Loss: 0.3493\n",
      "fold_2, epoch_988, Loss: 0.3526\n",
      "fold_2, epoch_989, Loss: 0.3508\n",
      "fold_2, epoch_990, Loss: 0.3533\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3500\n",
      "Accuracy:\t0.9633\n",
      "AUC:\t\t0.9623\n",
      "Precision:\t0.9901\n",
      "Recall:\t\t0.9364\n",
      "F1:\t\t\t0.9625\n",
      "\n",
      "fold_2, epoch_991, Loss: 0.3501\n",
      "fold_2, epoch_992, Loss: 0.3477\n",
      "fold_2, epoch_993, Loss: 0.3509\n",
      "fold_2, epoch_994, Loss: 0.3509\n",
      "fold_2, epoch_995, Loss: 0.3539\n",
      "fold_2, epoch_996, Loss: 0.3518\n",
      "fold_2, epoch_997, Loss: 0.3507\n",
      "fold_2, epoch_998, Loss: 0.3497\n",
      "fold_2, epoch_999, Loss: 0.3501\n",
      "fold_2, epoch_1000, Loss: 0.3506\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3517\n",
      "Accuracy:\t0.9615\n",
      "AUC:\t\t0.9603\n",
      "Precision:\t0.9892\n",
      "Recall:\t\t0.9326\n",
      "F1:\t\t\t0.9601\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/checkpoints/fold_3\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/tensorboard\n",
      "\n",
      "\n",
      "fold_3, epoch_1, Loss: 0.5963\n",
      "fold_3, epoch_2, Loss: 0.6490\n",
      "fold_3, epoch_3, Loss: 0.5642\n",
      "fold_3, epoch_4, Loss: 0.5477\n",
      "fold_3, epoch_5, Loss: 0.5456\n",
      "fold_3, epoch_6, Loss: 0.5332\n",
      "fold_3, epoch_7, Loss: 0.5278\n",
      "fold_3, epoch_8, Loss: 0.5243\n",
      "fold_3, epoch_9, Loss: 0.5186\n",
      "fold_3, epoch_10, Loss: 0.5129\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.5113\n",
      "Accuracy:\t0.7909\n",
      "AUC:\t\t0.8636\n",
      "Precision:\t0.7863\n",
      "Recall:\t\t0.7968\n",
      "F1:\t\t\t0.7915\n",
      "\n",
      "fold_3, epoch_11, Loss: 0.5100\n",
      "fold_3, epoch_12, Loss: 0.5093\n",
      "fold_3, epoch_13, Loss: 0.5035\n",
      "fold_3, epoch_14, Loss: 0.5028\n",
      "fold_3, epoch_15, Loss: 0.5008\n",
      "fold_3, epoch_16, Loss: 0.4952\n",
      "fold_3, epoch_17, Loss: 0.4956\n",
      "fold_3, epoch_18, Loss: 0.4920\n",
      "fold_3, epoch_19, Loss: 0.4936\n",
      "fold_3, epoch_20, Loss: 0.4844\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4860\n",
      "Accuracy:\t0.8221\n",
      "AUC:\t\t0.8806\n",
      "Precision:\t0.8054\n",
      "Recall:\t\t0.8507\n",
      "F1:\t\t\t0.8275\n",
      "\n",
      "fold_3, epoch_21, Loss: 0.4853\n",
      "fold_3, epoch_22, Loss: 0.4812\n",
      "fold_3, epoch_23, Loss: 0.4816\n",
      "fold_3, epoch_24, Loss: 0.4775\n",
      "fold_3, epoch_25, Loss: 0.4779\n",
      "fold_3, epoch_26, Loss: 0.4767\n",
      "fold_3, epoch_27, Loss: 0.4699\n",
      "fold_3, epoch_28, Loss: 0.4693\n",
      "fold_3, epoch_29, Loss: 0.4771\n",
      "fold_3, epoch_30, Loss: 0.4665\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4682\n",
      "Accuracy:\t0.8410\n",
      "AUC:\t\t0.8916\n",
      "Precision:\t0.8516\n",
      "Recall:\t\t0.8266\n",
      "F1:\t\t\t0.8389\n",
      "\n",
      "fold_3, epoch_31, Loss: 0.4654\n",
      "fold_3, epoch_32, Loss: 0.4643\n",
      "fold_3, epoch_33, Loss: 0.4601\n",
      "fold_3, epoch_34, Loss: 0.4630\n",
      "fold_3, epoch_35, Loss: 0.4595\n",
      "fold_3, epoch_36, Loss: 0.4587\n",
      "fold_3, epoch_37, Loss: 0.4560\n",
      "fold_3, epoch_38, Loss: 0.4561\n",
      "fold_3, epoch_39, Loss: 0.4577\n",
      "fold_3, epoch_40, Loss: 0.4496\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4651\n",
      "Accuracy:\t0.8456\n",
      "AUC:\t\t0.8901\n",
      "Precision:\t0.8369\n",
      "Recall:\t\t0.8594\n",
      "F1:\t\t\t0.8480\n",
      "\n",
      "fold_3, epoch_41, Loss: 0.4543\n",
      "fold_3, epoch_42, Loss: 0.4533\n",
      "fold_3, epoch_43, Loss: 0.4499\n",
      "fold_3, epoch_44, Loss: 0.4478\n",
      "fold_3, epoch_45, Loss: 0.4473\n",
      "fold_3, epoch_46, Loss: 0.4480\n",
      "fold_3, epoch_47, Loss: 0.4475\n",
      "fold_3, epoch_48, Loss: 0.4422\n",
      "fold_3, epoch_49, Loss: 0.4526\n",
      "fold_3, epoch_50, Loss: 0.4398\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4346\n",
      "Accuracy:\t0.8787\n",
      "AUC:\t\t0.9046\n",
      "Precision:\t0.8715\n",
      "Recall:\t\t0.8869\n",
      "F1:\t\t\t0.8792\n",
      "\n",
      "fold_3, epoch_51, Loss: 0.4421\n",
      "fold_3, epoch_52, Loss: 0.4477\n",
      "fold_3, epoch_53, Loss: 0.4409\n",
      "fold_3, epoch_54, Loss: 0.4393\n",
      "fold_3, epoch_55, Loss: 0.4371\n",
      "fold_3, epoch_56, Loss: 0.4393\n",
      "fold_3, epoch_57, Loss: 0.4348\n",
      "fold_3, epoch_58, Loss: 0.4389\n",
      "fold_3, epoch_59, Loss: 0.4271\n",
      "fold_3, epoch_60, Loss: 0.4326\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4253\n",
      "Accuracy:\t0.8866\n",
      "AUC:\t\t0.9118\n",
      "Precision:\t0.8669\n",
      "Recall:\t\t0.9138\n",
      "F1:\t\t\t0.8898\n",
      "\n",
      "fold_3, epoch_61, Loss: 0.4318\n",
      "fold_3, epoch_62, Loss: 0.4345\n",
      "fold_3, epoch_63, Loss: 0.4373\n",
      "fold_3, epoch_64, Loss: 0.4382\n",
      "fold_3, epoch_65, Loss: 0.4235\n",
      "fold_3, epoch_66, Loss: 0.4298\n",
      "fold_3, epoch_67, Loss: 0.4246\n",
      "fold_3, epoch_68, Loss: 0.4239\n",
      "fold_3, epoch_69, Loss: 0.4316\n",
      "fold_3, epoch_70, Loss: 0.4284\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4170\n",
      "Accuracy:\t0.8955\n",
      "AUC:\t\t0.9125\n",
      "Precision:\t0.8936\n",
      "Recall:\t\t0.8988\n",
      "F1:\t\t\t0.8962\n",
      "\n",
      "fold_3, epoch_71, Loss: 0.4221\n",
      "fold_3, epoch_72, Loss: 0.4165\n",
      "fold_3, epoch_73, Loss: 0.4188\n",
      "fold_3, epoch_74, Loss: 0.4184\n",
      "fold_3, epoch_75, Loss: 0.4187\n",
      "fold_3, epoch_76, Loss: 0.4177\n",
      "fold_3, epoch_77, Loss: 0.4166\n",
      "fold_3, epoch_78, Loss: 0.4299\n",
      "fold_3, epoch_79, Loss: 0.4167\n",
      "fold_3, epoch_80, Loss: 0.4178\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4161\n",
      "Accuracy:\t0.8960\n",
      "AUC:\t\t0.9164\n",
      "Precision:\t0.8916\n",
      "Recall:\t\t0.9029\n",
      "F1:\t\t\t0.8972\n",
      "\n",
      "fold_3, epoch_81, Loss: 0.4171\n",
      "fold_3, epoch_82, Loss: 0.4136\n",
      "fold_3, epoch_83, Loss: 0.4185\n",
      "fold_3, epoch_84, Loss: 0.4148\n",
      "fold_3, epoch_85, Loss: 0.4165\n",
      "fold_3, epoch_86, Loss: 0.4149\n",
      "fold_3, epoch_87, Loss: 0.4113\n",
      "fold_3, epoch_88, Loss: 0.4163\n",
      "fold_3, epoch_89, Loss: 0.4121\n",
      "fold_3, epoch_90, Loss: 0.4144\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4117\n",
      "Accuracy:\t0.9006\n",
      "AUC:\t\t0.9168\n",
      "Precision:\t0.8972\n",
      "Recall:\t\t0.9048\n",
      "F1:\t\t\t0.9010\n",
      "\n",
      "fold_3, epoch_91, Loss: 0.4127\n",
      "fold_3, epoch_92, Loss: 0.4098\n",
      "fold_3, epoch_93, Loss: 0.4113\n",
      "fold_3, epoch_94, Loss: 0.4117\n",
      "fold_3, epoch_95, Loss: 0.4070\n",
      "fold_3, epoch_96, Loss: 0.4074\n",
      "fold_3, epoch_97, Loss: 0.4150\n",
      "fold_3, epoch_98, Loss: 0.4074\n",
      "fold_3, epoch_99, Loss: 0.4091\n",
      "fold_3, epoch_100, Loss: 0.4044\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4002\n",
      "Accuracy:\t0.9127\n",
      "AUC:\t\t0.9247\n",
      "Precision:\t0.9180\n",
      "Recall:\t\t0.9066\n",
      "F1:\t\t\t0.9123\n",
      "\n",
      "fold_3, epoch_101, Loss: 0.4051\n",
      "fold_3, epoch_102, Loss: 0.4091\n",
      "fold_3, epoch_103, Loss: 0.4056\n",
      "fold_3, epoch_104, Loss: 0.4028\n",
      "fold_3, epoch_105, Loss: 0.4115\n",
      "fold_3, epoch_106, Loss: 0.4121\n",
      "fold_3, epoch_107, Loss: 0.4100\n",
      "fold_3, epoch_108, Loss: 0.4056\n",
      "fold_3, epoch_109, Loss: 0.4094\n",
      "fold_3, epoch_110, Loss: 0.4050\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4011\n",
      "Accuracy:\t0.9110\n",
      "AUC:\t\t0.9220\n",
      "Precision:\t0.8985\n",
      "Recall:\t\t0.9256\n",
      "F1:\t\t\t0.9118\n",
      "\n",
      "fold_3, epoch_111, Loss: 0.4029\n",
      "fold_3, epoch_112, Loss: 0.3993\n",
      "fold_3, epoch_113, Loss: 0.4057\n",
      "fold_3, epoch_114, Loss: 0.4059\n",
      "fold_3, epoch_115, Loss: 0.3959\n",
      "fold_3, epoch_116, Loss: 0.4036\n",
      "fold_3, epoch_117, Loss: 0.3975\n",
      "fold_3, epoch_118, Loss: 0.3981\n",
      "fold_3, epoch_119, Loss: 0.4006\n",
      "fold_3, epoch_120, Loss: 0.3980\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4002\n",
      "Accuracy:\t0.9128\n",
      "AUC:\t\t0.9239\n",
      "Precision:\t0.9210\n",
      "Recall:\t\t0.9044\n",
      "F1:\t\t\t0.9126\n",
      "\n",
      "fold_3, epoch_121, Loss: 0.4010\n",
      "fold_3, epoch_122, Loss: 0.3984\n",
      "fold_3, epoch_123, Loss: 0.3995\n",
      "fold_3, epoch_124, Loss: 0.3978\n",
      "fold_3, epoch_125, Loss: 0.3970\n",
      "fold_3, epoch_126, Loss: 0.4000\n",
      "fold_3, epoch_127, Loss: 0.3973\n",
      "fold_3, epoch_128, Loss: 0.3972\n",
      "fold_3, epoch_129, Loss: 0.3950\n",
      "fold_3, epoch_130, Loss: 0.3977\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3906\n",
      "Accuracy:\t0.9223\n",
      "AUC:\t\t0.9311\n",
      "Precision:\t0.9221\n",
      "Recall:\t\t0.9213\n",
      "F1:\t\t\t0.9217\n",
      "\n",
      "fold_3, epoch_131, Loss: 0.4003\n",
      "fold_3, epoch_132, Loss: 0.4013\n",
      "fold_3, epoch_133, Loss: 0.3954\n",
      "fold_3, epoch_134, Loss: 0.4002\n",
      "fold_3, epoch_135, Loss: 0.3946\n",
      "fold_3, epoch_136, Loss: 0.3927\n",
      "fold_3, epoch_137, Loss: 0.3973\n",
      "fold_3, epoch_138, Loss: 0.3894\n",
      "fold_3, epoch_139, Loss: 0.3931\n",
      "fold_3, epoch_140, Loss: 0.3934\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3932\n",
      "Accuracy:\t0.9194\n",
      "AUC:\t\t0.9305\n",
      "Precision:\t0.9239\n",
      "Recall:\t\t0.9143\n",
      "F1:\t\t\t0.9191\n",
      "\n",
      "fold_3, epoch_141, Loss: 0.3952\n",
      "fold_3, epoch_142, Loss: 0.3961\n",
      "fold_3, epoch_143, Loss: 0.3939\n",
      "fold_3, epoch_144, Loss: 0.3935\n",
      "fold_3, epoch_145, Loss: 0.3951\n",
      "fold_3, epoch_146, Loss: 0.3904\n",
      "fold_3, epoch_147, Loss: 0.3877\n",
      "fold_3, epoch_148, Loss: 0.3927\n",
      "fold_3, epoch_149, Loss: 0.3900\n",
      "fold_3, epoch_150, Loss: 0.3929\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3877\n",
      "Accuracy:\t0.9250\n",
      "AUC:\t\t0.9320\n",
      "Precision:\t0.9275\n",
      "Recall:\t\t0.9239\n",
      "F1:\t\t\t0.9257\n",
      "\n",
      "fold_3, epoch_151, Loss: 0.3902\n",
      "fold_3, epoch_152, Loss: 0.3858\n",
      "fold_3, epoch_153, Loss: 0.3924\n",
      "fold_3, epoch_154, Loss: 0.3893\n",
      "fold_3, epoch_155, Loss: 0.3899\n",
      "fold_3, epoch_156, Loss: 0.3852\n",
      "fold_3, epoch_157, Loss: 0.3927\n",
      "fold_3, epoch_158, Loss: 0.3916\n",
      "fold_3, epoch_159, Loss: 0.3866\n",
      "fold_3, epoch_160, Loss: 0.3841\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3820\n",
      "Accuracy:\t0.9311\n",
      "AUC:\t\t0.9377\n",
      "Precision:\t0.9392\n",
      "Recall:\t\t0.9211\n",
      "F1:\t\t\t0.9300\n",
      "\n",
      "fold_3, epoch_161, Loss: 0.3880\n",
      "fold_3, epoch_162, Loss: 0.3882\n",
      "fold_3, epoch_163, Loss: 0.3878\n",
      "fold_3, epoch_164, Loss: 0.3864\n",
      "fold_3, epoch_165, Loss: 0.3888\n",
      "fold_3, epoch_166, Loss: 0.3865\n",
      "fold_3, epoch_167, Loss: 0.3852\n",
      "fold_3, epoch_168, Loss: 0.3843\n",
      "fold_3, epoch_169, Loss: 0.3907\n",
      "fold_3, epoch_170, Loss: 0.3842\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3772\n",
      "Accuracy:\t0.9357\n",
      "AUC:\t\t0.9387\n",
      "Precision:\t0.9431\n",
      "Recall:\t\t0.9275\n",
      "F1:\t\t\t0.9352\n",
      "\n",
      "fold_3, epoch_171, Loss: 0.3874\n",
      "fold_3, epoch_172, Loss: 0.3864\n",
      "fold_3, epoch_173, Loss: 0.3867\n",
      "fold_3, epoch_174, Loss: 0.3864\n",
      "fold_3, epoch_175, Loss: 0.3807\n",
      "fold_3, epoch_176, Loss: 0.3875\n",
      "fold_3, epoch_177, Loss: 0.3866\n",
      "fold_3, epoch_178, Loss: 0.3823\n",
      "fold_3, epoch_179, Loss: 0.3822\n",
      "fold_3, epoch_180, Loss: 0.3837\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3751\n",
      "Accuracy:\t0.9381\n",
      "AUC:\t\t0.9411\n",
      "Precision:\t0.9449\n",
      "Recall:\t\t0.9308\n",
      "F1:\t\t\t0.9378\n",
      "\n",
      "fold_3, epoch_181, Loss: 0.3862\n",
      "fold_3, epoch_182, Loss: 0.3826\n",
      "fold_3, epoch_183, Loss: 0.3846\n",
      "fold_3, epoch_184, Loss: 0.3875\n",
      "fold_3, epoch_185, Loss: 0.3812\n",
      "fold_3, epoch_186, Loss: 0.3847\n",
      "fold_3, epoch_187, Loss: 0.3812\n",
      "fold_3, epoch_188, Loss: 0.3832\n",
      "fold_3, epoch_189, Loss: 0.3855\n",
      "fold_3, epoch_190, Loss: 0.3851\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3844\n",
      "Accuracy:\t0.9283\n",
      "AUC:\t\t0.9389\n",
      "Precision:\t0.9325\n",
      "Recall:\t\t0.9233\n",
      "F1:\t\t\t0.9279\n",
      "\n",
      "fold_3, epoch_191, Loss: 0.3836\n",
      "fold_3, epoch_192, Loss: 0.3851\n",
      "fold_3, epoch_193, Loss: 0.3803\n",
      "fold_3, epoch_194, Loss: 0.3810\n",
      "fold_3, epoch_195, Loss: 0.3779\n",
      "fold_3, epoch_196, Loss: 0.3853\n",
      "fold_3, epoch_197, Loss: 0.3824\n",
      "fold_3, epoch_198, Loss: 0.3850\n",
      "fold_3, epoch_199, Loss: 0.3807\n",
      "fold_3, epoch_200, Loss: 0.3814\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3825\n",
      "Accuracy:\t0.9300\n",
      "AUC:\t\t0.9372\n",
      "Precision:\t0.9408\n",
      "Recall:\t\t0.9174\n",
      "F1:\t\t\t0.9289\n",
      "\n",
      "fold_3, epoch_201, Loss: 0.3813\n",
      "fold_3, epoch_202, Loss: 0.3798\n",
      "fold_3, epoch_203, Loss: 0.3847\n",
      "fold_3, epoch_204, Loss: 0.3816\n",
      "fold_3, epoch_205, Loss: 0.3783\n",
      "fold_3, epoch_206, Loss: 0.3793\n",
      "fold_3, epoch_207, Loss: 0.3804\n",
      "fold_3, epoch_208, Loss: 0.3821\n",
      "fold_3, epoch_209, Loss: 0.3807\n",
      "fold_3, epoch_210, Loss: 0.3792\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3794\n",
      "Accuracy:\t0.9342\n",
      "AUC:\t\t0.9384\n",
      "Precision:\t0.9397\n",
      "Recall:\t\t0.9280\n",
      "F1:\t\t\t0.9338\n",
      "\n",
      "fold_3, epoch_211, Loss: 0.3950\n",
      "fold_3, epoch_212, Loss: 0.3846\n",
      "fold_3, epoch_213, Loss: 0.3775\n",
      "fold_3, epoch_214, Loss: 0.3760\n",
      "fold_3, epoch_215, Loss: 0.3743\n",
      "fold_3, epoch_216, Loss: 0.3874\n",
      "fold_3, epoch_217, Loss: 0.3842\n",
      "fold_3, epoch_218, Loss: 0.3768\n",
      "fold_3, epoch_219, Loss: 0.3772\n",
      "fold_3, epoch_220, Loss: 0.3790\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3740\n",
      "Accuracy:\t0.9385\n",
      "AUC:\t\t0.9417\n",
      "Precision:\t0.9492\n",
      "Recall:\t\t0.9272\n",
      "F1:\t\t\t0.9381\n",
      "\n",
      "fold_3, epoch_221, Loss: 0.3788\n",
      "fold_3, epoch_222, Loss: 0.3759\n",
      "fold_3, epoch_223, Loss: 0.3788\n",
      "fold_3, epoch_224, Loss: 0.3792\n",
      "fold_3, epoch_225, Loss: 0.3806\n",
      "fold_3, epoch_226, Loss: 0.3786\n",
      "fold_3, epoch_227, Loss: 0.3754\n",
      "fold_3, epoch_228, Loss: 0.3809\n",
      "fold_3, epoch_229, Loss: 0.3769\n",
      "fold_3, epoch_230, Loss: 0.3766\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3693\n",
      "Accuracy:\t0.9435\n",
      "AUC:\t\t0.9483\n",
      "Precision:\t0.9592\n",
      "Recall:\t\t0.9270\n",
      "F1:\t\t\t0.9428\n",
      "\n",
      "fold_3, epoch_231, Loss: 0.3779\n",
      "fold_3, epoch_232, Loss: 0.3752\n",
      "fold_3, epoch_233, Loss: 0.3779\n",
      "fold_3, epoch_234, Loss: 0.3747\n",
      "fold_3, epoch_235, Loss: 0.3754\n",
      "fold_3, epoch_236, Loss: 0.3775\n",
      "fold_3, epoch_237, Loss: 0.3848\n",
      "fold_3, epoch_238, Loss: 0.3746\n",
      "fold_3, epoch_239, Loss: 0.3804\n",
      "fold_3, epoch_240, Loss: 0.3743\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3718\n",
      "Accuracy:\t0.9412\n",
      "AUC:\t\t0.9442\n",
      "Precision:\t0.9520\n",
      "Recall:\t\t0.9285\n",
      "F1:\t\t\t0.9401\n",
      "\n",
      "fold_3, epoch_241, Loss: 0.3788\n",
      "fold_3, epoch_242, Loss: 0.3777\n",
      "fold_3, epoch_243, Loss: 0.3761\n",
      "fold_3, epoch_244, Loss: 0.3739\n",
      "fold_3, epoch_245, Loss: 0.3738\n",
      "fold_3, epoch_246, Loss: 0.3754\n",
      "fold_3, epoch_247, Loss: 0.3757\n",
      "fold_3, epoch_248, Loss: 0.3717\n",
      "fold_3, epoch_249, Loss: 0.3740\n",
      "fold_3, epoch_250, Loss: 0.3754\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3738\n",
      "Accuracy:\t0.9395\n",
      "AUC:\t\t0.9448\n",
      "Precision:\t0.9524\n",
      "Recall:\t\t0.9255\n",
      "F1:\t\t\t0.9388\n",
      "\n",
      "fold_3, epoch_251, Loss: 0.3764\n",
      "fold_3, epoch_252, Loss: 0.3699\n",
      "fold_3, epoch_253, Loss: 0.3725\n",
      "fold_3, epoch_254, Loss: 0.3743\n",
      "fold_3, epoch_255, Loss: 0.3759\n",
      "fold_3, epoch_256, Loss: 0.3713\n",
      "fold_3, epoch_257, Loss: 0.3744\n",
      "fold_3, epoch_258, Loss: 0.3762\n",
      "fold_3, epoch_259, Loss: 0.3715\n",
      "fold_3, epoch_260, Loss: 0.3720\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3675\n",
      "Accuracy:\t0.9455\n",
      "AUC:\t\t0.9465\n",
      "Precision:\t0.9593\n",
      "Recall:\t\t0.9312\n",
      "F1:\t\t\t0.9450\n",
      "\n",
      "fold_3, epoch_261, Loss: 0.3711\n",
      "fold_3, epoch_262, Loss: 0.3748\n",
      "fold_3, epoch_263, Loss: 0.3752\n",
      "fold_3, epoch_264, Loss: 0.3710\n",
      "fold_3, epoch_265, Loss: 0.3727\n",
      "fold_3, epoch_266, Loss: 0.3695\n",
      "fold_3, epoch_267, Loss: 0.3764\n",
      "fold_3, epoch_268, Loss: 0.3790\n",
      "fold_3, epoch_269, Loss: 0.3754\n",
      "fold_3, epoch_270, Loss: 0.3733\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3678\n",
      "Accuracy:\t0.9456\n",
      "AUC:\t\t0.9478\n",
      "Precision:\t0.9615\n",
      "Recall:\t\t0.9284\n",
      "F1:\t\t\t0.9447\n",
      "\n",
      "fold_3, epoch_271, Loss: 0.3742\n",
      "fold_3, epoch_272, Loss: 0.3751\n",
      "fold_3, epoch_273, Loss: 0.3704\n",
      "fold_3, epoch_274, Loss: 0.3742\n",
      "fold_3, epoch_275, Loss: 0.3776\n",
      "fold_3, epoch_276, Loss: 0.3701\n",
      "fold_3, epoch_277, Loss: 0.3707\n",
      "fold_3, epoch_278, Loss: 0.3725\n",
      "fold_3, epoch_279, Loss: 0.3708\n",
      "fold_3, epoch_280, Loss: 0.3730\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3691\n",
      "Accuracy:\t0.9436\n",
      "AUC:\t\t0.9466\n",
      "Precision:\t0.9602\n",
      "Recall:\t\t0.9262\n",
      "F1:\t\t\t0.9429\n",
      "\n",
      "fold_3, epoch_281, Loss: 0.3698\n",
      "fold_3, epoch_282, Loss: 0.3751\n",
      "fold_3, epoch_283, Loss: 0.3682\n",
      "fold_3, epoch_284, Loss: 0.3716\n",
      "fold_3, epoch_285, Loss: 0.3707\n",
      "fold_3, epoch_286, Loss: 0.3796\n",
      "fold_3, epoch_287, Loss: 0.3706\n",
      "fold_3, epoch_288, Loss: 0.3687\n",
      "fold_3, epoch_289, Loss: 0.3755\n",
      "fold_3, epoch_290, Loss: 0.3686\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3709\n",
      "Accuracy:\t0.9422\n",
      "AUC:\t\t0.9478\n",
      "Precision:\t0.9558\n",
      "Recall:\t\t0.9273\n",
      "F1:\t\t\t0.9413\n",
      "\n",
      "fold_3, epoch_291, Loss: 0.3764\n",
      "fold_3, epoch_292, Loss: 0.3711\n",
      "fold_3, epoch_293, Loss: 0.3703\n",
      "fold_3, epoch_294, Loss: 0.3710\n",
      "fold_3, epoch_295, Loss: 0.3704\n",
      "fold_3, epoch_296, Loss: 0.3704\n",
      "fold_3, epoch_297, Loss: 0.3666\n",
      "fold_3, epoch_298, Loss: 0.3730\n",
      "fold_3, epoch_299, Loss: 0.3718\n",
      "fold_3, epoch_300, Loss: 0.3670\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3752\n",
      "Accuracy:\t0.9372\n",
      "AUC:\t\t0.9438\n",
      "Precision:\t0.9454\n",
      "Recall:\t\t0.9272\n",
      "F1:\t\t\t0.9362\n",
      "\n",
      "fold_3, epoch_301, Loss: 0.3738\n",
      "fold_3, epoch_302, Loss: 0.3721\n",
      "fold_3, epoch_303, Loss: 0.3715\n",
      "fold_3, epoch_304, Loss: 0.3691\n",
      "fold_3, epoch_305, Loss: 0.3681\n",
      "fold_3, epoch_306, Loss: 0.3732\n",
      "fold_3, epoch_307, Loss: 0.3684\n",
      "fold_3, epoch_308, Loss: 0.3664\n",
      "fold_3, epoch_309, Loss: 0.3691\n",
      "fold_3, epoch_310, Loss: 0.3735\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3733\n",
      "Accuracy:\t0.9393\n",
      "AUC:\t\t0.9461\n",
      "Precision:\t0.9520\n",
      "Recall:\t\t0.9252\n",
      "F1:\t\t\t0.9384\n",
      "\n",
      "fold_3, epoch_311, Loss: 0.3688\n",
      "fold_3, epoch_312, Loss: 0.3671\n",
      "fold_3, epoch_313, Loss: 0.3690\n",
      "fold_3, epoch_314, Loss: 0.3741\n",
      "fold_3, epoch_315, Loss: 0.3699\n",
      "fold_3, epoch_316, Loss: 0.3664\n",
      "fold_3, epoch_317, Loss: 0.3718\n",
      "fold_3, epoch_318, Loss: 0.3679\n",
      "fold_3, epoch_319, Loss: 0.3671\n",
      "fold_3, epoch_320, Loss: 0.3672\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3656\n",
      "Accuracy:\t0.9473\n",
      "AUC:\t\t0.9498\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9256\n",
      "F1:\t\t\t0.9465\n",
      "\n",
      "fold_3, epoch_321, Loss: 0.3672\n",
      "fold_3, epoch_322, Loss: 0.3677\n",
      "fold_3, epoch_323, Loss: 0.3669\n",
      "fold_3, epoch_324, Loss: 0.3696\n",
      "fold_3, epoch_325, Loss: 0.3735\n",
      "fold_3, epoch_326, Loss: 0.3707\n",
      "fold_3, epoch_327, Loss: 0.3651\n",
      "fold_3, epoch_328, Loss: 0.3635\n",
      "fold_3, epoch_329, Loss: 0.3662\n",
      "fold_3, epoch_330, Loss: 0.3659\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3662\n",
      "Accuracy:\t0.9468\n",
      "AUC:\t\t0.9490\n",
      "Precision:\t0.9632\n",
      "Recall:\t\t0.9292\n",
      "F1:\t\t\t0.9459\n",
      "\n",
      "fold_3, epoch_331, Loss: 0.3635\n",
      "fold_3, epoch_332, Loss: 0.3674\n",
      "fold_3, epoch_333, Loss: 0.3684\n",
      "fold_3, epoch_334, Loss: 0.3708\n",
      "fold_3, epoch_335, Loss: 0.3672\n",
      "fold_3, epoch_336, Loss: 0.3692\n",
      "fold_3, epoch_337, Loss: 0.3693\n",
      "fold_3, epoch_338, Loss: 0.3649\n",
      "fold_3, epoch_339, Loss: 0.3672\n",
      "fold_3, epoch_340, Loss: 0.3673\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3830\n",
      "Accuracy:\t0.9298\n",
      "AUC:\t\t0.9433\n",
      "Precision:\t0.9638\n",
      "Recall:\t\t0.8920\n",
      "F1:\t\t\t0.9265\n",
      "\n",
      "fold_3, epoch_341, Loss: 0.3695\n",
      "fold_3, epoch_342, Loss: 0.3670\n",
      "fold_3, epoch_343, Loss: 0.3638\n",
      "fold_3, epoch_344, Loss: 0.3641\n",
      "fold_3, epoch_345, Loss: 0.3669\n",
      "fold_3, epoch_346, Loss: 0.3637\n",
      "fold_3, epoch_347, Loss: 0.3628\n",
      "fold_3, epoch_348, Loss: 0.3671\n",
      "fold_3, epoch_349, Loss: 0.3689\n",
      "fold_3, epoch_350, Loss: 0.3623\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3623\n",
      "Accuracy:\t0.9508\n",
      "AUC:\t\t0.9519\n",
      "Precision:\t0.9680\n",
      "Recall:\t\t0.9331\n",
      "F1:\t\t\t0.9502\n",
      "\n",
      "fold_3, epoch_351, Loss: 0.3651\n",
      "fold_3, epoch_352, Loss: 0.3663\n",
      "fold_3, epoch_353, Loss: 0.3651\n",
      "fold_3, epoch_354, Loss: 0.3689\n",
      "fold_3, epoch_355, Loss: 0.3675\n",
      "fold_3, epoch_356, Loss: 0.3625\n",
      "fold_3, epoch_357, Loss: 0.3654\n",
      "fold_3, epoch_358, Loss: 0.3611\n",
      "fold_3, epoch_359, Loss: 0.3660\n",
      "fold_3, epoch_360, Loss: 0.3642\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3632\n",
      "Accuracy:\t0.9498\n",
      "AUC:\t\t0.9516\n",
      "Precision:\t0.9682\n",
      "Recall:\t\t0.9300\n",
      "F1:\t\t\t0.9487\n",
      "\n",
      "fold_3, epoch_361, Loss: 0.3632\n",
      "fold_3, epoch_362, Loss: 0.3671\n",
      "fold_3, epoch_363, Loss: 0.3659\n",
      "fold_3, epoch_364, Loss: 0.3658\n",
      "fold_3, epoch_365, Loss: 0.3646\n",
      "fold_3, epoch_366, Loss: 0.3653\n",
      "fold_3, epoch_367, Loss: 0.3633\n",
      "fold_3, epoch_368, Loss: 0.3624\n",
      "fold_3, epoch_369, Loss: 0.3697\n",
      "fold_3, epoch_370, Loss: 0.3712\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3708\n",
      "Accuracy:\t0.9423\n",
      "AUC:\t\t0.9465\n",
      "Precision:\t0.9610\n",
      "Recall:\t\t0.9220\n",
      "F1:\t\t\t0.9411\n",
      "\n",
      "fold_3, epoch_371, Loss: 0.3714\n",
      "fold_3, epoch_372, Loss: 0.3636\n",
      "fold_3, epoch_373, Loss: 0.3613\n",
      "fold_3, epoch_374, Loss: 0.3656\n",
      "fold_3, epoch_375, Loss: 0.3629\n",
      "fold_3, epoch_376, Loss: 0.3642\n",
      "fold_3, epoch_377, Loss: 0.3613\n",
      "fold_3, epoch_378, Loss: 0.3618\n",
      "fold_3, epoch_379, Loss: 0.3663\n",
      "fold_3, epoch_380, Loss: 0.3622\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3608\n",
      "Accuracy:\t0.9523\n",
      "AUC:\t\t0.9536\n",
      "Precision:\t0.9718\n",
      "Recall:\t\t0.9313\n",
      "F1:\t\t\t0.9511\n",
      "\n",
      "fold_3, epoch_381, Loss: 0.3627\n",
      "fold_3, epoch_382, Loss: 0.3638\n",
      "fold_3, epoch_383, Loss: 0.3633\n",
      "fold_3, epoch_384, Loss: 0.3636\n",
      "fold_3, epoch_385, Loss: 0.3653\n",
      "fold_3, epoch_386, Loss: 0.3650\n",
      "fold_3, epoch_387, Loss: 0.3672\n",
      "fold_3, epoch_388, Loss: 0.3643\n",
      "fold_3, epoch_389, Loss: 0.3639\n",
      "fold_3, epoch_390, Loss: 0.3608\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3599\n",
      "Accuracy:\t0.9533\n",
      "AUC:\t\t0.9529\n",
      "Precision:\t0.9729\n",
      "Recall:\t\t0.9331\n",
      "F1:\t\t\t0.9526\n",
      "\n",
      "fold_3, epoch_391, Loss: 0.3615\n",
      "fold_3, epoch_392, Loss: 0.3638\n",
      "fold_3, epoch_393, Loss: 0.3618\n",
      "fold_3, epoch_394, Loss: 0.3664\n",
      "fold_3, epoch_395, Loss: 0.3626\n",
      "fold_3, epoch_396, Loss: 0.3668\n",
      "fold_3, epoch_397, Loss: 0.3643\n",
      "fold_3, epoch_398, Loss: 0.3624\n",
      "fold_3, epoch_399, Loss: 0.3636\n",
      "fold_3, epoch_400, Loss: 0.3647\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3631\n",
      "Accuracy:\t0.9499\n",
      "AUC:\t\t0.9530\n",
      "Precision:\t0.9665\n",
      "Recall:\t\t0.9315\n",
      "F1:\t\t\t0.9487\n",
      "\n",
      "fold_3, epoch_401, Loss: 0.3646\n",
      "fold_3, epoch_402, Loss: 0.3630\n",
      "fold_3, epoch_403, Loss: 0.3661\n",
      "fold_3, epoch_404, Loss: 0.3615\n",
      "fold_3, epoch_405, Loss: 0.3655\n",
      "fold_3, epoch_406, Loss: 0.3606\n",
      "fold_3, epoch_407, Loss: 0.3610\n",
      "fold_3, epoch_408, Loss: 0.3642\n",
      "fold_3, epoch_409, Loss: 0.3616\n",
      "fold_3, epoch_410, Loss: 0.3631\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3607\n",
      "Accuracy:\t0.9523\n",
      "AUC:\t\t0.9535\n",
      "Precision:\t0.9715\n",
      "Recall:\t\t0.9324\n",
      "F1:\t\t\t0.9515\n",
      "\n",
      "fold_3, epoch_411, Loss: 0.3589\n",
      "fold_3, epoch_412, Loss: 0.3621\n",
      "fold_3, epoch_413, Loss: 0.3639\n",
      "fold_3, epoch_414, Loss: 0.3599\n",
      "fold_3, epoch_415, Loss: 0.3626\n",
      "fold_3, epoch_416, Loss: 0.3637\n",
      "fold_3, epoch_417, Loss: 0.3626\n",
      "fold_3, epoch_418, Loss: 0.3637\n",
      "fold_3, epoch_419, Loss: 0.3623\n",
      "fold_3, epoch_420, Loss: 0.3650\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3625\n",
      "Accuracy:\t0.9504\n",
      "AUC:\t\t0.9517\n",
      "Precision:\t0.9663\n",
      "Recall:\t\t0.9329\n",
      "F1:\t\t\t0.9493\n",
      "\n",
      "fold_3, epoch_421, Loss: 0.3627\n",
      "fold_3, epoch_422, Loss: 0.3645\n",
      "fold_3, epoch_423, Loss: 0.3627\n",
      "fold_3, epoch_424, Loss: 0.3619\n",
      "fold_3, epoch_425, Loss: 0.3582\n",
      "fold_3, epoch_426, Loss: 0.3634\n",
      "fold_3, epoch_427, Loss: 0.3632\n",
      "fold_3, epoch_428, Loss: 0.3606\n",
      "fold_3, epoch_429, Loss: 0.3597\n",
      "fold_3, epoch_430, Loss: 0.3604\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3587\n",
      "Accuracy:\t0.9544\n",
      "AUC:\t\t0.9550\n",
      "Precision:\t0.9705\n",
      "Recall:\t\t0.9375\n",
      "F1:\t\t\t0.9537\n",
      "\n",
      "fold_3, epoch_431, Loss: 0.3639\n",
      "fold_3, epoch_432, Loss: 0.3670\n",
      "fold_3, epoch_433, Loss: 0.3635\n",
      "fold_3, epoch_434, Loss: 0.3616\n",
      "fold_3, epoch_435, Loss: 0.3592\n",
      "fold_3, epoch_436, Loss: 0.3614\n",
      "fold_3, epoch_437, Loss: 0.3634\n",
      "fold_3, epoch_438, Loss: 0.3619\n",
      "fold_3, epoch_439, Loss: 0.3612\n",
      "fold_3, epoch_440, Loss: 0.3624\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3593\n",
      "Accuracy:\t0.9539\n",
      "AUC:\t\t0.9552\n",
      "Precision:\t0.9745\n",
      "Recall:\t\t0.9323\n",
      "F1:\t\t\t0.9529\n",
      "\n",
      "fold_3, epoch_441, Loss: 0.3650\n",
      "fold_3, epoch_442, Loss: 0.3596\n",
      "fold_3, epoch_443, Loss: 0.3601\n",
      "fold_3, epoch_444, Loss: 0.3640\n",
      "fold_3, epoch_445, Loss: 0.3639\n",
      "fold_3, epoch_446, Loss: 0.3635\n",
      "fold_3, epoch_447, Loss: 0.3587\n",
      "fold_3, epoch_448, Loss: 0.3618\n",
      "fold_3, epoch_449, Loss: 0.3607\n",
      "fold_3, epoch_450, Loss: 0.3655\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3629\n",
      "Accuracy:\t0.9501\n",
      "AUC:\t\t0.9539\n",
      "Precision:\t0.9671\n",
      "Recall:\t\t0.9322\n",
      "F1:\t\t\t0.9493\n",
      "\n",
      "fold_3, epoch_451, Loss: 0.3630\n",
      "fold_3, epoch_452, Loss: 0.3602\n",
      "fold_3, epoch_453, Loss: 0.3614\n",
      "fold_3, epoch_454, Loss: 0.3605\n",
      "fold_3, epoch_455, Loss: 0.3608\n",
      "fold_3, epoch_456, Loss: 0.3633\n",
      "fold_3, epoch_457, Loss: 0.3588\n",
      "fold_3, epoch_458, Loss: 0.3626\n",
      "fold_3, epoch_459, Loss: 0.3613\n",
      "fold_3, epoch_460, Loss: 0.3607\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3609\n",
      "Accuracy:\t0.9522\n",
      "AUC:\t\t0.9547\n",
      "Precision:\t0.9712\n",
      "Recall:\t\t0.9325\n",
      "F1:\t\t\t0.9515\n",
      "\n",
      "fold_3, epoch_461, Loss: 0.3662\n",
      "fold_3, epoch_462, Loss: 0.3587\n",
      "fold_3, epoch_463, Loss: 0.3607\n",
      "fold_3, epoch_464, Loss: 0.3601\n",
      "fold_3, epoch_465, Loss: 0.3600\n",
      "fold_3, epoch_466, Loss: 0.3599\n",
      "fold_3, epoch_467, Loss: 0.3575\n",
      "fold_3, epoch_468, Loss: 0.3625\n",
      "fold_3, epoch_469, Loss: 0.3625\n",
      "fold_3, epoch_470, Loss: 0.3599\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3585\n",
      "Accuracy:\t0.9544\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9738\n",
      "Recall:\t\t0.9342\n",
      "F1:\t\t\t0.9536\n",
      "\n",
      "fold_3, epoch_471, Loss: 0.3625\n",
      "fold_3, epoch_472, Loss: 0.3584\n",
      "fold_3, epoch_473, Loss: 0.3588\n",
      "fold_3, epoch_474, Loss: 0.3592\n",
      "fold_3, epoch_475, Loss: 0.3568\n",
      "fold_3, epoch_476, Loss: 0.3641\n",
      "fold_3, epoch_477, Loss: 0.3592\n",
      "fold_3, epoch_478, Loss: 0.3613\n",
      "fold_3, epoch_479, Loss: 0.3614\n",
      "fold_3, epoch_480, Loss: 0.3619\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3613\n",
      "Accuracy:\t0.9517\n",
      "AUC:\t\t0.9543\n",
      "Precision:\t0.9692\n",
      "Recall:\t\t0.9322\n",
      "F1:\t\t\t0.9503\n",
      "\n",
      "fold_3, epoch_481, Loss: 0.3626\n",
      "fold_3, epoch_482, Loss: 0.3615\n",
      "fold_3, epoch_483, Loss: 0.3600\n",
      "fold_3, epoch_484, Loss: 0.3633\n",
      "fold_3, epoch_485, Loss: 0.3588\n",
      "fold_3, epoch_486, Loss: 0.3584\n",
      "fold_3, epoch_487, Loss: 0.3619\n",
      "fold_3, epoch_488, Loss: 0.3637\n",
      "fold_3, epoch_489, Loss: 0.3599\n",
      "fold_3, epoch_490, Loss: 0.3614\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3578\n",
      "Accuracy:\t0.9555\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9730\n",
      "Recall:\t\t0.9371\n",
      "F1:\t\t\t0.9547\n",
      "\n",
      "fold_3, epoch_491, Loss: 0.3607\n",
      "fold_3, epoch_492, Loss: 0.3608\n",
      "fold_3, epoch_493, Loss: 0.3616\n",
      "fold_3, epoch_494, Loss: 0.3602\n",
      "fold_3, epoch_495, Loss: 0.3585\n",
      "fold_3, epoch_496, Loss: 0.3600\n",
      "fold_3, epoch_497, Loss: 0.3622\n",
      "fold_3, epoch_498, Loss: 0.3606\n",
      "fold_3, epoch_499, Loss: 0.3623\n",
      "fold_3, epoch_500, Loss: 0.3596\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3628\n",
      "Accuracy:\t0.9503\n",
      "AUC:\t\t0.9521\n",
      "Precision:\t0.9719\n",
      "Recall:\t\t0.9279\n",
      "F1:\t\t\t0.9494\n",
      "\n",
      "fold_3, epoch_501, Loss: 0.3580\n",
      "fold_3, epoch_502, Loss: 0.3633\n",
      "fold_3, epoch_503, Loss: 0.3590\n",
      "fold_3, epoch_504, Loss: 0.3605\n",
      "fold_3, epoch_505, Loss: 0.3579\n",
      "fold_3, epoch_506, Loss: 0.3589\n",
      "fold_3, epoch_507, Loss: 0.3597\n",
      "fold_3, epoch_508, Loss: 0.3594\n",
      "fold_3, epoch_509, Loss: 0.3612\n",
      "fold_3, epoch_510, Loss: 0.3607\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3593\n",
      "Accuracy:\t0.9537\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9723\n",
      "Recall:\t\t0.9342\n",
      "F1:\t\t\t0.9529\n",
      "\n",
      "fold_3, epoch_511, Loss: 0.3599\n",
      "fold_3, epoch_512, Loss: 0.3602\n",
      "fold_3, epoch_513, Loss: 0.3575\n",
      "fold_3, epoch_514, Loss: 0.3578\n",
      "fold_3, epoch_515, Loss: 0.3583\n",
      "fold_3, epoch_516, Loss: 0.3584\n",
      "fold_3, epoch_517, Loss: 0.3580\n",
      "fold_3, epoch_518, Loss: 0.3560\n",
      "fold_3, epoch_519, Loss: 0.3621\n",
      "fold_3, epoch_520, Loss: 0.3619\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3592\n",
      "Accuracy:\t0.9540\n",
      "AUC:\t\t0.9538\n",
      "Precision:\t0.9740\n",
      "Recall:\t\t0.9327\n",
      "F1:\t\t\t0.9529\n",
      "\n",
      "fold_3, epoch_521, Loss: 0.3610\n",
      "fold_3, epoch_522, Loss: 0.3576\n",
      "fold_3, epoch_523, Loss: 0.3605\n",
      "fold_3, epoch_524, Loss: 0.3561\n",
      "fold_3, epoch_525, Loss: 0.3567\n",
      "fold_3, epoch_526, Loss: 0.3601\n",
      "fold_3, epoch_527, Loss: 0.3623\n",
      "fold_3, epoch_528, Loss: 0.3595\n",
      "fold_3, epoch_529, Loss: 0.3590\n",
      "fold_3, epoch_530, Loss: 0.3649\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3640\n",
      "Accuracy:\t0.9489\n",
      "AUC:\t\t0.9524\n",
      "Precision:\t0.9716\n",
      "Recall:\t\t0.9242\n",
      "F1:\t\t\t0.9473\n",
      "\n",
      "fold_3, epoch_531, Loss: 0.3605\n",
      "fold_3, epoch_532, Loss: 0.3570\n",
      "fold_3, epoch_533, Loss: 0.3585\n",
      "fold_3, epoch_534, Loss: 0.3614\n",
      "fold_3, epoch_535, Loss: 0.3577\n",
      "fold_3, epoch_536, Loss: 0.3591\n",
      "fold_3, epoch_537, Loss: 0.3634\n",
      "fold_3, epoch_538, Loss: 0.3553\n",
      "fold_3, epoch_539, Loss: 0.3587\n",
      "fold_3, epoch_540, Loss: 0.3560\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3608\n",
      "Accuracy:\t0.9525\n",
      "AUC:\t\t0.9539\n",
      "Precision:\t0.9733\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9512\n",
      "\n",
      "fold_3, epoch_541, Loss: 0.3556\n",
      "fold_3, epoch_542, Loss: 0.3581\n",
      "fold_3, epoch_543, Loss: 0.3600\n",
      "fold_3, epoch_544, Loss: 0.3548\n",
      "fold_3, epoch_545, Loss: 0.3582\n",
      "fold_3, epoch_546, Loss: 0.3602\n",
      "fold_3, epoch_547, Loss: 0.3548\n",
      "fold_3, epoch_548, Loss: 0.3622\n",
      "fold_3, epoch_549, Loss: 0.3572\n",
      "fold_3, epoch_550, Loss: 0.3579\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3569\n",
      "Accuracy:\t0.9564\n",
      "AUC:\t\t0.9560\n",
      "Precision:\t0.9754\n",
      "Recall:\t\t0.9353\n",
      "F1:\t\t\t0.9549\n",
      "\n",
      "fold_3, epoch_551, Loss: 0.3581\n",
      "fold_3, epoch_552, Loss: 0.3549\n",
      "fold_3, epoch_553, Loss: 0.3538\n",
      "fold_3, epoch_554, Loss: 0.3606\n",
      "fold_3, epoch_555, Loss: 0.3577\n",
      "fold_3, epoch_556, Loss: 0.3616\n",
      "fold_3, epoch_557, Loss: 0.3585\n",
      "fold_3, epoch_558, Loss: 0.3556\n",
      "fold_3, epoch_559, Loss: 0.3529\n",
      "fold_3, epoch_560, Loss: 0.3561\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3558\n",
      "Accuracy:\t0.9575\n",
      "AUC:\t\t0.9574\n",
      "Precision:\t0.9793\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9566\n",
      "\n",
      "fold_3, epoch_561, Loss: 0.3573\n",
      "fold_3, epoch_562, Loss: 0.3578\n",
      "fold_3, epoch_563, Loss: 0.3568\n",
      "fold_3, epoch_564, Loss: 0.3566\n",
      "fold_3, epoch_565, Loss: 0.3564\n",
      "fold_3, epoch_566, Loss: 0.3598\n",
      "fold_3, epoch_567, Loss: 0.3607\n",
      "fold_3, epoch_568, Loss: 0.3570\n",
      "fold_3, epoch_569, Loss: 0.3557\n",
      "fold_3, epoch_570, Loss: 0.3560\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3555\n",
      "Accuracy:\t0.9577\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9317\n",
      "F1:\t\t\t0.9557\n",
      "\n",
      "fold_3, epoch_571, Loss: 0.3558\n",
      "fold_3, epoch_572, Loss: 0.3558\n",
      "fold_3, epoch_573, Loss: 0.3555\n",
      "fold_3, epoch_574, Loss: 0.3563\n",
      "fold_3, epoch_575, Loss: 0.3576\n",
      "fold_3, epoch_576, Loss: 0.3570\n",
      "fold_3, epoch_577, Loss: 0.3586\n",
      "fold_3, epoch_578, Loss: 0.3574\n",
      "fold_3, epoch_579, Loss: 0.3601\n",
      "fold_3, epoch_580, Loss: 0.3624\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3558\n",
      "Accuracy:\t0.9572\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9797\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9564\n",
      "\n",
      "fold_3, epoch_581, Loss: 0.3578\n",
      "fold_3, epoch_582, Loss: 0.3572\n",
      "fold_3, epoch_583, Loss: 0.3557\n",
      "fold_3, epoch_584, Loss: 0.3562\n",
      "fold_3, epoch_585, Loss: 0.3581\n",
      "fold_3, epoch_586, Loss: 0.3567\n",
      "fold_3, epoch_587, Loss: 0.3559\n",
      "fold_3, epoch_588, Loss: 0.3576\n",
      "fold_3, epoch_589, Loss: 0.3553\n",
      "fold_3, epoch_590, Loss: 0.3561\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3548\n",
      "Accuracy:\t0.9583\n",
      "AUC:\t\t0.9576\n",
      "Precision:\t0.9794\n",
      "Recall:\t\t0.9363\n",
      "F1:\t\t\t0.9574\n",
      "\n",
      "fold_3, epoch_591, Loss: 0.3576\n",
      "fold_3, epoch_592, Loss: 0.3581\n",
      "fold_3, epoch_593, Loss: 0.3580\n",
      "fold_3, epoch_594, Loss: 0.3576\n",
      "fold_3, epoch_595, Loss: 0.3562\n",
      "fold_3, epoch_596, Loss: 0.3546\n",
      "fold_3, epoch_597, Loss: 0.3580\n",
      "fold_3, epoch_598, Loss: 0.3548\n",
      "fold_3, epoch_599, Loss: 0.3564\n",
      "fold_3, epoch_600, Loss: 0.3579\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3547\n",
      "Accuracy:\t0.9586\n",
      "AUC:\t\t0.9586\n",
      "Precision:\t0.9763\n",
      "Recall:\t\t0.9394\n",
      "F1:\t\t\t0.9575\n",
      "\n",
      "fold_3, epoch_601, Loss: 0.3545\n",
      "fold_3, epoch_602, Loss: 0.3564\n",
      "fold_3, epoch_603, Loss: 0.3564\n",
      "fold_3, epoch_604, Loss: 0.3595\n",
      "fold_3, epoch_605, Loss: 0.3563\n",
      "fold_3, epoch_606, Loss: 0.3535\n",
      "fold_3, epoch_607, Loss: 0.3550\n",
      "fold_3, epoch_608, Loss: 0.3562\n",
      "fold_3, epoch_609, Loss: 0.3555\n",
      "fold_3, epoch_610, Loss: 0.3562\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9795\n",
      "Recall:\t\t0.9369\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_3, epoch_611, Loss: 0.3576\n",
      "fold_3, epoch_612, Loss: 0.3550\n",
      "fold_3, epoch_613, Loss: 0.3563\n",
      "fold_3, epoch_614, Loss: 0.3542\n",
      "fold_3, epoch_615, Loss: 0.3562\n",
      "fold_3, epoch_616, Loss: 0.3591\n",
      "fold_3, epoch_617, Loss: 0.3534\n",
      "fold_3, epoch_618, Loss: 0.3561\n",
      "fold_3, epoch_619, Loss: 0.3577\n",
      "fold_3, epoch_620, Loss: 0.3564\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3547\n",
      "Accuracy:\t0.9584\n",
      "AUC:\t\t0.9583\n",
      "Precision:\t0.9793\n",
      "Recall:\t\t0.9366\n",
      "F1:\t\t\t0.9574\n",
      "\n",
      "fold_3, epoch_621, Loss: 0.3557\n",
      "fold_3, epoch_622, Loss: 0.3611\n",
      "fold_3, epoch_623, Loss: 0.3554\n",
      "fold_3, epoch_624, Loss: 0.3546\n",
      "fold_3, epoch_625, Loss: 0.3601\n",
      "fold_3, epoch_626, Loss: 0.3562\n",
      "fold_3, epoch_627, Loss: 0.3579\n",
      "fold_3, epoch_628, Loss: 0.3547\n",
      "fold_3, epoch_629, Loss: 0.3552\n",
      "fold_3, epoch_630, Loss: 0.3603\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9595\n",
      "AUC:\t\t0.9589\n",
      "Precision:\t0.9788\n",
      "Recall:\t\t0.9389\n",
      "F1:\t\t\t0.9584\n",
      "\n",
      "fold_3, epoch_631, Loss: 0.3542\n",
      "fold_3, epoch_632, Loss: 0.3541\n",
      "fold_3, epoch_633, Loss: 0.3559\n",
      "fold_3, epoch_634, Loss: 0.3559\n",
      "fold_3, epoch_635, Loss: 0.3578\n",
      "fold_3, epoch_636, Loss: 0.3581\n",
      "fold_3, epoch_637, Loss: 0.3549\n",
      "fold_3, epoch_638, Loss: 0.3571\n",
      "fold_3, epoch_639, Loss: 0.3541\n",
      "fold_3, epoch_640, Loss: 0.3545\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3517\n",
      "Accuracy:\t0.9613\n",
      "AUC:\t\t0.9603\n",
      "Precision:\t0.9813\n",
      "Recall:\t\t0.9407\n",
      "F1:\t\t\t0.9606\n",
      "\n",
      "fold_3, epoch_641, Loss: 0.3541\n",
      "fold_3, epoch_642, Loss: 0.3533\n",
      "fold_3, epoch_643, Loss: 0.3540\n",
      "fold_3, epoch_644, Loss: 0.3562\n",
      "fold_3, epoch_645, Loss: 0.3563\n",
      "fold_3, epoch_646, Loss: 0.3529\n",
      "fold_3, epoch_647, Loss: 0.3593\n",
      "fold_3, epoch_648, Loss: 0.3541\n",
      "fold_3, epoch_649, Loss: 0.3550\n",
      "fold_3, epoch_650, Loss: 0.3545\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3578\n",
      "Accuracy:\t0.9552\n",
      "AUC:\t\t0.9584\n",
      "Precision:\t0.9756\n",
      "Recall:\t\t0.9338\n",
      "F1:\t\t\t0.9542\n",
      "\n",
      "fold_3, epoch_651, Loss: 0.3581\n",
      "fold_3, epoch_652, Loss: 0.3576\n",
      "fold_3, epoch_653, Loss: 0.3553\n",
      "fold_3, epoch_654, Loss: 0.3571\n",
      "fold_3, epoch_655, Loss: 0.3549\n",
      "fold_3, epoch_656, Loss: 0.3567\n",
      "fold_3, epoch_657, Loss: 0.3534\n",
      "fold_3, epoch_658, Loss: 0.3537\n",
      "fold_3, epoch_659, Loss: 0.3563\n",
      "fold_3, epoch_660, Loss: 0.3554\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3548\n",
      "Accuracy:\t0.9584\n",
      "AUC:\t\t0.9582\n",
      "Precision:\t0.9790\n",
      "Recall:\t\t0.9362\n",
      "F1:\t\t\t0.9571\n",
      "\n",
      "fold_3, epoch_661, Loss: 0.3614\n",
      "fold_3, epoch_662, Loss: 0.3568\n",
      "fold_3, epoch_663, Loss: 0.3546\n",
      "fold_3, epoch_664, Loss: 0.3545\n",
      "fold_3, epoch_665, Loss: 0.3571\n",
      "fold_3, epoch_666, Loss: 0.3545\n",
      "fold_3, epoch_667, Loss: 0.3573\n",
      "fold_3, epoch_668, Loss: 0.3592\n",
      "fold_3, epoch_669, Loss: 0.3527\n",
      "fold_3, epoch_670, Loss: 0.3538\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3554\n",
      "Accuracy:\t0.9573\n",
      "AUC:\t\t0.9588\n",
      "Precision:\t0.9813\n",
      "Recall:\t\t0.9322\n",
      "F1:\t\t\t0.9561\n",
      "\n",
      "fold_3, epoch_671, Loss: 0.3552\n",
      "fold_3, epoch_672, Loss: 0.3552\n",
      "fold_3, epoch_673, Loss: 0.3603\n",
      "fold_3, epoch_674, Loss: 0.3562\n",
      "fold_3, epoch_675, Loss: 0.3526\n",
      "fold_3, epoch_676, Loss: 0.3538\n",
      "fold_3, epoch_677, Loss: 0.3536\n",
      "fold_3, epoch_678, Loss: 0.3527\n",
      "fold_3, epoch_679, Loss: 0.3579\n",
      "fold_3, epoch_680, Loss: 0.3587\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3563\n",
      "Accuracy:\t0.9570\n",
      "AUC:\t\t0.9572\n",
      "Precision:\t0.9790\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9561\n",
      "\n",
      "fold_3, epoch_681, Loss: 0.3547\n",
      "fold_3, epoch_682, Loss: 0.3549\n",
      "fold_3, epoch_683, Loss: 0.3557\n",
      "fold_3, epoch_684, Loss: 0.3552\n",
      "fold_3, epoch_685, Loss: 0.3537\n",
      "fold_3, epoch_686, Loss: 0.3579\n",
      "fold_3, epoch_687, Loss: 0.3558\n",
      "fold_3, epoch_688, Loss: 0.3526\n",
      "fold_3, epoch_689, Loss: 0.3519\n",
      "fold_3, epoch_690, Loss: 0.3540\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3540\n",
      "Accuracy:\t0.9593\n",
      "AUC:\t\t0.9578\n",
      "Precision:\t0.9804\n",
      "Recall:\t\t0.9375\n",
      "F1:\t\t\t0.9585\n",
      "\n",
      "fold_3, epoch_691, Loss: 0.3539\n",
      "fold_3, epoch_692, Loss: 0.3537\n",
      "fold_3, epoch_693, Loss: 0.3558\n",
      "fold_3, epoch_694, Loss: 0.3552\n",
      "fold_3, epoch_695, Loss: 0.3556\n",
      "fold_3, epoch_696, Loss: 0.3551\n",
      "fold_3, epoch_697, Loss: 0.3559\n",
      "fold_3, epoch_698, Loss: 0.3541\n",
      "fold_3, epoch_699, Loss: 0.3550\n",
      "fold_3, epoch_700, Loss: 0.3569\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3585\n",
      "Accuracy:\t0.9545\n",
      "AUC:\t\t0.9581\n",
      "Precision:\t0.9732\n",
      "Recall:\t\t0.9347\n",
      "F1:\t\t\t0.9536\n",
      "\n",
      "fold_3, epoch_701, Loss: 0.3592\n",
      "fold_3, epoch_702, Loss: 0.3565\n",
      "fold_3, epoch_703, Loss: 0.3535\n",
      "fold_3, epoch_704, Loss: 0.3552\n",
      "fold_3, epoch_705, Loss: 0.3552\n",
      "fold_3, epoch_706, Loss: 0.3542\n",
      "fold_3, epoch_707, Loss: 0.3564\n",
      "fold_3, epoch_708, Loss: 0.3528\n",
      "fold_3, epoch_709, Loss: 0.3511\n",
      "fold_3, epoch_710, Loss: 0.3570\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3567\n",
      "Accuracy:\t0.9564\n",
      "AUC:\t\t0.9589\n",
      "Precision:\t0.9741\n",
      "Recall:\t\t0.9374\n",
      "F1:\t\t\t0.9554\n",
      "\n",
      "fold_3, epoch_711, Loss: 0.3556\n",
      "fold_3, epoch_712, Loss: 0.3523\n",
      "fold_3, epoch_713, Loss: 0.3538\n",
      "fold_3, epoch_714, Loss: 0.3559\n",
      "fold_3, epoch_715, Loss: 0.3546\n",
      "fold_3, epoch_716, Loss: 0.3560\n",
      "fold_3, epoch_717, Loss: 0.3529\n",
      "fold_3, epoch_718, Loss: 0.3517\n",
      "fold_3, epoch_719, Loss: 0.3555\n",
      "fold_3, epoch_720, Loss: 0.3541\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3518\n",
      "Accuracy:\t0.9614\n",
      "AUC:\t\t0.9602\n",
      "Precision:\t0.9810\n",
      "Recall:\t\t0.9409\n",
      "F1:\t\t\t0.9605\n",
      "\n",
      "fold_3, epoch_721, Loss: 0.3532\n",
      "fold_3, epoch_722, Loss: 0.3569\n",
      "fold_3, epoch_723, Loss: 0.3532\n",
      "fold_3, epoch_724, Loss: 0.3519\n",
      "fold_3, epoch_725, Loss: 0.3554\n",
      "fold_3, epoch_726, Loss: 0.3545\n",
      "fold_3, epoch_727, Loss: 0.3549\n",
      "fold_3, epoch_728, Loss: 0.3522\n",
      "fold_3, epoch_729, Loss: 0.3523\n",
      "fold_3, epoch_730, Loss: 0.3519\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9588\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9372\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_3, epoch_731, Loss: 0.3557\n",
      "fold_3, epoch_732, Loss: 0.3542\n",
      "fold_3, epoch_733, Loss: 0.3512\n",
      "fold_3, epoch_734, Loss: 0.3523\n",
      "fold_3, epoch_735, Loss: 0.3528\n",
      "fold_3, epoch_736, Loss: 0.3530\n",
      "fold_3, epoch_737, Loss: 0.3532\n",
      "fold_3, epoch_738, Loss: 0.3549\n",
      "fold_3, epoch_739, Loss: 0.3529\n",
      "fold_3, epoch_740, Loss: 0.3579\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3606\n",
      "Accuracy:\t0.9524\n",
      "AUC:\t\t0.9573\n",
      "Precision:\t0.9737\n",
      "Recall:\t\t0.9303\n",
      "F1:\t\t\t0.9515\n",
      "\n",
      "fold_3, epoch_741, Loss: 0.3548\n",
      "fold_3, epoch_742, Loss: 0.3548\n",
      "fold_3, epoch_743, Loss: 0.3576\n",
      "fold_3, epoch_744, Loss: 0.3534\n",
      "fold_3, epoch_745, Loss: 0.3515\n",
      "fold_3, epoch_746, Loss: 0.3535\n",
      "fold_3, epoch_747, Loss: 0.3547\n",
      "fold_3, epoch_748, Loss: 0.3536\n",
      "fold_3, epoch_749, Loss: 0.3553\n",
      "fold_3, epoch_750, Loss: 0.3533\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3519\n",
      "Accuracy:\t0.9612\n",
      "AUC:\t\t0.9614\n",
      "Precision:\t0.9835\n",
      "Recall:\t\t0.9390\n",
      "F1:\t\t\t0.9607\n",
      "\n",
      "fold_3, epoch_751, Loss: 0.3543\n",
      "fold_3, epoch_752, Loss: 0.3543\n",
      "fold_3, epoch_753, Loss: 0.3554\n",
      "fold_3, epoch_754, Loss: 0.3516\n",
      "fold_3, epoch_755, Loss: 0.3541\n",
      "fold_3, epoch_756, Loss: 0.3540\n",
      "fold_3, epoch_757, Loss: 0.3532\n",
      "fold_3, epoch_758, Loss: 0.3528\n",
      "fold_3, epoch_759, Loss: 0.3529\n",
      "fold_3, epoch_760, Loss: 0.3537\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3526\n",
      "Accuracy:\t0.9607\n",
      "AUC:\t\t0.9586\n",
      "Precision:\t0.9838\n",
      "Recall:\t\t0.9368\n",
      "F1:\t\t\t0.9597\n",
      "\n",
      "fold_3, epoch_761, Loss: 0.3540\n",
      "fold_3, epoch_762, Loss: 0.3524\n",
      "fold_3, epoch_763, Loss: 0.3542\n",
      "fold_3, epoch_764, Loss: 0.3552\n",
      "fold_3, epoch_765, Loss: 0.3546\n",
      "fold_3, epoch_766, Loss: 0.3516\n",
      "fold_3, epoch_767, Loss: 0.3525\n",
      "fold_3, epoch_768, Loss: 0.3547\n",
      "fold_3, epoch_769, Loss: 0.3543\n",
      "fold_3, epoch_770, Loss: 0.3528\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3528\n",
      "Accuracy:\t0.9603\n",
      "AUC:\t\t0.9588\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9357\n",
      "F1:\t\t\t0.9593\n",
      "\n",
      "fold_3, epoch_771, Loss: 0.3510\n",
      "fold_3, epoch_772, Loss: 0.3514\n",
      "fold_3, epoch_773, Loss: 0.3560\n",
      "fold_3, epoch_774, Loss: 0.3551\n",
      "fold_3, epoch_775, Loss: 0.3582\n",
      "fold_3, epoch_776, Loss: 0.3524\n",
      "fold_3, epoch_777, Loss: 0.3556\n",
      "fold_3, epoch_778, Loss: 0.3542\n",
      "fold_3, epoch_779, Loss: 0.3543\n",
      "fold_3, epoch_780, Loss: 0.3528\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9623\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9843\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9614\n",
      "\n",
      "fold_3, epoch_781, Loss: 0.3570\n",
      "fold_3, epoch_782, Loss: 0.3550\n",
      "fold_3, epoch_783, Loss: 0.3523\n",
      "fold_3, epoch_784, Loss: 0.3535\n",
      "fold_3, epoch_785, Loss: 0.3524\n",
      "fold_3, epoch_786, Loss: 0.3529\n",
      "fold_3, epoch_787, Loss: 0.3527\n",
      "fold_3, epoch_788, Loss: 0.3541\n",
      "fold_3, epoch_789, Loss: 0.3535\n",
      "fold_3, epoch_790, Loss: 0.3509\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9586\n",
      "AUC:\t\t0.9590\n",
      "Precision:\t0.9774\n",
      "Recall:\t\t0.9394\n",
      "F1:\t\t\t0.9580\n",
      "\n",
      "fold_3, epoch_791, Loss: 0.3522\n",
      "fold_3, epoch_792, Loss: 0.3533\n",
      "fold_3, epoch_793, Loss: 0.3538\n",
      "fold_3, epoch_794, Loss: 0.3528\n",
      "fold_3, epoch_795, Loss: 0.3515\n",
      "fold_3, epoch_796, Loss: 0.3543\n",
      "fold_3, epoch_797, Loss: 0.3536\n",
      "fold_3, epoch_798, Loss: 0.3541\n",
      "fold_3, epoch_799, Loss: 0.3535\n",
      "fold_3, epoch_800, Loss: 0.3525\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9623\n",
      "AUC:\t\t0.9610\n",
      "Precision:\t0.9865\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9617\n",
      "\n",
      "fold_3, epoch_801, Loss: 0.3496\n",
      "fold_3, epoch_802, Loss: 0.3545\n",
      "fold_3, epoch_803, Loss: 0.3565\n",
      "fold_3, epoch_804, Loss: 0.3525\n",
      "fold_3, epoch_805, Loss: 0.3543\n",
      "fold_3, epoch_806, Loss: 0.3509\n",
      "fold_3, epoch_807, Loss: 0.3519\n",
      "fold_3, epoch_808, Loss: 0.3528\n",
      "fold_3, epoch_809, Loss: 0.3529\n",
      "fold_3, epoch_810, Loss: 0.3551\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3543\n",
      "Accuracy:\t0.9588\n",
      "AUC:\t\t0.9580\n",
      "Precision:\t0.9776\n",
      "Recall:\t\t0.9387\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_3, epoch_811, Loss: 0.3543\n",
      "fold_3, epoch_812, Loss: 0.3564\n",
      "fold_3, epoch_813, Loss: 0.3539\n",
      "fold_3, epoch_814, Loss: 0.3530\n",
      "fold_3, epoch_815, Loss: 0.3524\n",
      "fold_3, epoch_816, Loss: 0.3562\n",
      "fold_3, epoch_817, Loss: 0.3535\n",
      "fold_3, epoch_818, Loss: 0.3511\n",
      "fold_3, epoch_819, Loss: 0.3502\n",
      "fold_3, epoch_820, Loss: 0.3550\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3576\n",
      "Accuracy:\t0.9555\n",
      "AUC:\t\t0.9588\n",
      "Precision:\t0.9776\n",
      "Recall:\t\t0.9324\n",
      "F1:\t\t\t0.9545\n",
      "\n",
      "fold_3, epoch_821, Loss: 0.3542\n",
      "fold_3, epoch_822, Loss: 0.3503\n",
      "fold_3, epoch_823, Loss: 0.3546\n",
      "fold_3, epoch_824, Loss: 0.3532\n",
      "fold_3, epoch_825, Loss: 0.3521\n",
      "fold_3, epoch_826, Loss: 0.3529\n",
      "fold_3, epoch_827, Loss: 0.3538\n",
      "fold_3, epoch_828, Loss: 0.3527\n",
      "fold_3, epoch_829, Loss: 0.3522\n",
      "fold_3, epoch_830, Loss: 0.3551\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9586\n",
      "AUC:\t\t0.9594\n",
      "Precision:\t0.9817\n",
      "Recall:\t\t0.9351\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_3, epoch_831, Loss: 0.3542\n",
      "fold_3, epoch_832, Loss: 0.3527\n",
      "fold_3, epoch_833, Loss: 0.3535\n",
      "fold_3, epoch_834, Loss: 0.3532\n",
      "fold_3, epoch_835, Loss: 0.3517\n",
      "fold_3, epoch_836, Loss: 0.3535\n",
      "fold_3, epoch_837, Loss: 0.3545\n",
      "fold_3, epoch_838, Loss: 0.3511\n",
      "fold_3, epoch_839, Loss: 0.3517\n",
      "fold_3, epoch_840, Loss: 0.3522\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3505\n",
      "Accuracy:\t0.9627\n",
      "AUC:\t\t0.9630\n",
      "Precision:\t0.9835\n",
      "Recall:\t\t0.9414\n",
      "F1:\t\t\t0.9620\n",
      "\n",
      "fold_3, epoch_841, Loss: 0.3538\n",
      "fold_3, epoch_842, Loss: 0.3544\n",
      "fold_3, epoch_843, Loss: 0.3512\n",
      "fold_3, epoch_844, Loss: 0.3526\n",
      "fold_3, epoch_845, Loss: 0.3531\n",
      "fold_3, epoch_846, Loss: 0.3534\n",
      "fold_3, epoch_847, Loss: 0.3547\n",
      "fold_3, epoch_848, Loss: 0.3531\n",
      "fold_3, epoch_849, Loss: 0.3502\n",
      "fold_3, epoch_850, Loss: 0.3513\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3530\n",
      "Accuracy:\t0.9603\n",
      "AUC:\t\t0.9593\n",
      "Precision:\t0.9823\n",
      "Recall:\t\t0.9377\n",
      "F1:\t\t\t0.9595\n",
      "\n",
      "fold_3, epoch_851, Loss: 0.3503\n",
      "fold_3, epoch_852, Loss: 0.3526\n",
      "fold_3, epoch_853, Loss: 0.3505\n",
      "fold_3, epoch_854, Loss: 0.3529\n",
      "fold_3, epoch_855, Loss: 0.3561\n",
      "fold_3, epoch_856, Loss: 0.3528\n",
      "fold_3, epoch_857, Loss: 0.3546\n",
      "fold_3, epoch_858, Loss: 0.3526\n",
      "fold_3, epoch_859, Loss: 0.3539\n",
      "fold_3, epoch_860, Loss: 0.3529\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3524\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9603\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9394\n",
      "F1:\t\t\t0.9597\n",
      "\n",
      "fold_3, epoch_861, Loss: 0.3515\n",
      "fold_3, epoch_862, Loss: 0.3514\n",
      "fold_3, epoch_863, Loss: 0.3505\n",
      "fold_3, epoch_864, Loss: 0.3531\n",
      "fold_3, epoch_865, Loss: 0.3527\n",
      "fold_3, epoch_866, Loss: 0.3531\n",
      "fold_3, epoch_867, Loss: 0.3537\n",
      "fold_3, epoch_868, Loss: 0.3511\n",
      "fold_3, epoch_869, Loss: 0.3526\n",
      "fold_3, epoch_870, Loss: 0.3504\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3491\n",
      "Accuracy:\t0.9640\n",
      "AUC:\t\t0.9623\n",
      "Precision:\t0.9873\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9633\n",
      "\n",
      "fold_3, epoch_871, Loss: 0.3490\n",
      "fold_3, epoch_872, Loss: 0.3551\n",
      "fold_3, epoch_873, Loss: 0.3528\n",
      "fold_3, epoch_874, Loss: 0.3521\n",
      "fold_3, epoch_875, Loss: 0.3501\n",
      "fold_3, epoch_876, Loss: 0.3510\n",
      "fold_3, epoch_877, Loss: 0.3514\n",
      "fold_3, epoch_878, Loss: 0.3523\n",
      "fold_3, epoch_879, Loss: 0.3532\n",
      "fold_3, epoch_880, Loss: 0.3537\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3515\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9604\n",
      "Precision:\t0.9852\n",
      "Recall:\t\t0.9374\n",
      "F1:\t\t\t0.9607\n",
      "\n",
      "fold_3, epoch_881, Loss: 0.3501\n",
      "fold_3, epoch_882, Loss: 0.3521\n",
      "fold_3, epoch_883, Loss: 0.3520\n",
      "fold_3, epoch_884, Loss: 0.3516\n",
      "fold_3, epoch_885, Loss: 0.3530\n",
      "fold_3, epoch_886, Loss: 0.3519\n",
      "fold_3, epoch_887, Loss: 0.3519\n",
      "fold_3, epoch_888, Loss: 0.3524\n",
      "fold_3, epoch_889, Loss: 0.3535\n",
      "fold_3, epoch_890, Loss: 0.3533\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3525\n",
      "Accuracy:\t0.9606\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9811\n",
      "Recall:\t\t0.9392\n",
      "F1:\t\t\t0.9597\n",
      "\n",
      "fold_3, epoch_891, Loss: 0.3547\n",
      "fold_3, epoch_892, Loss: 0.3498\n",
      "fold_3, epoch_893, Loss: 0.3514\n",
      "fold_3, epoch_894, Loss: 0.3500\n",
      "fold_3, epoch_895, Loss: 0.3524\n",
      "fold_3, epoch_896, Loss: 0.3508\n",
      "fold_3, epoch_897, Loss: 0.3533\n",
      "fold_3, epoch_898, Loss: 0.3543\n",
      "fold_3, epoch_899, Loss: 0.3536\n",
      "fold_3, epoch_900, Loss: 0.3513\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3502\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9864\n",
      "Recall:\t\t0.9384\n",
      "F1:\t\t\t0.9618\n",
      "\n",
      "fold_3, epoch_901, Loss: 0.3526\n",
      "fold_3, epoch_902, Loss: 0.3518\n",
      "fold_3, epoch_903, Loss: 0.3529\n",
      "fold_3, epoch_904, Loss: 0.3533\n",
      "fold_3, epoch_905, Loss: 0.3544\n",
      "fold_3, epoch_906, Loss: 0.3502\n",
      "fold_3, epoch_907, Loss: 0.3517\n",
      "fold_3, epoch_908, Loss: 0.3524\n",
      "fold_3, epoch_909, Loss: 0.3579\n",
      "fold_3, epoch_910, Loss: 0.3537\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9623\n",
      "Precision:\t0.9813\n",
      "Recall:\t\t0.9417\n",
      "F1:\t\t\t0.9611\n",
      "\n",
      "fold_3, epoch_911, Loss: 0.3504\n",
      "fold_3, epoch_912, Loss: 0.3525\n",
      "fold_3, epoch_913, Loss: 0.3499\n",
      "fold_3, epoch_914, Loss: 0.3526\n",
      "fold_3, epoch_915, Loss: 0.3515\n",
      "fold_3, epoch_916, Loss: 0.3512\n",
      "fold_3, epoch_917, Loss: 0.3518\n",
      "fold_3, epoch_918, Loss: 0.3516\n",
      "fold_3, epoch_919, Loss: 0.3513\n",
      "fold_3, epoch_920, Loss: 0.3538\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3488\n",
      "Accuracy:\t0.9643\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9876\n",
      "Recall:\t\t0.9412\n",
      "F1:\t\t\t0.9638\n",
      "\n",
      "fold_3, epoch_921, Loss: 0.3498\n",
      "fold_3, epoch_922, Loss: 0.3485\n",
      "fold_3, epoch_923, Loss: 0.3500\n",
      "fold_3, epoch_924, Loss: 0.3512\n",
      "fold_3, epoch_925, Loss: 0.3534\n",
      "fold_3, epoch_926, Loss: 0.3516\n",
      "fold_3, epoch_927, Loss: 0.3519\n",
      "fold_3, epoch_928, Loss: 0.3527\n",
      "fold_3, epoch_929, Loss: 0.3512\n",
      "fold_3, epoch_930, Loss: 0.3536\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9618\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9857\n",
      "Recall:\t\t0.9376\n",
      "F1:\t\t\t0.9610\n",
      "\n",
      "fold_3, epoch_931, Loss: 0.3507\n",
      "fold_3, epoch_932, Loss: 0.3526\n",
      "fold_3, epoch_933, Loss: 0.3526\n",
      "fold_3, epoch_934, Loss: 0.3502\n",
      "fold_3, epoch_935, Loss: 0.3559\n",
      "fold_3, epoch_936, Loss: 0.3511\n",
      "fold_3, epoch_937, Loss: 0.3532\n",
      "fold_3, epoch_938, Loss: 0.3532\n",
      "fold_3, epoch_939, Loss: 0.3517\n",
      "fold_3, epoch_940, Loss: 0.3516\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3495\n",
      "Accuracy:\t0.9638\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9847\n",
      "Recall:\t\t0.9421\n",
      "F1:\t\t\t0.9629\n",
      "\n",
      "fold_3, epoch_941, Loss: 0.3542\n",
      "fold_3, epoch_942, Loss: 0.3515\n",
      "fold_3, epoch_943, Loss: 0.3509\n",
      "fold_3, epoch_944, Loss: 0.3499\n",
      "fold_3, epoch_945, Loss: 0.3516\n",
      "fold_3, epoch_946, Loss: 0.3513\n",
      "fold_3, epoch_947, Loss: 0.3502\n",
      "fold_3, epoch_948, Loss: 0.3515\n",
      "fold_3, epoch_949, Loss: 0.3527\n",
      "fold_3, epoch_950, Loss: 0.3512\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3514\n",
      "Accuracy:\t0.9619\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9876\n",
      "Recall:\t\t0.9360\n",
      "F1:\t\t\t0.9611\n",
      "\n",
      "fold_3, epoch_951, Loss: 0.3526\n",
      "fold_3, epoch_952, Loss: 0.3535\n",
      "fold_3, epoch_953, Loss: 0.3503\n",
      "fold_3, epoch_954, Loss: 0.3516\n",
      "fold_3, epoch_955, Loss: 0.3503\n",
      "fold_3, epoch_956, Loss: 0.3529\n",
      "fold_3, epoch_957, Loss: 0.3502\n",
      "fold_3, epoch_958, Loss: 0.3518\n",
      "fold_3, epoch_959, Loss: 0.3525\n",
      "fold_3, epoch_960, Loss: 0.3522\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3510\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9609\n",
      "Precision:\t0.9856\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9613\n",
      "\n",
      "fold_3, epoch_961, Loss: 0.3514\n",
      "fold_3, epoch_962, Loss: 0.3507\n",
      "fold_3, epoch_963, Loss: 0.3502\n",
      "fold_3, epoch_964, Loss: 0.3527\n",
      "fold_3, epoch_965, Loss: 0.3551\n",
      "fold_3, epoch_966, Loss: 0.3514\n",
      "fold_3, epoch_967, Loss: 0.3489\n",
      "fold_3, epoch_968, Loss: 0.3495\n",
      "fold_3, epoch_969, Loss: 0.3507\n",
      "fold_3, epoch_970, Loss: 0.3529\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3519\n",
      "Accuracy:\t0.9613\n",
      "AUC:\t\t0.9601\n",
      "Precision:\t0.9862\n",
      "Recall:\t\t0.9355\n",
      "F1:\t\t\t0.9602\n",
      "\n",
      "fold_3, epoch_971, Loss: 0.3528\n",
      "fold_3, epoch_972, Loss: 0.3502\n",
      "fold_3, epoch_973, Loss: 0.3502\n",
      "fold_3, epoch_974, Loss: 0.3551\n",
      "fold_3, epoch_975, Loss: 0.3559\n",
      "fold_3, epoch_976, Loss: 0.3517\n",
      "fold_3, epoch_977, Loss: 0.3534\n",
      "fold_3, epoch_978, Loss: 0.3533\n",
      "fold_3, epoch_979, Loss: 0.3517\n",
      "fold_3, epoch_980, Loss: 0.3501\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3502\n",
      "Accuracy:\t0.9630\n",
      "AUC:\t\t0.9619\n",
      "Precision:\t0.9861\n",
      "Recall:\t\t0.9392\n",
      "F1:\t\t\t0.9621\n",
      "\n",
      "fold_3, epoch_981, Loss: 0.3515\n",
      "fold_3, epoch_982, Loss: 0.3516\n",
      "fold_3, epoch_983, Loss: 0.3503\n",
      "fold_3, epoch_984, Loss: 0.3509\n",
      "fold_3, epoch_985, Loss: 0.3519\n",
      "fold_3, epoch_986, Loss: 0.3529\n",
      "fold_3, epoch_987, Loss: 0.3503\n",
      "fold_3, epoch_988, Loss: 0.3508\n",
      "fold_3, epoch_989, Loss: 0.3513\n",
      "fold_3, epoch_990, Loss: 0.3504\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9599\n",
      "Precision:\t0.9860\n",
      "Recall:\t\t0.9317\n",
      "F1:\t\t\t0.9581\n",
      "\n",
      "fold_3, epoch_991, Loss: 0.3519\n",
      "fold_3, epoch_992, Loss: 0.3522\n",
      "fold_3, epoch_993, Loss: 0.3509\n",
      "fold_3, epoch_994, Loss: 0.3507\n",
      "fold_3, epoch_995, Loss: 0.3514\n",
      "fold_3, epoch_996, Loss: 0.3504\n",
      "fold_3, epoch_997, Loss: 0.3520\n",
      "fold_3, epoch_998, Loss: 0.3540\n",
      "fold_3, epoch_999, Loss: 0.3514\n",
      "fold_3, epoch_1000, Loss: 0.3510\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9624\n",
      "AUC:\t\t0.9604\n",
      "Precision:\t0.9869\n",
      "Recall:\t\t0.9377\n",
      "F1:\t\t\t0.9617\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/checkpoints/fold_4\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_23_57_23.366142/tensorboard\n",
      "\n",
      "\n",
      "fold_4, epoch_1, Loss: 0.5846\n",
      "fold_4, epoch_2, Loss: 0.5526\n",
      "fold_4, epoch_3, Loss: 0.5365\n",
      "fold_4, epoch_4, Loss: 0.5309\n",
      "fold_4, epoch_5, Loss: 0.5279\n",
      "fold_4, epoch_6, Loss: 0.5223\n",
      "fold_4, epoch_7, Loss: 0.5147\n",
      "fold_4, epoch_8, Loss: 0.5123\n",
      "fold_4, epoch_9, Loss: 0.5076\n",
      "fold_4, epoch_10, Loss: 0.5027\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.5086\n",
      "Accuracy:\t0.7954\n",
      "AUC:\t\t0.8684\n",
      "Precision:\t0.7541\n",
      "Recall:\t\t0.8782\n",
      "F1:\t\t\t0.8114\n",
      "\n",
      "fold_4, epoch_11, Loss: 0.5025\n",
      "fold_4, epoch_12, Loss: 0.4957\n",
      "fold_4, epoch_13, Loss: 0.4936\n",
      "fold_4, epoch_14, Loss: 0.4922\n",
      "fold_4, epoch_15, Loss: 0.4878\n",
      "fold_4, epoch_16, Loss: 0.4894\n",
      "fold_4, epoch_17, Loss: 0.4864\n",
      "fold_4, epoch_18, Loss: 0.4824\n",
      "fold_4, epoch_19, Loss: 0.4828\n",
      "fold_4, epoch_20, Loss: 0.4762\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4763\n",
      "Accuracy:\t0.8333\n",
      "AUC:\t\t0.8868\n",
      "Precision:\t0.8440\n",
      "Recall:\t\t0.8164\n",
      "F1:\t\t\t0.8300\n",
      "\n",
      "fold_4, epoch_21, Loss: 0.4706\n",
      "fold_4, epoch_22, Loss: 0.4762\n",
      "fold_4, epoch_23, Loss: 0.4673\n",
      "fold_4, epoch_24, Loss: 0.4689\n",
      "fold_4, epoch_25, Loss: 0.4635\n",
      "fold_4, epoch_26, Loss: 0.4626\n",
      "fold_4, epoch_27, Loss: 0.4567\n",
      "fold_4, epoch_28, Loss: 0.4566\n",
      "fold_4, epoch_29, Loss: 0.4603\n",
      "fold_4, epoch_30, Loss: 0.4561\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4663\n",
      "Accuracy:\t0.8419\n",
      "AUC:\t\t0.8956\n",
      "Precision:\t0.8494\n",
      "Recall:\t\t0.8363\n",
      "F1:\t\t\t0.8428\n",
      "\n",
      "fold_4, epoch_31, Loss: 0.4526\n",
      "fold_4, epoch_32, Loss: 0.4472\n",
      "fold_4, epoch_33, Loss: 0.4447\n",
      "fold_4, epoch_34, Loss: 0.4450\n",
      "fold_4, epoch_35, Loss: 0.4455\n",
      "fold_4, epoch_36, Loss: 0.4408\n",
      "fold_4, epoch_37, Loss: 0.4382\n",
      "fold_4, epoch_38, Loss: 0.4456\n",
      "fold_4, epoch_39, Loss: 0.4329\n",
      "fold_4, epoch_40, Loss: 0.4359\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4358\n",
      "Accuracy:\t0.8749\n",
      "AUC:\t\t0.9088\n",
      "Precision:\t0.8751\n",
      "Recall:\t\t0.8727\n",
      "F1:\t\t\t0.8739\n",
      "\n",
      "fold_4, epoch_41, Loss: 0.4425\n",
      "fold_4, epoch_42, Loss: 0.4413\n",
      "fold_4, epoch_43, Loss: 0.4336\n",
      "fold_4, epoch_44, Loss: 0.4362\n",
      "fold_4, epoch_45, Loss: 0.4259\n",
      "fold_4, epoch_46, Loss: 0.4316\n",
      "fold_4, epoch_47, Loss: 0.4350\n",
      "fold_4, epoch_48, Loss: 0.4302\n",
      "fold_4, epoch_49, Loss: 0.4229\n",
      "fold_4, epoch_50, Loss: 0.4267\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4411\n",
      "Accuracy:\t0.8701\n",
      "AUC:\t\t0.9025\n",
      "Precision:\t0.8359\n",
      "Recall:\t\t0.9207\n",
      "F1:\t\t\t0.8762\n",
      "\n",
      "fold_4, epoch_51, Loss: 0.4273\n",
      "fold_4, epoch_52, Loss: 0.4231\n",
      "fold_4, epoch_53, Loss: 0.4219\n",
      "fold_4, epoch_54, Loss: 0.4216\n",
      "fold_4, epoch_55, Loss: 0.4201\n",
      "fold_4, epoch_56, Loss: 0.4252\n",
      "fold_4, epoch_57, Loss: 0.4155\n",
      "fold_4, epoch_58, Loss: 0.4139\n",
      "fold_4, epoch_59, Loss: 0.4133\n",
      "fold_4, epoch_60, Loss: 0.4172\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4252\n",
      "Accuracy:\t0.8859\n",
      "AUC:\t\t0.9165\n",
      "Precision:\t0.8574\n",
      "Recall:\t\t0.9240\n",
      "F1:\t\t\t0.8894\n",
      "\n",
      "fold_4, epoch_61, Loss: 0.4141\n",
      "fold_4, epoch_62, Loss: 0.4134\n",
      "fold_4, epoch_63, Loss: 0.4149\n",
      "fold_4, epoch_64, Loss: 0.4113\n",
      "fold_4, epoch_65, Loss: 0.4112\n",
      "fold_4, epoch_66, Loss: 0.4164\n",
      "fold_4, epoch_67, Loss: 0.4123\n",
      "fold_4, epoch_68, Loss: 0.4072\n",
      "fold_4, epoch_69, Loss: 0.4121\n",
      "fold_4, epoch_70, Loss: 0.4052\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4183\n",
      "Accuracy:\t0.8933\n",
      "AUC:\t\t0.9227\n",
      "Precision:\t0.9149\n",
      "Recall:\t\t0.8679\n",
      "F1:\t\t\t0.8908\n",
      "\n",
      "fold_4, epoch_71, Loss: 0.4042\n",
      "fold_4, epoch_72, Loss: 0.4096\n",
      "fold_4, epoch_73, Loss: 0.4071\n",
      "fold_4, epoch_74, Loss: 0.4091\n",
      "fold_4, epoch_75, Loss: 0.4117\n",
      "fold_4, epoch_76, Loss: 0.4153\n",
      "fold_4, epoch_77, Loss: 0.4051\n",
      "fold_4, epoch_78, Loss: 0.4101\n",
      "fold_4, epoch_79, Loss: 0.4085\n",
      "fold_4, epoch_80, Loss: 0.3998\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4014\n",
      "Accuracy:\t0.9113\n",
      "AUC:\t\t0.9254\n",
      "Precision:\t0.9119\n",
      "Recall:\t\t0.9100\n",
      "F1:\t\t\t0.9109\n",
      "\n",
      "fold_4, epoch_81, Loss: 0.4061\n",
      "fold_4, epoch_82, Loss: 0.4028\n",
      "fold_4, epoch_83, Loss: 0.3993\n",
      "fold_4, epoch_84, Loss: 0.4156\n",
      "fold_4, epoch_85, Loss: 0.4041\n",
      "fold_4, epoch_86, Loss: 0.4029\n",
      "fold_4, epoch_87, Loss: 0.4035\n",
      "fold_4, epoch_88, Loss: 0.3964\n",
      "fold_4, epoch_89, Loss: 0.4009\n",
      "fold_4, epoch_90, Loss: 0.3975\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3947\n",
      "Accuracy:\t0.9179\n",
      "AUC:\t\t0.9277\n",
      "Precision:\t0.9161\n",
      "Recall:\t\t0.9204\n",
      "F1:\t\t\t0.9183\n",
      "\n",
      "fold_4, epoch_91, Loss: 0.4000\n",
      "fold_4, epoch_92, Loss: 0.4034\n",
      "fold_4, epoch_93, Loss: 0.3963\n",
      "fold_4, epoch_94, Loss: 0.3951\n",
      "fold_4, epoch_95, Loss: 0.4017\n",
      "fold_4, epoch_96, Loss: 0.3952\n",
      "fold_4, epoch_97, Loss: 0.3948\n",
      "fold_4, epoch_98, Loss: 0.3940\n",
      "fold_4, epoch_99, Loss: 0.3941\n",
      "fold_4, epoch_100, Loss: 0.3923\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3964\n",
      "Accuracy:\t0.9165\n",
      "AUC:\t\t0.9286\n",
      "Precision:\t0.9118\n",
      "Recall:\t\t0.9209\n",
      "F1:\t\t\t0.9163\n",
      "\n",
      "fold_4, epoch_101, Loss: 0.4021\n",
      "fold_4, epoch_102, Loss: 0.3989\n",
      "fold_4, epoch_103, Loss: 0.3938\n",
      "fold_4, epoch_104, Loss: 0.3921\n",
      "fold_4, epoch_105, Loss: 0.3962\n",
      "fold_4, epoch_106, Loss: 0.3925\n",
      "fold_4, epoch_107, Loss: 0.3921\n",
      "fold_4, epoch_108, Loss: 0.3888\n",
      "fold_4, epoch_109, Loss: 0.3886\n",
      "fold_4, epoch_110, Loss: 0.3893\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3911\n",
      "Accuracy:\t0.9212\n",
      "AUC:\t\t0.9331\n",
      "Precision:\t0.9247\n",
      "Recall:\t\t0.9163\n",
      "F1:\t\t\t0.9205\n",
      "\n",
      "fold_4, epoch_111, Loss: 0.3919\n",
      "fold_4, epoch_112, Loss: 0.3895\n",
      "fold_4, epoch_113, Loss: 0.3882\n",
      "fold_4, epoch_114, Loss: 0.3926\n",
      "fold_4, epoch_115, Loss: 0.3903\n",
      "fold_4, epoch_116, Loss: 0.3896\n",
      "fold_4, epoch_117, Loss: 0.3865\n",
      "fold_4, epoch_118, Loss: 0.3873\n",
      "fold_4, epoch_119, Loss: 0.3874\n",
      "fold_4, epoch_120, Loss: 0.3883\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3849\n",
      "Accuracy:\t0.9276\n",
      "AUC:\t\t0.9361\n",
      "Precision:\t0.9247\n",
      "Recall:\t\t0.9308\n",
      "F1:\t\t\t0.9277\n",
      "\n",
      "fold_4, epoch_121, Loss: 0.3888\n",
      "fold_4, epoch_122, Loss: 0.3897\n",
      "fold_4, epoch_123, Loss: 0.3878\n",
      "fold_4, epoch_124, Loss: 0.3854\n",
      "fold_4, epoch_125, Loss: 0.3830\n",
      "fold_4, epoch_126, Loss: 0.3879\n",
      "fold_4, epoch_127, Loss: 0.3840\n",
      "fold_4, epoch_128, Loss: 0.3892\n",
      "fold_4, epoch_129, Loss: 0.3850\n",
      "fold_4, epoch_130, Loss: 0.3875\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3836\n",
      "Accuracy:\t0.9289\n",
      "AUC:\t\t0.9393\n",
      "Precision:\t0.9318\n",
      "Recall:\t\t0.9256\n",
      "F1:\t\t\t0.9287\n",
      "\n",
      "fold_4, epoch_131, Loss: 0.3882\n",
      "fold_4, epoch_132, Loss: 0.3837\n",
      "fold_4, epoch_133, Loss: 0.3829\n",
      "fold_4, epoch_134, Loss: 0.3811\n",
      "fold_4, epoch_135, Loss: 0.3870\n",
      "fold_4, epoch_136, Loss: 0.3846\n",
      "fold_4, epoch_137, Loss: 0.3837\n",
      "fold_4, epoch_138, Loss: 0.3812\n",
      "fold_4, epoch_139, Loss: 0.3837\n",
      "fold_4, epoch_140, Loss: 0.3869\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3794\n",
      "Accuracy:\t0.9331\n",
      "AUC:\t\t0.9417\n",
      "Precision:\t0.9298\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9340\n",
      "\n",
      "fold_4, epoch_141, Loss: 0.3856\n",
      "fold_4, epoch_142, Loss: 0.3822\n",
      "fold_4, epoch_143, Loss: 0.3833\n",
      "fold_4, epoch_144, Loss: 0.3852\n",
      "fold_4, epoch_145, Loss: 0.3913\n",
      "fold_4, epoch_146, Loss: 0.3814\n",
      "fold_4, epoch_147, Loss: 0.3858\n",
      "fold_4, epoch_148, Loss: 0.3844\n",
      "fold_4, epoch_149, Loss: 0.3840\n",
      "fold_4, epoch_150, Loss: 0.3806\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3841\n",
      "Accuracy:\t0.9281\n",
      "AUC:\t\t0.9413\n",
      "Precision:\t0.9409\n",
      "Recall:\t\t0.9136\n",
      "F1:\t\t\t0.9271\n",
      "\n",
      "fold_4, epoch_151, Loss: 0.3803\n",
      "fold_4, epoch_152, Loss: 0.3817\n",
      "fold_4, epoch_153, Loss: 0.3772\n",
      "fold_4, epoch_154, Loss: 0.3803\n",
      "fold_4, epoch_155, Loss: 0.3790\n",
      "fold_4, epoch_156, Loss: 0.3779\n",
      "fold_4, epoch_157, Loss: 0.3814\n",
      "fold_4, epoch_158, Loss: 0.3723\n",
      "fold_4, epoch_159, Loss: 0.3757\n",
      "fold_4, epoch_160, Loss: 0.3762\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3775\n",
      "Accuracy:\t0.9349\n",
      "AUC:\t\t0.9436\n",
      "Precision:\t0.9390\n",
      "Recall:\t\t0.9308\n",
      "F1:\t\t\t0.9349\n",
      "\n",
      "fold_4, epoch_161, Loss: 0.3817\n",
      "fold_4, epoch_162, Loss: 0.3752\n",
      "fold_4, epoch_163, Loss: 0.3763\n",
      "fold_4, epoch_164, Loss: 0.3796\n",
      "fold_4, epoch_165, Loss: 0.3778\n",
      "fold_4, epoch_166, Loss: 0.3725\n",
      "fold_4, epoch_167, Loss: 0.3759\n",
      "fold_4, epoch_168, Loss: 0.3753\n",
      "fold_4, epoch_169, Loss: 0.3753\n",
      "fold_4, epoch_170, Loss: 0.3805\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3740\n",
      "Accuracy:\t0.9390\n",
      "AUC:\t\t0.9449\n",
      "Precision:\t0.9494\n",
      "Recall:\t\t0.9281\n",
      "F1:\t\t\t0.9386\n",
      "\n",
      "fold_4, epoch_171, Loss: 0.3732\n",
      "fold_4, epoch_172, Loss: 0.3765\n",
      "fold_4, epoch_173, Loss: 0.3786\n",
      "fold_4, epoch_174, Loss: 0.3763\n",
      "fold_4, epoch_175, Loss: 0.3752\n",
      "fold_4, epoch_176, Loss: 0.3737\n",
      "fold_4, epoch_177, Loss: 0.3802\n",
      "fold_4, epoch_178, Loss: 0.3777\n",
      "fold_4, epoch_179, Loss: 0.3775\n",
      "fold_4, epoch_180, Loss: 0.3743\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3725\n",
      "Accuracy:\t0.9403\n",
      "AUC:\t\t0.9465\n",
      "Precision:\t0.9471\n",
      "Recall:\t\t0.9319\n",
      "F1:\t\t\t0.9394\n",
      "\n",
      "fold_4, epoch_181, Loss: 0.3775\n",
      "fold_4, epoch_182, Loss: 0.3727\n",
      "fold_4, epoch_183, Loss: 0.3756\n",
      "fold_4, epoch_184, Loss: 0.3723\n",
      "fold_4, epoch_185, Loss: 0.3730\n",
      "fold_4, epoch_186, Loss: 0.3754\n",
      "fold_4, epoch_187, Loss: 0.3757\n",
      "fold_4, epoch_188, Loss: 0.3747\n",
      "fold_4, epoch_189, Loss: 0.3750\n",
      "fold_4, epoch_190, Loss: 0.3747\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3696\n",
      "Accuracy:\t0.9432\n",
      "AUC:\t\t0.9465\n",
      "Precision:\t0.9550\n",
      "Recall:\t\t0.9297\n",
      "F1:\t\t\t0.9422\n",
      "\n",
      "fold_4, epoch_191, Loss: 0.3706\n",
      "fold_4, epoch_192, Loss: 0.3725\n",
      "fold_4, epoch_193, Loss: 0.3726\n",
      "fold_4, epoch_194, Loss: 0.3702\n",
      "fold_4, epoch_195, Loss: 0.3687\n",
      "fold_4, epoch_196, Loss: 0.3727\n",
      "fold_4, epoch_197, Loss: 0.3717\n",
      "fold_4, epoch_198, Loss: 0.3758\n",
      "fold_4, epoch_199, Loss: 0.3730\n",
      "fold_4, epoch_200, Loss: 0.3684\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3704\n",
      "Accuracy:\t0.9427\n",
      "AUC:\t\t0.9484\n",
      "Precision:\t0.9468\n",
      "Recall:\t\t0.9367\n",
      "F1:\t\t\t0.9417\n",
      "\n",
      "fold_4, epoch_201, Loss: 0.3676\n",
      "fold_4, epoch_202, Loss: 0.3687\n",
      "fold_4, epoch_203, Loss: 0.3687\n",
      "fold_4, epoch_204, Loss: 0.3695\n",
      "fold_4, epoch_205, Loss: 0.3734\n",
      "fold_4, epoch_206, Loss: 0.3686\n",
      "fold_4, epoch_207, Loss: 0.3658\n",
      "fold_4, epoch_208, Loss: 0.3699\n",
      "fold_4, epoch_209, Loss: 0.3673\n",
      "fold_4, epoch_210, Loss: 0.3702\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3705\n",
      "Accuracy:\t0.9421\n",
      "AUC:\t\t0.9471\n",
      "Precision:\t0.9523\n",
      "Recall:\t\t0.9318\n",
      "F1:\t\t\t0.9419\n",
      "\n",
      "fold_4, epoch_211, Loss: 0.3703\n",
      "fold_4, epoch_212, Loss: 0.3673\n",
      "fold_4, epoch_213, Loss: 0.3712\n",
      "fold_4, epoch_214, Loss: 0.3732\n",
      "fold_4, epoch_215, Loss: 0.3686\n",
      "fold_4, epoch_216, Loss: 0.3684\n",
      "fold_4, epoch_217, Loss: 0.3670\n",
      "fold_4, epoch_218, Loss: 0.3672\n",
      "fold_4, epoch_219, Loss: 0.3674\n",
      "fold_4, epoch_220, Loss: 0.3674\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3675\n",
      "Accuracy:\t0.9453\n",
      "AUC:\t\t0.9490\n",
      "Precision:\t0.9574\n",
      "Recall:\t\t0.9307\n",
      "F1:\t\t\t0.9439\n",
      "\n",
      "fold_4, epoch_221, Loss: 0.3674\n",
      "fold_4, epoch_222, Loss: 0.3668\n",
      "fold_4, epoch_223, Loss: 0.3681\n",
      "fold_4, epoch_224, Loss: 0.3696\n",
      "fold_4, epoch_225, Loss: 0.3651\n",
      "fold_4, epoch_226, Loss: 0.3679\n",
      "fold_4, epoch_227, Loss: 0.3666\n",
      "fold_4, epoch_228, Loss: 0.3686\n",
      "fold_4, epoch_229, Loss: 0.3694\n",
      "fold_4, epoch_230, Loss: 0.3657\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3644\n",
      "Accuracy:\t0.9484\n",
      "AUC:\t\t0.9527\n",
      "Precision:\t0.9592\n",
      "Recall:\t\t0.9370\n",
      "F1:\t\t\t0.9480\n",
      "\n",
      "fold_4, epoch_231, Loss: 0.3660\n",
      "fold_4, epoch_232, Loss: 0.3661\n",
      "fold_4, epoch_233, Loss: 0.3718\n",
      "fold_4, epoch_234, Loss: 0.3666\n",
      "fold_4, epoch_235, Loss: 0.3673\n",
      "fold_4, epoch_236, Loss: 0.3663\n",
      "fold_4, epoch_237, Loss: 0.3669\n",
      "fold_4, epoch_238, Loss: 0.3659\n",
      "fold_4, epoch_239, Loss: 0.3650\n",
      "fold_4, epoch_240, Loss: 0.3683\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3724\n",
      "Accuracy:\t0.9406\n",
      "AUC:\t\t0.9468\n",
      "Precision:\t0.9524\n",
      "Recall:\t\t0.9270\n",
      "F1:\t\t\t0.9396\n",
      "\n",
      "fold_4, epoch_241, Loss: 0.3661\n",
      "fold_4, epoch_242, Loss: 0.3639\n",
      "fold_4, epoch_243, Loss: 0.3657\n",
      "fold_4, epoch_244, Loss: 0.3658\n",
      "fold_4, epoch_245, Loss: 0.3612\n",
      "fold_4, epoch_246, Loss: 0.3682\n",
      "fold_4, epoch_247, Loss: 0.3669\n",
      "fold_4, epoch_248, Loss: 0.3677\n",
      "fold_4, epoch_249, Loss: 0.3648\n",
      "fold_4, epoch_250, Loss: 0.3680\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3623\n",
      "Accuracy:\t0.9508\n",
      "AUC:\t\t0.9534\n",
      "Precision:\t0.9612\n",
      "Recall:\t\t0.9391\n",
      "F1:\t\t\t0.9500\n",
      "\n",
      "fold_4, epoch_251, Loss: 0.3655\n",
      "fold_4, epoch_252, Loss: 0.3622\n",
      "fold_4, epoch_253, Loss: 0.3654\n",
      "fold_4, epoch_254, Loss: 0.3657\n",
      "fold_4, epoch_255, Loss: 0.3650\n",
      "fold_4, epoch_256, Loss: 0.3640\n",
      "fold_4, epoch_257, Loss: 0.3649\n",
      "fold_4, epoch_258, Loss: 0.3649\n",
      "fold_4, epoch_259, Loss: 0.3638\n",
      "fold_4, epoch_260, Loss: 0.3667\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3748\n",
      "Accuracy:\t0.9381\n",
      "AUC:\t\t0.9487\n",
      "Precision:\t0.9579\n",
      "Recall:\t\t0.9174\n",
      "F1:\t\t\t0.9373\n",
      "\n",
      "fold_4, epoch_261, Loss: 0.3643\n",
      "fold_4, epoch_262, Loss: 0.3663\n",
      "fold_4, epoch_263, Loss: 0.3626\n",
      "fold_4, epoch_264, Loss: 0.3680\n",
      "fold_4, epoch_265, Loss: 0.3623\n",
      "fold_4, epoch_266, Loss: 0.3618\n",
      "fold_4, epoch_267, Loss: 0.3634\n",
      "fold_4, epoch_268, Loss: 0.3638\n",
      "fold_4, epoch_269, Loss: 0.3614\n",
      "fold_4, epoch_270, Loss: 0.3577\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3580\n",
      "Accuracy:\t0.9554\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9718\n",
      "Recall:\t\t0.9384\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_4, epoch_271, Loss: 0.3626\n",
      "fold_4, epoch_272, Loss: 0.3628\n",
      "fold_4, epoch_273, Loss: 0.3601\n",
      "fold_4, epoch_274, Loss: 0.3617\n",
      "fold_4, epoch_275, Loss: 0.3660\n",
      "fold_4, epoch_276, Loss: 0.3626\n",
      "fold_4, epoch_277, Loss: 0.3630\n",
      "fold_4, epoch_278, Loss: 0.3631\n",
      "fold_4, epoch_279, Loss: 0.3667\n",
      "fold_4, epoch_280, Loss: 0.3608\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3581\n",
      "Accuracy:\t0.9550\n",
      "AUC:\t\t0.9562\n",
      "Precision:\t0.9673\n",
      "Recall:\t\t0.9415\n",
      "F1:\t\t\t0.9542\n",
      "\n",
      "fold_4, epoch_281, Loss: 0.3658\n",
      "fold_4, epoch_282, Loss: 0.3608\n",
      "fold_4, epoch_283, Loss: 0.3609\n",
      "fold_4, epoch_284, Loss: 0.3649\n",
      "fold_4, epoch_285, Loss: 0.3630\n",
      "fold_4, epoch_286, Loss: 0.3596\n",
      "fold_4, epoch_287, Loss: 0.3611\n",
      "fold_4, epoch_288, Loss: 0.3632\n",
      "fold_4, epoch_289, Loss: 0.3648\n",
      "fold_4, epoch_290, Loss: 0.3610\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3635\n",
      "Accuracy:\t0.9496\n",
      "AUC:\t\t0.9525\n",
      "Precision:\t0.9607\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9492\n",
      "\n",
      "fold_4, epoch_291, Loss: 0.3599\n",
      "fold_4, epoch_292, Loss: 0.3612\n",
      "fold_4, epoch_293, Loss: 0.3602\n",
      "fold_4, epoch_294, Loss: 0.3637\n",
      "fold_4, epoch_295, Loss: 0.3580\n",
      "fold_4, epoch_296, Loss: 0.3642\n",
      "fold_4, epoch_297, Loss: 0.3620\n",
      "fold_4, epoch_298, Loss: 0.3592\n",
      "fold_4, epoch_299, Loss: 0.3627\n",
      "fold_4, epoch_300, Loss: 0.3615\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3677\n",
      "Accuracy:\t0.9446\n",
      "AUC:\t\t0.9528\n",
      "Precision:\t0.9573\n",
      "Recall:\t\t0.9304\n",
      "F1:\t\t\t0.9437\n",
      "\n",
      "fold_4, epoch_301, Loss: 0.3637\n",
      "fold_4, epoch_302, Loss: 0.3588\n",
      "fold_4, epoch_303, Loss: 0.3577\n",
      "fold_4, epoch_304, Loss: 0.3621\n",
      "fold_4, epoch_305, Loss: 0.3604\n",
      "fold_4, epoch_306, Loss: 0.3577\n",
      "fold_4, epoch_307, Loss: 0.3619\n",
      "fold_4, epoch_308, Loss: 0.3579\n",
      "fold_4, epoch_309, Loss: 0.3608\n",
      "fold_4, epoch_310, Loss: 0.3600\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3589\n",
      "Accuracy:\t0.9543\n",
      "AUC:\t\t0.9577\n",
      "Precision:\t0.9706\n",
      "Recall:\t\t0.9370\n",
      "F1:\t\t\t0.9535\n",
      "\n",
      "fold_4, epoch_311, Loss: 0.3621\n",
      "fold_4, epoch_312, Loss: 0.3564\n",
      "fold_4, epoch_313, Loss: 0.3581\n",
      "fold_4, epoch_314, Loss: 0.3612\n",
      "fold_4, epoch_315, Loss: 0.3639\n",
      "fold_4, epoch_316, Loss: 0.3589\n",
      "fold_4, epoch_317, Loss: 0.3597\n",
      "fold_4, epoch_318, Loss: 0.3578\n",
      "fold_4, epoch_319, Loss: 0.3569\n",
      "fold_4, epoch_320, Loss: 0.3556\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3548\n",
      "Accuracy:\t0.9584\n",
      "AUC:\t\t0.9576\n",
      "Precision:\t0.9735\n",
      "Recall:\t\t0.9427\n",
      "F1:\t\t\t0.9578\n",
      "\n",
      "fold_4, epoch_321, Loss: 0.3612\n",
      "fold_4, epoch_322, Loss: 0.3607\n",
      "fold_4, epoch_323, Loss: 0.3567\n",
      "fold_4, epoch_324, Loss: 0.3563\n",
      "fold_4, epoch_325, Loss: 0.3573\n",
      "fold_4, epoch_326, Loss: 0.3590\n",
      "fold_4, epoch_327, Loss: 0.3603\n",
      "fold_4, epoch_328, Loss: 0.3563\n",
      "fold_4, epoch_329, Loss: 0.3564\n",
      "fold_4, epoch_330, Loss: 0.3564\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3554\n",
      "Accuracy:\t0.9576\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9737\n",
      "Recall:\t\t0.9403\n",
      "F1:\t\t\t0.9567\n",
      "\n",
      "fold_4, epoch_331, Loss: 0.3584\n",
      "fold_4, epoch_332, Loss: 0.3595\n",
      "fold_4, epoch_333, Loss: 0.3595\n",
      "fold_4, epoch_334, Loss: 0.3561\n",
      "fold_4, epoch_335, Loss: 0.3577\n",
      "fold_4, epoch_336, Loss: 0.3573\n",
      "fold_4, epoch_337, Loss: 0.3589\n",
      "fold_4, epoch_338, Loss: 0.3577\n",
      "fold_4, epoch_339, Loss: 0.3592\n",
      "fold_4, epoch_340, Loss: 0.3568\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3538\n",
      "Accuracy:\t0.9594\n",
      "AUC:\t\t0.9580\n",
      "Precision:\t0.9743\n",
      "Recall:\t\t0.9434\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_4, epoch_341, Loss: 0.3596\n",
      "fold_4, epoch_342, Loss: 0.3601\n",
      "fold_4, epoch_343, Loss: 0.3601\n",
      "fold_4, epoch_344, Loss: 0.3552\n",
      "fold_4, epoch_345, Loss: 0.3611\n",
      "fold_4, epoch_346, Loss: 0.3570\n",
      "fold_4, epoch_347, Loss: 0.3574\n",
      "fold_4, epoch_348, Loss: 0.3581\n",
      "fold_4, epoch_349, Loss: 0.3569\n",
      "fold_4, epoch_350, Loss: 0.3571\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3574\n",
      "Accuracy:\t0.9559\n",
      "AUC:\t\t0.9578\n",
      "Precision:\t0.9667\n",
      "Recall:\t\t0.9438\n",
      "F1:\t\t\t0.9551\n",
      "\n",
      "fold_4, epoch_351, Loss: 0.3575\n",
      "fold_4, epoch_352, Loss: 0.3574\n",
      "fold_4, epoch_353, Loss: 0.3552\n",
      "fold_4, epoch_354, Loss: 0.3602\n",
      "fold_4, epoch_355, Loss: 0.3567\n",
      "fold_4, epoch_356, Loss: 0.3572\n",
      "fold_4, epoch_357, Loss: 0.3580\n",
      "fold_4, epoch_358, Loss: 0.3607\n",
      "fold_4, epoch_359, Loss: 0.3565\n",
      "fold_4, epoch_360, Loss: 0.3559\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3567\n",
      "Accuracy:\t0.9566\n",
      "AUC:\t\t0.9561\n",
      "Precision:\t0.9735\n",
      "Recall:\t\t0.9393\n",
      "F1:\t\t\t0.9561\n",
      "\n",
      "fold_4, epoch_361, Loss: 0.3565\n",
      "fold_4, epoch_362, Loss: 0.3590\n",
      "fold_4, epoch_363, Loss: 0.3576\n",
      "fold_4, epoch_364, Loss: 0.3555\n",
      "fold_4, epoch_365, Loss: 0.3547\n",
      "fold_4, epoch_366, Loss: 0.3574\n",
      "fold_4, epoch_367, Loss: 0.3558\n",
      "fold_4, epoch_368, Loss: 0.3570\n",
      "fold_4, epoch_369, Loss: 0.3550\n",
      "fold_4, epoch_370, Loss: 0.3593\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3577\n",
      "Accuracy:\t0.9556\n",
      "AUC:\t\t0.9586\n",
      "Precision:\t0.9733\n",
      "Recall:\t\t0.9376\n",
      "F1:\t\t\t0.9551\n",
      "\n",
      "fold_4, epoch_371, Loss: 0.3601\n",
      "fold_4, epoch_372, Loss: 0.3560\n",
      "fold_4, epoch_373, Loss: 0.3544\n",
      "fold_4, epoch_374, Loss: 0.3563\n",
      "fold_4, epoch_375, Loss: 0.3560\n",
      "fold_4, epoch_376, Loss: 0.3576\n",
      "fold_4, epoch_377, Loss: 0.3555\n",
      "fold_4, epoch_378, Loss: 0.3553\n",
      "fold_4, epoch_379, Loss: 0.3557\n",
      "fold_4, epoch_380, Loss: 0.3545\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3563\n",
      "Accuracy:\t0.9564\n",
      "AUC:\t\t0.9607\n",
      "Precision:\t0.9722\n",
      "Recall:\t\t0.9391\n",
      "F1:\t\t\t0.9554\n",
      "\n",
      "fold_4, epoch_381, Loss: 0.3548\n",
      "fold_4, epoch_382, Loss: 0.3562\n",
      "fold_4, epoch_383, Loss: 0.3550\n",
      "fold_4, epoch_384, Loss: 0.3588\n",
      "fold_4, epoch_385, Loss: 0.3541\n",
      "fold_4, epoch_386, Loss: 0.3565\n",
      "fold_4, epoch_387, Loss: 0.3595\n",
      "fold_4, epoch_388, Loss: 0.3564\n",
      "fold_4, epoch_389, Loss: 0.3586\n",
      "fold_4, epoch_390, Loss: 0.3553\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3536\n",
      "Accuracy:\t0.9592\n",
      "AUC:\t\t0.9607\n",
      "Precision:\t0.9788\n",
      "Recall:\t\t0.9393\n",
      "F1:\t\t\t0.9586\n",
      "\n",
      "fold_4, epoch_391, Loss: 0.3554\n",
      "fold_4, epoch_392, Loss: 0.3560\n",
      "fold_4, epoch_393, Loss: 0.3562\n",
      "fold_4, epoch_394, Loss: 0.3550\n",
      "fold_4, epoch_395, Loss: 0.3549\n",
      "fold_4, epoch_396, Loss: 0.3560\n",
      "fold_4, epoch_397, Loss: 0.3582\n",
      "fold_4, epoch_398, Loss: 0.3533\n",
      "fold_4, epoch_399, Loss: 0.3544\n",
      "fold_4, epoch_400, Loss: 0.3564\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3549\n",
      "Accuracy:\t0.9583\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9755\n",
      "Recall:\t\t0.9405\n",
      "F1:\t\t\t0.9577\n",
      "\n",
      "fold_4, epoch_401, Loss: 0.3548\n",
      "fold_4, epoch_402, Loss: 0.3543\n",
      "fold_4, epoch_403, Loss: 0.3557\n",
      "fold_4, epoch_404, Loss: 0.3566\n",
      "fold_4, epoch_405, Loss: 0.3557\n",
      "fold_4, epoch_406, Loss: 0.3554\n",
      "fold_4, epoch_407, Loss: 0.3530\n",
      "fold_4, epoch_408, Loss: 0.3547\n",
      "fold_4, epoch_409, Loss: 0.3533\n",
      "fold_4, epoch_410, Loss: 0.3556\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9603\n",
      "AUC:\t\t0.9583\n",
      "Precision:\t0.9779\n",
      "Recall:\t\t0.9413\n",
      "F1:\t\t\t0.9592\n",
      "\n",
      "fold_4, epoch_411, Loss: 0.3569\n",
      "fold_4, epoch_412, Loss: 0.3567\n",
      "fold_4, epoch_413, Loss: 0.3550\n",
      "fold_4, epoch_414, Loss: 0.3543\n",
      "fold_4, epoch_415, Loss: 0.3564\n",
      "fold_4, epoch_416, Loss: 0.3553\n",
      "fold_4, epoch_417, Loss: 0.3534\n",
      "fold_4, epoch_418, Loss: 0.3568\n",
      "fold_4, epoch_419, Loss: 0.3529\n",
      "fold_4, epoch_420, Loss: 0.3542\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3511\n",
      "Accuracy:\t0.9620\n",
      "AUC:\t\t0.9623\n",
      "Precision:\t0.9784\n",
      "Recall:\t\t0.9446\n",
      "F1:\t\t\t0.9612\n",
      "\n",
      "fold_4, epoch_421, Loss: 0.3512\n",
      "fold_4, epoch_422, Loss: 0.3564\n",
      "fold_4, epoch_423, Loss: 0.3534\n",
      "fold_4, epoch_424, Loss: 0.3535\n",
      "fold_4, epoch_425, Loss: 0.3522\n",
      "fold_4, epoch_426, Loss: 0.3539\n",
      "fold_4, epoch_427, Loss: 0.3548\n",
      "fold_4, epoch_428, Loss: 0.3526\n",
      "fold_4, epoch_429, Loss: 0.3576\n",
      "fold_4, epoch_430, Loss: 0.3538\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3502\n",
      "Accuracy:\t0.9631\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9778\n",
      "Recall:\t\t0.9477\n",
      "F1:\t\t\t0.9625\n",
      "\n",
      "fold_4, epoch_431, Loss: 0.3498\n",
      "fold_4, epoch_432, Loss: 0.3528\n",
      "fold_4, epoch_433, Loss: 0.3570\n",
      "fold_4, epoch_434, Loss: 0.3576\n",
      "fold_4, epoch_435, Loss: 0.3568\n",
      "fold_4, epoch_436, Loss: 0.3538\n",
      "fold_4, epoch_437, Loss: 0.3583\n",
      "fold_4, epoch_438, Loss: 0.3553\n",
      "fold_4, epoch_439, Loss: 0.3529\n",
      "fold_4, epoch_440, Loss: 0.3542\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9590\n",
      "AUC:\t\t0.9589\n",
      "Precision:\t0.9741\n",
      "Recall:\t\t0.9433\n",
      "F1:\t\t\t0.9585\n",
      "\n",
      "fold_4, epoch_441, Loss: 0.3511\n",
      "fold_4, epoch_442, Loss: 0.3549\n",
      "fold_4, epoch_443, Loss: 0.3518\n",
      "fold_4, epoch_444, Loss: 0.3537\n",
      "fold_4, epoch_445, Loss: 0.3560\n",
      "fold_4, epoch_446, Loss: 0.3529\n",
      "fold_4, epoch_447, Loss: 0.3511\n",
      "fold_4, epoch_448, Loss: 0.3507\n",
      "fold_4, epoch_449, Loss: 0.3529\n",
      "fold_4, epoch_450, Loss: 0.3563\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3526\n",
      "Accuracy:\t0.9606\n",
      "AUC:\t\t0.9614\n",
      "Precision:\t0.9755\n",
      "Recall:\t\t0.9449\n",
      "F1:\t\t\t0.9599\n",
      "\n",
      "fold_4, epoch_451, Loss: 0.3543\n",
      "fold_4, epoch_452, Loss: 0.3517\n",
      "fold_4, epoch_453, Loss: 0.3525\n",
      "fold_4, epoch_454, Loss: 0.3536\n",
      "fold_4, epoch_455, Loss: 0.3542\n",
      "fold_4, epoch_456, Loss: 0.3558\n",
      "fold_4, epoch_457, Loss: 0.3521\n",
      "fold_4, epoch_458, Loss: 0.3542\n",
      "fold_4, epoch_459, Loss: 0.3510\n",
      "fold_4, epoch_460, Loss: 0.3518\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9585\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9742\n",
      "Recall:\t\t0.9414\n",
      "F1:\t\t\t0.9575\n",
      "\n",
      "fold_4, epoch_461, Loss: 0.3566\n",
      "fold_4, epoch_462, Loss: 0.3542\n",
      "fold_4, epoch_463, Loss: 0.3586\n",
      "fold_4, epoch_464, Loss: 0.3547\n",
      "fold_4, epoch_465, Loss: 0.3524\n",
      "fold_4, epoch_466, Loss: 0.3515\n",
      "fold_4, epoch_467, Loss: 0.3534\n",
      "fold_4, epoch_468, Loss: 0.3550\n",
      "fold_4, epoch_469, Loss: 0.3537\n",
      "fold_4, epoch_470, Loss: 0.3543\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3491\n",
      "Accuracy:\t0.9642\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9813\n",
      "Recall:\t\t0.9464\n",
      "F1:\t\t\t0.9635\n",
      "\n",
      "fold_4, epoch_471, Loss: 0.3512\n",
      "fold_4, epoch_472, Loss: 0.3533\n",
      "fold_4, epoch_473, Loss: 0.3535\n",
      "fold_4, epoch_474, Loss: 0.3534\n",
      "fold_4, epoch_475, Loss: 0.3506\n",
      "fold_4, epoch_476, Loss: 0.3529\n",
      "fold_4, epoch_477, Loss: 0.3542\n",
      "fold_4, epoch_478, Loss: 0.3535\n",
      "fold_4, epoch_479, Loss: 0.3528\n",
      "fold_4, epoch_480, Loss: 0.3508\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3589\n",
      "Accuracy:\t0.9544\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9759\n",
      "Recall:\t\t0.9313\n",
      "F1:\t\t\t0.9531\n",
      "\n",
      "fold_4, epoch_481, Loss: 0.3520\n",
      "fold_4, epoch_482, Loss: 0.3511\n",
      "fold_4, epoch_483, Loss: 0.3515\n",
      "fold_4, epoch_484, Loss: 0.3538\n",
      "fold_4, epoch_485, Loss: 0.3532\n",
      "fold_4, epoch_486, Loss: 0.3551\n",
      "fold_4, epoch_487, Loss: 0.3525\n",
      "fold_4, epoch_488, Loss: 0.3510\n",
      "fold_4, epoch_489, Loss: 0.3548\n",
      "fold_4, epoch_490, Loss: 0.3531\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3494\n",
      "Accuracy:\t0.9638\n",
      "AUC:\t\t0.9628\n",
      "Precision:\t0.9789\n",
      "Recall:\t\t0.9480\n",
      "F1:\t\t\t0.9632\n",
      "\n",
      "fold_4, epoch_491, Loss: 0.3549\n",
      "fold_4, epoch_492, Loss: 0.3523\n",
      "fold_4, epoch_493, Loss: 0.3521\n",
      "fold_4, epoch_494, Loss: 0.3538\n",
      "fold_4, epoch_495, Loss: 0.3522\n",
      "fold_4, epoch_496, Loss: 0.3509\n",
      "fold_4, epoch_497, Loss: 0.3499\n",
      "fold_4, epoch_498, Loss: 0.3498\n",
      "fold_4, epoch_499, Loss: 0.3507\n",
      "fold_4, epoch_500, Loss: 0.3553\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3547\n",
      "Accuracy:\t0.9583\n",
      "AUC:\t\t0.9598\n",
      "Precision:\t0.9749\n",
      "Recall:\t\t0.9405\n",
      "F1:\t\t\t0.9574\n",
      "\n",
      "fold_4, epoch_501, Loss: 0.3568\n",
      "fold_4, epoch_502, Loss: 0.3559\n",
      "fold_4, epoch_503, Loss: 0.3527\n",
      "fold_4, epoch_504, Loss: 0.3511\n",
      "fold_4, epoch_505, Loss: 0.3512\n",
      "fold_4, epoch_506, Loss: 0.3519\n",
      "fold_4, epoch_507, Loss: 0.3520\n",
      "fold_4, epoch_508, Loss: 0.3504\n",
      "fold_4, epoch_509, Loss: 0.3509\n",
      "fold_4, epoch_510, Loss: 0.3516\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3518\n",
      "Accuracy:\t0.9612\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9769\n",
      "Recall:\t\t0.9443\n",
      "F1:\t\t\t0.9603\n",
      "\n",
      "fold_4, epoch_511, Loss: 0.3507\n",
      "fold_4, epoch_512, Loss: 0.3510\n",
      "fold_4, epoch_513, Loss: 0.3532\n",
      "fold_4, epoch_514, Loss: 0.3508\n",
      "fold_4, epoch_515, Loss: 0.3501\n",
      "fold_4, epoch_516, Loss: 0.3505\n",
      "fold_4, epoch_517, Loss: 0.3506\n",
      "fold_4, epoch_518, Loss: 0.3530\n",
      "fold_4, epoch_519, Loss: 0.3504\n",
      "fold_4, epoch_520, Loss: 0.3523\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3518\n",
      "Accuracy:\t0.9614\n",
      "AUC:\t\t0.9625\n",
      "Precision:\t0.9803\n",
      "Recall:\t\t0.9419\n",
      "F1:\t\t\t0.9607\n",
      "\n",
      "fold_4, epoch_521, Loss: 0.3540\n",
      "fold_4, epoch_522, Loss: 0.3531\n",
      "fold_4, epoch_523, Loss: 0.3506\n",
      "fold_4, epoch_524, Loss: 0.3558\n",
      "fold_4, epoch_525, Loss: 0.3519\n",
      "fold_4, epoch_526, Loss: 0.3515\n",
      "fold_4, epoch_527, Loss: 0.3490\n",
      "fold_4, epoch_528, Loss: 0.3484\n",
      "fold_4, epoch_529, Loss: 0.3517\n",
      "fold_4, epoch_530, Loss: 0.3517\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3505\n",
      "Accuracy:\t0.9628\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9825\n",
      "Recall:\t\t0.9420\n",
      "F1:\t\t\t0.9619\n",
      "\n",
      "fold_4, epoch_531, Loss: 0.3522\n",
      "fold_4, epoch_532, Loss: 0.3494\n",
      "fold_4, epoch_533, Loss: 0.3538\n",
      "fold_4, epoch_534, Loss: 0.3529\n",
      "fold_4, epoch_535, Loss: 0.3491\n",
      "fold_4, epoch_536, Loss: 0.3493\n",
      "fold_4, epoch_537, Loss: 0.3533\n",
      "fold_4, epoch_538, Loss: 0.3545\n",
      "fold_4, epoch_539, Loss: 0.3509\n",
      "fold_4, epoch_540, Loss: 0.3525\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3491\n",
      "Accuracy:\t0.9642\n",
      "AUC:\t\t0.9626\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9432\n",
      "F1:\t\t\t0.9632\n",
      "\n",
      "fold_4, epoch_541, Loss: 0.3483\n",
      "fold_4, epoch_542, Loss: 0.3527\n",
      "fold_4, epoch_543, Loss: 0.3535\n",
      "fold_4, epoch_544, Loss: 0.3524\n",
      "fold_4, epoch_545, Loss: 0.3510\n",
      "fold_4, epoch_546, Loss: 0.3536\n",
      "fold_4, epoch_547, Loss: 0.3514\n",
      "fold_4, epoch_548, Loss: 0.3535\n",
      "fold_4, epoch_549, Loss: 0.3525\n",
      "fold_4, epoch_550, Loss: 0.3524\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3519\n",
      "Accuracy:\t0.9613\n",
      "AUC:\t\t0.9601\n",
      "Precision:\t0.9805\n",
      "Recall:\t\t0.9424\n",
      "F1:\t\t\t0.9611\n",
      "\n",
      "fold_4, epoch_551, Loss: 0.3497\n",
      "fold_4, epoch_552, Loss: 0.3525\n",
      "fold_4, epoch_553, Loss: 0.3528\n",
      "fold_4, epoch_554, Loss: 0.3528\n",
      "fold_4, epoch_555, Loss: 0.3524\n",
      "fold_4, epoch_556, Loss: 0.3494\n",
      "fold_4, epoch_557, Loss: 0.3532\n",
      "fold_4, epoch_558, Loss: 0.3527\n",
      "fold_4, epoch_559, Loss: 0.3509\n",
      "fold_4, epoch_560, Loss: 0.3514\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9806\n",
      "Recall:\t\t0.9433\n",
      "F1:\t\t\t0.9616\n",
      "\n",
      "fold_4, epoch_561, Loss: 0.3496\n",
      "fold_4, epoch_562, Loss: 0.3518\n",
      "fold_4, epoch_563, Loss: 0.3517\n",
      "fold_4, epoch_564, Loss: 0.3538\n",
      "fold_4, epoch_565, Loss: 0.3502\n",
      "fold_4, epoch_566, Loss: 0.3524\n",
      "fold_4, epoch_567, Loss: 0.3510\n",
      "fold_4, epoch_568, Loss: 0.3519\n",
      "fold_4, epoch_569, Loss: 0.3514\n",
      "fold_4, epoch_570, Loss: 0.3498\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3520\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9794\n",
      "Recall:\t\t0.9415\n",
      "F1:\t\t\t0.9601\n",
      "\n",
      "fold_4, epoch_571, Loss: 0.3523\n",
      "fold_4, epoch_572, Loss: 0.3512\n",
      "fold_4, epoch_573, Loss: 0.3538\n",
      "fold_4, epoch_574, Loss: 0.3504\n",
      "fold_4, epoch_575, Loss: 0.3533\n",
      "fold_4, epoch_576, Loss: 0.3512\n",
      "fold_4, epoch_577, Loss: 0.3502\n",
      "fold_4, epoch_578, Loss: 0.3531\n",
      "fold_4, epoch_579, Loss: 0.3500\n",
      "fold_4, epoch_580, Loss: 0.3497\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3485\n",
      "Accuracy:\t0.9645\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9832\n",
      "Recall:\t\t0.9456\n",
      "F1:\t\t\t0.9640\n",
      "\n",
      "fold_4, epoch_581, Loss: 0.3511\n",
      "fold_4, epoch_582, Loss: 0.3493\n",
      "fold_4, epoch_583, Loss: 0.3495\n",
      "fold_4, epoch_584, Loss: 0.3516\n",
      "fold_4, epoch_585, Loss: 0.3488\n",
      "fold_4, epoch_586, Loss: 0.3489\n",
      "fold_4, epoch_587, Loss: 0.3516\n",
      "fold_4, epoch_588, Loss: 0.3545\n",
      "fold_4, epoch_589, Loss: 0.3512\n",
      "fold_4, epoch_590, Loss: 0.3502\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3481\n",
      "Accuracy:\t0.9652\n",
      "AUC:\t\t0.9634\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9453\n",
      "F1:\t\t\t0.9642\n",
      "\n",
      "fold_4, epoch_591, Loss: 0.3481\n",
      "fold_4, epoch_592, Loss: 0.3490\n",
      "fold_4, epoch_593, Loss: 0.3503\n",
      "fold_4, epoch_594, Loss: 0.3543\n",
      "fold_4, epoch_595, Loss: 0.3518\n",
      "fold_4, epoch_596, Loss: 0.3506\n",
      "fold_4, epoch_597, Loss: 0.3493\n",
      "fold_4, epoch_598, Loss: 0.3530\n",
      "fold_4, epoch_599, Loss: 0.3495\n",
      "fold_4, epoch_600, Loss: 0.3522\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3520\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9788\n",
      "Recall:\t\t0.9423\n",
      "F1:\t\t\t0.9602\n",
      "\n",
      "fold_4, epoch_601, Loss: 0.3525\n",
      "fold_4, epoch_602, Loss: 0.3501\n",
      "fold_4, epoch_603, Loss: 0.3515\n",
      "fold_4, epoch_604, Loss: 0.3501\n",
      "fold_4, epoch_605, Loss: 0.3501\n",
      "fold_4, epoch_606, Loss: 0.3507\n",
      "fold_4, epoch_607, Loss: 0.3519\n",
      "fold_4, epoch_608, Loss: 0.3514\n",
      "fold_4, epoch_609, Loss: 0.3474\n",
      "fold_4, epoch_610, Loss: 0.3529\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9626\n",
      "Precision:\t0.9806\n",
      "Recall:\t\t0.9436\n",
      "F1:\t\t\t0.9617\n",
      "\n",
      "fold_4, epoch_611, Loss: 0.3511\n",
      "fold_4, epoch_612, Loss: 0.3500\n",
      "fold_4, epoch_613, Loss: 0.3483\n",
      "fold_4, epoch_614, Loss: 0.3511\n",
      "fold_4, epoch_615, Loss: 0.3513\n",
      "fold_4, epoch_616, Loss: 0.3499\n",
      "fold_4, epoch_617, Loss: 0.3515\n",
      "fold_4, epoch_618, Loss: 0.3507\n",
      "fold_4, epoch_619, Loss: 0.3515\n",
      "fold_4, epoch_620, Loss: 0.3509\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9615\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9830\n",
      "Recall:\t\t0.9390\n",
      "F1:\t\t\t0.9605\n",
      "\n",
      "fold_4, epoch_621, Loss: 0.3505\n",
      "fold_4, epoch_622, Loss: 0.3502\n",
      "fold_4, epoch_623, Loss: 0.3498\n",
      "fold_4, epoch_624, Loss: 0.3472\n",
      "fold_4, epoch_625, Loss: 0.3498\n",
      "fold_4, epoch_626, Loss: 0.3500\n",
      "fold_4, epoch_627, Loss: 0.3513\n",
      "fold_4, epoch_628, Loss: 0.3504\n",
      "fold_4, epoch_629, Loss: 0.3513\n",
      "fold_4, epoch_630, Loss: 0.3488\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3475\n",
      "Accuracy:\t0.9656\n",
      "AUC:\t\t0.9656\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9468\n",
      "F1:\t\t\t0.9651\n",
      "\n",
      "fold_4, epoch_631, Loss: 0.3503\n",
      "fold_4, epoch_632, Loss: 0.3497\n",
      "fold_4, epoch_633, Loss: 0.3479\n",
      "fold_4, epoch_634, Loss: 0.3487\n",
      "fold_4, epoch_635, Loss: 0.3474\n",
      "fold_4, epoch_636, Loss: 0.3495\n",
      "fold_4, epoch_637, Loss: 0.3523\n",
      "fold_4, epoch_638, Loss: 0.3482\n",
      "fold_4, epoch_639, Loss: 0.3495\n",
      "fold_4, epoch_640, Loss: 0.3505\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3501\n",
      "Accuracy:\t0.9630\n",
      "AUC:\t\t0.9641\n",
      "Precision:\t0.9815\n",
      "Recall:\t\t0.9433\n",
      "F1:\t\t\t0.9620\n",
      "\n",
      "fold_4, epoch_641, Loss: 0.3506\n",
      "fold_4, epoch_642, Loss: 0.3490\n",
      "fold_4, epoch_643, Loss: 0.3496\n",
      "fold_4, epoch_644, Loss: 0.3518\n",
      "fold_4, epoch_645, Loss: 0.3503\n",
      "fold_4, epoch_646, Loss: 0.3478\n",
      "fold_4, epoch_647, Loss: 0.3478\n",
      "fold_4, epoch_648, Loss: 0.3485\n",
      "fold_4, epoch_649, Loss: 0.3493\n",
      "fold_4, epoch_650, Loss: 0.3523\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3504\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9633\n",
      "Precision:\t0.9831\n",
      "Recall:\t\t0.9422\n",
      "F1:\t\t\t0.9622\n",
      "\n",
      "fold_4, epoch_651, Loss: 0.3494\n",
      "fold_4, epoch_652, Loss: 0.3503\n",
      "fold_4, epoch_653, Loss: 0.3503\n",
      "fold_4, epoch_654, Loss: 0.3498\n",
      "fold_4, epoch_655, Loss: 0.3502\n",
      "fold_4, epoch_656, Loss: 0.3520\n",
      "fold_4, epoch_657, Loss: 0.3513\n",
      "fold_4, epoch_658, Loss: 0.3477\n",
      "fold_4, epoch_659, Loss: 0.3525\n",
      "fold_4, epoch_660, Loss: 0.3474\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9625\n",
      "AUC:\t\t0.9620\n",
      "Precision:\t0.9854\n",
      "Recall:\t\t0.9393\n",
      "F1:\t\t\t0.9618\n",
      "\n",
      "fold_4, epoch_661, Loss: 0.3478\n",
      "fold_4, epoch_662, Loss: 0.3482\n",
      "fold_4, epoch_663, Loss: 0.3538\n",
      "fold_4, epoch_664, Loss: 0.3508\n",
      "fold_4, epoch_665, Loss: 0.3489\n",
      "fold_4, epoch_666, Loss: 0.3521\n",
      "fold_4, epoch_667, Loss: 0.3498\n",
      "fold_4, epoch_668, Loss: 0.3490\n",
      "fold_4, epoch_669, Loss: 0.3495\n",
      "fold_4, epoch_670, Loss: 0.3513\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3477\n",
      "Accuracy:\t0.9657\n",
      "AUC:\t\t0.9634\n",
      "Precision:\t0.9853\n",
      "Recall:\t\t0.9451\n",
      "F1:\t\t\t0.9648\n",
      "\n",
      "fold_4, epoch_671, Loss: 0.3493\n",
      "fold_4, epoch_672, Loss: 0.3486\n",
      "fold_4, epoch_673, Loss: 0.3498\n",
      "fold_4, epoch_674, Loss: 0.3503\n",
      "fold_4, epoch_675, Loss: 0.3483\n",
      "fold_4, epoch_676, Loss: 0.3492\n",
      "fold_4, epoch_677, Loss: 0.3491\n",
      "fold_4, epoch_678, Loss: 0.3502\n",
      "fold_4, epoch_679, Loss: 0.3479\n",
      "fold_4, epoch_680, Loss: 0.3488\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3470\n",
      "Accuracy:\t0.9663\n",
      "AUC:\t\t0.9642\n",
      "Precision:\t0.9860\n",
      "Recall:\t\t0.9457\n",
      "F1:\t\t\t0.9654\n",
      "\n",
      "fold_4, epoch_681, Loss: 0.3483\n",
      "fold_4, epoch_682, Loss: 0.3478\n",
      "fold_4, epoch_683, Loss: 0.3493\n",
      "fold_4, epoch_684, Loss: 0.3483\n",
      "fold_4, epoch_685, Loss: 0.3478\n",
      "fold_4, epoch_686, Loss: 0.3467\n",
      "fold_4, epoch_687, Loss: 0.3484\n",
      "fold_4, epoch_688, Loss: 0.3519\n",
      "fold_4, epoch_689, Loss: 0.3477\n",
      "fold_4, epoch_690, Loss: 0.3487\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3482\n",
      "Accuracy:\t0.9651\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9852\n",
      "Recall:\t\t0.9445\n",
      "F1:\t\t\t0.9644\n",
      "\n",
      "fold_4, epoch_691, Loss: 0.3490\n",
      "fold_4, epoch_692, Loss: 0.3507\n",
      "fold_4, epoch_693, Loss: 0.3497\n",
      "fold_4, epoch_694, Loss: 0.3499\n",
      "fold_4, epoch_695, Loss: 0.3479\n",
      "fold_4, epoch_696, Loss: 0.3483\n",
      "fold_4, epoch_697, Loss: 0.3494\n",
      "fold_4, epoch_698, Loss: 0.3497\n",
      "fold_4, epoch_699, Loss: 0.3485\n",
      "fold_4, epoch_700, Loss: 0.3486\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3481\n",
      "Accuracy:\t0.9648\n",
      "AUC:\t\t0.9644\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9424\n",
      "F1:\t\t\t0.9640\n",
      "\n",
      "fold_4, epoch_701, Loss: 0.3475\n",
      "fold_4, epoch_702, Loss: 0.3489\n",
      "fold_4, epoch_703, Loss: 0.3475\n",
      "fold_4, epoch_704, Loss: 0.3499\n",
      "fold_4, epoch_705, Loss: 0.3477\n",
      "fold_4, epoch_706, Loss: 0.3469\n",
      "fold_4, epoch_707, Loss: 0.3498\n",
      "fold_4, epoch_708, Loss: 0.3486\n",
      "fold_4, epoch_709, Loss: 0.3486\n",
      "fold_4, epoch_710, Loss: 0.3489\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3584\n",
      "Accuracy:\t0.9546\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9745\n",
      "Recall:\t\t0.9334\n",
      "F1:\t\t\t0.9535\n",
      "\n",
      "fold_4, epoch_711, Loss: 0.3500\n",
      "fold_4, epoch_712, Loss: 0.3459\n",
      "fold_4, epoch_713, Loss: 0.3469\n",
      "fold_4, epoch_714, Loss: 0.3470\n",
      "fold_4, epoch_715, Loss: 0.3456\n",
      "fold_4, epoch_716, Loss: 0.3473\n",
      "fold_4, epoch_717, Loss: 0.3485\n",
      "fold_4, epoch_718, Loss: 0.3463\n",
      "fold_4, epoch_719, Loss: 0.3479\n",
      "fold_4, epoch_720, Loss: 0.3466\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9625\n",
      "AUC:\t\t0.9645\n",
      "Precision:\t0.9826\n",
      "Recall:\t\t0.9413\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_4, epoch_721, Loss: 0.3486\n",
      "fold_4, epoch_722, Loss: 0.3494\n",
      "fold_4, epoch_723, Loss: 0.3475\n",
      "fold_4, epoch_724, Loss: 0.3480\n",
      "fold_4, epoch_725, Loss: 0.3481\n",
      "fold_4, epoch_726, Loss: 0.3466\n",
      "fold_4, epoch_727, Loss: 0.3475\n",
      "fold_4, epoch_728, Loss: 0.3496\n",
      "fold_4, epoch_729, Loss: 0.3481\n",
      "fold_4, epoch_730, Loss: 0.3471\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3461\n",
      "Accuracy:\t0.9671\n",
      "AUC:\t\t0.9656\n",
      "Precision:\t0.9871\n",
      "Recall:\t\t0.9464\n",
      "F1:\t\t\t0.9663\n",
      "\n",
      "fold_4, epoch_731, Loss: 0.3491\n",
      "fold_4, epoch_732, Loss: 0.3477\n",
      "fold_4, epoch_733, Loss: 0.3472\n",
      "fold_4, epoch_734, Loss: 0.3465\n",
      "fold_4, epoch_735, Loss: 0.3451\n",
      "fold_4, epoch_736, Loss: 0.3486\n",
      "fold_4, epoch_737, Loss: 0.3477\n",
      "fold_4, epoch_738, Loss: 0.3481\n",
      "fold_4, epoch_739, Loss: 0.3456\n",
      "fold_4, epoch_740, Loss: 0.3469\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3464\n",
      "Accuracy:\t0.9667\n",
      "AUC:\t\t0.9661\n",
      "Precision:\t0.9845\n",
      "Recall:\t\t0.9486\n",
      "F1:\t\t\t0.9662\n",
      "\n",
      "fold_4, epoch_741, Loss: 0.3469\n",
      "fold_4, epoch_742, Loss: 0.3477\n",
      "fold_4, epoch_743, Loss: 0.3484\n",
      "fold_4, epoch_744, Loss: 0.3460\n",
      "fold_4, epoch_745, Loss: 0.3480\n",
      "fold_4, epoch_746, Loss: 0.3489\n",
      "fold_4, epoch_747, Loss: 0.3473\n",
      "fold_4, epoch_748, Loss: 0.3477\n",
      "fold_4, epoch_749, Loss: 0.3462\n",
      "fold_4, epoch_750, Loss: 0.3462\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3517\n",
      "Accuracy:\t0.9615\n",
      "AUC:\t\t0.9641\n",
      "Precision:\t0.9826\n",
      "Recall:\t\t0.9389\n",
      "F1:\t\t\t0.9602\n",
      "\n",
      "fold_4, epoch_751, Loss: 0.3468\n",
      "fold_4, epoch_752, Loss: 0.3472\n",
      "fold_4, epoch_753, Loss: 0.3480\n",
      "fold_4, epoch_754, Loss: 0.3481\n",
      "fold_4, epoch_755, Loss: 0.3503\n",
      "fold_4, epoch_756, Loss: 0.3480\n",
      "fold_4, epoch_757, Loss: 0.3485\n",
      "fold_4, epoch_758, Loss: 0.3453\n",
      "fold_4, epoch_759, Loss: 0.3474\n",
      "fold_4, epoch_760, Loss: 0.3467\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3459\n",
      "Accuracy:\t0.9672\n",
      "AUC:\t\t0.9659\n",
      "Precision:\t0.9869\n",
      "Recall:\t\t0.9472\n",
      "F1:\t\t\t0.9666\n",
      "\n",
      "fold_4, epoch_761, Loss: 0.3469\n",
      "fold_4, epoch_762, Loss: 0.3468\n",
      "fold_4, epoch_763, Loss: 0.3474\n",
      "fold_4, epoch_764, Loss: 0.3501\n",
      "fold_4, epoch_765, Loss: 0.3458\n",
      "fold_4, epoch_766, Loss: 0.3507\n",
      "fold_4, epoch_767, Loss: 0.3490\n",
      "fold_4, epoch_768, Loss: 0.3458\n",
      "fold_4, epoch_769, Loss: 0.3455\n",
      "fold_4, epoch_770, Loss: 0.3474\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3464\n",
      "Accuracy:\t0.9668\n",
      "AUC:\t\t0.9656\n",
      "Precision:\t0.9878\n",
      "Recall:\t\t0.9449\n",
      "F1:\t\t\t0.9659\n",
      "\n",
      "fold_4, epoch_771, Loss: 0.3452\n",
      "fold_4, epoch_772, Loss: 0.3483\n",
      "fold_4, epoch_773, Loss: 0.3467\n",
      "fold_4, epoch_774, Loss: 0.3455\n",
      "fold_4, epoch_775, Loss: 0.3503\n",
      "fold_4, epoch_776, Loss: 0.3509\n",
      "fold_4, epoch_777, Loss: 0.3474\n",
      "fold_4, epoch_778, Loss: 0.3461\n",
      "fold_4, epoch_779, Loss: 0.3464\n",
      "fold_4, epoch_780, Loss: 0.3453\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3464\n",
      "Accuracy:\t0.9668\n",
      "AUC:\t\t0.9662\n",
      "Precision:\t0.9869\n",
      "Recall:\t\t0.9469\n",
      "F1:\t\t\t0.9665\n",
      "\n",
      "fold_4, epoch_781, Loss: 0.3462\n",
      "fold_4, epoch_782, Loss: 0.3484\n",
      "fold_4, epoch_783, Loss: 0.3461\n",
      "fold_4, epoch_784, Loss: 0.3444\n",
      "fold_4, epoch_785, Loss: 0.3469\n",
      "fold_4, epoch_786, Loss: 0.3459\n",
      "fold_4, epoch_787, Loss: 0.3452\n",
      "fold_4, epoch_788, Loss: 0.3463\n",
      "fold_4, epoch_789, Loss: 0.3485\n",
      "fold_4, epoch_790, Loss: 0.3476\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3433\n",
      "Accuracy:\t0.9700\n",
      "AUC:\t\t0.9674\n",
      "Precision:\t0.9885\n",
      "Recall:\t\t0.9498\n",
      "F1:\t\t\t0.9688\n",
      "\n",
      "fold_4, epoch_791, Loss: 0.3466\n",
      "fold_4, epoch_792, Loss: 0.3484\n",
      "fold_4, epoch_793, Loss: 0.3452\n",
      "fold_4, epoch_794, Loss: 0.3456\n",
      "fold_4, epoch_795, Loss: 0.3486\n",
      "fold_4, epoch_796, Loss: 0.3480\n",
      "fold_4, epoch_797, Loss: 0.3475\n",
      "fold_4, epoch_798, Loss: 0.3470\n",
      "fold_4, epoch_799, Loss: 0.3497\n",
      "fold_4, epoch_800, Loss: 0.3478\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3469\n",
      "Accuracy:\t0.9664\n",
      "AUC:\t\t0.9658\n",
      "Precision:\t0.9858\n",
      "Recall:\t\t0.9465\n",
      "F1:\t\t\t0.9657\n",
      "\n",
      "fold_4, epoch_801, Loss: 0.3481\n",
      "fold_4, epoch_802, Loss: 0.3487\n",
      "fold_4, epoch_803, Loss: 0.3469\n",
      "fold_4, epoch_804, Loss: 0.3451\n",
      "fold_4, epoch_805, Loss: 0.3465\n",
      "fold_4, epoch_806, Loss: 0.3475\n",
      "fold_4, epoch_807, Loss: 0.3490\n",
      "fold_4, epoch_808, Loss: 0.3463\n",
      "fold_4, epoch_809, Loss: 0.3480\n",
      "fold_4, epoch_810, Loss: 0.3473\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3461\n",
      "Accuracy:\t0.9671\n",
      "AUC:\t\t0.9664\n",
      "Precision:\t0.9874\n",
      "Recall:\t\t0.9461\n",
      "F1:\t\t\t0.9663\n",
      "\n",
      "fold_4, epoch_811, Loss: 0.3455\n",
      "fold_4, epoch_812, Loss: 0.3478\n",
      "fold_4, epoch_813, Loss: 0.3471\n",
      "fold_4, epoch_814, Loss: 0.3468\n",
      "fold_4, epoch_815, Loss: 0.3452\n",
      "fold_4, epoch_816, Loss: 0.3470\n",
      "fold_4, epoch_817, Loss: 0.3487\n",
      "fold_4, epoch_818, Loss: 0.3474\n",
      "fold_4, epoch_819, Loss: 0.3452\n",
      "fold_4, epoch_820, Loss: 0.3474\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3451\n",
      "Accuracy:\t0.9679\n",
      "AUC:\t\t0.9670\n",
      "Precision:\t0.9874\n",
      "Recall:\t\t0.9479\n",
      "F1:\t\t\t0.9672\n",
      "\n",
      "fold_4, epoch_821, Loss: 0.3443\n",
      "fold_4, epoch_822, Loss: 0.3474\n",
      "fold_4, epoch_823, Loss: 0.3459\n",
      "fold_4, epoch_824, Loss: 0.3450\n",
      "fold_4, epoch_825, Loss: 0.3467\n",
      "fold_4, epoch_826, Loss: 0.3478\n",
      "fold_4, epoch_827, Loss: 0.3461\n",
      "fold_4, epoch_828, Loss: 0.3475\n",
      "fold_4, epoch_829, Loss: 0.3457\n",
      "fold_4, epoch_830, Loss: 0.3467\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9625\n",
      "AUC:\t\t0.9636\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9381\n",
      "F1:\t\t\t0.9618\n",
      "\n",
      "fold_4, epoch_831, Loss: 0.3457\n",
      "fold_4, epoch_832, Loss: 0.3465\n",
      "fold_4, epoch_833, Loss: 0.3460\n",
      "fold_4, epoch_834, Loss: 0.3461\n",
      "fold_4, epoch_835, Loss: 0.3456\n",
      "fold_4, epoch_836, Loss: 0.3476\n",
      "fold_4, epoch_837, Loss: 0.3456\n",
      "fold_4, epoch_838, Loss: 0.3471\n",
      "fold_4, epoch_839, Loss: 0.3455\n",
      "fold_4, epoch_840, Loss: 0.3475\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3487\n",
      "Accuracy:\t0.9644\n",
      "AUC:\t\t0.9644\n",
      "Precision:\t0.9871\n",
      "Recall:\t\t0.9407\n",
      "F1:\t\t\t0.9634\n",
      "\n",
      "fold_4, epoch_841, Loss: 0.3480\n",
      "fold_4, epoch_842, Loss: 0.3446\n",
      "fold_4, epoch_843, Loss: 0.3458\n",
      "fold_4, epoch_844, Loss: 0.3479\n",
      "fold_4, epoch_845, Loss: 0.3470\n",
      "fold_4, epoch_846, Loss: 0.3462\n",
      "fold_4, epoch_847, Loss: 0.3449\n",
      "fold_4, epoch_848, Loss: 0.3466\n",
      "fold_4, epoch_849, Loss: 0.3469\n",
      "fold_4, epoch_850, Loss: 0.3488\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3480\n",
      "Accuracy:\t0.9651\n",
      "AUC:\t\t0.9646\n",
      "Precision:\t0.9873\n",
      "Recall:\t\t0.9423\n",
      "F1:\t\t\t0.9643\n",
      "\n",
      "fold_4, epoch_851, Loss: 0.3446\n",
      "fold_4, epoch_852, Loss: 0.3447\n",
      "fold_4, epoch_853, Loss: 0.3462\n",
      "fold_4, epoch_854, Loss: 0.3457\n",
      "fold_4, epoch_855, Loss: 0.3432\n",
      "fold_4, epoch_856, Loss: 0.3467\n",
      "fold_4, epoch_857, Loss: 0.3452\n",
      "fold_4, epoch_858, Loss: 0.3451\n",
      "fold_4, epoch_859, Loss: 0.3451\n",
      "fold_4, epoch_860, Loss: 0.3460\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3566\n",
      "Accuracy:\t0.9564\n",
      "AUC:\t\t0.9625\n",
      "Precision:\t0.9792\n",
      "Recall:\t\t0.9337\n",
      "F1:\t\t\t0.9559\n",
      "\n",
      "fold_4, epoch_861, Loss: 0.3504\n",
      "fold_4, epoch_862, Loss: 0.3462\n",
      "fold_4, epoch_863, Loss: 0.3436\n",
      "fold_4, epoch_864, Loss: 0.3455\n",
      "fold_4, epoch_865, Loss: 0.3459\n",
      "fold_4, epoch_866, Loss: 0.3463\n",
      "fold_4, epoch_867, Loss: 0.3479\n",
      "fold_4, epoch_868, Loss: 0.3456\n",
      "fold_4, epoch_869, Loss: 0.3450\n",
      "fold_4, epoch_870, Loss: 0.3451\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3460\n",
      "Accuracy:\t0.9672\n",
      "AUC:\t\t0.9669\n",
      "Precision:\t0.9884\n",
      "Recall:\t\t0.9462\n",
      "F1:\t\t\t0.9668\n",
      "\n",
      "fold_4, epoch_871, Loss: 0.3471\n",
      "fold_4, epoch_872, Loss: 0.3460\n",
      "fold_4, epoch_873, Loss: 0.3444\n",
      "fold_4, epoch_874, Loss: 0.3484\n",
      "fold_4, epoch_875, Loss: 0.3428\n",
      "fold_4, epoch_876, Loss: 0.3465\n",
      "fold_4, epoch_877, Loss: 0.3472\n",
      "fold_4, epoch_878, Loss: 0.3446\n",
      "fold_4, epoch_879, Loss: 0.3475\n",
      "fold_4, epoch_880, Loss: 0.3459\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3482\n",
      "Accuracy:\t0.9648\n",
      "AUC:\t\t0.9654\n",
      "Precision:\t0.9865\n",
      "Recall:\t\t0.9424\n",
      "F1:\t\t\t0.9639\n",
      "\n",
      "fold_4, epoch_881, Loss: 0.3468\n",
      "fold_4, epoch_882, Loss: 0.3456\n",
      "fold_4, epoch_883, Loss: 0.3456\n",
      "fold_4, epoch_884, Loss: 0.3446\n",
      "fold_4, epoch_885, Loss: 0.3451\n",
      "fold_4, epoch_886, Loss: 0.3464\n",
      "fold_4, epoch_887, Loss: 0.3478\n",
      "fold_4, epoch_888, Loss: 0.3465\n",
      "fold_4, epoch_889, Loss: 0.3448\n",
      "fold_4, epoch_890, Loss: 0.3433\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3451\n",
      "Accuracy:\t0.9680\n",
      "AUC:\t\t0.9670\n",
      "Precision:\t0.9877\n",
      "Recall:\t\t0.9477\n",
      "F1:\t\t\t0.9673\n",
      "\n",
      "fold_4, epoch_891, Loss: 0.3435\n",
      "fold_4, epoch_892, Loss: 0.3457\n",
      "fold_4, epoch_893, Loss: 0.3463\n",
      "fold_4, epoch_894, Loss: 0.3467\n",
      "fold_4, epoch_895, Loss: 0.3452\n",
      "fold_4, epoch_896, Loss: 0.3458\n",
      "fold_4, epoch_897, Loss: 0.3451\n",
      "fold_4, epoch_898, Loss: 0.3467\n",
      "fold_4, epoch_899, Loss: 0.3450\n",
      "fold_4, epoch_900, Loss: 0.3451\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3445\n",
      "Accuracy:\t0.9687\n",
      "AUC:\t\t0.9672\n",
      "Precision:\t0.9880\n",
      "Recall:\t\t0.9491\n",
      "F1:\t\t\t0.9682\n",
      "\n",
      "fold_4, epoch_901, Loss: 0.3462\n",
      "fold_4, epoch_902, Loss: 0.3441\n",
      "fold_4, epoch_903, Loss: 0.3461\n",
      "fold_4, epoch_904, Loss: 0.3443\n",
      "fold_4, epoch_905, Loss: 0.3457\n",
      "fold_4, epoch_906, Loss: 0.3451\n",
      "fold_4, epoch_907, Loss: 0.3453\n",
      "fold_4, epoch_908, Loss: 0.3434\n",
      "fold_4, epoch_909, Loss: 0.3463\n",
      "fold_4, epoch_910, Loss: 0.3453\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3451\n",
      "Accuracy:\t0.9681\n",
      "AUC:\t\t0.9677\n",
      "Precision:\t0.9862\n",
      "Recall:\t\t0.9494\n",
      "F1:\t\t\t0.9675\n",
      "\n",
      "fold_4, epoch_911, Loss: 0.3462\n",
      "fold_4, epoch_912, Loss: 0.3457\n",
      "fold_4, epoch_913, Loss: 0.3461\n",
      "fold_4, epoch_914, Loss: 0.3463\n",
      "fold_4, epoch_915, Loss: 0.3462\n",
      "fold_4, epoch_916, Loss: 0.3456\n",
      "fold_4, epoch_917, Loss: 0.3462\n",
      "fold_4, epoch_918, Loss: 0.3452\n",
      "fold_4, epoch_919, Loss: 0.3447\n",
      "fold_4, epoch_920, Loss: 0.3442\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3473\n",
      "Accuracy:\t0.9659\n",
      "AUC:\t\t0.9656\n",
      "Precision:\t0.9873\n",
      "Recall:\t\t0.9442\n",
      "F1:\t\t\t0.9652\n",
      "\n",
      "fold_4, epoch_921, Loss: 0.3469\n",
      "fold_4, epoch_922, Loss: 0.3457\n",
      "fold_4, epoch_923, Loss: 0.3454\n",
      "fold_4, epoch_924, Loss: 0.3452\n",
      "fold_4, epoch_925, Loss: 0.3456\n",
      "fold_4, epoch_926, Loss: 0.3448\n",
      "fold_4, epoch_927, Loss: 0.3463\n",
      "fold_4, epoch_928, Loss: 0.3452\n",
      "fold_4, epoch_929, Loss: 0.3443\n",
      "fold_4, epoch_930, Loss: 0.3457\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3447\n",
      "Accuracy:\t0.9684\n",
      "AUC:\t\t0.9670\n",
      "Precision:\t0.9897\n",
      "Recall:\t\t0.9471\n",
      "F1:\t\t\t0.9679\n",
      "\n",
      "fold_4, epoch_931, Loss: 0.3465\n",
      "fold_4, epoch_932, Loss: 0.3440\n",
      "fold_4, epoch_933, Loss: 0.3452\n",
      "fold_4, epoch_934, Loss: 0.3440\n",
      "fold_4, epoch_935, Loss: 0.3462\n",
      "fold_4, epoch_936, Loss: 0.3455\n",
      "fold_4, epoch_937, Loss: 0.3455\n",
      "fold_4, epoch_938, Loss: 0.3453\n",
      "fold_4, epoch_939, Loss: 0.3472\n",
      "fold_4, epoch_940, Loss: 0.3453\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3455\n",
      "Accuracy:\t0.9677\n",
      "AUC:\t\t0.9673\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9482\n",
      "F1:\t\t\t0.9671\n",
      "\n",
      "fold_4, epoch_941, Loss: 0.3446\n",
      "fold_4, epoch_942, Loss: 0.3456\n",
      "fold_4, epoch_943, Loss: 0.3434\n",
      "fold_4, epoch_944, Loss: 0.3469\n",
      "fold_4, epoch_945, Loss: 0.3460\n",
      "fold_4, epoch_946, Loss: 0.3447\n",
      "fold_4, epoch_947, Loss: 0.3467\n",
      "fold_4, epoch_948, Loss: 0.3454\n",
      "fold_4, epoch_949, Loss: 0.3428\n",
      "fold_4, epoch_950, Loss: 0.3440\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3444\n",
      "Accuracy:\t0.9688\n",
      "AUC:\t\t0.9681\n",
      "Precision:\t0.9881\n",
      "Recall:\t\t0.9487\n",
      "F1:\t\t\t0.9680\n",
      "\n",
      "fold_4, epoch_951, Loss: 0.3456\n",
      "fold_4, epoch_952, Loss: 0.3451\n",
      "fold_4, epoch_953, Loss: 0.3466\n",
      "fold_4, epoch_954, Loss: 0.3444\n",
      "fold_4, epoch_955, Loss: 0.3469\n",
      "fold_4, epoch_956, Loss: 0.3454\n",
      "fold_4, epoch_957, Loss: 0.3456\n",
      "fold_4, epoch_958, Loss: 0.3454\n",
      "fold_4, epoch_959, Loss: 0.3458\n",
      "fold_4, epoch_960, Loss: 0.3456\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3460\n",
      "Accuracy:\t0.9672\n",
      "AUC:\t\t0.9654\n",
      "Precision:\t0.9884\n",
      "Recall:\t\t0.9454\n",
      "F1:\t\t\t0.9664\n",
      "\n",
      "fold_4, epoch_961, Loss: 0.3458\n",
      "fold_4, epoch_962, Loss: 0.3450\n",
      "fold_4, epoch_963, Loss: 0.3464\n",
      "fold_4, epoch_964, Loss: 0.3444\n",
      "fold_4, epoch_965, Loss: 0.3439\n",
      "fold_4, epoch_966, Loss: 0.3443\n",
      "fold_4, epoch_967, Loss: 0.3445\n",
      "fold_4, epoch_968, Loss: 0.3452\n",
      "fold_4, epoch_969, Loss: 0.3432\n",
      "fold_4, epoch_970, Loss: 0.3443\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3436\n",
      "Accuracy:\t0.9696\n",
      "AUC:\t\t0.9679\n",
      "Precision:\t0.9898\n",
      "Recall:\t\t0.9487\n",
      "F1:\t\t\t0.9688\n",
      "\n",
      "fold_4, epoch_971, Loss: 0.3447\n",
      "fold_4, epoch_972, Loss: 0.3448\n",
      "fold_4, epoch_973, Loss: 0.3438\n",
      "fold_4, epoch_974, Loss: 0.3446\n",
      "fold_4, epoch_975, Loss: 0.3459\n",
      "fold_4, epoch_976, Loss: 0.3454\n",
      "fold_4, epoch_977, Loss: 0.3462\n",
      "fold_4, epoch_978, Loss: 0.3465\n",
      "fold_4, epoch_979, Loss: 0.3441\n",
      "fold_4, epoch_980, Loss: 0.3445\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3435\n",
      "Accuracy:\t0.9697\n",
      "AUC:\t\t0.9668\n",
      "Precision:\t0.9915\n",
      "Recall:\t\t0.9472\n",
      "F1:\t\t\t0.9688\n",
      "\n",
      "fold_4, epoch_981, Loss: 0.3437\n",
      "fold_4, epoch_982, Loss: 0.3441\n",
      "fold_4, epoch_983, Loss: 0.3434\n",
      "fold_4, epoch_984, Loss: 0.3442\n",
      "fold_4, epoch_985, Loss: 0.3445\n",
      "fold_4, epoch_986, Loss: 0.3428\n",
      "fold_4, epoch_987, Loss: 0.3436\n",
      "fold_4, epoch_988, Loss: 0.3461\n",
      "fold_4, epoch_989, Loss: 0.3469\n",
      "fold_4, epoch_990, Loss: 0.3448\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3440\n",
      "Accuracy:\t0.9690\n",
      "AUC:\t\t0.9686\n",
      "Precision:\t0.9903\n",
      "Recall:\t\t0.9477\n",
      "F1:\t\t\t0.9685\n",
      "\n",
      "fold_4, epoch_991, Loss: 0.3449\n",
      "fold_4, epoch_992, Loss: 0.3446\n",
      "fold_4, epoch_993, Loss: 0.3440\n",
      "fold_4, epoch_994, Loss: 0.3448\n",
      "fold_4, epoch_995, Loss: 0.3460\n",
      "fold_4, epoch_996, Loss: 0.3456\n",
      "fold_4, epoch_997, Loss: 0.3457\n",
      "fold_4, epoch_998, Loss: 0.3475\n",
      "fold_4, epoch_999, Loss: 0.3435\n",
      "fold_4, epoch_1000, Loss: 0.3425\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3440\n",
      "Accuracy:\t0.9693\n",
      "AUC:\t\t0.9667\n",
      "Precision:\t0.9915\n",
      "Recall:\t\t0.9469\n",
      "F1:\t\t\t0.9686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_driver.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7.4 Monitor Cross-Validation Progress in Tensorbard\n",
    "Near the start of the terminal output from the previous code cell, look for the lines:\n",
    "```\n",
    "Checkpoints will be saved in:\n",
    "/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard\n",
    "```\n",
    "Then, start a zsh shell inside the app container, and launch tensorboard server:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app /bin/zsh\n",
    "$ tensorboard --logdir=/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "The Tensorboard output can now be viewed in your browswer at http://localhost:6006.\n",
    "\n",
    "This Tensorboard screenshot was taken at the end of a 5-fold, 1000 epoch per fold cross-validation run.\n",
    "![tensorboard_image](images/tensorboard_5fold_cv_best_params_1000epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.5 Summarize Results\n",
    "We can use a CrossValidationSummarizer to view best performance during training of each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.349761</td>\n",
       "      <td>0.345473</td>\n",
       "      <td>0.965451</td>\n",
       "      <td>0.967849</td>\n",
       "      <td>0.967258</td>\n",
       "      <td>0.989938</td>\n",
       "      <td>0.945595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>920</td>\n",
       "      <td>0.345712</td>\n",
       "      <td>0.340703</td>\n",
       "      <td>0.970717</td>\n",
       "      <td>0.972498</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.988792</td>\n",
       "      <td>0.955595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960</td>\n",
       "      <td>0.349870</td>\n",
       "      <td>0.349510</td>\n",
       "      <td>0.961955</td>\n",
       "      <td>0.963678</td>\n",
       "      <td>0.962606</td>\n",
       "      <td>0.989406</td>\n",
       "      <td>0.937220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>920</td>\n",
       "      <td>0.353771</td>\n",
       "      <td>0.348848</td>\n",
       "      <td>0.963220</td>\n",
       "      <td>0.964304</td>\n",
       "      <td>0.963820</td>\n",
       "      <td>0.987560</td>\n",
       "      <td>0.941194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>790</td>\n",
       "      <td>0.347615</td>\n",
       "      <td>0.343309</td>\n",
       "      <td>0.967401</td>\n",
       "      <td>0.969995</td>\n",
       "      <td>0.968765</td>\n",
       "      <td>0.988480</td>\n",
       "      <td>0.949821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  validation_loss       auc  accuracy        f1   \n",
       "0   1000    0.349761         0.345473  0.965451  0.967849  0.967258  \\\n",
       "1    920    0.345712         0.340703  0.970717  0.972498  0.971910   \n",
       "2    960    0.349870         0.349510  0.961955  0.963678  0.962606   \n",
       "3    920    0.353771         0.348848  0.963220  0.964304  0.963820   \n",
       "4    790    0.347615         0.343309  0.967401  0.969995  0.968765   \n",
       "\n",
       "   precision    recall  \n",
       "0   0.989938  0.945595  \n",
       "1   0.988792  0.955595  \n",
       "2   0.989406  0.937220  \n",
       "3   0.987560  0.941194  \n",
       "4   0.988480  0.949821  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validation_summarizer as cvs\n",
    "cv_summarizer = cvs.CrossValidationSummarizer.from_cv_checkpoints_dir()\n",
    "optimal_results_df = cv_summarizer.get_optimal_results_df(\n",
    "        metric=cvs.EvalMetric.VALIDATION_LOSS,\n",
    "        optimize_direction=cvs.OptimizeDirection.MIN,\n",
    "    )\n",
    "\n",
    "optimal_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the mean and standard deviation of each performance metric using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.349346</td>\n",
       "      <td>0.345568</td>\n",
       "      <td>0.965749</td>\n",
       "      <td>0.967665</td>\n",
       "      <td>0.966872</td>\n",
       "      <td>0.988835</td>\n",
       "      <td>0.945885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.007193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_loss  validation_loss       auc  accuracy        f1  precision   \n",
       "mean    0.349346         0.345568  0.965749  0.967665  0.966872   0.988835  \\\n",
       "std     0.003010         0.003711  0.003475  0.003742  0.003763   0.000908   \n",
       "\n",
       "        recall  \n",
       "mean  0.945885  \n",
       "std   0.007193  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_results_df.describe().loc[[\"mean\", \"std\"], optimal_results_df.columns != \"epoch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 Comparison with Prior Work\n",
    "\n",
    "The table below compares the predictive performance of the LSTM model in this work with other LSTM-based models using the same dataset. The current model shows the best predictive performance among all models in the table based on AUC and F1 scores. \n",
    "\n",
    "\n",
    "|  | Authors       | Model      | Input Features | AUC             | F1              | Precision       | Recall          |\n",
    "|-|------------|------------|----------------|-----------------|-----------------|-----------------|-----------------|\n",
    "|1 |Sun et al.  | LSTM-128 + FC-32 + FC-2 | [13 labs, 6 vitals] x 48 hr  | 0.9094 (0.0053) | 0.5429 (0.0194) | 0.4100 (0.0272) | 0.8071 (0.0269) |\n",
    "|2 |Tang et al. | LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr + demographic data  | 0.949 (0.003) | 0.623 (0.012) | \n",
    "| 3|Tang et al. | CNN + LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr + demographic data | 0.940 (0.0071) | 0.633 (0.031) | \n",
    "|4 |Tang et al. | CNN + LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr | 0.933 (0.006) | 0.587 (0.025) |\n",
    "|5 |Tang et al. | LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr | 0.907 (0.006) | 0.526 (0.013) |\n",
    "|6 |This work   | LSTM-128 + FC-16 + FC-2 | [13 labs, 6 vitals] x 48 hr  | 0.9657 (0.0035) | 0.9669 (0.0038) | 0.9888 (0.0009) | 0.9459 (0.0072) |\n",
    "\n",
    "> **Notes** LSTM-X indicates an LSTM with X hidden layers. FC-X indicates a fully connected layer with an output size of X. All LSTMs are bidirectional. The demographic data used in studies #2 and #3 was obtained from MIMIC-III.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Adversarial Attack Algorithm on the Trained Model\n",
    "\n",
    "$ X $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"654pt\"\n",
       " viewBox=\"0.00 0.00 222.00 654.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 650)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-650 218,-650 218,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"166,-646 48,-646 48,-614 166,-614 166,-646\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48,-614 48,-646 118,-646 118,-614 48,-614\"/>\n",
       "<text text-anchor=\"start\" x=\"53\" y=\"-633\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"64.5\" y=\"-622\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"118,-614 118,-646 166,-646 166,-614 118,-614\"/>\n",
       "<text text-anchor=\"start\" x=\"123\" y=\"-627.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 19)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"214,-578 0,-578 0,-536 214,-536 214,-578\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-536 0,-578 47,-578 47,-536 0,-536\"/>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-560\" font-family=\"Linux libertine\" font-size=\"10.00\">LSTM</text>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-549\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"47,-557 47,-578 95,-578 95,-557 47,-557\"/>\n",
       "<text text-anchor=\"start\" x=\"57\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95,-557 95,-578 214,-578 214,-557 95,-557\"/>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-565\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 19) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"47,-536 47,-557 95,-557 95,-536 47,-536\"/>\n",
       "<text text-anchor=\"start\" x=\"52\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95,-536 95,-557 214,-557 214,-536 95,-536\"/>\n",
       "<text text-anchor=\"start\" x=\"100\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 256), 2 x (2, 128) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-613.94C107,-606.45 107,-597.12 107,-588.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-588.16 107,-578.16 103.5,-588.16 110.5,-588.16\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"183,-500 31,-500 31,-458 183,-458 183,-500\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"31,-458 31,-500 78,-500 78,-458 31,-458\"/>\n",
       "<text text-anchor=\"start\" x=\"43\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">Tanh</text>\n",
       "<text text-anchor=\"start\" x=\"36\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"78,-479 78,-500 126,-500 126,-479 78,-479\"/>\n",
       "<text text-anchor=\"start\" x=\"88\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"126,-479 126,-500 183,-500 183,-479 126,-479\"/>\n",
       "<text text-anchor=\"start\" x=\"131\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"78,-458 78,-479 126,-479 126,-458 78,-458\"/>\n",
       "<text text-anchor=\"start\" x=\"83\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"126,-458 126,-479 183,-479 183,-458 126,-458\"/>\n",
       "<text text-anchor=\"start\" x=\"131\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 256) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-535.63C107,-527.82 107,-518.73 107,-510.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-510.16 107,-500.16 103.5,-510.16 110.5,-510.16\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"184.5,-422 29.5,-422 29.5,-380 184.5,-380 184.5,-422\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"30,-380 30,-422 80,-422 80,-380 30,-380\"/>\n",
       "<text text-anchor=\"start\" x=\"35\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">Dropout</text>\n",
       "<text text-anchor=\"start\" x=\"36.5\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80,-401 80,-422 128,-422 128,-401 80,-401\"/>\n",
       "<text text-anchor=\"start\" x=\"90\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"128,-401 128,-422 185,-422 185,-401 128,-401\"/>\n",
       "<text text-anchor=\"start\" x=\"133\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"80,-380 80,-401 128,-401 128,-380 80,-380\"/>\n",
       "<text text-anchor=\"start\" x=\"85\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"128,-380 128,-401 185,-401 185,-380 128,-380\"/>\n",
       "<text text-anchor=\"start\" x=\"133\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 256) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-457.63C107,-449.82 107,-440.73 107,-432.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-432.16 107,-422.16 103.5,-432.16 110.5,-432.16\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"183,-344 31,-344 31,-302 183,-302 183,-344\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"31,-302 31,-344 78,-344 78,-302 31,-302\"/>\n",
       "<text text-anchor=\"start\" x=\"39\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"36\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"78,-323 78,-344 126,-344 126,-323 78,-323\"/>\n",
       "<text text-anchor=\"start\" x=\"88\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"126,-323 126,-344 183,-344 183,-323 126,-323\"/>\n",
       "<text text-anchor=\"start\" x=\"131\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 256) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"78,-302 78,-323 126,-323 126,-302 78,-302\"/>\n",
       "<text text-anchor=\"start\" x=\"83\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"126,-302 126,-323 183,-323 183,-302 126,-302\"/>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 16) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-379.63C107,-371.82 107,-362.73 107,-354.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-354.16 107,-344.16 103.5,-354.16 110.5,-354.16\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"180,-266 34,-266 34,-224 180,-224 180,-266\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34,-224 34,-266 81,-266 81,-224 34,-224\"/>\n",
       "<text text-anchor=\"start\" x=\"46\" y=\"-248\" font-family=\"Linux libertine\" font-size=\"10.00\">Tanh</text>\n",
       "<text text-anchor=\"start\" x=\"39\" y=\"-237\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81,-245 81,-266 129,-266 129,-245 81,-245\"/>\n",
       "<text text-anchor=\"start\" x=\"91\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"129,-245 129,-266 180,-266 180,-245 129,-245\"/>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 16) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81,-224 81,-245 129,-245 129,-224 81,-224\"/>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"129,-224 129,-245 180,-245 180,-224 129,-224\"/>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 16) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-301.63C107,-293.82 107,-284.73 107,-276.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-276.16 107,-266.16 103.5,-276.16 110.5,-276.16\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"180,-188 34,-188 34,-146 180,-146 180,-188\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"34,-146 34,-188 81,-188 81,-146 34,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"42\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"39\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81,-167 81,-188 129,-188 129,-167 81,-167\"/>\n",
       "<text text-anchor=\"start\" x=\"91\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"129,-167 129,-188 180,-188 180,-167 129,-167\"/>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 16) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81,-146 81,-167 129,-167 129,-146 81,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"129,-146 129,-167 180,-167 180,-146 129,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"137\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 2) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-223.63C107,-215.82 107,-206.73 107,-198.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-198.16 107,-188.16 103.5,-198.16 110.5,-198.16\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"179,-110 35,-110 35,-68 179,-68 179,-110\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"35,-68 35,-110 86,-110 86,-68 35,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"40\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">Softmax</text>\n",
       "<text text-anchor=\"start\" x=\"42\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"86,-89 86,-110 134,-110 134,-89 86,-89\"/>\n",
       "<text text-anchor=\"start\" x=\"96\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"134,-89 134,-110 179,-110 179,-89 134,-89\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 2) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"86,-68 86,-89 134,-89 134,-68 86,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"91\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"134,-68 134,-89 179,-89 179,-68 134,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 2) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-145.63C107,-137.82 107,-128.73 107,-120.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-120.16 107,-110.16 103.5,-120.16 110.5,-120.16\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"166.5,-32 47.5,-32 47.5,0 166.5,0 166.5,-32\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48,0 48,-32 125,-32 125,0 48,0\"/>\n",
       "<text text-anchor=\"start\" x=\"53\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,0 125,-32 167,-32 167,0 125,0\"/>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(32, 2)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107,-67.84C107,-59.89 107,-50.66 107,-42.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.5,-42.24 107,-32.24 103.5,-42.24 110.5,-42.24\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f15661cfb20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib  import Path\n",
    "from torchview import draw_graph\n",
    "import torch.nn as nn\n",
    "import lstm_adversarial_attack.resource_io as rio\n",
    "import lstm_adversarial_attack.config_paths as lcp\n",
    "import lstm_adversarial_attack.tune_train.tuner_helpers as tuh\n",
    "\n",
    "\n",
    "ongoing_study_path = lcp.ONGOING_TUNING_STUDY_PICKLE\n",
    "\n",
    "ongoing_study = rio.ResourceImporter().import_pickle_to_object(\n",
    "    path=ongoing_study_path\n",
    ")\n",
    "\n",
    "hyperparameters = tuh.X19LSTMHyperParameterSettings(**ongoing_study.best_params)\n",
    "cur_model = tuh.X19LSTMBuilder(settings=hyperparameters).build_for_tensorboard()\n",
    "# cur_model = nn.LSTM(\n",
    "#     input_size=19,\n",
    "#     hidden_size=128,\n",
    "#     bidirectional=True,\n",
    "#     batch_first=True\n",
    "# )\n",
    "\n",
    "cur_model_graph = draw_graph(model=cur_model, input_size=(32, 19), device=\"meta\")\n",
    "\n",
    "cur_model_graph.visual_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
