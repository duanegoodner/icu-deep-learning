{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks\n",
    "## Predictive models of patient outcomes based on ICU data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to reproduce results originally published in:\n",
    "Sun, M., Tang, F., Yi, J., Wang, F. and Zhou, J., 2018, July. Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining (pp. 793-801). (https://arxiv.org/abs/1802.04822)\n",
    "\n",
    "The original paper trained a Long Short-Term Memory (LSTM) model using time series of Intensive Care Unit (ICU) patient vital-sign and lab measurements as the inputs, and in-hospital mortality as the prediction target. An adversarial attack algorithm was then used to identify small perturbations which, when applied to a real, correctly-classified input sample, result in misclassification of the perturbed input. Susceptibility calculations were then performed to quantify the attack vulnerability as functions of time and the measurement type within the input feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import sys\n",
    "import src_paths\n",
    "import torch\n",
    "sys.path.append(str(src_paths.lstm_adversarial_attack_pkg))\n",
    "import lstm_adversarial_attack.config_paths as lcp\n",
    "import lstm_adversarial_attack.config_settings as lcs\n",
    "import lstm_adversarial_attack.query_db.mimiciii_database as mdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/devspace/project/src/mimiciii_queries/icustay_detail.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_bg.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_lab.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_vital.sql')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(lcs.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_access = mdb.MimiciiiDatabaseAccess(\n",
    "    dotenv_path=lcp.DB_DOTENV_PATH, output_dir=lcp.DB_OUTPUT_DIR\n",
    ")\n",
    "db_access.connect()\n",
    "db_query_results = db_access.run_sql_queries(\n",
    "    sql_query_paths=lcs.DB_QUERIES\n",
    ")\n",
    "db_access.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.preprocess.preprocessor as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = pre.Preprocessor()\n",
    "pprint.pprint([item.__class__ for item in preprocessor.modules])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_resources = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "dataset = xmd.X19MGeneralDataset.from_feature_finalizer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset = 41951\n",
      "Type returned by dataset.__getitem__ = <class 'tuple'>\n",
      "Length of each tuple returned by dataset.__getitem__ = 2\n",
      "\n",
      "Object type, dimensionality, and datatype of each element in a tuple returned by dataset.__getitem__:\n",
      "((<class 'torch.Tensor'>, 2, torch.float32), (<class 'torch.Tensor'>, 0, torch.int64))\n",
      "The 'input size' (# columns) of each feature matrix is 19\n",
      "The various sequence lengths (# rows) among the input feature matrices are\n",
      "[ 6 13 14 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36\n",
      " 37 38 39 40 41 42 43 44 45 46 47 48]\n",
      "[[    6     1]\n",
      " [   13     1]\n",
      " [   14     1]\n",
      " [   16     2]\n",
      " [   17     4]\n",
      " [   18     3]\n",
      " [   19     8]\n",
      " [   20    12]\n",
      " [   21    25]\n",
      " [   22    49]\n",
      " [   23    84]\n",
      " [   24   144]\n",
      " [   25   126]\n",
      " [   26   110]\n",
      " [   27    93]\n",
      " [   28    95]\n",
      " [   29    84]\n",
      " [   30    90]\n",
      " [   31    75]\n",
      " [   32    99]\n",
      " [   33    98]\n",
      " [   34   113]\n",
      " [   35   148]\n",
      " [   36   152]\n",
      " [   37   189]\n",
      " [   38   199]\n",
      " [   39   220]\n",
      " [   40   178]\n",
      " [   41   231]\n",
      " [   42   203]\n",
      " [   43   211]\n",
      " [   44   191]\n",
      " [   45   185]\n",
      " [   46   221]\n",
      " [   47   474]\n",
      " [   48 37832]]\n",
      "[[    0 37338]\n",
      " [    1  4613]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in dataset = {len(dataset)}\")\n",
    "print(f\"Type returned by dataset.__getitem__ = {type(dataset[0])}\")\n",
    "print(\n",
    "    f\"Length of each tuple returned by dataset.__getitem__ = {len(dataset[0])}\"\n",
    ")\n",
    "print(\n",
    "    \"\\nObject type, dimensionality, and datatype of each element in a tuple\"\n",
    "    \" returned by dataset.__getitem__:\"\n",
    ")\n",
    "print(tuple([(type(item), item.dim(), item.dtype) for item in dataset[0]]))\n",
    "print(f\"The 'input size' (# columns) of each feature matrix is \"\n",
    "     f\"{np.unique([item.shape[1] for item in dataset[:][0]]).item()}\")\n",
    "print(f\"The various sequence lengths (# rows) among the input feature matrices are\\n\"\n",
    "     f\"{np.unique([item.shape[0] for item in dataset[:][0]])}\")\n",
    "\n",
    "\n",
    "\n",
    "unique_sequence_lengths, sequence_length_counts = np.unique(\n",
    "    [item.shape[0] for item in dataset[:][0]], return_counts=True\n",
    ")\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            unique_sequence_lengths.reshape(-1, 1),\n",
    "            sequence_length_counts.reshape(-1, 1),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "unique_labels, label_counts = np.unique([dataset[:][1]], return_counts=True)\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (unique_labels.reshape(-1, 1), label_counts.reshape(-1, 1)), axis=1\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import lstm_adversarial_attack.tune_train.tuner_driver as td\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cur_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    cur_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"cur_device is {cur_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_driver = td.TunerDriver(device=cur_device)\n",
    "pprint.pprint(tuner_driver.tuner.tuning_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(tuner_driver.tuner.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completed_study = tuner_driver(num_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
