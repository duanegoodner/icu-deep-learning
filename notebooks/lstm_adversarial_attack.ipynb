{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "\n",
    "### 1.1 Summary of Prior Work\n",
    "\n",
    "This project builds on results originally published in:\n",
    "\n",
    "[Sun, M., Tang, F., Yi, J., Wang, F. and Zhou, J., 2018, July. Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining* (pp. 793-801)](https://dl.acm.org/doi/10.1145/3219819.3219909) \n",
    "\n",
    "The original paper trained a Long Short-Term Memory (LSTM) time series model using patient vital-sign and lab data from the Medical Information Mart for Intensive Care (MIMIC-III) database to predict in-hospital mortality. MIMIC-III consists of de-identified data from in-patients critical care units of Beth Israel Hospital from 2005 to 2011. The full dataset consists of data from 46,520 patients and 58,976 hospital admissions. After filtering to remove patients with age < 18 years, and hospital stays < 24 hours, \n",
    "\n",
    "The input features consisted of data from 13 lab measurements (Blood Urea Nitrogen, HCO<sub>3</sub>, Na, PaCO<sub>2</sub>, Glucose, Creatinine, Albumin, Mg, K, Ca, Platelets, and Lactate), and 6 vital signs (Heart Rate, Respiration Rate, Systolic Blood Pressure, Diastolic Blood Pressure, Oxygen Saturation, and Temperature). The prediction target was a binary variable representing in-hospital mortality.  Input data were collected over time spans ranging from 6 to 48 hours. Each patient was represented by a 48 (hour) x 19 (measurements) input feature matrix of floating point values, and a binary output label. Missing data were imputed by interpolation vs. time when possible. If no data was available for a particular patient and measurement parameter, the global mean of that parameter (across all patients and times) was used.\n",
    "\n",
    "Sun et al. implemented an LSTM model using Tensorflow, and after cross-validation hypertuning, selected a final model architecture consisting of:\n",
    "* A single-layer, bi-directional LSTM with; an input size of 19; 128 hidden states per direction; and Tanh activation of the outputs \n",
    "* A dropout layer with dropout probability = 50%\n",
    "* A fully-connected layer with an input size of 256 (for the 2 x 128 LSTM outputs),  32 output nodes, and ReLU activation.\n",
    "* A final 2-node layer with soft-max activation.\n",
    "\n",
    "This model was trained using a Binary Cross Entropy loss; and an Adam optimizer with learning rate = 1e-4, momentum decay rate = 0.999, and moving average decay rate = 0.5. An adversarial attack algorithm was then used to identify small perturbations which, when applied to a real, correctly-classified input features, caused the trained model to misclassify the perturbed input. The attack algorithm used L1 regularization to favor adversarial examples with sparse perturbations which simulate the structure of data entry errors in real medical data.\n",
    "\n",
    "### 1.2 Focus of Current Poject\n",
    "\n",
    "The current project follows the general approach of Sun et al, and adds the modifications / extensions:\n",
    "\n",
    "* A streamlined `preprocess` sub-package is used to convert database SQL query outputs to the tensor form used for model input. This package reduces RAM consumption by saving large intermediate data structures to disk (primarily Pandas dataframes saved as .pickle files) instead of returning them to global scope. It also performs the query output to tensor conversion 90% faster than the original code, primarily through the use of vectorized operations. \n",
    "* A GPU-compatible adversarial attack algorithm that allows attacks to run on batches of samples\n",
    "* Improved LSTM predictive performance achieved through hyperparameter tuning the Optuna Tree-structued Parzen Estimator (TPE) algorithm\n",
    "* Hyperparameter tuning of the attack algorithm (also using TPE) to find adversarial perturbations with higher sparsity and lower magnitude\n",
    "\n",
    "### 1.3 Structure of Current Project\n",
    "\n",
    "The project is stru\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, review the project README at https://github.com/duanegoodner/lstm_adversarial_attack, and complete all steps in the \"How to run this project\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standard Library Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 External Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Internal Project Modules and Sub-packages\n",
    "To help gain a sense of project structure, we will import internal packages and modules as-needed (i.e. immediately before the code cells where they are first needed). For now, we will import the project `src` path defined in `lstm_adversarial_attack/notebooks/src_path` and add it to sys.path so we can easily import project code into this notebook, and we import project config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src_paths\n",
    "sys.path.append(str(src_paths.lstm_adversarial_attack_pkg))\n",
    "import lstm_adversarial_attack.config_paths as cfg_paths\n",
    "import lstm_adversarial_attack.config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Queries\n",
    "We need to run four queries on the PostgreSQL database. The paths to files containing the queries are stored in a list as `DB_QUERIES` in the project `config_paths` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/devspace/project/src/mimiciii_queries/icustay_detail.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_bg.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_lab.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_vital.sql')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_paths.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database, and execute the queries, we instantiate a `MimiciiiDatabaseAccess` object from module `mimiciii_database` of project sub-package `query_db` and use its .connect(), .run_sql_queries() and .close_connection() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 of 4\n",
      "Executing: /home/devspace/project/src/mimiciii_queries/icustay_detail.sql\n",
      "Done. Query time = 0.58 seconds\n",
      "Writing result to csv: /home/devspace/project/data/mimiciii_query_results/icustay_detail.csv\n",
      "Done. csv write time = 0.49 seconds\n",
      "\n",
      "Query 2 of 4\n",
      "Executing: /home/devspace/project/src/mimiciii_queries/pivoted_bg.sql\n",
      "Done. Query time = 17.22 seconds\n",
      "Writing result to csv: /home/devspace/project/data/mimiciii_query_results/pivoted_bg.csv\n",
      "Done. csv write time = 3.58 seconds\n",
      "\n",
      "Query 3 of 4\n",
      "Executing: /home/devspace/project/src/mimiciii_queries/pivoted_lab.sql\n",
      "Done. Query time = 25.36 seconds\n",
      "Writing result to csv: /home/devspace/project/data/mimiciii_query_results/pivoted_lab.csv\n",
      "Done. csv write time = 5.74 seconds\n",
      "\n",
      "Query 4 of 4\n",
      "Executing: /home/devspace/project/src/mimiciii_queries/pivoted_vital.sql\n",
      "Done. Query time = 64.41 seconds\n",
      "Writing result to csv: /home/devspace/project/data/mimiciii_query_results/pivoted_vital.csv\n",
      "Done. csv write time = 25.88 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lstm_adversarial_attack.query_db.mimiciii_database as mdb\n",
    "\n",
    "db_access = mdb.MimiciiiDatabaseAccess(\n",
    "    dotenv_path=cfg_paths.DB_DOTENV_PATH, output_dir=cfg_paths.DB_OUTPUT_DIR\n",
    ")\n",
    "db_access.connect()\n",
    "db_query_results = db_access.run_sql_queries(\n",
    "    sql_query_paths=cfg_paths.DB_QUERIES\n",
    ")\n",
    "db_access.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of each `.sql` query is saved to a `.csv` file. The path to each of these files is shown in the terminal output above. The output path of the queries is defined by variable `DB_OUTPUT_DIR` in the project `config_settings` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instantiate a Preprocessor object\n",
    "We import the `preprocessor` module from internal sub-package `preprocess`, instantiate a `Preprocessor` object, and examine its .preprocess_modules data member. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.preprocess.preprocessor as pre\n",
    "preprocessor = pre.Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a general idea of how the `lstm_adversarial_attack.preprocess` sub-package works by looking at the `Preprocessor` object's `.preprocessor_modules` data member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'lstm_adversarial_attack.preprocess.prefilter.Prefilter'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.icustay_measurement_combiner.ICUStayMeasurementCombiner'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.sample_list_builder.FullAdmissionListBuilder'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.feature_builder.FeatureBuilder'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.feature_finalizer.FeatureFinalizer'>]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint([item.__class__ for item in preprocessor.preprocess_modules])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prefilter reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* ICUStayMeasurementCombiner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running preprocess module 1 of 5: Prefilter\n",
      "Incoming resources:\n",
      "/home/devspace/project/data/mimiciii_query_results/icustay_detail.csv\n",
      "/home/devspace/project/data/mimiciii_query_results/pivoted_bg.csv\n",
      "/home/devspace/project/data/mimiciii_query_results/pivoted_vital.csv\n",
      "/home/devspace/project/data/mimiciii_query_results/pivoted_lab.csv\n",
      "Done with Prefilter. Results saved to:\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/1_prefilter/icustay.pickle, data_type: DataFrame\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/1_prefilter/bg.pickle, data_type: DataFrame\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/1_prefilter/vital.pickle, data_type: DataFrame\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/1_prefilter/lab.pickle, data_type: DataFrame\n",
      "\n",
      "Running preprocess module 2 of 5: ICU Stay Data + Measurement Data Combiner\n",
      "Incoming resources:\n",
      "/home/devspace/project/data/preprocess_checkpoints/1_prefilter/icustay.pickle\n",
      "/home/devspace/project/data/preprocess_checkpoints/1_prefilter/bg.pickle\n",
      "/home/devspace/project/data/preprocess_checkpoints/1_prefilter/lab.pickle\n",
      "/home/devspace/project/data/preprocess_checkpoints/1_prefilter/vital.pickle\n",
      "Done with ICU Stay Data + Measurement Data Combiner. Results saved to:\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/2_merged_stay_measurements/icustay_bg_lab_vital.pickle, data_type: DataFrame\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/2_merged_stay_measurements/bg_lab_vital_summary_stats.pickle, data_type: DataFrame\n",
      "\n",
      "Running preprocess module 3 of 5: FullAdmission Object List Builder\n",
      "Incoming resources:\n",
      "/home/devspace/project/data/preprocess_checkpoints/2_merged_stay_measurements/icustay_bg_lab_vital.pickle\n",
      "Done with FullAdmission Object List Builder. Results saved to:\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/3_full_admission_list/full_admission_list.pickle, data_type: list\n",
      "\n",
      "Running preprocess module 4 of 5: Feature Builder\n",
      "Incoming resources:\n",
      "/home/devspace/project/data/preprocess_checkpoints/3_full_admission_list/full_admission_list.pickle\n",
      "/home/devspace/project/data/preprocess_checkpoints/2_merged_stay_measurements/bg_lab_vital_summary_stats.pickle\n",
      "Done building features for sample 5000/41960\n",
      "Done building features for sample 10000/41960\n",
      "Done building features for sample 15000/41960\n",
      "Done building features for sample 20000/41960\n",
      "Done building features for sample 25000/41960\n",
      "Done building features for sample 30000/41960\n",
      "Done building features for sample 35000/41960\n",
      "Done building features for sample 40000/41960\n",
      "Done with Feature Builder. Results saved to:\n",
      "path: /home/devspace/project/data/preprocess_checkpoints/4_feature_builder/hadm_list_with_processed_dfs.pickle, data_type: list\n",
      "\n",
      "Running preprocess module 5 of 5: Feature Finalizer\n",
      "Incoming resources:\n",
      "/home/devspace/project/data/preprocess_checkpoints/4_feature_builder/hadm_list_with_processed_dfs.pickle\n",
      "Done with Feature Finalizer. Results saved to:\n",
      "path: /home/devspace/project/data/output_feature_finalizer/measurement_col_names.pickle, data_type: tuple\n",
      "path: /home/devspace/project/data/output_feature_finalizer/measurement_data_list.pickle, data_type: list\n",
      "path: /home/devspace/project/data/output_feature_finalizer/in_hospital_mortality_list.pickle, data_type: list\n",
      "\n",
      "All preprocess modules complete.\n",
      "Total preprocessing time = 531.34 seconds\n"
     ]
    }
   ],
   "source": [
    "preprocessed_resources = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LSTM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Architecture and Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "dataset = xmd.X19MGeneralDataset.from_feature_finalizer_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples in dataset = {len(dataset)}\")\n",
    "print(f\"Type returned by dataset.__getitem__ = {type(dataset[0])}\")\n",
    "print(\n",
    "    f\"Length of each tuple returned by dataset.__getitem__ = {len(dataset[0])}\"\n",
    ")\n",
    "print(\n",
    "    \"\\nObject type, dimensionality, and datatype of each element in a tuple\"\n",
    "    \" returned by dataset.__getitem__:\"\n",
    ")\n",
    "print(tuple([(type(item), item.dim(), item.dtype) for item in dataset[0]]))\n",
    "print(f\"The 'input size' (# columns) of each feature matrix is \"\n",
    "     f\"{np.unique([item.shape[1] for item in dataset[:][0]]).item()}\")\n",
    "print(f\"The various sequence lengths (# rows) among the input feature matrices are\\n\"\n",
    "     f\"{np.unique([item.shape[0] for item in dataset[:][0]])}\")\n",
    "\n",
    "\n",
    "\n",
    "unique_sequence_lengths, sequence_length_counts = np.unique(\n",
    "    [item.shape[0] for item in dataset[:][0]], return_counts=True\n",
    ")\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            unique_sequence_lengths.reshape(-1, 1),\n",
    "            sequence_length_counts.reshape(-1, 1),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "unique_labels, label_counts = np.unique([dataset[:][1]], return_counts=True)\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (unique_labels.reshape(-1, 1), label_counts.reshape(-1, 1)), axis=1\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import lstm_adversarial_attack.tune_train.tuner_driver as td\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cur_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    cur_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"cur_device is {cur_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_driver = td.TunerDriver(device=cur_device)\n",
    "pprint.pprint(tuner_driver.tuner.tuning_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(tuner_driver.tuner.dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completed_study = tuner_driver(num_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
