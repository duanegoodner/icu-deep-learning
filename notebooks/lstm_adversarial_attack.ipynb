{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Background Information\n",
    "\n",
    "This project reproduces and expands upon work published in [1] and [2] on Long Short-Term Memory (LSTM) predictive models of Intensive Care Unit (ICU) patient outcomes, and adversarial attacks on those models. Following the approach of the previous studies, we use patient data from the Medical Information Mart for Intensive Care (MIMIC-III) database, and build a LSTM model with inputs consisting of 13 lab measurements and 6 vital signs. The prediction target is a binary variable representing in-hospital mortaliy. An adversarial attack algorithm with L1 regularization is then used to identify small perturbations which, when applied to a real, correctly-classified input features, caused a trained model to misclassify the perturbed input. After attacking a full dataset, susceptibility calculations were  performed to identify input feature space regions most vulnerable to adversarial attack.\n",
    "\n",
    "Aspects of the current work that expand upon the previous studies include faster data preprocessing algorithms; extensive hyperparameter tuning of both the predictive model and attack algorithm; improved performance of the predictive model; implementation of a GPU-compatible attack algorithm that enables attacking samples in batches; and not halting the attack process upon finding a single adversarial perturbation for a sample, allowing the discovery of additional, lower loss adversarial perturbations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Confirm Development Environment Setup\n",
    "The code and instructions in this notebook assume you have completed all steps in the [How to run this project](https://github.com/duanegoodner/lstm_adversarial_attack/tree/main#3-how-to-run-this-project) section of the project [README](https://github.com/duanegoodner/lstm_adversarial_attack), and you are running this notebook using Jupyter Lab inside Docker container `lstm_aa_app`. Run the following tests to confirm the environment is set up correcly:\n",
    "\n",
    "### 2.1 Docker Containers\n",
    "\n",
    "From a **local terminal** (not in any docker container), run `docker ps --format \"table {{.ID}}\\t{{.Ports}}\\t{{.Names}}\"`. The output should include the following lines:\n",
    "\n",
    "```\n",
    "CONTAINER ID   PORTS                                                                        NAMES\n",
    "152b6903a45b   127.0.0.1:6006->6006/tcp, 127.0.0.1:8888->8888/tcp, 127.0.0.1:2200->22/tcp   lstm_aa_app\n",
    "5520201f8420   0.0.0.0:5556->5432/tcp, :::5556->5432/tcp                                    postgres_optuna\n",
    "92e83589a4c8   0.0.0.0:5555->5432/tcp, :::5555->5432/tcp                                    postgres_mimiciii\n",
    "```\n",
    "Python code will run in `lstm_aa_app`. An instance of PostgreSQL in `postgres_mmimiciii` will hold MIMIC-III raw data for our model, and databases in `postgres_optuna` will store data from studies used to tune hyperparameters of our predictive model and adversarial attack model.\n",
    "\n",
    "### 2.2 Python Interpreter and IPython Kernel\n",
    "\n",
    "Runt the following quick tests to confirm which Python interpreter and IPython kernel we are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devspace/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "# Output should be: /home/devspace/env/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gen_user/.local/share/jupyter/runtime/kernel-50eac167-e16b-46bb-a857-0763b933bcca.json'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "get_ipython().kernel.config[\"IPKernelApp\"][\"connection_file\"]\n",
    "# Outptut should be similar to: '/home/gen_user/.local/share/jupyter/runtime/kernel-v2-26202uI0Vk7x2nHkK.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test Database Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to test the MIMIC-III database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to MIMIC-III database.\n",
      "Connection to MIMIC-III database successfully closed.\n"
     ]
    }
   ],
   "source": [
    "!python /home/devspace/project/src/lstm_adversarial_attack/query_db/test_mimiciii_db.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run test queries on the databases that will handle hyperparameter tuning data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_tuning database successfully queried.\n",
      "Found 13 tuning studies.\n",
      "attack_tuning database successfully queried.\n",
      "Found 21 tuning studies.\n"
     ]
    }
   ],
   "source": [
    "!python /home/devspace/project/src/lstm_adversarial_attack/tuning_db/test_tuning_study_dbs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check for GPU\n",
    "\n",
    "The PyTorch code in our project will run much faster on a GPU than it will on a CPU. Let's find out if we have GPU access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Change Working Directory\n",
    "Many of the code cells in this notebook use relative paths and assume we are in directory `/home/devspace/project/src/lstm_adversarial_attack`, so let's change to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/devspace/project/src/lstm_adversarial_attack\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/devspace/project/src/lstm_adversarial_attack\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Project Structure\n",
    "Our `docker-compose.yml` maps the local project root directory to `/home/devspace/project` in the container. Run the following cell for an overview of our project layout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project\u001b[0m\n",
      "├── \u001b[01;32mREADME.md\u001b[0m\n",
      "├── \u001b[01;32mconfig.toml\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "├── \u001b[01;34mdocker\u001b[0m\n",
      "├── \u001b[01;34mdocs\u001b[0m\n",
      "├── \u001b[01;34mlogs\u001b[0m\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\n",
      "└── \u001b[01;34msrc\u001b[0m\n",
      "\n",
      "6 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1 /home/devspace/project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 `src/`\n",
    "The contents of `/home/devspace/project/src/lstm_adversarial_attack` are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project/src/lstm_adversarial_attack\u001b[0m\n",
      "├── \u001b[01;34m__pycache__\u001b[0m\n",
      "├── \u001b[01;34mattack\u001b[0m\n",
      "├── \u001b[01;34mattack_analysis\u001b[0m\n",
      "├── \u001b[01;34mconfig\u001b[0m\n",
      "├── \u001b[01;34mdataset\u001b[0m\n",
      "├── \u001b[01;34mmodel\u001b[0m\n",
      "├── \u001b[01;34mpreprocess\u001b[0m\n",
      "├── \u001b[01;34mquery_db\u001b[0m\n",
      "├── \u001b[01;34mtuning_db\u001b[0m\n",
      "└── \u001b[01;34mutils\u001b[0m\n",
      "\n",
      "10 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 1 /home/devspace/project/src/lstm_adversarial_attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Code in the sub-directories listed above forms our project pipeline: \n",
    " * **query_db** runs .sql queries to extract patient lab, vital sign, and in-hospital mortality data from the MIMIC-III PostgreSQL database.\n",
    " * **preprocess** transforms .sql query output into a form that can be input to PyTorch models. \n",
    " * **model** tunes and trains a PyTorch model for predicting in-hospital mortality based on lab and vital sign time-series data.\n",
    " * **attack** tunes and trains a PyTorch attack model that generates adversarial examples for the predictive model.\n",
    " * **attack_analysis** generates plots for visualizing characteristics of adversarial examples found by the attack model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 `config.toml`\n",
    "Project configuration variables are set in the `config.toml` file. We can use the `get_config_value` and `set_config_value` from `utils.notebook_helpers` to read and write to the `config.toml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_config_value in module utils.notebook_helpers:\n",
      "\n",
      "get_config_value(config_key: str) -> str\n",
      "    Gets value from config.toml\n",
      "    :param config_key: config.toml key as dotted string\n",
      "    :return: value corresponding to config.toml key\n",
      "\n",
      "Help on function set_config_value in module utils.notebook_helpers:\n",
      "\n",
      "set_config_value(config_key: str, value: Any)\n",
      "    Sets value from config.toml\n",
      "    :param config_key: config.toml key as dotted string\n",
      "    :param value: value to assign to key\n",
      "    :return: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import utils.notebook_helpers as nh\n",
    "\n",
    "help(nh.get_config_value)\n",
    "help(nh.set_config_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick example of reading and writing to `config.toml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: 1234\n",
      "Value changed to: 2024\n",
      "Final value: 1234\n"
     ]
    }
   ],
   "source": [
    "orig_kfold_random_seed = nh.get_config_value(\"model.tuner_driver.kfold_random_seed\")\n",
    "print(f\"Original value: {orig_kfold_random_seed}\")\n",
    "\n",
    "nh.set_config_value(\"model.tuner_driver.kfold_random_seed\", 2024)\n",
    "modified_kfold_random_seed = nh.get_config_value(\"model.tuner_driver.kfold_random_seed\")\n",
    "print(f\"Value changed to: {modified_kfold_random_seed}\")\n",
    "\n",
    "nh.set_config_value(\"model.tuner_driver.kfold_random_seed\", orig_kfold_random_seed)\n",
    "\n",
    "final_kfold_random_seed = nh.get_config_value(\"model.tuner_driver.kfold_random_seed\")\n",
    "print(f\"Final value: {final_kfold_random_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 `data/`\n",
    "\n",
    "For each of the critical directories under `src/lstm_adversarial_attack/`, there is a corresponding directory under `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project/data\u001b[0m\n",
      "├── \u001b[01;34mattack\u001b[0m\n",
      "├── \u001b[01;34mattack_analysis\u001b[0m\n",
      "├── \u001b[01;34mmodel\u001b[0m\n",
      "├── \u001b[01;34mpreprocess\u001b[0m\n",
      "└── \u001b[01;34mquery_db\u001b[0m\n",
      "\n",
      "5 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1 /home/devspace/project/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subdirectories under `/data` contain output from runs of a particular data-generating sub-package or module. Example contents of `data/query_db` are shown below. There are data from three runs, with each containing `.csv` query result files as well as `.toml` files capturing the project configuration settings at the time of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/devspace/project/data/query_db\u001b[0m\n",
      "├── \u001b[01;34m20240812132846066518\u001b[0m\n",
      "│   ├── \u001b[01;34mconfigs\u001b[0m\n",
      "│   │   ├── \u001b[01;32msession_config.toml\u001b[0m\n",
      "│   │   └── \u001b[01;32msession_config_paths.toml\u001b[0m\n",
      "│   ├── \u001b[01;32micustay_detail.csv\u001b[0m\n",
      "│   ├── \u001b[01;32mpivoted_bg.csv\u001b[0m\n",
      "│   ├── \u001b[01;32mpivoted_lab.csv\u001b[0m\n",
      "│   └── \u001b[01;32mpivoted_vital.csv\u001b[0m\n",
      "├── \u001b[01;34m20240812143507816088\u001b[0m\n",
      "│   ├── \u001b[01;34mconfigs\u001b[0m\n",
      "│   │   ├── \u001b[01;32msession_config.toml\u001b[0m\n",
      "│   │   └── \u001b[01;32msession_config_paths.toml\u001b[0m\n",
      "│   ├── \u001b[01;32micustay_detail.csv\u001b[0m\n",
      "│   ├── \u001b[01;32mpivoted_bg.csv\u001b[0m\n",
      "│   ├── \u001b[01;32mpivoted_lab.csv\u001b[0m\n",
      "│   └── \u001b[01;32mpivoted_vital.csv\u001b[0m\n",
      "└── \u001b[01;34m20240812154615226070\u001b[0m\n",
      "    ├── \u001b[01;34mconfigs\u001b[0m\n",
      "    │   ├── \u001b[01;32msession_config.toml\u001b[0m\n",
      "    │   └── \u001b[01;32msession_config_paths.toml\u001b[0m\n",
      "    ├── \u001b[01;32micustay_detail.csv\u001b[0m\n",
      "    ├── \u001b[01;32mpivoted_bg.csv\u001b[0m\n",
      "    ├── \u001b[01;32mpivoted_lab.csv\u001b[0m\n",
      "    └── \u001b[01;32mpivoted_vital.csv\u001b[0m\n",
      "\n",
      "6 directories, 18 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/devspace/project/data/query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Keeping Track of the Data Pipeline when Running in a Notebook\n",
    "We will use an instance of `notebook_helpers.PipelineInfo` to store and retrieve module and sub-package runs' metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PipelineInfo in module utils.notebook_helpers:\n",
      "\n",
      "class PipelineInfo(builtins.object)\n",
      " |  PipelineInfo(sessions: dict[str, utils.notebook_helpers.SessionInfo] = None, next_session_index: int = 1)\n",
      " |  \n",
      " |  Container metadata of data-generating sessions. Intended for use in Jupyter\n",
      " |   notebooks.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sessions: dict[str, utils.notebook_helpers.SessionInfo] = None, next_session_index: int = 1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_stored_session(self, session_type: utils.notebook_helpers.SessionType, session_id: str | int = None) -> utils.notebook_helpers.SessionInfo\n",
      " |      Gets info on a stored session. If PipelineInfo object has more than one\n",
      " |      entry for session of session_type, must specify session ID.\n",
      " |      :param session_type: Type of session to retrieve\n",
      " |      :param session_id: ID of session\n",
      " |      :return: info for session\n",
      " |  \n",
      " |  store_session(self, session_type: utils.notebook_helpers.SessionType, session_id: str | int = None, comment: str = None)\n",
      " |      Stores info for a data generating session\n",
      " |      :param session_type: type of session\n",
      " |      :param session_id: ID of session\n",
      " |      :param comment: optional comment\n",
      " |      :return: None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nh.PipelineInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will instantiate an empty PipelineInfo object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pipeline_info = nh.PipelineInfo()\n",
    "pprint.pprint(pipeline_info.sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we run any data-generating code, we will store metadata in our PipelineInfo object. Note that we can also use the `store_session` method to store metadata to a data-generating run performed outside of our notebook session. This outside run could have been initiated from the command line, or from an ealier notebook session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Database Queries\n",
    "\n",
    "Raw ICU patient data can be extracted from the MIMIC-III database using modified versions of four `.sql`queries from the [MIT-LCP mimic-code repository](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts/pivot).\n",
    "\n",
    "### 4.1 Running the Queries\n",
    "\n",
    "We connect to the database and execute the queries by running the [\\_\\_main__](../src/lstm_adversarial_attack/query_db/__main__.py) module of the [query_db](../src/lstm_adversarial_attack/query_db/\\_\\_init__.py) sub-package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [-q [QUERY_DIR]]\n",
      "\n",
      "Runs .sql queries on MIMIC-III database\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -q [QUERY_DIR], --query_dir [QUERY_DIR]\n",
      "                        Directory containing .sql query files. Defaults to\n",
      "                        path specified by paths.db.output_root in config.toml\n"
     ]
    }
   ],
   "source": [
    "!python -m query_db --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting query session: 20240813074946702581\n",
      "\n",
      "Query 1 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/icustay_detail.sql\n",
      "Done. Query time = 0.25 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20240813074946702581/icustay_detail.csv\n",
      "Done. csv write time = 0.18 seconds\n",
      "\n",
      "Query 2 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_bg.sql\n",
      "Done. Query time = 8.15 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20240813074946702581/pivoted_bg.csv\n",
      "Done. csv write time = 1.43 seconds\n",
      "\n",
      "Query 3 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_lab.sql\n",
      "Done. Query time = 10.44 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20240813074946702581/pivoted_lab.csv\n",
      "Done. csv write time = 2.38 seconds\n",
      "\n",
      "Query 4 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_vital.sql\n",
      "Done. Query time = 34.95 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/20240813074946702581/pivoted_vital.csv\n",
      "Done. csv write time = 10.09 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m query_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Storing Query Session Info\n",
    "We can register the most recently created query session in our `PipelineInfo` storage container using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240812154615226070 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type = nh.SessionType.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20240812154615226070': SessionInfo(session_type=<SessionType.DB_QUERIES: 1>,\n",
      "                                     session_id='20240812154615226070',\n",
      "                                     comment=None)}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(pipeline_info.sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Implementation Details\n",
    "\n",
    "We will use the [`preprocess`](../src/lstm_adversarial_attack/preprocess/__init__.py) sub-package to transform information from the `.csv` files output by the `.sql` queries into numpy arrays (which can then be easily converted into PyTorch tensors). Running this sub-package instantiates a `Preprocessor` object with a `.preprocess_modules` attribute assigned by the following code in  [`preprocessor.py`](../src/lstm_adversarial_attack/preprocess/preprocessor.py):\n",
    "\n",
    "```\n",
    "self.preprocess_modules = [\n",
    "            prf.Prefilter(),\n",
    "            imc.ICUStayMeasurementCombiner(),\n",
    "            slb.FullAdmissionListBuilder(),\n",
    "            fb.FeatureBuilder(),\n",
    "            ff.FeatureFinalizer(),\n",
    "        ]\n",
    "```\n",
    "Each element of the `.preprocess_modules` attribute is a subclass of [`PreprocessModule`](../src/lstm_adversarial_attack/preprocess/preprocess_module.py).\n",
    "\n",
    "* [`Prefilter`](../src/lstm_adversarial_attack/preprocess/prefilter.py) reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* [`ICUStayMeasurementCombiner`](../src/lstm_adversarial_attack/preprocess/icustay_measurement_combiner.py) performs various joins (aka \"merges\" in the language of Pandas) to combine lab and vital sign measurement data with ICU stay data.\n",
    "* [`FullAdmissionListBuilder`](../src/lstm_adversarial_attack/preprocess/sample_list_builder.py) generates a list consisting of one FullAdmissionData object per ICU stay. The attributes of a FullAdmissionData object include ICU stay info, and a dataframe containing the measurement and timestamp data for all vital sign and lab data associated with the ICU stay.\n",
    "* [`FeatureBuilder`](../src/lstm_adversarial_attack/preprocess/feature_builder.py) resamples the time series datafame to one-hour intervals, imputes missing data, winsorizes measurement values (with cutoffs at the 5th and 95th global percentiles), and normalizes the measuremnt values so all data are between 0 and 1.\n",
    "* [`FeatureFinalizer`](../src/lstm_adversarial_attack/preprocess/feature_finalizer.py) selects the data observation time window (default starts at hospital admission time and ends 48 hours after admission). This module outputs the entire dataset features as a list of numpy arrays, and the mortality labels as a list of integers. These data structures (saved as .pickle files) will be convenient starting points when the `tune_train` and `attack` sub-packages need to create PyTorch Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Set Preprocess Config Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"preprocess\", {'min_age': 18,\n",
    " 'min_los_hospital': 1,\n",
    " 'min_los_icu': 1,\n",
    " 'bg_data_cols': ['potassium', 'calcium', 'ph', 'pco2', 'lactate'],\n",
    " 'lab_data_cols': ['albumin',\n",
    "  'bun',\n",
    "  'creatinine',\n",
    "  'sodium',\n",
    "  'bicarbonate',\n",
    "  'platelet',\n",
    "  'glucose',\n",
    "  'magnesium'],\n",
    " 'vital_data_cols': ['heartrate',\n",
    "  'sysbp',\n",
    "  'diasbp',\n",
    "  'tempc',\n",
    "  'resprate',\n",
    "  'spo2'],\n",
    " 'winsorize_low': '5%',\n",
    " 'winsorize_high': '95%',\n",
    " 'resample_interpolation_method': 'linear',\n",
    " 'resample_limit_direction': 'both',\n",
    " 'min_observation_hours': 48,\n",
    " 'observation_window_hours': 48,\n",
    " 'observation_window_start': 'intime'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Run the Preprocess Modules\n",
    "\n",
    "We can run all preprocessing modules by executing the `preprocess` sub-packages `__main__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [-d [DB_RESULT_ID]]\n",
      "\n",
      "Takes data output from database query, and runs through preprocess modules.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -d [DB_RESULT_ID], --db_result_id [DB_RESULT_ID]\n",
      "                        ID of database query session to take output from.\n",
      "                        Defaults to latest query.\n"
     ]
    }
   ],
   "source": [
    "!python -m preprocess --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20240812154615226070 \n"
     ]
    }
   ],
   "source": [
    "db_queries_session = pipeline_info.get_stored_session(session_type=nh.SessionType.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess session will use data from database query session 20240812154615226070\n",
      "Starting preprocess session 20240812171345859649\n",
      "\n",
      "Running Prefilter\n",
      "Prefilter init time = 5.473727226257324\n",
      "Prefilter process time = 1.3746631145477295\n",
      "Prefilter export time = 0.44367122650146484\n",
      "Output saved in /home/devspace/project/data/preprocess/20240812171345859649/1_prefilter\n",
      "\n",
      "Running ICUStayMeasurementMerger\n",
      "ICUStayMeasurementMerger init time = 0.02394270896911621\n",
      "ICUStayMeasurementMerger process time = 15.41568374633789\n",
      "ICUStayMeasurementMerger export time = 2.689767360687256\n",
      "Output saved in /home/devspace/project/data/preprocess/20240812171345859649/2_merged_stay_measurements\n",
      "\n",
      "Running AdmissionListBuilder\n",
      "AdmissionListBuilder init time = 0.009439706802368164\n",
      "AdmissionListBuilder process time = 18.67876958847046\n",
      "AdmissionListBuilder export time = 16.087619304656982\n",
      "Output saved in /home/devspace/project/data/preprocess/20240812171345859649/3_full_admission_list\n",
      "\n",
      "Running FeatureBuilder\n",
      "FeatureBuilder init time = 0.006751060485839844\n",
      "Done building features for sample 5000/41960\n",
      "Done building features for sample 10000/41960\n",
      "Done building features for sample 15000/41960\n",
      "Done building features for sample 20000/41960\n",
      "Done building features for sample 25000/41960\n",
      "Done building features for sample 30000/41960\n",
      "Done building features for sample 35000/41960\n",
      "Done building features for sample 40000/41960\n",
      "FeatureBuilder process time = 131.22970628738403\n",
      "FeatureBuilder export time = 23.426507711410522\n",
      "Output saved in /home/devspace/project/data/preprocess/20240812171345859649/4_feature_builder\n",
      "\n",
      "Running FeatureFinalizer\n",
      "FeatureFinalizer init time = 0.0039026737213134766\n",
      "Received 41960 samples.\n",
      "Sending 37832 samples to final output.\n",
      "FeatureFinalizer process time = 11.751338005065918\n",
      "FeatureFinalizer export time = 1.2275211811065674\n",
      "Output saved in /home/devspace/project/data/preprocess/20240812171345859649/5_feature_finalizer\n",
      "\n",
      "Total preprocess time = 227.84651899337769\n"
     ]
    }
   ],
   "source": [
    "!python -m preprocess -d {db_queries_session.session_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240812171345859649 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20240812154615226070': SessionInfo(session_type=<SessionType.DB_QUERIES: 1>,\n",
      "                                     session_id='20240812154615226070',\n",
      "                                     comment=None),\n",
      " '20240812171345859649': SessionInfo(session_type=<SessionType.PREPROCESS: 2>,\n",
      "                                     session_id='20240812171345859649',\n",
      "                                     comment=None)}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(pipeline_info.sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Summarize Feature Finalizer Output\n",
    "We can get information about the array shape and value distributions of the preprocessed using the `preprocess` sub-package's `inspect_feature_finalizer` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: inspect_feature_finalizer_output.py [-h] [-p [PREPROCESS_ID]]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p [PREPROCESS_ID], --preprocess_id [PREPROCESS_ID]\n",
      "                        ID of preprocess session to use as data source.\n",
      "                        Defaults to latest session\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/inspect_feature_finalizer_output.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20240812171345859649 \n"
     ]
    }
   ],
   "source": [
    "preprocess_session = pipeline_info.get_stored_session(session_type=nh.SessionType.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of output from preprocess session 20240812171345859649\n",
      "\n",
      "Number of samples = 37832\n",
      "\n",
      "Time Series Sequence Length Distribution\n",
      "----------------------------------------\n",
      "sequence_length     48\n",
      "count            37832\n",
      "\n",
      "Measurement Column Counts Distribution\n",
      "--------------------------------------\n",
      "num_measurements     19\n",
      "count             37832\n",
      "\n",
      "Min value of any element in any feature matrix = 0.0\n",
      "Max value of any element in any feature matrix = 1.0\n",
      "\n",
      "Class Labels Distribution\n",
      "-------------------------\n",
      "class_label      0     1\n",
      "count        33991  3841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/inspect_feature_finalizer_output.py -p {preprocess_session.session_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in the FeatureFinalizer output is from a unique ICU stay, and consists of a 2D matrix of input features and a binary class label. Each column in a feature matrix corresponds to a particular lab or vital sign measurement, and each row in a feature matrix corresponds to the number of hours elapsed after a patient's hospital admission time. A class label of 1 indicates an in-hospital mortality event.\n",
    "\n",
    "When preprocessor parameters in `config.toml` are set to default values, the FeatureFinalizer output consists of 37832 samples, and the shape of all input feature arrays is 48 x 19, and approximately 11% of the preprocessed samples have class label = 1. Later, when we tune and train our predictive model, we will use oversampling techniques to deal with the significant class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Preprocessing Time\n",
    "\n",
    "On an Intel i7-13700K CPU, the above preprocessing work takes approximately 3.9 minutes. Achieving the same transformations on the same machine with preprocessing code from [[1](#References)] takes approximately 45 minutes. This time difference is largely due to the fact that the current project preprocess subpackage avoids using  unnecessary loops and relies heavily vectorized Pandas and Numpy operations.\n",
    "\n",
    "Additional time reduction could be achieved by parellelizing the preprocess computations with tools such as [pandaparallel](https://github.com/nalepae/pandarallel) or [pyspark](https://spark.apache.org/docs/3.3.1/api/python/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture\n",
    "\n",
    "The starting point for our predictive model is based on the model in [1] and consists of the following layers:\n",
    "\n",
    "| Layer # | Description        | Input Shape                            | Parameters          | Output Shape           | Activation       |\n",
    "| ------- | ------------------ | -------------------------------------- | ------------------- | ---------------------- | ---------------- |\n",
    "| 1       | Bidirectional LSTM | (b, t<sub>max</sub> = 48, n<sub>meas</sub> = 19) | n<sub>LSTM</sub>    | (b, 2n<sub>LSTM</sub>) | a<sub>LSTM</sub> |\n",
    "| 2       | Dropoout           | (b, 2n<sub>LSTM</sub>)                 | P<sub>dropout</sub> | (b, 2n<sub>LSTM</sub>) | -                |\n",
    "| 3       | Fully Connected    | (b, 2n<sub>LSTM</sub>)                 | n<sub>FC</sub>      | (b, n<sub>FC</sub>)    | a<sub>FC</sub>   |\n",
    "| 4       | Output             | (b, n<sub>FC</sub>)                    | n<sub>out</sub> = 2 | (b, n<sub>out</sub>    | a<sub>out</sub>  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from the above table are defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter           | Description                                             |\n",
    "| ------------------- | ------------------------------------------------------- |\n",
    "| b                   | Batch size                                              |\n",
    "| t<sub>max</sub>     | Maximum input sequence length                           |\n",
    "| n<sub>meas</sub>    | Number of patient measurement types                     |\n",
    "| n<sub>LSTM</sub>    | Number of features in a LSTM hidden state               |\n",
    "| a<sub>LSTM</sub>    | Activation function for the LSTM output                 |\n",
    "| P<sub>dropout</sub> | Dropout probablity                                      |\n",
    "| n<sub>FC</sub>      | Numbef of nodes in the fully connected layer            |\n",
    "| a<sub>FC</sub>      | Activation function for the fully connected layer ouput |\n",
    "| n<sub>out</sub>     | Number of nodes in the output layer                     |\n",
    "| a<sub>out</sub>     | Activation function for the output layer                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that n<sub>meas</sub>, n<sub>out</sub>, abd s<sub>max</sub> are fixed. We have chosen to always use all 19 patient measurement types, and our classification problem always has two classes. In our current data pipeline, data collected outside of a specified time window are removed during the final preprocessing phase. If we want the observation window to be tunable, it would be helpful to move the `preprocess.feature_finalizer` module into the `tune_attack` sub-package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Hyperparameter Tuning\n",
    "\n",
    "### 7.1 Architectural hyperparameters\n",
    "\n",
    "The following table lists the ranges architectural parameters to be explored during hyperparameter tuning.\n",
    "\n",
    "| Parameter           | Tuning Type  | Values                            |\n",
    "| ------------------- | ------------ | --------------------------------- |\n",
    "| b                   | Discrete     | 2<sup>k</sup> , k = 5, 6, 7, 8    |                    \n",
    "| h<sub>LSTM</sub>    | Discrete     | 2<sup>k</sup> , k = 5, 6, 7       |\n",
    "| a<sub>LSTM</sub>    | Discrete     | ReLU, Tanh                        |\n",
    "| P<sub>dropout</sub> | Continuous   | 0.000 $\\textemdash$ 0.5000        |\n",
    "| h<sub>FC</sub>      | Discrete     | 2<sup>k</sup> , k = 4, 5, 6, 7, 8 |\n",
    "| a<sub>FC</sub>      | Discrete     | ReLU, Tanh                        |\n",
    "\n",
    "\n",
    "### 7.2 Trainer hyperparameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During hyperparameter tuning, we also explore different training optimization algorithms and learning rates.\n",
    "\n",
    "| Parameter     | Tuning Type | Values             |\n",
    "| ------------- | ----------- | ------------------ |\n",
    "| Optimizer     | Discrete    | SGD, RMSprop, Adam |\n",
    "| Learning Rate | Continuous  | 1e-5 - 1e-1        |\n",
    "\n",
    "When using the Adam optimizer, we always use the Pytorch default values of $\\beta_1 = 0.9, \\beta_2 = 0.999, \\epsilon = 10^{-8}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Implementation Details\n",
    "The [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py) class in the [`model`](../src/lstm_adversarial_attack/model/__init__.py) sub-package implements a cross-validation tuning scheme that utilizes the [Optuna](https://optuna.org/) framework. The boundaries of hyperparameter space to explore during tuning are set in the `[model.tuner_driver.tuning_ranges]` section of the projectr `config.toml` file.\n",
    "\n",
    "Other model hyperparameter tuning settings are also configured under `[model.tuner_driver]`. In the standard configuration, a PyTorch [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) generator is used to assign samples to each fold. When selecting samples for each training batch, we use a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) with a [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler) to oversample from the minority class (label = 1). For a given set of hyperparameters, the [`HyperParameterTuner.objective_fn`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) method returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna [`TPESampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html) to select new sets of hyperparameters for additional trials. [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) also uses an Optuna [`MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html) to stop unpromising trials early.\n",
    "\n",
    "### 7.4 Model Tuning Configuration Settings\n",
    "Set `[model.tuner_driver]` configuration values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"model.tuner_driver\", {'num_trials': 60,\n",
    " 'num_folds': 5,\n",
    " 'num_cv_epochs': 10,\n",
    " 'epochs_per_fold': 5,\n",
    " 'kfold_random_seed': 1234,\n",
    " 'performance_metric': 'validation_loss',\n",
    " 'optimization_direction_label': 'minimize',\n",
    " 'tuning_output_dir': 'data/model/tuning',\n",
    " 'pruner_name': 'MedianPruner',\n",
    " 'sampler_name': 'TPESampler',\n",
    " 'db_env_var_name': 'MODEL_TUNING_DB_NAME',\n",
    " 'fold_class_name': 'StratifiedKFold',\n",
    " 'collate_fn_name': 'x19m_collate_fn',\n",
    " 'cv_mean_tensorboard_metrics': ['accuracy',\n",
    "  'auc',\n",
    "  'f1',\n",
    "  'precision',\n",
    "  'recall',\n",
    "  'validation_loss'],\n",
    " 'tuning_ranges': {'log_lstm_hidden_size': [5, 7],\n",
    "  'lstm_act_options': ['ReLU', 'Tanh'],\n",
    "  'dropout': [0.0, 0.5],\n",
    "  'log_fc_hidden_size': [4, 8],\n",
    "  'fc_act_options': ['ReLU', 'Tanh'],\n",
    "  'optimizer_options': ['Adam', 'RMSprop', 'SGD'],\n",
    "  'learning_rate': [1e-05, 0.1],\n",
    "  'log_batch_size': [5, 8]},\n",
    " 'pruner_kwargs': {'n_startup_trials': 5, 'n_warmup_steps': 3},\n",
    " 'sampler_kwargs': {}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `[model.tuner_driver]` secton of the `config.toml` includes parameters that determine the number of tuning trials, cross-validation folds, and epochs. With the values set above, we run an Optuna study with 60 trials. Each trial uses 5-fold cross-validation, and we run `num_cv_epochs * epochs_per_fold = 10 * 5 = 50` total epochs on each fold. (NOTE: Consider changing tname of `epochs_per_fold` to something less confusing.)\n",
    "\n",
    "### 7.5 Start a New Hyperparameter Tuning Study\n",
    "Before starting, a few things to note:\n",
    "* Depending your GPU compute power, running the full 30 trials could take 2 - 20 hours.\n",
    "* Results will be saved to a newly created directory (with a timestamp-based name) under `data/model/tuning/<tuning_session_id>`. \n",
    "* If the study is stopped early (via CTRL-C or the Jupyter Stop button), learning from whatever trials have completed up to that point will be saved.\n",
    "* While the tuning trials are running, read ahead to the notebook section with instructions on how to monitor progress in Tensorboard.\n",
    "\n",
    "We can start a new hyperparaemter tuning session by running the `tune_new` module in the `model` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_new.py [-h] [-p [PREPROCESS_ID]] [-r]\n",
      "\n",
      "Creates and runs a new model hyperparameter tuning study.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -p [PREPROCESS_ID], --preprocess_id [PREPROCESS_ID]\n",
      "                        ID of preprocess session to use as data source.\n",
      "                        Defaults to most recently created preprocess session.\n",
      "  -r, --redirect        Redirect terminal output to log file\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_new.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since terminal output during tuning can be very long, we will use the  `-r` option to redirect output to a log file and keep our notebook tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20240812171345859649 \n"
     ]
    }
   ],
   "source": [
    "preprocess_session_for_tuning_input = pipeline_info.get_stored_session(session_type=nh.SessionType.PREPROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new model hyperparameter tuning session 20240812173842769010\n",
      "\n",
      "To monitor tuning in tensorboard, run the following command in another terminal:\n",
      "tensorboard --logdir=/home/devspace/project/data/model/tuning/20240812173842769010/tensorboard --host=0.0.0.0\n",
      "Then go to http://localhost:6006/ in your browser.\n",
      "\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/model/tuning/20240812173842769010.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/model/tuning/20240812173842769010.log\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_new.py -p {preprocess_session_for_tuning_input.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we store the model tuning session ID in our `PipelineInfo` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240812173842769010 stored\n"
     ]
    }
   ],
   "source": [
    "pipeline_info.store_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Resume an Existing Hyperparameter Tuning Study\n",
    "We can run additional trials for an existing study using the `model` sub-package's `tune_resume` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_resume.py [-h] [-t [MODEL_TUNING_ID]] [-r]\n",
      "\n",
      "Runs additional model hyperparameter tuning trials for an existing tuning\n",
      "study. Uses previously saved ModelTunerDriver and optuna.Study as starting\n",
      "points. New trial results are added to the existing Study.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [MODEL_TUNING_ID], --model_tuning_id [MODEL_TUNING_ID]\n",
      "                        ID of model tuning session to resume. Defaults to ID\n",
      "                        of most recently created session.\n",
      "  -r, --redirect        Redirect terminal output to log file\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_resume.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to continue a study, we can un-comment each of the next two cells, and assign a value to `model_tuning_id_for_continuation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20240812173842769010 \n"
     ]
    }
   ],
   "source": [
    "model_tuning_session_to_continue = pipeline_info.get_stored_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing existing model hyperparameter tuning session 20240812173842769010\n",
      "To monitor tuning in tensorboard, run the following command in another terminal:\n",
      "tensorboard --logdir=/home/devspace/project/data/model/tuning/20240812173842769010/tensorboard --host=0.0.0.0' in a different terminal\n",
      "Then go to http://localhost:6006/ in your browser.\n",
      "\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/model/tuning/20240812173842769010.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/model/tuning/20240812173842769010.log\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python model/tune_resume.py -t {model_tuning_session_to_continue.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Monitor Tuning Progress with Tensorboard\n",
    "\n",
    "While we are tuning hyperparameters, we can monitor results in Tensorboard. Use Jupyter Lab to open a new terminal, and run:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/home/devspace/project/data/model/tuning/<tuning-session-id>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "\n",
    "Then, in your browser, go to: `http://localhost:6006/`. You should see something like the screenshot below.  The x-axis for all plots is epoch number. (Unfortunately, there is no good way to add axis labels in Tensorboard.) Note: `<tuning-session-ID>` is included in the output when running the `tune_new` and/or `tune_resume` modules.\n",
    "\n",
    "Here is an example screen-shot of plots displayed in Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard_image](images/tensorboard_model_tuning_50_epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.9 Review Hyperparameters and Objective Function Scores from Model Tuning Study Trial(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: view_model_hyperparameters.py [-h] [-t [MODEL_TUNING_ID]]\n",
      "                                     [--model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER]\n",
      "\n",
      "Retrieves and displays hyperparameters tested during a model tuning session.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [MODEL_TUNING_ID], --model_tuning_id [MODEL_TUNING_ID]\n",
      "                        ID of model tuning session. Defaults to most recently\n",
      "                        created session.\n",
      "  --model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER, -n MODEL_TUNING_TRIAL_NUMBER\n",
      "                        Optional integer specifying trial number (within\n",
      "                        study).Defaults to best trial from study.\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_hyperparameters.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20240812173842769010 \n"
     ]
    }
   ],
   "source": [
    "model_tuning_session_to_review = pipeline_info.get_stored_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of model tuning session 20240812173842769010, trial number 50:\n",
      "Objective function value = 0.4429136210276763\n",
      "Hyperparameters = \n",
      "{'dropout': 0.3031822675388802,\n",
      " 'fc_act_name': 'Tanh',\n",
      " 'learning_rate': 0.000407083686425774,\n",
      " 'log_batch_size': 5,\n",
      " 'log_fc_hidden_size': 6,\n",
      " 'log_lstm_hidden_size': 7,\n",
      " 'lstm_act_name': 'ReLU',\n",
      " 'optimizer_name': 'Adam'}\n",
      "\n",
      "The best trial from tuning session 20240812173842769010:\n",
      "Trial number 50 with objective function value = 0.4429136210276763\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_hyperparameters.py -t {model_tuning_session_to_review.session_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to view information from a trial other than the best trial from the study, we can specify the trial number to review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of model tuning session 20240812173842769010, trial number 1:\n",
      "Objective function value = 0.8103571544719648\n",
      "Hyperparameters = \n",
      "{'dropout': 0.3886990807917804,\n",
      " 'fc_act_name': 'Tanh',\n",
      " 'learning_rate': 0.09081104279004466,\n",
      " 'log_batch_size': 7,\n",
      " 'log_fc_hidden_size': 4,\n",
      " 'log_lstm_hidden_size': 7,\n",
      " 'lstm_act_name': 'ReLU',\n",
      " 'optimizer_name': 'RMSprop'}\n",
      "\n",
      "The best trial from tuning session 20240812173842769010:\n",
      "Trial number 50 with objective function value = 0.4429136210276763\n"
     ]
    }
   ],
   "source": [
    "!python model/view_model_hyperparameters.py -t {model_tuning_session_to_review.session_id} -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Training\n",
    "For model hyperparameter tuning described in the previous section, we typically run ~50 epochs per fold (in the interest of reducing compute requirements). Based on the validation loss, AUC, and F1 curves from tuning trials, it appears that predictive performance could be improved by training for a larger number of epochs. We now run another round of Stratified K-fold cross-validation with our best set of parameters with a larger number of epochs.\n",
    "\n",
    "### 8.1 Notes on our Method\n",
    "* We are using \"flat\" cross-validation (as was done in previous studies on this dataset). This method computationally less expensive than nested cross-validation. Flat cross-validation has the potential to overestimate of model performance. In many cases the magnitude of overestimation is small. We also mitigate this effect by using a different set of (randomly generated) fold assignments than was used for hyperparameter tuning. \n",
    "* By selecting our hyperparameters based on the smaller number of epochs (100), we favor models that are faster to to train. It is possible that using a larger number of epochs in the tuning runs would have yielded a different (and better) set of \"best\" hyperparameters, but would also be computationally more expensive.\n",
    "\n",
    "### 8.2 Cross-Validation Training Settings\n",
    "Settings used during model training are specified in the `[model.cv_driver_settings]` section of the `config.toml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh.set_config_value(\"model.cv_driver_settings\", {'collate_fn_name': 'x19m_collate_fn',\n",
    " 'epochs_per_fold': 1000,\n",
    " 'eval_interval': 10,\n",
    " 'fold_class_name': 'StratifiedKFold',\n",
    " 'kfold_random_seed': 20240807,\n",
    " 'num_folds': 5,\n",
    " 'single_fold_eval_fraction': 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Run Cross-Validation Training\n",
    "We can begin a training session by running the `train` module in the `model` sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [-t [MODEL_TUNING_ID]] [-r]\n",
      "                [--model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER]\n",
      "\n",
      "Runs cross-validation training using the best model hyperparameters from a\n",
      "particular model tuning session.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -t [MODEL_TUNING_ID], --model_tuning_id [MODEL_TUNING_ID]\n",
      "                        ID of model tuning session that hyperparameters are\n",
      "                        obtained from. Defaults to the most recently created\n",
      "                        session.\n",
      "  -r, --redirect        Redirect terminal output to log file\n",
      "  --model_tuning_trial_number MODEL_TUNING_TRIAL_NUMBER, -n MODEL_TUNING_TRIAL_NUMBER\n",
      "                        Optional integer specifying trial number (within\n",
      "                        study).Defaults to best trial from study.\n"
     ]
    }
   ],
   "source": [
    "!python model/train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved session: 20240812173842769010 \n"
     ]
    }
   ],
   "source": [
    "model_tuning_session_for_training_input = pipeline_info.get_stored_session(session_type=nh.SessionType.MODEL_TUNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new cross-validation training session 20240813075558351261.\n",
      "\n",
      "Will use best hyperparameters from model tuning session 20240812173842769010\n",
      "\n",
      "To monitor training in tensorboard, run the following command in another terminal:\n",
      "tensorboard --logdir /home/devspace/project/data/model/cross_validation/20240813075558351261/tensorboard --host=0.0.0.0\n",
      "Then go to http://localhost:6006/ in your browser.\n",
      "\n",
      "stdout and stderr will be redirected to /home/devspace/project/logs/model/training/20240813075558351261.log\n",
      "Output can be viewed in real time by running the following command in another terminal:\n",
      "tail -f /home/devspace/project/logs/model/training/20240813075558351261.log\n"
     ]
    }
   ],
   "source": [
    "!python model/train.py -t {model_tuning_session_for_training_input.session_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Monitor Cross-Validation Progress in Tensorbard\n",
    "\n",
    "To view training curves in tensorboard, use Jupyter Lab to open a new terminal, and run:\n",
    "```\n",
    "tensorboard --logdir /home/devspace/project/data/model/tuning/<cross-validation-training-session-id>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "\n",
    "Then, go to http://localhost:6006 in your browser.\n",
    "\n",
    "This Tensorboard screenshot was taken at the end of a 5-fold, 1000 epoch per fold cross-validation run.\n",
    "![tensorboard_image](images/tensorboard_model_training_1000_epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Model Training Behavior: Continued Improvement at High Epoch Counts\n",
    "\n",
    "The above AUC and validation loss curves show continued (though diminishing) improvement in predictive performance during the entire 1000 epochs. The fact that we do not observe any sign of overfitting at such a large number of epochs is somewhat unusual. A likely cause of this behavior is the `WeightedRandomSampler` used in our training `DataLoaders`. Samples with our minority class label (`mortality = 1`) only represent ~15% of the total dataset. To deal with this imbalanced dataset, we oversample from the minority class and undersample from the majority class when creating batches of samples for training. In our current implementation, some samples from the majority class go unseen by the `StandardModelTrainer` for a large number of epochs. The number of unseen samples slowly dwindles (and the amount of information available for training slowly increases), even at very high epoch counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Summarize Model Training Results\n",
    "We can run the `model` sub-package's `view_model_training_summary` module to summarize each fold's best-performing checkpoint as well as the means and standard deviations of performance metrics across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO assign value if not using most recently created tuning session\n",
    "custom_cv_training_id_for_summary = 20240803135302155971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_training_id_for_summary = get_session_id(custom_cv_training_id_for_summary, \"model.cv_driver.output_dir\")\n",
    "cv_training_id_for_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python model/view_model_training_summary.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python model/view_model_training_summary.py -t {cv_training_id_for_summary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 Comparing Training Results with Prior Studies' Predictive Models\n",
    "\n",
    "The table below compares the predictive performance of the LSTM model in this work with other LSTM-based models using the same dataset. The current model shows the best predictive performance among all models in the table based on AUC and F1 scores. \n",
    "\n",
    "\n",
    "| # | Authors     | Model                   | Input Features                                 | AUC             | F1              | Precision       | Recall          |\n",
    "|---|-------------|-------------------------|------------------------------------------------|-----------------|-----------------|-----------------|-----------------|\n",
    "|1  | Sun et al.  | LSTM-128 + FC-32 + FC-2 | [13 labs, 6 vitals] x 48 hr                    | 0.9094 (0.0053) | 0.5429 (0.0194) | 0.4100 (0.0272) | 0.8071 (0.0269) |\n",
    "|2  | Tang et al. | LSTM-256 + FC-2         | [13 labs, 6 vitals] x 48 hr + demographic data | 0.949 (0.003)   | 0.623 (0.012)   | -               | -               |\n",
    "|3  | Tang et al. | CNN + LSTM-256 + FC-2   | [13 labs, 6 vitals] x 48 hr + demographic data | 0.940 (0.0071)  | 0.633 (0.031)   | -               | -               |\n",
    "|4  | Tang et al. | CNN + LSTM-256 + FC-2   | [13 labs, 6 vitals] x 48 hr                    | 0.933 (0.006)   | 0.587 (0.025)   | -               | -               |\n",
    "|5  | Tang et al. | LSTM-256 + FC-2         | [13 labs, 6 vitals] x 48 hr                    | 0.907 (0.006)   | 0.526 (0.013)   | -               | -               |\n",
    "|6  | This work   | LSTM-128 + FC-16 + FC-2 | [13 labs, 6 vitals] x 48 hr                    | 0.9657 (0.0035) | 0.9669 (0.0038) | 0.9888 (0.0009) | 0.9459 (0.0072) |\n",
    "\n",
    "> **Notes** LSTM-X indicates an LSTM with X hidden layers. FC-X indicates a fully connected layer with an output size of X. All LSTMs are bidirectional. The demographic data used in studies #2 and #3 was obtained from MIMIC-III.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Attack Hyperparameter Tuning\n",
    "\n",
    "Before running an attack on the entire dataset, we tune attack hyperparameters with help from `optuna`. Our approach here is not as rigourous as the one we used for predictive model tuning. We use only a fraction of the total dataset for tuning, and do not perform cross-validation.\n",
    "\n",
    "### 9.1 Set ID of Training Session to Use as Input for Attack Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cv_training_id_for_attack_tuning = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if custom_cv_training_id_for_attack_tuning is None:\n",
    "    cv_training_id_for_attack_tuning = cv_training_id_for_summary\n",
    "else:\n",
    "    cv_training_id_for_attack_tuning = custom_cv_training_id_for_attack_tuning\n",
    "    \n",
    "cv_training_id_for_attack_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Attack Hyperparameter Tuning Config Settings\n",
    "\n",
    "Settings that affect attack hyperparameter tuning are under `[attack.tuning.ranges]` and `[attack.tuner_driver_settings]`in the `config.toml`. We can view the current values of these settings using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_MODIFIER.set(\"attack.tuning.ranges\", {'kappa': [0.0, 2.0],\n",
    " 'lambda_1': [1e-07, 1.0],\n",
    " 'learning_rate': [1e-05, 1.0],\n",
    " 'log_batch_size': [5, 7],\n",
    " 'optimizer_options': ['Adam', 'RMSprop', 'SGD']})\n",
    "\n",
    "CONFIG_MODIFIER.set(\"attack.tuner_driver_settings\", {'db_env_var_name': 'ATTACK_TUNING_DB_NAME',\n",
    " 'num_trials': 75,\n",
    " 'epochs_per_batch': 1000,\n",
    " 'max_num_samples': 1028,\n",
    " 'sample_selection_seed': 2023,\n",
    " 'pruner_name': 'MedianPruner',\n",
    " 'sampler_name': 'TPESampler',\n",
    " 'objective_name': 'sparse_small',\n",
    " 'max_perts': 0,\n",
    " 'attack_misclassified_samples': False,\n",
    " 'objective_extra_kwargs': {},\n",
    " 'pruner_kwargs': {},\n",
    " 'sampler_kwargs': {}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `max_num_samples` parameter specifies the number of samples to be considered for attack. However, samples that are misclassified by the target model are not attacked, so the actual number of samples used for tuning will be slightly lower.\n",
    "\n",
    "### 9.2 Adversarial Example Quality Scores\n",
    "\n",
    "Each trial in an attack tuning study runs `epochs_per_batch` attack iterations on each of the selected samples. Then, an adversarial example quality score is calculated for the lowest loss adversarial example each sample that has at least one associated adversarial example. A trial's score is the sum of these example quality scores. The `objective_name` parameter specifies the objective function used to calculate the quality scores.\n",
    " \n",
    " The following table summarizes how each of the available objective functions calculates the quality score of a single adversarial perturbation matrix $P_{adv}$.\n",
    "| Objective               | Example Quality Score Formula                              |\n",
    "| ------------------------| -----------------------------------------------------------|\n",
    "| sparsity                | $1 - f_{nonzero}$                                          |\n",
    "| max_num_nonzero_perts   | $if\\; n_{nonzero} < n_{critical}: 1, otherwise: 0$         |\n",
    "| sparse_small            | $sparsity\\;/\\;\\|P_{adv}\\|_1$                               |\n",
    "| sparse_small_max                                            | $sparsity\\;/\\ max(|P_{adv}|)$                              |\n",
    "\n",
    "where $n_{nonzero}$ is the number of non-zero elements in $P_{adv}$, $f_{nonzero}$ is the fraction of non-zero elements, $\\|P_{adv}\\|_1$ is the L1 norm, and $|P_{adv}|$ is the element-wise absolute value.\n",
    "\n",
    "### 9.3 Tune Attack with `sparse_small` Objective\n",
    "\n",
    "Although, `attack.tuner_driver_settings.objective_name` should already be set to `sparse_small_max`, let's set it again to be sure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_MODIFIER.set(\"attack.tuner_driver_settings.objective_name\", \"sparse_small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start a new attack hyperparameter tuning session with the `attack` sub-package's `tune_attack_new` module. If a tuning session is stopped early (via CTRL-C or the notebook Stop button), data from completed trials will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_new.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_new.py -t {cv_training_id_for_attack_tuning} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Tune Attack with `sparse_small_max` Objective\n",
    "\n",
    "We change the objective name in our `config.toml` using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_MODIFIER.set(\"attack.tuner_driver_settings.objective_name\", \"sparse_small_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_new.py -t {cv_training_id_for_attack_tuning} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 9.4 Resuming an Existing Attack Tuning Session\n",
    "The `tune_attack_resume` module can be used to run more trials as part of an existing attack tuning study. If we are resuming the most recently created attack tuning study, we can set `custom_attack_tuning_id_to_resume` in the next cell to `None`. Otherwise, set it to the ID of the session we want to resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set this to ID of session to resume (OK to leave as None if resuming most recently created study)\n",
    "custom_attack_tuning_id_to_resume = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_tuning_id_to_resume = get_session_id(custom_attack_tuning_id_to_resume, \"attack.tuner_driver.output_dir\")\n",
    "attack_tuning_id_to_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_resume.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/tune_attack_resume.py -t {attack_tuning_id_to_resume} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Attacking the Full Dataset with Tuned Attack Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_READER.get_value(\"attack.driver_settings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_MODIFIER.set(\"attack.driver_settings\", {'epochs_per_batch': 1000,\n",
    " 'max_num_samples': 40000,\n",
    " 'sample_selection_seed': 2023,\n",
    " 'attack_misclassified_samples': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Attack Using Best Hyperparameters from `sparse_small_max` Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/attack.py -t {sparse_small_max_attack_tuning_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Attack Using Best Hyperparameters from `sparse_small` Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python attack/attack.py -t {sparse_small_attack_tuning_id} -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id=\"ref_01\"></a>1. [Sun, M., Tang, F., Yi, J., Wang, F. and Zhou, J., 2018, July. Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In *Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining* (pp. 793-801).](https://dl.acm.org/doi/10.1145/3219819.3219909)\n",
    "\n",
    "<a id=\"ref_02\">2.</a> [Tang, F., Xiao, C., Wang, F. and Zhou, J., 2018. Predictive modeling in urgent care: a comparative study of machine learning approaches. *Jamia Open*, *1*(1), pp.87-98.](https://academic.oup.com/jamiaopen/article/1/1/87/5032901)\n",
    "\n",
    "<a><a id=\"ref_03\">3.</a> </a>[Johnson, A., Pollard, T., and Mark, R. (2016) 'MIMIC-III Clinical Database' (version 1.4), *PhysioNet*.](https://doi.org/10.13026/C2XW26) \n",
    "\n",
    "<a id=\"ref_04\">4.</a> [Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.](https://www.nature.com/articles/sdata201635)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
