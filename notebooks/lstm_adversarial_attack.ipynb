{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. Background Information\n",
    "\n",
    "This project reproduces and expands upon work published in [1] and [2] on Long Short-Term Memory (LSTM) predictive models and adversarial attacks on those models.  The previous studies used Long Short-Term Memory (LSTM) time series classification models trained with data from the Medical Information Mart for Intensive Care (MIMIC-III) database to predict Intensive Care Unit (ICU) patient outcomes. Input features to the classification models consisted of 13 lab measurements and 6 vital signs. A binary variable representing in-hospital mortality was the prediction target.\n",
    "\n",
    "In [1], an adversarial attack algorithm was used to identify small perturbations which, when applied to a real, correctly-classified input features, caused a trained model to misclassify the perturbed input. L1 regularization was applied to the adversarial attack loss function to favor adversarial examples with sparse perturbations that resemble the structure of data entry errors most likely to occur in real medical data. Samples were attacked serially (one a time), and the attack process on a sample was stopped upon finding a single adversarial perturbation to that samples input features. After attacking a full dataset, susceptibility calculations were  performed to identify input feature space regions most vulnerable to adversarial attack.\n",
    "\n",
    "The current study follows an approach similar to that of the previous studies. We use the same dataset, input features, and prediction targets to train a LSTM binary classification model and subsequently search for adversarial examples using an L1 regularized attack algorithm. Aspects of the current work that expand upon the previous studies include a vectorized (faster) approach to data preprocessing, extensive hyperparameter tuning (of both the predictive model and attack algorithm), improved performance of the predictive model, implementation of a GPU-compatible attack algorithm that enables attacking samples in batches, and not halting the attack process upon finding a single adversarial perturbation for a sample (so that additional, lower loss adversarial perturbations can be discovered)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Development Environment Setup\n",
    "\n",
    "### 2.1 Docker Container\n",
    "\n",
    "The code and instructions in this notebook assume the development environment has been set up by completing all steps in the [How to run this project](https://github.com/duanegoodner/lstm_adversarial_attack/tree/main#3-how-to-run-this-project) section of the project [README](https://github.com/duanegoodner/lstm_adversarial_attack).  \n",
    "\n",
    "First we import a few modules that we will use to confirm our local project paths are correctly mapped to paths in the container.\n",
    "If you have used the procedure described there to run this notebook inside a `lstm_aa_app` Docker container, then the output of the following code cell should be `PosixPath('/home/devspace/project/notebooks')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "import src_paths\n",
    "# from dotenv import load_dotenv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path(os.getenv(\"CONTAINER_PROJECT_ROOT\"))\n",
    "os.chdir(project_root / \"src\" / \"lstm_adversarial_attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/devspace/project/src/lstm_adversarial_attack')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_paths as cfg_paths\n",
    "import config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src',\n",
       " '.idea',\n",
       " '.gitignore',\n",
       " 'README.md',\n",
       " '.gitattributes',\n",
       " '.ipynb_checkpoints',\n",
       " 'data',\n",
       " '.git',\n",
       " 'docs',\n",
       " 'docker',\n",
       " 'Untitled.ipynb',\n",
       " 'notebooks']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.name for item in list(src_paths.project_root.iterdir())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `/home/devspace/project` is correctly mapped to your local project root, the output of the next cell match the list of files in the local `lstm_adversarial_attack` project root directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. Project File Structure\n",
    "TODO: change to description of running from command line args (if we implement that change)\n",
    "\n",
    "All .py files are in `/home/devspace/project/src/lstm_adversarial_attack`. This directory contains four sub-packages responsible for different parts of the project data pipeline (`query_db`, `preprocess`, `tune_train`, `attack`, and `attack_analysis`). The code snippets in this notebook instantiate classes and call methods of files under the `src` directory. Look to the code and docstrings there for implementation details. \n",
    "\n",
    "\n",
    "Data files are under `/home/devspace/project/data/` in subdirectories with names that match the sub-package names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Standard Library and External Packages\n",
    "Most of the necessary standard library imports and external package imports are handled code in the `src` sub-packages, but we need to import a few things here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pprint\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "# import torch\n",
    "# from IPython.display import Markdown as md\n",
    "# from torch.utils.data import Dataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.2 Internal Project Sub-packages and Modules\n",
    "To make it easier to understand how a particular internal package or module is used, we will wait to import each package / module until just before the notebook code cells where it is first used. For now, we import the `src` path defined in [`notebooks/src_paths.py`](./src_paths.py), and add it to `sys.path` (so we can easily import project code). We also import project config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src_paths\n",
    "# sys.path.append(str(src_paths.lstm_adversarial_attack_pkg))\n",
    "# import lstm_adversarial_attack.config_paths as cfg_paths\n",
    "# import lstm_adversarial_attack.config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check for GPU\n",
    "\n",
    "We won't need a GPU until we reach the HyperParameter Tuning section, but it is good to find out now we have a GPU that PyTorch can use. If we do not have one, we likely do not want to try to run the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cur_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    cur_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"cur_device is {cur_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Database Queries\n",
    "\n",
    "### 5.1 `.sql` files\n",
    "To obtain the necessary raw data, we will use modified versions of files (originally intended for Google Big Query) from https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts/pivot. The paths to the `.sql` query files are stored as a list in variable [`config_paths.DB_QUERIES`](../src/lstm_adversarial_attack/config_paths.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/icustay_detail.sql'),\n",
      " PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_bg.sql'),\n",
      " PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_lab.sql'),\n",
      " PosixPath('/home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_vital.sql')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_paths.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Connecting to Database and Executing Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database, and execute the queries, we use the [\\_\\_main__](../src/lstm_adversarial_attack/query_db/__main__.py) module of the [query_db](../src/lstm_adversarial_attack/query_db/\\_\\_init__.py) sub-package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/icustay_detail.sql\n",
      "Done. Query time = 0.25 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/icustay_detail.csv\n",
      "Done. csv write time = 0.18 seconds\n",
      "\n",
      "Query 2 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_bg.sql\n",
      "Done. Query time = 8.71 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/pivoted_bg.csv\n",
      "Done. csv write time = 1.46 seconds\n",
      "\n",
      "Query 3 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_lab.sql\n",
      "Done. Query time = 10.50 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/pivoted_lab.csv\n",
      "Done. csv write time = 2.43 seconds\n",
      "\n",
      "Query 4 of 4\n",
      "Executing: /home/devspace/project/src/lstm_adversarial_attack/query_db/mimiciii_queries/pivoted_vital.sql\n",
      "Done. Query time = 34.37 seconds\n",
      "Writing result to csv: /home/devspace/project/data/query_db/pivoted_vital.csv\n",
      "Done. csv write time = 10.12 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m query_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lstm_adversarial_attack.query_db.__main__ as query_db\n",
    "# query_db.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of each `.sql` query is saved to a `.csv` file. The path to each of these files is shown in the terminal output above. The output path of the queries is defined by variable `DB_OUTPUT_DIR` in [config_settings](../src/lstm_adversarial_attack/config_settings.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Implementation Details\n",
    "\n",
    "We will use the [`preprocess`](../src/lstm_adversarial_attack/preprocess/__init__.py) sub-package's [`\\_\\_main__`](../src/lstm_adversarial_attack/preprocess/__main__.py) module to transform information from the `.csv` files output by the `.sql` queries into numpy arrays (which can then be asily converted into PyTorch tensors). Examining the code of [`preprocess.\\_\\_main__.main()`](../src/lstm_adversarial_attack/preprocess/__main__.py), we see that it instantiates a `Preprocessor` object. Looking at the implementation of [`Preprocessor`](../src/lstm_adversarial_attack/preprocess/preprocessor.py), we see that this class has a `.preprocess_modules` attribute assigned by the following code:\n",
    "\n",
    "```\n",
    "self.preprocess_modules = [\n",
    "            prf.Prefilter(),\n",
    "            imc.ICUStayMeasurementCombiner(),\n",
    "            slb.FullAdmissionListBuilder(),\n",
    "            fb.FeatureBuilder(),\n",
    "            ff.FeatureFinalizer(),\n",
    "        ]\n",
    "```\n",
    "Each element of the `.preprocess_modules` attribute is a subclass of [`PreprocessModule`](../src/lstm_adversarial_attack/preprocess/preprocess_module.py) and performs performs a portion the preprocessing tasks.\n",
    "\n",
    "* [`Prefilter`](../src/lstm_adversarial_attack/preprocess/prefilter.py) reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* [`ICUStayMeasurementCombiner`](../src/lstm_adversarial_attack/preprocess/icustay_measurement_combiner.py) performs various joins (aka \"merges\" in the language of Pandas) to combine lab and vital sign measurement data with ICU stay data.\n",
    "* [`FullAdmissionListBuilder`](../src/lstm_adversarial_attack/preprocess/sample_list_builder.py) generates a list consisting of one FullAdmissionData object per ICU stay. The attributes of a FullAdmissionData object include ICU stay info, and a dataframe containing the measurement and timestamp data for all vital sign and lab data associated with the ICU stay.\n",
    "* [`FeatureBuilder`](../src/lstm_adversarial_attack/preprocess/feature_builder.py) resamples the time series datafame to one-hour intervals, imputes missing data, winsorizes measurement values (with cutoffs at the 5th and 95th global percentiles), and normalizes the measuremnt values so all data are between 0 and 1.\n",
    "* [`FeatureFinalizer`](../src/lstm_adversarial_attack/preprocess/feature_finalizer.py) selects the data observation time window (default starts at hospital admission time and ends 48 hours after admission). This module outputs the entire dataset features as a list of numpy arrays, and the mortality labels as a list of integers. These data structures (saved as .pickle files) will be convenient starting points when the `tune_train` and `attack` sub-packages need to create PyTorch Datasets.\n",
    "\n",
    "Files output by [`Prefilter`](../src/lstm_adversarial_attack/preprocess/prefilter.py), [`ICUStayMeasurementCombiner`](../src/lstm_adversarial_attack/preprocess/icustay_measurement_combiner.py), [`FullAdmissionListBuilder`](../src/lstm_adversarial_attack/preprocess/sample_list_builder.py), and [`FeatureBuilder`](../src/lstm_adversarial_attack/preprocess/feature_builder.py) are saved under subdirectories of `data/preprocess/checkpoints/`, and the output of [`FeatureFinalizer`](../src/lstm_adversarial_attack/preprocess/feature_finalizer.py) is saved in `data/preprocess/final_output/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Run the Preprocess Modules\n",
    "\n",
    "We run the preprocess code using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prefilter\n",
      "Prefilter init time = 5.651925563812256\n",
      "Prefilter process time = 1.632859706878662\n",
      "Prefilter export time = 0.2474663257598877\n",
      "\n",
      "Running ICUStayMeasurementMerger\n",
      "ICUStayMeasurementMerger init time = 0.01740097999572754\n",
      "ICUStayMeasurementMerger process time = 9.08578872680664\n",
      "ICUStayMeasurementMerger export time = 1.1397287845611572\n",
      "\n",
      "Running AdmissionListBuilder\n",
      "AdmissionListBuilder init time = 0.003233671188354492\n",
      "AdmissionListBuilder process time = 17.22941255569458\n",
      "AdmissionListBuilder export time = 16.773188591003418\n",
      "\n",
      "Running FeatureBuilder\n",
      "FeatureBuilder init time = 0.0023224353790283203\n",
      "Done building features for sample 5000/41960\n",
      "Done building features for sample 10000/41960\n",
      "Done building features for sample 15000/41960\n",
      "Done building features for sample 20000/41960\n",
      "Done building features for sample 25000/41960\n",
      "Done building features for sample 30000/41960\n",
      "Done building features for sample 35000/41960\n",
      "Done building features for sample 40000/41960\n",
      "FeatureBuilder process time = 128.79142332077026\n",
      "FeatureBuilder export time = 24.899065494537354\n",
      "\n",
      "Running FeatureFinalizer\n",
      "FeatureFinalizer init time = 2.002716064453125e-05\n",
      "FeatureFinalizer process time = 11.620139360427856\n",
      "FeatureFinalizer export time = 1.6180975437164307\n",
      "\n",
      "total time = 218.71237683296204\n"
     ]
    }
   ],
   "source": [
    "!python -m preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lstm_adversarial_attack.preprocess.__main__ as preprocess\n",
    "# preprocess.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Performance\n",
    "\n",
    "On an Intel i7-13700K CPU, the above preprocessing work takes approximately 3.9 minutes. The same data transformations on the same machine with preprocessing code from [] approximately 45 minutes. This time difference is largely due to the fact that the current project preprocess subpackage avoids the use of `for` loops and relies heavily vectorized Pandas and Numpy operations.\n",
    "\n",
    "Additional time reduction could be achieved by parellelizing the preprocess computations with tools such as [pandaparallel](https://github.com/nalepae/pandarallel) or [pyspark](https://spark.apache.org/docs/3.3.1/api/python/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Create the Pytorch Dataset object\n",
    "We import module `x19_mort_general_dataset` and use it along with files saved by the `preprocessor.feature_finalizer` to insantiate a Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import x19_mort_general_dataset as xmd\n",
    "dataset = xmd.X19MGeneralDataset.from_feature_finalizer_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Examine the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we instantiate a DatasetInspector from the `x19_mort_general_dataset` module and use its methods to display some basic information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41951 samples in the Dataset.\n",
      "Calling `__getitem__` on the Dataset returns a tuple of length 2.\n",
      "The first element of this tuple is a 2-D Tensor with 19 columns and data type torch.float32.\n",
      "The second element is a 0-D Tensor with data type torch.int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>seq_length</th>\n",
       "      <th>6</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_samples</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>84</td>\n",
       "      <td>144</td>\n",
       "      <td>126</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>113</td>\n",
       "      <td>148</td>\n",
       "      <td>152</td>\n",
       "      <td>189</td>\n",
       "      <td>199</td>\n",
       "      <td>220</td>\n",
       "      <td>178</td>\n",
       "      <td>231</td>\n",
       "      <td>203</td>\n",
       "      <td>211</td>\n",
       "      <td>191</td>\n",
       "      <td>185</td>\n",
       "      <td>221</td>\n",
       "      <td>474</td>\n",
       "      <td>37832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nunm_samples</th>\n",
       "      <td>37338</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_inspector = xmd.DatasetInspector(dataset=dataset)\n",
    "dataset_inspector.view_basic_info()\n",
    "dataset_inspector.view_seq_length_summary()\n",
    "dataset_inspector.view_label_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the dataset is from a unique ICU stay. The input features for a single sample are represented by a 2D tensor where the column corresponds to a particular lab or vital sign measurement, and the row corresponds to time in hours after hospital admission. All samples' input feature tensors have the same number of columns, but the number of rows can vary from sample-to-sample. In LSTM lingo, the number of time steps assiciated with a sample is called the *sequence length*. In the current analysis, the Preprocessor removed all measuremens > 48 hours post-admission, so the maximum sequence length is 48. Samples ICU stays with < 48 hours of observations have smaller sequence lengths.\n",
    "\n",
    "A class label of 1 corresponds to an in-hospital mortality event. Less than 15% of samples belong this class. We will need to take the class imabalance into account when tuning and training predictive models with this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Architecture\n",
    "\n",
    "The starting point for our predictive model is based on the model in [1] and consists of the following layers:\n",
    "\n",
    "| Layer # | Description        | Input Shape                            | Parameters          | Output Shape           | Activation       |\n",
    "| ------- | ------------------ | -------------------------------------- | ------------------- | ---------------------- | ---------------- |\n",
    "| 1       | Bidirectional LSTM | (b, t<sub>max</sub> = 48, n<sub>meas</sub> = 19) | n<sub>LSTM</sub>    | (b, 2n<sub>LSTM</sub>) | a<sub>LSTM</sub> |\n",
    "| 2       | Dropoout           | (b, 2n<sub>LSTM</sub>)                 | P<sub>dropout</sub> | (b, 2n<sub>LSTM</sub>) | -                |\n",
    "| 3       | Fully Connected    | (b, 2n<sub>LSTM</sub>)                 | n<sub>FC</sub>      | (b, n<sub>FC</sub>)    | a<sub>FC</sub>   |\n",
    "| 4       | Output             | (b, n<sub>FC</sub>)                    | n<sub>out</sub> = 2 | (b, n<sub>out</sub>    | a<sub>out</sub>  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters from the above table are defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter           | Description                                             |\n",
    "| ------------------- | ------------------------------------------------------- |\n",
    "| b                   | Batch size                                              |\n",
    "| t<sub>max</sub>     | Maximum input sequence length                           |\n",
    "| n<sub>meas</sub>    | Number of patient measurement types                     |\n",
    "| n<sub>LSTM</sub>    | Number of features in a LSTM hidden state               |\n",
    "| a<sub>LSTM</sub>    | Activation function for the LSTM output                 |\n",
    "| P<sub>dropout</sub> | Dropout probablity                                      |\n",
    "| n<sub>FC</sub>      | Numbef of nodes in the fully connected layer            |\n",
    "| a<sub>FC</sub>      | Activation function for the fully connected layer ouput |\n",
    "| n<sub>out</sub>     | Number of nodes in the output layer                     |\n",
    "| a<sub>out</sub>     | Activation function for the output layer                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that n<sub>meas</sub>, n<sub>out</sub>, abd s<sub>max</sub> are fixed. We have chosen to always use all 19 patient measurement types, and our classification problem always has two classes. In our current data pipeline, data collected outside of a specified time window are removed during the final preprocessing phase. If we want the observation window to be tunable, it would be helpful to move the `preprocess.feature_finalizer` module into the `tune_attack` sub-package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning\n",
    "\n",
    "### 9.1 Architectural hyperparameters\n",
    "\n",
    "The following table lists the ranges architectural parameters to be explored during hyperparameter tuning.\n",
    "\n",
    "| Parameter           | Tuning Type  | Values                            |\n",
    "| ------------------- | ------------ | --------------------------------- |\n",
    "| b                   | Discrete     | 2<sup>k</sup> , k = 5, 6, 7, 8    |                    \n",
    "| h<sub>LSTM</sub>    | Discrete     | 2<sup>k</sup> , k = 5, 6, 7       |\n",
    "| a<sub>LSTM</sub>    | Discrete     | ReLU, Tanh                        |\n",
    "| P<sub>dropout</sub> | Continuous   | 0.000 $\\textemdash$ 0.5000        |\n",
    "| h<sub>FC</sub>      | Discrete     | 2<sup>k</sup> , k = 4, 5, 6, 7, 8 |\n",
    "| a<sub>FC</sub>      | Discrete     | ReLU, Tanh                        |\n",
    "\n",
    "\n",
    "### 9.2 Trainer hyperparameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During hyperparameter tuning, we also explore different training optimization algorithms and learning rates.\n",
    "\n",
    "| Parameter     | Tuning Type | Values             |\n",
    "| ------------- | ----------- | ------------------ |\n",
    "| Optimizer     | Discrete    | SGD, RMSprop, Adam |\n",
    "| Learning Rate | Continuous  | 1e-5 - 1e-1        |\n",
    "\n",
    "When using the Adam optimizer, we always use the Pytorch default values of $\\beta_1 = 0.9, \\beta_2 = 0.999, \\epsilon = 10^{-8}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Implementation Details\n",
    "The [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py) class in the [`tune_train`](../src/lstm_adversarial_attack/tune_train/__init__.py) sub-package implements a cross-validation tuning scheme that utilizes the [Optuna](https://optuna.org/) framework. The boundaries of hyperparameter space to explore during tuning are passed to the [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py) constructor in a [`X19MLSTMTuningRanges`](../src/lstm_adversarial_attack/tune_train/tuner_helpers.py) object. The default attribute of a [`X19MLSTMTuningRanges`](../src/lstm_adversarial_attack/tune_train/tuner_helpers.py) object are stored in the following config variables in [`config_settings`](../src/lstm_adversarial_attack/config_settings.py):\n",
    "```\n",
    "    TUNING_LOG_LSTM_HIDDEN_SIZE\n",
    "    TUNING_LSTM_ACT_OPTIONS\n",
    "    TUNING_DROPOUT\n",
    "    TUNING_LOG_FC_HIDDEN_SIZE\n",
    "    TUNING_FC_ACT_OPTIONS\n",
    "    TUNING_OPTIMIZER_OPTIONS\n",
    "    TUNING_LEARNING_RATE\n",
    "    TUNING_LOG_BATCH_SIZE\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) generator is used to assign samples to each fold. When selecting samples for each training batch, we use a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) with a [`WeightedRandomSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler) to oversample from the minority class (label = 1). For a given set of hyperparameters, the [`HyperParameterTuner.objective_fn`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) method returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna [`TPESampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html) to select new sets of hyperparameters for additional trials. [`HyperParameterTuner`](../src/lstm_adversarial_attack/tune_train/hyperparaemter_tuner.py) also uses an Optuna [`MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html) to stop unpromising trials early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Starting a New Hyperparameter Tuning Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, a few things to note:\n",
    "* Depending your GPU compute power, running the full 30 trials could take 2 - 20 hours.\n",
    "* Results will be saved to a newly created directory (with a timestamp-based name) under `data/tune_train/hyperparameter_tuning`. \n",
    "* If the study is stopped early (via CTRL-C or the Jupyter Stop button), learning from whatever trials have completed up to that point will be saved.\n",
    "* While the tuning trials are running, look ahead to the next Markdown cell for instructions on how to monitor progress in Tensorboard (depending on your notebook output settings you may need to scroll down to see that cell)\n",
    "\n",
    "We can start a new hyperparaemter tuning study using the [`tune_new`](../src/lstm_adversarial_attack/tune_train/tune_new.py) module from the [`tune_train`](../src/lstm_adversarial_attack/tune_train/__init__.py) subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-20 09:56:00,694] A new study created in RDB with name: model_tuning_20231220095600579628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning.\n",
      "\n",
      "Data for Tensorboard will be written to:\n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095600579628/tensorboard\n",
      "\n",
      "CV mean logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095600579628/cv_mean_logs\n",
      "\n",
      "Individual trainer logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095600579628/trainer_output\n",
      "fold_0, epoch_1, Loss: 0.6073\n",
      "fold_0, epoch_2, Loss: 0.5511\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5368\n",
      "Accuracy:\t0.7610\n",
      "AUC:\t\t0.8349\n",
      "Precision:\t0.7662\n",
      "Recall:\t\t0.7527\n",
      "F1:\t\t\t0.7594\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6113\n",
      "fold_1, epoch_2, Loss: 0.5551\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5394\n",
      "Accuracy:\t0.7610\n",
      "AUC:\t\t0.8293\n",
      "Precision:\t0.7653\n",
      "Recall:\t\t0.7563\n",
      "F1:\t\t\t0.7608\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6093\n",
      "fold_2, epoch_2, Loss: 0.5624\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5426\n",
      "Accuracy:\t0.7582\n",
      "AUC:\t\t0.8316\n",
      "Precision:\t0.7807\n",
      "Recall:\t\t0.7179\n",
      "F1:\t\t\t0.7480\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.5393\n",
      "fold_0, epoch_4, Loss: 0.5336\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5359\n",
      "Accuracy:\t0.7630\n",
      "AUC:\t\t0.8543\n",
      "Precision:\t0.7183\n",
      "Recall:\t\t0.8731\n",
      "F1:\t\t\t0.7882\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.5416\n",
      "fold_1, epoch_4, Loss: 0.5375\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5333\n",
      "Accuracy:\t0.7691\n",
      "AUC:\t\t0.8421\n",
      "Precision:\t0.7474\n",
      "Recall:\t\t0.8105\n",
      "F1:\t\t\t0.7777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-12-20 09:56:17,902] Trial 0 failed with parameters: {'log_lstm_hidden_size': 5, 'lstm_act_name': 'Tanh', 'dropout': 0.09193135917994699, 'log_fc_hidden_size': 7, 'fc_act_name': 'ReLU', 'optimizer_name': 'Adam', 'learning_rate': 0.0005216742304472665, 'log_batch_size': 7} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 320, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 192, in train_model\n",
      "    y_hat = self.model(inputs).squeeze()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/lstm_model_stc.py\", line 54, in forward\n",
      "    unpacked_lstm_out, lstm_out_lengths = pad_packed_sequence(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/utils/rnn.py\", line 333, in pad_packed_sequence\n",
      "    padded_output, lengths = _VF._pad_packed_sequence(\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-20 09:56:17,903] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlstm_adversarial_attack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtune_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tune_new\n\u001b[0;32m----> 2\u001b[0m my_completed_study \u001b[38;5;241m=\u001b[39m \u001b[43mtune_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_new.py:37\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(num_trials)\u001b[0m\n\u001b[1;32m     31\u001b[0m     cur_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m tuner_driver \u001b[38;5;241m=\u001b[39m td\u001b[38;5;241m.\u001b[39mTunerDriver(\n\u001b[1;32m     34\u001b[0m     device\u001b[38;5;241m=\u001b[39mcur_device,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mtuner_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py:221\u001b[0m, in \u001b[0;36mTunerDriver.__call__\u001b[0;34m(self, num_trials)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_trials: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m optuna\u001b[38;5;241m.\u001b[39mStudy:\n\u001b[0;32m--> 221\u001b[0m     completed_study \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m completed_study\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py:217\u001b[0m, in \u001b[0;36mTunerDriver.run\u001b[0;34m(self, num_trials)\u001b[0m\n\u001b[1;32m    198\u001b[0m tuner \u001b[38;5;241m=\u001b[39m htu\u001b[38;5;241m.\u001b[39mHyperParameterTuner(\n\u001b[1;32m    199\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    200\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mxmd\u001b[38;5;241m.\u001b[39mX19MGeneralDataset\u001b[38;5;241m.\u001b[39mfrom_feature_finalizer_output(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     study\u001b[38;5;241m=\u001b[39mstudy,\n\u001b[1;32m    215\u001b[0m )\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# completed_study = self.tuner.tune(num_trials=num_trials)\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m completed_study \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completed_study\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py:404\u001b[0m, in \u001b[0;36mHyperParameterTuner.tune\u001b[0;34m(self, num_trials, timeout)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting hyperparameter tuning.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData for Tensorboard will be written to:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dirs\u001b[38;5;241m.\u001b[39mtrainer_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    401\u001b[0m )\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial_num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_trials):\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py:320\u001b[0m, in \u001b[0;36mHyperParameterTuner.objective_fn\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    318\u001b[0m eval_epoch_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, trainer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(objective_tools\u001b[38;5;241m.\u001b[39mtrainers):\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs_per_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     eval_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate_model()\n\u001b[1;32m    322\u001b[0m     eval_epoch_results\u001b[38;5;241m.\u001b[39mappend(eval_result)\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py:192\u001b[0m, in \u001b[0;36mStandardModelTrainer.train_model\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m    187\u001b[0m inputs\u001b[38;5;241m.\u001b[39mfeatures, y \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m     inputs\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    189\u001b[0m     y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    190\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 192\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    193\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(y_hat, y)\n\u001b[1;32m    194\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/tune_train/lstm_model_stc.py:54\u001b[0m, in \u001b[0;36mBidirectionalX19LSTM.forward\u001b[0;34m(self, variable_length_features)\u001b[0m\n\u001b[1;32m     47\u001b[0m packed_features \u001b[38;5;241m=\u001b[39m pack_padded_sequence(\n\u001b[1;32m     48\u001b[0m     variable_length_features\u001b[38;5;241m.\u001b[39mfeatures,\n\u001b[1;32m     49\u001b[0m     lengths\u001b[38;5;241m=\u001b[39mvariable_length_features\u001b[38;5;241m.\u001b[39mlengths,\n\u001b[1;32m     50\u001b[0m     batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m     enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m lstm_out_packed, (h_n, c_n) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(packed_features)\n\u001b[0;32m---> 54\u001b[0m unpacked_lstm_out, lstm_out_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mpad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlstm_out_packed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m final_lstm_out \u001b[38;5;241m=\u001b[39m unpacked_lstm_out[\n\u001b[1;32m     58\u001b[0m     torch\u001b[38;5;241m.\u001b[39marange(unpacked_lstm_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), lstm_out_lengths \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, :\n\u001b[1;32m     59\u001b[0m ]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_lstm_out\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/torch/nn/utils/rnn.py:333\u001b[0m, in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected total_length to be at least the length \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the longest sequence in input, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and max sequence length being \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_seq_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m                          )\n\u001b[1;32m    332\u001b[0m     max_seq_length \u001b[38;5;241m=\u001b[39m total_length\n\u001b[0;32m--> 333\u001b[0m padded_output, lengths \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m unsorted_indices \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39munsorted_indices\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsorted_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lstm_adversarial_attack.tune_train import tune_new\n",
    "my_completed_study = tune_new.main(num_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-20 09:56:25,815]\u001b[0m A new study created in RDB with name: model_tuning_20231220095625747572\u001b[0m\n",
      "Starting hyperparameter tuning.\n",
      "\n",
      "Data for Tensorboard will be written to:\n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095625747572/tensorboard\n",
      "\n",
      "CV mean logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095625747572/cv_mean_logs\n",
      "\n",
      "Individual trainer logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095625747572/trainer_output\n",
      "fold_0, epoch_1, Loss: 0.6938\n",
      "fold_0, epoch_2, Loss: 0.6914\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6905\n",
      "Accuracy:\t0.5014\n",
      "AUC:\t\t0.7596\n",
      "Precision:\t0.5014\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6679\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6915\n",
      "fold_1, epoch_2, Loss: 0.6897\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6885\n",
      "Accuracy:\t0.6223\n",
      "AUC:\t\t0.7202\n",
      "Precision:\t0.5924\n",
      "Recall:\t\t0.7712\n",
      "F1:\t\t\t0.6701\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6911\n",
      "fold_2, epoch_2, Loss: 0.6888\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6871\n",
      "Accuracy:\t0.6610\n",
      "AUC:\t\t0.7417\n",
      "Precision:\t0.8005\n",
      "Recall:\t\t0.4272\n",
      "F1:\t\t\t0.5571\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.6888\n",
      "fold_0, epoch_4, Loss: 0.6847\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6816\n",
      "Accuracy:\t0.5720\n",
      "AUC:\t\t0.7784\n",
      "Precision:\t0.5406\n",
      "Recall:\t\t0.9587\n",
      "F1:\t\t\t0.6913\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.6870\n",
      "fold_1, epoch_4, Loss: 0.6836\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6811\n",
      "Accuracy:\t0.6969\n",
      "AUC:\t\t0.7495\n",
      "Precision:\t0.7416\n",
      "Recall:\t\t0.5996\n",
      "F1:\t\t\t0.6631\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.6854\n",
      "fold_2, epoch_4, Loss: 0.6808\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6777\n",
      "Accuracy:\t0.6958\n",
      "AUC:\t\t0.7559\n",
      "Precision:\t0.7219\n",
      "Recall:\t\t0.6296\n",
      "F1:\t\t\t0.6726\n",
      "\n",
      "\u001b[32m[I 2023-12-20 09:56:45,855]\u001b[0m Trial 0 finished with value: 0.6801634203171983 and parameters: {'log_lstm_hidden_size': 5, 'lstm_act_name': 'ReLU', 'dropout': 0.2562287202398084, 'log_fc_hidden_size': 5, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 1.9946386850727703e-05, 'log_batch_size': 7}. Best is trial 0 with value: 0.6801634203171983.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.8110\n",
      "fold_0, epoch_2, Loss: 0.8158\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.8092\n",
      "Accuracy:\t0.5038\n",
      "AUC:\t\t0.4028\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.8128\n",
      "fold_1, epoch_2, Loss: 0.8178\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.8134\n",
      "Accuracy:\t0.4997\n",
      "AUC:\t\t0.5000\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.8109\n",
      "fold_2, epoch_2, Loss: 0.8124\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.8132\n",
      "Accuracy:\t0.5000\n",
      "AUC:\t\t0.5000\n",
      "Precision:\t0.5000\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6667\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.8124\n",
      "fold_0, epoch_4, Loss: 0.8103\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.8103\n",
      "Accuracy:\t0.5029\n",
      "AUC:\t\t0.4049\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.8137\n",
      "fold_1, epoch_4, Loss: 0.8113\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.8111\n",
      "Accuracy:\t0.5020\n",
      "AUC:\t\t0.5000\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.8118\n",
      "fold_2, epoch_4, Loss: 0.8148\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.8107\n",
      "Accuracy:\t0.5027\n",
      "AUC:\t\t0.5000\n",
      "Precision:\t0.5027\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6690\n",
      "\n",
      "\u001b[32m[I 2023-12-20 09:57:02,947]\u001b[0m Trial 1 finished with value: 0.8107030878872631 and parameters: {'log_lstm_hidden_size': 5, 'lstm_act_name': 'ReLU', 'dropout': 0.41655046680302504, 'log_fc_hidden_size': 8, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 0.03521694857952425, 'log_batch_size': 7}. Best is trial 0 with value: 0.6801634203171983.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.8091\n",
      "fold_0, epoch_2, Loss: 0.8128\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.8114\n",
      "Accuracy:\t0.5018\n",
      "AUC:\t\t0.6121\n",
      "Precision:\t0.5018\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6682\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.8133\n",
      "fold_1, epoch_2, Loss: 0.8171\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.8137\n",
      "Accuracy:\t0.4991\n",
      "AUC:\t\t0.6112\n",
      "Precision:\t0.4991\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6659\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.8180\n",
      "fold_2, epoch_2, Loss: 0.8105\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.8163\n",
      "Accuracy:\t0.4973\n",
      "AUC:\t\t0.5000\n",
      "Precision:\t0.4973\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6642\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.8176\n",
      "fold_0, epoch_4, Loss: 0.8111\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.8186\n",
      "Accuracy:\t0.4945\n",
      "AUC:\t\t0.6129\n",
      "Precision:\t0.4945\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6618\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.8176\n",
      "fold_1, epoch_4, Loss: 0.8109\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.8115\n",
      "Accuracy:\t0.5019\n",
      "AUC:\t\t0.6100\n",
      "Precision:\t0.5019\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6684\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.8097\n",
      "fold_2, epoch_4, Loss: 0.8183\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.8192\n",
      "Accuracy:\t0.4941\n",
      "AUC:\t\t0.5000\n",
      "Precision:\t0.4941\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6614\n",
      "\n",
      "\u001b[32m[I 2023-12-20 09:57:17,312]\u001b[0m Trial 2 finished with value: 0.8138023369240038 and parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'Tanh', 'dropout': 0.02132222758653557, 'log_fc_hidden_size': 7, 'fc_act_name': 'ReLU', 'optimizer_name': 'RMSprop', 'learning_rate': 0.01739668764583513, 'log_batch_size': 8}. Best is trial 0 with value: 0.6801634203171983.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.6934\n",
      "fold_0, epoch_2, Loss: 0.6924\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6919\n",
      "Accuracy:\t0.5038\n",
      "AUC:\t\t0.6658\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6935\n",
      "fold_1, epoch_2, Loss: 0.6927\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6922\n",
      "Accuracy:\t0.5454\n",
      "AUC:\t\t0.5919\n",
      "Precision:\t0.5337\n",
      "Recall:\t\t0.7504\n",
      "F1:\t\t\t0.6238\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6936\n",
      "fold_2, epoch_2, Loss: 0.6928\n",
      "/home/devspace/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6923\n",
      "Accuracy:\t0.5013\n",
      "AUC:\t\t0.6242\n",
      "Precision:\t0.0000\n",
      "Recall:\t\t0.0000\n",
      "F1:\t\t\t0.0000\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.6917\n",
      "fold_0, epoch_4, Loss: 0.6909\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6906\n",
      "Accuracy:\t0.5109\n",
      "AUC:\t\t0.7274\n",
      "Precision:\t0.9359\n",
      "Recall:\t\t0.0189\n",
      "F1:\t\t\t0.0370\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.6919\n",
      "fold_1, epoch_4, Loss: 0.6912\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6907\n",
      "Accuracy:\t0.6380\n",
      "AUC:\t\t0.6852\n",
      "Precision:\t0.6935\n",
      "Recall:\t\t0.4862\n",
      "F1:\t\t\t0.5716\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.6922\n",
      "fold_2, epoch_4, Loss: 0.6914\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6912\n",
      "Accuracy:\t0.5279\n",
      "AUC:\t\t0.6971\n",
      "Precision:\t0.8739\n",
      "Recall:\t\t0.0635\n",
      "F1:\t\t\t0.1184\n",
      "\n",
      "\u001b[32m[I 2023-12-20 09:57:42,603]\u001b[0m Trial 3 finished with value: 0.690815537258653 and parameters: {'log_lstm_hidden_size': 5, 'lstm_act_name': 'Tanh', 'dropout': 0.2253424998678462, 'log_fc_hidden_size': 8, 'fc_act_name': 'Tanh', 'optimizer_name': 'SGD', 'learning_rate': 0.0011160590751006676, 'log_batch_size': 5}. Best is trial 0 with value: 0.6801634203171983.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.6730\n",
      "fold_0, epoch_2, Loss: 0.6103\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6020\n",
      "Accuracy:\t0.7055\n",
      "AUC:\t\t0.7609\n",
      "Precision:\t0.7340\n",
      "Recall:\t\t0.6536\n",
      "F1:\t\t\t0.6915\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6818\n",
      "fold_1, epoch_2, Loss: 0.6306\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6204\n",
      "Accuracy:\t0.6931\n",
      "AUC:\t\t0.7496\n",
      "Precision:\t0.7109\n",
      "Recall:\t\t0.6430\n",
      "F1:\t\t\t0.6753\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6805\n",
      "fold_2, epoch_2, Loss: 0.6262\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6130\n",
      "Accuracy:\t0.6926\n",
      "AUC:\t\t0.7499\n",
      "Precision:\t0.6926\n",
      "Recall:\t\t0.6988\n",
      "F1:\t\t\t0.6957\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.5960\n",
      "fold_0, epoch_4, Loss: 0.5855\n",
      "^C\n",
      "\u001b[33m[W 2023-12-20 09:57:55,423]\u001b[0m Trial 4 failed with parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'Tanh', 'dropout': 0.47212225023010346, 'log_fc_hidden_size': 4, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 5.260243776705152e-05, 'log_batch_size': 7} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 321, in objective_fn\n",
      "    eval_result = trainer.evaluate_model()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 242, in evaluate_model\n",
      "    for num_batches, (inputs, y) in enumerate(self.train_loader):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/x19_mort_general_dataset.py\", line 88, in x19m_collate_fn\n",
      "    padded_features = pad_sequence(sequences=features, batch_first=True)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/utils/rnn.py\", line 400, in pad_sequence\n",
      "    return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-12-20 09:57:55,424]\u001b[0m Trial 4 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_new.py\", line 54, in <module>\n",
      "    completed_study = main(**args_namespace.__dict__)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_new.py\", line 37, in main\n",
      "    study = tuner_driver(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 221, in __call__\n",
      "    completed_study = self.run(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 217, in run\n",
      "    completed_study = tuner.tune(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 404, in tune\n",
      "    self.study.optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 321, in objective_fn\n",
      "    eval_result = trainer.evaluate_model()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 242, in evaluate_model\n",
      "    for num_batches, (inputs, y) in enumerate(self.train_loader):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/x19_mort_general_dataset.py\", line 88, in x19m_collate_fn\n",
      "    padded_features = pad_sequence(sequences=features, batch_first=True)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/utils/rnn.py\", line 400, in pad_sequence\n",
      "    return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python tune_train/tune_new.py --num_trials 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 Monitor Tuning Progress with Tensorboard\n",
    "\n",
    "While we are tuning hyperparameters, we can monitor results in Tensorboard. One (relatively straightforward) way to start Tensorboard is to first launch a `zsh` shell inside the project container:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app_dev /bin/zsh\n",
    "```\n",
    "Next, at the container `zsh` prompt, run the following command to start a Tensorboard server:\n",
    "\n",
    "```\n",
    "> tensorboard --logdir=/home/devspace/project/data/hyperparameter_tuning/continued_trials/tensorboard --host=0.0.0.0\n",
    "```\n",
    "Then, in your browser, go to: `http://localhost:6006/` You should see something like the screenshot below.  The x-axis for all plots is epoch number. (Unfortunately, there is no good way to add axis labels in Tensorboard.) In this example we are in the middle of running trial #21. Trial #20 completed the default number of epochs per fold (100). Trial #19 only ran 20 epochs because it was pruned by the Optuna `MeadianPruner`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard_image](images/tensorboard_hyperparameter_tuning.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.6 Run Additional Trials on an Exiting Tuning Study\n",
    "\n",
    "If we want to run additional trials using the results saved from a tuning study that previously ran, we can use the [`tune_train.tune_resume`](../src/lstm_adversarial_attack/tune_train/tune_resume.py) module.  When we resume an existing study, the Optuna framework can use learning from earlier trials in the study to choose conditios for the new trials. The new trial results are saved to the same directory and `optuna.Study` filepath containing results from the study's previous trials.\n",
    "\n",
    "We use the next code cell to resume tuning with an existing Study. When we do not provide an argument for tune_resume.main study_dir parameter (as is the case below), we default to the directory under `data/tune_train/hyperparameter_tuning` that contains the most recently modified `optuna_study.pickle` file.\n",
    "\n",
    ">**Note** If we want to use a study other than the most recently modified one, our call to `tune_resume.main` would look something like this:\n",
    "\n",
    ">`tune_resume.main(study_dir=/home/devspace/project/data/tune_train/hyperparameter_tuning/2023-07-27_17_04_20.069961/checkpoints_tuner,\n",
    "> num_trials=30)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lstm_adversarial_attack.tune_train import tune_resume\n",
    "tune_resume.main(num_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune_resume.py [-h] [-s [STUDY_NAME]] [-n [NUM_TRIALS]]\n",
      "\n",
      "Runs additional hyperparameter tuning trials using previously saved\n",
      "TunerDriver and optuna.Study as startingpoints. New trial results are added to\n",
      "the existing Study.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -s [STUDY_NAME], --study_name [STUDY_NAME]\n",
      "                        Name (as saved in RDB) of study to resume\n",
      "  -n [NUM_TRIALS], --num_trials [NUM_TRIALS]\n",
      "                        Number of additional trials to run for the study in\n",
      "                        study_dir. Defaults to value stored in\n",
      "                        config_settings.TUNER_NUM_TRIALS.\n"
     ]
    }
   ],
   "source": [
    "!python tune_train/tune_resume.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_set.TUNER_NUM_TRIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-20 09:58:21,385]\u001b[0m Using an existing study with name 'model_tuning_20231212145059484285' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,388]\u001b[0m Using an existing study with name 'model_tuning_20231212145403542782' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,390]\u001b[0m Using an existing study with name 'model_tuning_20231212145658762150' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,392]\u001b[0m Using an existing study with name 'model_tuning_20231212145945456284' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,394]\u001b[0m Using an existing study with name 'model_tuning_20231212150617988279' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,396]\u001b[0m Using an existing study with name 'model_tuning_20231212163145594546' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,397]\u001b[0m Using an existing study with name 'model_tuning_20231212163921995927' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,399]\u001b[0m Using an existing study with name 'model_tuning_20231213091504341520' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,401]\u001b[0m Using an existing study with name 'model_tuning_20231213211245732172' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,403]\u001b[0m Using an existing study with name 'model_tuning_20231215122602892379' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,405]\u001b[0m Using an existing study with name 'model_tuning_20231220095600579628' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,406]\u001b[0m Using an existing study with name 'model_tuning_20231220095625747572' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-12-20 09:58:21,515]\u001b[0m Using an existing study with name 'model_tuning_20231220095625747572' instead of creating a new one.\u001b[0m\n",
      "Starting hyperparameter tuning.\n",
      "\n",
      "Data for Tensorboard will be written to:\n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095625747572/tensorboard\n",
      "\n",
      "CV mean logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095625747572/cv_mean_logs\n",
      "\n",
      "Individual trainer logs will be written to: \n",
      "/home/devspace/project/data/tune_train/hyperparameter_tuning/model_tuning_20231220095625747572/trainer_output\n",
      "fold_0, epoch_1, Loss: 0.6370\n",
      "fold_0, epoch_2, Loss: 0.5559\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5479\n",
      "Accuracy:\t0.7473\n",
      "AUC:\t\t0.8356\n",
      "Precision:\t0.8144\n",
      "Recall:\t\t0.6435\n",
      "F1:\t\t\t0.7189\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6553\n",
      "fold_1, epoch_2, Loss: 0.5674\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5581\n",
      "Accuracy:\t0.7389\n",
      "AUC:\t\t0.8130\n",
      "Precision:\t0.7131\n",
      "Recall:\t\t0.7934\n",
      "F1:\t\t\t0.7511\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6106\n",
      "fold_2, epoch_2, Loss: 0.5606\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5478\n",
      "Accuracy:\t0.7538\n",
      "AUC:\t\t0.8266\n",
      "Precision:\t0.7398\n",
      "Recall:\t\t0.7844\n",
      "F1:\t\t\t0.7614\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.5458\n",
      "fold_0, epoch_4, Loss: 0.5403\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.5448\n",
      "Accuracy:\t0.7549\n",
      "AUC:\t\t0.8439\n",
      "Precision:\t0.7086\n",
      "Recall:\t\t0.8773\n",
      "F1:\t\t\t0.7840\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.5572\n",
      "fold_1, epoch_4, Loss: 0.5488\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5492\n",
      "Accuracy:\t0.7449\n",
      "AUC:\t\t0.8313\n",
      "Precision:\t0.7015\n",
      "Recall:\t\t0.8481\n",
      "F1:\t\t\t0.7679\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.5514\n",
      "fold_2, epoch_4, Loss: 0.5472\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.5356\n",
      "Accuracy:\t0.7637\n",
      "AUC:\t\t0.8400\n",
      "Precision:\t0.7565\n",
      "Recall:\t\t0.7751\n",
      "F1:\t\t\t0.7657\n",
      "\n",
      "\u001b[32m[I 2023-12-20 09:58:43,195]\u001b[0m Trial 5 finished with value: 0.5432155244335918 and parameters: {'log_lstm_hidden_size': 6, 'lstm_act_name': 'ReLU', 'dropout': 0.022927363436071102, 'log_fc_hidden_size': 5, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 0.013505867783722595, 'log_batch_size': 7}. Best is trial 5 with value: 0.5432155244335918.\u001b[0m\n",
      "fold_0, epoch_1, Loss: 0.6931\n",
      "fold_0, epoch_2, Loss: 0.6925\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6921\n",
      "Accuracy:\t0.6773\n",
      "AUC:\t\t0.7487\n",
      "Precision:\t0.7881\n",
      "Recall:\t\t0.4859\n",
      "F1:\t\t\t0.6011\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.6928\n",
      "fold_1, epoch_2, Loss: 0.6919\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6914\n",
      "Accuracy:\t0.6944\n",
      "AUC:\t\t0.7604\n",
      "Precision:\t0.7087\n",
      "Recall:\t\t0.6453\n",
      "F1:\t\t\t0.6755\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.6929\n",
      "fold_2, epoch_2, Loss: 0.6918\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6913\n",
      "Accuracy:\t0.4972\n",
      "AUC:\t\t0.7713\n",
      "Precision:\t0.4971\n",
      "Recall:\t\t1.0000\n",
      "F1:\t\t\t0.6641\n",
      "\n",
      "fold_0, epoch_3, Loss: 0.6918\n",
      "fold_0, epoch_4, Loss: 0.6909\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.6903\n",
      "Accuracy:\t0.7094\n",
      "AUC:\t\t0.7654\n",
      "Precision:\t0.7427\n",
      "Recall:\t\t0.6411\n",
      "F1:\t\t\t0.6882\n",
      "\n",
      "fold_1, epoch_3, Loss: 0.6907\n",
      "fold_1, epoch_4, Loss: 0.6888\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.6874\n",
      "Accuracy:\t0.6916\n",
      "AUC:\t\t0.7671\n",
      "Precision:\t0.7640\n",
      "Recall:\t\t0.5508\n",
      "F1:\t\t\t0.6401\n",
      "\n",
      "fold_2, epoch_3, Loss: 0.6907\n",
      "fold_2, epoch_4, Loss: 0.6887\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.6875\n",
      "Accuracy:\t0.6967\n",
      "AUC:\t\t0.7680\n",
      "Precision:\t0.7740\n",
      "Recall:\t\t0.5565\n",
      "F1:\t\t\t0.6475\n",
      "\n",
      "\u001b[32m[I 2023-12-20 09:59:00,579]\u001b[0m Trial 6 finished with value: 0.6883810146288439 and parameters: {'log_lstm_hidden_size': 7, 'lstm_act_name': 'ReLU', 'dropout': 0.16128400728193665, 'log_fc_hidden_size': 7, 'fc_act_name': 'ReLU', 'optimizer_name': 'SGD', 'learning_rate': 0.06830505155451734, 'log_batch_size': 8}. Best is trial 5 with value: 0.5432155244335918.\u001b[0m\n",
      "^C\n",
      "\u001b[33m[W 2023-12-20 09:59:01,787]\u001b[0m Trial 7 failed with parameters: {'log_lstm_hidden_size': 5, 'lstm_act_name': 'ReLU', 'dropout': 0.3099303307195342, 'log_fc_hidden_size': 5, 'fc_act_name': 'Tanh', 'optimizer_name': 'RMSprop', 'learning_rate': 0.0011624603704662026, 'log_batch_size': 5} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 320, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 192, in train_model\n",
      "    y_hat = self.model(inputs).squeeze()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/lstm_model_stc.py\", line 53, in forward\n",
      "    lstm_out_packed, (h_n, c_n) = self.lstm(packed_features)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/rnn.py\", line 882, in forward\n",
      "    result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-12-20 09:59:01,787]\u001b[0m Trial 7 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_resume.py\", line 89, in <module>\n",
      "    completed_study = main(**args_namespace.__dict__)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tune_resume.py\", line 56, in main\n",
      "    study = tuner_driver(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 221, in __call__\n",
      "    completed_study = self.run(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/tuner_driver.py\", line 217, in run\n",
      "    completed_study = tuner.tune(num_trials=num_trials)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 404, in tune\n",
      "    self.study.optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/hyperparameter_tuner.py\", line 320, in objective_fn\n",
      "    trainer.train_model(num_epochs=self.epochs_per_fold)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/standard_model_trainer.py\", line 192, in train_model\n",
      "    y_hat = self.model(inputs).squeeze()\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/project/src/lstm_adversarial_attack/tune_train/lstm_model_stc.py\", line 53, in forward\n",
      "    lstm_out_packed, (h_n, c_n) = self.lstm(packed_features)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/devspace/env/lib/python3.10/site-packages/torch/nn/modules/rnn.py\", line 882, in forward\n",
      "    result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python tune_train/tune_resume.py --num_trials 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.7 Select Final Hyperparameters\n",
    "When we are done tuning, we can view our best set of hyperparameters by examining the `Optuna.Study` object from our above tuning run(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_ParzenEstimatorParameters.__new__() missing 1 required positional argument: 'categorical_distance_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlstm_adversarial_attack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresource_io\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrio\u001b[39;00m\n\u001b[1;32m      3\u001b[0m study_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/devspace/project/data/tune_train/hyperparameter_tuning/continued_trials/checkpoints_tuner/optuna_study.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceImporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_pickle_to_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudy_path\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best trial result is from trial # \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe set of hyperparameters from this trial are:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/resource_io.py:58\u001b[0m, in \u001b[0;36mResourceImporter.import_pickle_to_object\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_path(path\u001b[38;5;241m=\u001b[39mpath, file_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m path\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/home/devspace/project/src/lstm_adversarial_attack/custom_unpickler.py:14\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file_obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file_obj):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCustomUnpickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/devspace/env/lib/python3.10/site-packages/dill/_dill.py:442\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mStockUnpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_main_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore:\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;66;03m# point obj class to main\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: _ParzenEstimatorParameters.__new__() missing 1 required positional argument: 'categorical_distance_func'"
     ]
    }
   ],
   "source": [
    "import lstm_adversarial_attack.resource_io as rio\n",
    "\n",
    "study_path = Path(\"/home/devspace/project/data/tune_train/hyperparameter_tuning/continued_trials/checkpoints_tuner/optuna_study.pickle\")\n",
    "\n",
    "study = rio.ResourceImporter().import_pickle_to_object(\n",
    "    path=study_path\n",
    ")\n",
    "\n",
    "print(f\"The best trial result is from trial # {study.best_trial.number}.\\n\")\n",
    "print(\"The set of hyperparameters from this trial are:\")\n",
    "pprint.pprint(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.8 Run K-Fold Cross Validation with \"Best\" Hyperparameters and Extended Training (More Epochs)\n",
    "In the above tuning runs, we only run 100 epochs per fold (in the interest of reducing compute requirements). Based on the validation loss and AUC curves, it appears that we could improve our predictive performance (i.e. decrease validation loss, and increase AUC) by training longer. We now run another round of Stratified K-fold cross-validation with our best set of parameters with a larger number of epochs.\n",
    "\n",
    "#### 9.8.1 Notes on our Method\n",
    "Some caveats about our methodology:\n",
    "* We are using \"flat\" cross-validation (as was done in previous studies on this dataset). This method computationally less expensive than nested cross-validation. Flat cross-validation has the potential to overestimate of model performance. In many cases the magnitude of overestimation is small. We also mitigate this effect by using a different set of (randomly generated) fold assignments than was used for hyperparameter tuning. \n",
    "* By selecting our hyperparameters based on the smaller number of epochs (100), we favor models that are faster to to train. It is possible that using a larger number of epochs in the tuning runs would have yielded a different (and better) set of \"best\" hyperparameters, but would also be computationally more expensive.\n",
    "\n",
    "\n",
    "#### 9.8.2 Instantiate a CrossValidatorDriver\n",
    "We use a CrossValidatorDriver object to run cross-validation with a single set of hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validator_driver as cvd\n",
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "\n",
    "cv_driver = cvd.CrossValidatorDriver.from_study_path(\n",
    "        device=cur_device,\n",
    "        dataset=dataset,\n",
    "        study_path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data members of `cv_driver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(cv_driver.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run 5-fold cross-validation using 1000 epochs per fold. We will evaluate performance and save a checkpoint once every 10 epochs. These settings are determined by the values of `CV_DRIVER_EPOCHS_PER_FOLD`, `CV_DRIVER_NUM_FOLDS`, `CV_DRIVER_EVAL_INTERVAL`, and `CV_DRIVER_EVALS_PER_CHECKPOINT` in `lstm_adversarial_attacker.config_settings`. The `.from_study_path()` class method we used to construct `cv_driver` extracts the best set of hyperparameters from `study_path` and passes them to the CrossValidationDriver constructor.\n",
    "\n",
    "#### 9.8.3 Run Cross-Validation\n",
    "We now call `cv_driver`'s `.run()` method to start the cross-validation runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "collapsed"
    ]
   },
   "outputs": [],
   "source": [
    "cv_driver.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.8.4 Monitor Cross-Validation Progress in Tensorbard\n",
    "Near the start of the terminal output from the previous code cell, look for the lines:\n",
    "```\n",
    "Checkpoints will be saved in:\n",
    "/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard\n",
    "```\n",
    "Then, start a zsh shell inside the app container, and launch tensorboard server:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app /bin/zsh\n",
    "$ tensorboard --logdir=/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "The Tensorboard output can now be viewed in your browswer at http://localhost:6006\n",
    "\n",
    "This Tensorboard screenshot was taken at the end of a 5-fold, 1000 epoch per fold cross-validation run.\n",
    "![tensorboard_image](images/tensorboard_5fold_cv_best_params_1000epochs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.8.5 Why Do We See Continued (Slow) Increase in Predictive Performance Up To Such High (1000) Epoch Counts?\n",
    "\n",
    "The above AUC and validation loss curves show continued (though diminishing) improvement in predictive performance during the entire 1000 epochs. The fact that we do not observe any sign of overfitting at such a large number of epochs is somewhat unusual. A likely cause of this behavior is the `WeightedRandomSampler` used in our training `DataLoaders`. Samples with our minority class label (`mortality = 1`) only represent ~15% of the total dataset. To deal with this imbalanced dataset, we oversample from the minority class and undersample from the majority class when creating batches of samples for training. In our current implementation, some samples from the majority class go unseen by the `StandardModelTrainer` for a large number of epochs. The number of unseen samples slowly dwindles (and the amount of information available for training slowly increases), even at very high epoch counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.8.6 Summarize Results\n",
    "We can use a CrossValidationSummarizer to identify and summarize each fold's best-performing checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validation_summarizer as cvs\n",
    "cv_summarizer = cvs.CrossValidationSummarizer.from_cv_checkpoints_dir()\n",
    "optimal_results_df = cv_summarizer.get_optimal_results_df(\n",
    "        metric=cvs.EvalMetric.VALIDATION_LOSS,\n",
    "        optimize_direction=cvs.OptimizeDirection.MIN,\n",
    "    )\n",
    "\n",
    "optimal_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the mean and standard deviation of each performance metric using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_results_df.describe().loc[[\"mean\", \"std\"], (optimal_results_df.columns != \"epoch\") & (optimal_results_df.columns != \"fold\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.9 Comparison with Prior Work\n",
    "\n",
    "The table below compares the predictive performance of the LSTM model in this work with other LSTM-based models using the same dataset. The current model shows the best predictive performance among all models in the table based on AUC and F1 scores. \n",
    "\n",
    "\n",
    "|  | Authors       | Model      | Input Features | AUC             | F1              | Precision       | Recall          |\n",
    "|-|------------|------------|----------------|-----------------|-----------------|-----------------|-----------------|\n",
    "|1 |Sun et al.  | LSTM-128 + FC-32 + FC-2 | [13 labs, 6 vitals] x 48 hr  | 0.9094 (0.0053) | 0.5429 (0.0194) | 0.4100 (0.0272) | 0.8071 (0.0269) |\n",
    "|2 |Tang et al. | LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr + demographic data  | 0.949 (0.003) | 0.623 (0.012) | \n",
    "| 3|Tang et al. | CNN + LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr + demographic data | 0.940 (0.0071) | 0.633 (0.031) | \n",
    "|4 |Tang et al. | CNN + LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr | 0.933 (0.006) | 0.587 (0.025) |\n",
    "|5 |Tang et al. | LSTM-256 + FC-2 | [13 labs, 6 vitals] x 48 hr | 0.907 (0.006) | 0.526 (0.013) |\n",
    "|6 |This work   | LSTM-128 + FC-16 + FC-2 | [13 labs, 6 vitals] x 48 hr  | 0.9657 (0.0035) | 0.9669 (0.0038) | 0.9888 (0.0009) | 0.9459 (0.0072) |\n",
    "\n",
    "> **Notes** LSTM-X indicates an LSTM with X hidden layers. FC-X indicates a fully connected layer with an output size of X. All LSTMs are bidirectional. The demographic data used in studies #2 and #3 was obtained from MIMIC-III.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Adversarial Attack Algorithm on the Trained Model\n",
    "\n",
    "### 10.1 Adversarial Loss and Regularization\n",
    "Our method of adversarial attack is similar to Chen et al.'s approach that uses an adversarial loss function and L1 regularization. When attacking a binary classification model with trained parameters $\\theta$, we start with the input feature matrix $X$ of a sample that the model correctly predicts to be in class $t_{c}$, so  $M(X) = t_{c}$ where $M$ is the model's prediction function. We then search for a perturbation matrix $P$ that meets the condition:\n",
    "$$\n",
    "M(X + P) \\ne t_{c}\n",
    "$$\n",
    "Since we are dealing with binary classification, this condition is equivalent to:\n",
    "$$\n",
    "M(X + P) = \\neg{t_{c}}\n",
    "$$\n",
    "where $\\neg{t_c}$ is the negation of $t_c$. Defining a perturbed feature matrix $\\widetilde{X} = X + P$ , an adversarial loss function can be written as:\n",
    "$$\n",
    "max\\{[Logit(\\widetilde{X})]_{t_c} - [Logit(\\widetilde{X})]_{\\neg{t_c}}, - \\kappa \\}\n",
    "$$\n",
    "\n",
    "When running perturbed input $\\widetilde{X}$ through a forward pass, $[Logit(\\widetilde{X})]_{t_c}$ and $[Logit(\\widetilde{X})]_{\\neg{t_c}}$ are the **pre-activation** values at the nodes corresponding to $t_c$ and $\\neg{t_c}$ the in 2-node final layer. A value $\\ge 0$ is chosen for $\\kappa$. Using a small non-zero value of $\\kappa$ will prevent an attack algorithm from optimizing toward an infinitesimally small gap between $[Logit(\\widetilde{X})]_{t_c}$ and $[Logit(\\widetilde{X})]_{\\neg{t_c}}$ while still targeting the small difference we want for an adversarial example.\n",
    "\n",
    "To encourage an attack algorithm to find sparse perturbations, the following regularized version of Equation  () is used  \n",
    "\n",
    "$$\n",
    "max\\{[Logit(\\widetilde{X})]_{y_\\theta} - [Logit(X)]_{\\widetilde{y}_\\theta}, - \\kappa \\} + \\lambda||\\widetilde{X}-X||_1\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is the L1 regularization constant. Equation () can be minimized by subgradient descent or by an Iterative Soft-Thresholding Algorithm (ISTA). The latter approach typically converges faster. \n",
    "\n",
    "\n",
    "### 10.2 Attack Algorithm and Regularization\n",
    "\n",
    "Adversarial attacks on a particular model and dataset input features are managed by an `AdversarialAttackTrainer`. In the procedure outlined below, we discover an adversarial example any time we find $[Logit(\\widetilde{X})]_{\\neg{t_c}} > [Logit(\\widetilde{X})]_{t_c}$, even if we have not converged near a minimum value of Equation (). We attack each batch of samples for a fixed number of iterations, regardless of how many (if any) adversarial examples are found.\n",
    "\n",
    "1. A `LogitNoDropoutModelBuiler` creates a modified version of the target model. The modified model has all dropout probabilities set to zero, and does not have an activation function on the output layer.\n",
    "2. Batches of input features are run through a `FeaturePerturber` (implemented in `attack.feature_perturber`) that generates slightly modified versions of original features\n",
    "3. The perturbed features are run through the modified model that was built by the `LogitNoDropoutModelBuiler` to obtain values for $[Logit(\\widetilde{X})]_{t_c}$ and $[Logit(\\widetilde{X})]_{\\neg{t_c}}$\n",
    "4. An instance of custom PyTorch loss function ` AdversarialLoss`, which implements Equation (), calculates a loss tensor\n",
    "5. The Pytorch `.backward()`  method of the loss tensor finds the gradient of the loss with respect to the elements of the `FeaturePerturber.perturbation` tensor\n",
    "\n",
    "6. If the current $Logit$ values resulting from a sample's perturbed input features represent an adversarial example, and the example is either the first or lowest loss example for that sample, the perturbations and other details are stored in a `BatchResult` object.\n",
    "\n",
    "7. A Pytorch optimizer uses the loss gradient to calculate and apply adjustments to the perturbations\n",
    "\n",
    "8. The `AdversarialAttackTrainer.apply_soft_bounded_threshold()` method performs ISTA thresholding on the perturbations\n",
    "\n",
    "9. The perturbations (which have been adjusted by the optimizer *and* ISTA thresholding, are used in step 1 of the next attack iteration.\n",
    "\n",
    "Two key points from above procedure are: (1) Unlike the method used in [], we do not stop attacking an example upon finding a single adversarial perturbation for it.  (2) We use a combination of subgradient descent (in step 7), and ISTA (in step 8) to minimize (or at least reduce) the value of equation (). We do not know if this approach is guaranteed to converge to a minimum in the adversarial loss function, but empirically, we find this subgradient descent + ISTA more effective at finding sparse adversarial examples than either method is on its own.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Attack Hyperparameter Tuning\n",
    "\n",
    "Before running an attack on the entire dataset, we tune attack hyperparameters with help from `optuna`. Our approach here is not as rigourous as the one we used for predictive model tuning. We just use small fraction of the total dataset for tuning, and no cross-validation is involved.\n",
    "\n",
    "#### 10.3.1 Viewing / Setting the Tuning Ranges\n",
    "\n",
    "First, let's look at the current values of the project config variables that determine how an attack hyperparameter tuning session will run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kappa: min = {cfg_set.ATTACK_TUNING_KAPPA[0]}, max = {cfg_set.ATTACK_TUNING_KAPPA[1]}\")\n",
    "print(f\"Lambda: min = {cfg_set.ATTACK_TUNING_LAMBDA_1[0]}, max = {cfg_set.ATTACK_TUNING_LAMBDA_1[1]}\")\n",
    "print(f\"Optimizer: {cfg_set.ATTACK_TUNING_OPTIMIZER_OPTIONS}\")\n",
    "print(f\"Learning rate: min = {cfg_set.ATTACK_TUNING_LEARNING_RATE[0]}, max = {cfg_set.ATTACK_TUNING_LEARNING_RATE[1]}\")\n",
    "print(f\"Batch size: min = {2 ** cfg_set.ATTACK_TUNING_LOG_BATCH_SIZE[0]}, max = {2 ** cfg_set.ATTACK_TUNING_LOG_BATCH_SIZE[1]}\")\n",
    "print(f\"Attack iterations per batch: {cfg_set.ATTACK_TUNING_EPOCHS}\")\n",
    "print(f\"Max number of samples: {cfg_set.ATTACK_TUNING_MAX_NUM_SAMPLES}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are stored as variables in `src/lstm_adversarial_attack/config_settings.py` and can be modified as needed to customize a tuning session.\n",
    "\n",
    ">**Note** The `ATTACK_TUNING_MAX_NUM_SAMPLES` specifies the number of samples to be considered for attack. However, samples that are misclassified by the target model are not attacked, so the actual number of samples used for tuning will be slightly lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.2 Running an AttackHyperParameterTuner\n",
    "\n",
    "We can run a new attack hyperparameter tunin session with function `initiate_attack_tuning_study()` from the `attack.tune_attacks` module. The `target_mode_assessment_type` determines whether we use a model trained by cross-validation or single-fold training. The default behavior is to choose the most recent result of whichever assessment type is specified. We can influence the type of adversarial perturbation our tuned algorithm will produce through the argument passed to the `objective` parameter. We use the return value of any method of class `AttackTunerObjectivesBuilder`. Current options are:\n",
    "\n",
    "| Objective                                                   | Maximizes                                                    |\n",
    "| ----------------------------------------------------------- | ------------------------------------------------------------ |\n",
    "| `sparsity()`        | Sum of the perturbation sparsities of the lowest loss adversarial example of each sample |\n",
    "| `max_num_nonzero_perts()` | Number of adversarial perturbations with only one non-zero element |\n",
    "| `sparse_small()`           | Sum of (sparsity / L1 norm) of the lowest loss adversarial example of each sample |\n",
    "| `sparse_small_max()`       | Sum of (sparsity / largest magnitude of any perturbation element) of lowest loss adversarial example of each sample |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.attack.attack_hyperparameter_tuner as aht\n",
    "import lstm_adversarial_attack.attack.tune_attacks as tua\n",
    "\n",
    "# initial_attack_tuning_study = tua.main()\n",
    "help(tua.main)\n",
    "\n",
    "# initial_attack_tuning_study = tua.start_new_tuning(\n",
    "#         num_trials=50,\n",
    "#         # target_model_assessment_type=amr.ModelAssessmentType.KFOLD,\n",
    "#         objective=aht.AttackTunerObjectivesBuilder.sparse_small_max(),\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results will be saved in a subdirectory of `/home/devspace/project/data/attack/attack_hyperparameter_tuning`. If we want to run additional trials for an existing study, we can use the following code. Again, the default behavior is to use the newest existing study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "continued_study = tua.resume_tuning(num_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3 Attacking the full dataset\n",
    "\n",
    "Next we use function  `attack_with_tuned_params()` to attack all correctly classified samples using the results of our latest hyperparamter tuning session. Results will be saved in a subdirectory of /home/devspace/project/data/attack/frozen_hyperparameter_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.attack.attack as atk\n",
    "atk.attack_with_tuned_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Attack Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.attack_analysis.attack_analysis as ata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lstm_adversarial_attack.attack_analysis import attack_analysis_driver as aad\n",
    "aad.plot_latest_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
