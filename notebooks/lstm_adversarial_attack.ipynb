{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Deep Learning and Adversarial Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. About this Notebook\n",
    "\n",
    "See the project [README](https://github.com/duanegoodner/lstm_adversarial_attack) for general information on the dataset and approach used in this notebook.\n",
    "\n",
    "The implementation details for this project are encapsulated in various classes and methods defined in modules under the project `src` directory, and various intermediate data structures and logs are saved in the project `data` directory. Most of the code in this notebook simply instantiates top-level classes and makes calls to their methods without revealing implementation details. Please look to code in the `src` and `data` directories if you interested in lower level details. The import paths as well as the terminal output shown in this notebook will provide some guidance on where to look within those directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, review the project README at https://github.com/duanegoodner/lstm_adversarial_attack, and complete all steps in the \"How to run this project\" section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports\n",
    "Most of the necessary standard library imports and external package imports are handled modules in the `src` directory, but we need to import a few here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Standard Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 External Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Internal Project Modules and Sub-packages\n",
    "To help gain a sense of project structure, we will import internal packages and modules as-needed (i.e. immediately before the notebook code cells where they are first used). For now, we import the project `src` path defined in `lstm_adversarial_attack/notebooks/src_path`, add it to sys.path (so we can easily import project code), and we import project config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src_paths\n",
    "sys.path.append(str(src_paths.lstm_adversarial_attack_pkg))\n",
    "import lstm_adversarial_attack.config_paths as cfg_paths\n",
    "import lstm_adversarial_attack.config_settings as cfg_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Queries\n",
    "We need to run four queries on the MIMIC-III PostgreSQL database. The paths to files containing the queries are stored in a list as `DB_QUERIES` in the project `config_paths` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/devspace/project/src/mimiciii_queries/icustay_detail.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_bg.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_lab.sql'),\n",
      " PosixPath('/home/devspace/project/src/mimiciii_queries/pivoted_vital.sql')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_paths.DB_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the database, and execute the queries, we instantiate a `MimiciiiDatabaseAccess` object from module `mimiciii_database` of project sub-package `query_db` and use its .connect(), .run_sql_queries() and .close_connection() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.query_db.mimiciii_database as mdb\n",
    "\n",
    "db_access = mdb.MimiciiiDatabaseAccess(\n",
    "    dotenv_path=cfg_paths.DB_DOTENV_PATH, output_dir=cfg_paths.DB_OUTPUT_DIR\n",
    ")\n",
    "db_access.connect()\n",
    "db_query_results = db_access.run_sql_queries(\n",
    "    sql_query_paths=cfg_paths.DB_QUERIES\n",
    ")\n",
    "db_access.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of each `.sql` query is saved to a `.csv` file. The path to each of these files is shown in the terminal output above. The output path of the queries is defined by variable `DB_OUTPUT_DIR` in the project `config_settings` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Instantiate a Preprocessor object\n",
    "We import the `preprocessor` module from internal sub-package `preprocess`, instantiate a `Preprocessor` object, and examine its .preprocess_modules data member. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.preprocess.preprocessor as pre\n",
    "preprocessor = pre.Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a general idea of how the `lstm_adversarial_attack.preprocess` sub-package works by looking at the `Preprocessor` object's `.preprocessor_modules` data member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'lstm_adversarial_attack.preprocess.prefilter.Prefilter'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.icustay_measurement_combiner.ICUStayMeasurementCombiner'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.sample_list_builder.FullAdmissionListBuilder'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.feature_builder.FeatureBuilder'>,\n",
      " <class 'lstm_adversarial_attack.preprocess.feature_finalizer.FeatureFinalizer'>]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint([item.__class__ for item in preprocessor.preprocess_modules])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prefilter reads the database query outputs into Pandas Dataframes, removes all data related to patients younger than 18 years in age, ensures consistent column naming formats, and takes care of datatype details.\n",
    "* ICUStayMeasurementCombiner performs various joins (aka \"merges\" in the language of Pandas) to combine lab and vital sign measurement data with ICU stay data.\n",
    "* FullAdmissionListBuilder generates a list consisting of one FullAdmissionData object per ICU stay. The attributes of a FullAdmissionData object include ICU stay info, and a dataframe containing the measurement and timestamp data for all vital sign and lab data associated with the ICU stay.\n",
    "* FeatureBuilder resamples the time series datafame to one-hour intervals, imputes missing data, winsorizes measurement values (with cutoffs at the 5th and 95th global percentiles), and normalizes the measuremnt values so all data are between 0 and 1.\n",
    "* FeatureFinalizer selects the data observation time window (default starts at hospital admission time and ends 48 hours after admission). This module outputs the entire dataset features as a list of numpy arrays, and the mortality labels as a list of integers. These data structures (saved as .pickle files) will be convenient starting points when the `tune_train` and `attack` sub-packages need to create PyTorch Datasets.\n",
    "\n",
    "Now that we have a some background info, we are ready to run the Preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_resources = preprocessor.preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pytorch Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create the Dataset\n",
    "We import module `x19_mort_general_dataset` and use it along with files saved by the Preprocessor's Feature Finalizer module to insantiate a Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "dataset = xmd.X19MGeneralDataset.from_feature_finalizer_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Examine the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Dataset size, tensor shapes, and data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in dataset = 41951\n",
      "\n",
      "Type returned by dataset.__getitem__ = <class 'tuple'>\n",
      "\n",
      "Length of each tuple returned by dataset.__getitem__ = 2\n",
      "\n",
      "Object type, dimensionality, and datatype of each element in a tuple returned by dataset.__getitem__:\n",
      "((<class 'torch.Tensor'>, 2, torch.float32), (<class 'torch.Tensor'>, 0, torch.int64))\n",
      "\n",
      "input size (# columns) of each feature matrix is:\n",
      "19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in dataset = {len(dataset)}\\n\")\n",
    "print(f\"Type returned by dataset.__getitem__ = {type(dataset[0])}\\n\")\n",
    "print(\n",
    "    f\"Length of each tuple returned by dataset.__getitem__ = {len(dataset[0])}\"\n",
    ")\n",
    "print(\n",
    "    \"\\nObject type, dimensionality, and datatype of each element in a tuple\"\n",
    "    \" returned by dataset.__getitem__:\"\n",
    ")\n",
    "print(tuple([(type(item), item.dim(), item.dtype) for item in dataset[0]]))\n",
    "print(f\"\\ninput size (# columns) of each feature matrix is:\\n\"\n",
    "     f\"{np.unique([item.shape[1] for item in dataset[:][0]]).item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Distributions of feature sequence lengths and label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of input sequence lengths (# rows):\n",
      "length\tcounts\n",
      "[[    6     1]\n",
      " [   13     1]\n",
      " [   14     1]\n",
      " [   16     2]\n",
      " [   17     4]\n",
      " [   18     3]\n",
      " [   19     8]\n",
      " [   20    12]\n",
      " [   21    25]\n",
      " [   22    49]\n",
      " [   23    84]\n",
      " [   24   144]\n",
      " [   25   126]\n",
      " [   26   110]\n",
      " [   27    93]\n",
      " [   28    95]\n",
      " [   29    84]\n",
      " [   30    90]\n",
      " [   31    75]\n",
      " [   32    99]\n",
      " [   33    98]\n",
      " [   34   113]\n",
      " [   35   148]\n",
      " [   36   152]\n",
      " [   37   189]\n",
      " [   38   199]\n",
      " [   39   220]\n",
      " [   40   178]\n",
      " [   41   231]\n",
      " [   42   203]\n",
      " [   43   211]\n",
      " [   44   191]\n",
      " [   45   185]\n",
      " [   46   221]\n",
      " [   47   474]\n",
      " [   48 37832]]\n",
      "\n",
      "Label counts:\n",
      "value\tcounts\n",
      "[[    0 37338]\n",
      " [    1  4613]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of input sequence lengths (# rows):\")\n",
    "print(\"length\\tcounts\")\n",
    "unique_sequence_lengths, sequence_length_counts = np.unique(\n",
    "    [item.shape[0] for item in dataset[:][0]], return_counts=True\n",
    ")\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            unique_sequence_lengths.reshape(-1, 1),\n",
    "            sequence_length_counts.reshape(-1, 1),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nLabel counts:\")\n",
    "print(\"value\\tcounts\")\n",
    "unique_labels, label_counts = np.unique([dataset[:][1]], return_counts=True)\n",
    "print(\n",
    "    np.concatenate(\n",
    "        (unique_labels.reshape(-1, 1), label_counts.reshape(-1, 1)), axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Tuning Parameters\n",
    "\n",
    "We define the following architecture for our LSTM predictive model\n",
    "\n",
    "| Item  | Detail #1 | Detail #2| Detail #3 |\n",
    "| :-------------- | :---------| :---------| :---------\n",
    "| Bidirectional LSTM | input size = 19 | # hidden states per direction = *x<sub>1</sub>* | activation = ReLU or Tanh  |\n",
    "| Dropout | P<sub>dropout</sub> = *x<sub>2</sub>* | -  | -  |\n",
    "| Fully Connected Layer #1 | input size = *2x<sub>1</sub>*| output size = *x<sub>3</sub>* | activation = ReLU or Tanh |\n",
    "| Fully Connected Layer #2 | input size = *x<sub>3</sub>* | output size = 2 | activation = Softmax |\n",
    "| Optimizer | type = SGD or RMSProp or Adam | learning rate = *x<sub>4</sub>* | - |\n",
    "\n",
    "*x<sub>1</sub>*, *x<sub>2</sub>*, *x<sub>3</sub>*, *x<sub>4</sub>*, activation functions for the LSTM and FC #1, the optimizer type, and learning rate will be determined through hyperparameter tuning.\n",
    "\n",
    "The `HyperParameterTuner` class in the `lstm_adversarial_attack.tune_train` sub-package implements a K-fold (default K = 5) cross-validation tuning scheme that utilizes the Optuna framework. For a given set of hyperparameters, the `HyperParameterTUner.objective_fn()` returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna `TPESampler` to select new sets of hyperparameters for additional trials. `HyperParameterTuner` also uses an Optuna `MedianPruner` to stop unpromising trials early.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 General Approach\n",
    "The `HyperParameterTuner` class in the `lstm_adversarial_attack.tune_train` sub-package implements a Stratified K-fold (default K = 5) cross-validation tuning scheme that utilizes the Optuna framework. When defining the dataset indices for each fold, we oversample from samples in the minority class (label = 1) using a For a given set of hyperparameters, the `HyperParameterTUner.objective_fn()` returns the mean validation loss across the K folds, and this mean loss is used as a minimization target by an Optuna `TPESampler` to select new sets of hyperparameters for additional trials. `HyperParameterTuner` also uses an Optuna `MedianPruner` to stop unpromising trials early.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Check for GPU\n",
    "Model hyperparameter tuning (along with training, and model attacks) is implemented in PyTorch, and we really need a GPU to run things in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_device is cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cur_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    cur_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"cur_device is {cur_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Instantiate and Examine TunerDriver\n",
    "We then instantiate a TunerDriver object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_adversarial_attack.tune_train.tuner_driver as td\n",
    "tuner_driver = td.TunerDriver(\n",
    "    device=cur_device,\n",
    "    dataset=dataset,\n",
    "    continue_study_path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE,\n",
    "    output_dir=cfg_paths.ONGOING_TUNING_STUDY_DIR,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `continue_study_path` and `output_dir` arguments passed to the `TunerDriver` constructor will allow us to build upon an existing Optuna study that contains learning from previously run trials. Model hyperparameter tuning is the most time-consuming part of the overall project pipeline, so we usually do not want to start from scratch. (But if you really want to start from scratch, just don't pass either of these path arguments to the `TuneDriver` constructor). For reference, the values of the two path variables we passed to the TunerDriver constructor are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue_study_path = /home/devspace/project/data/hyperparameter_tuning/continued_trials/checkpoints_tuner/optuna_study.pickle\n",
      "output_dir = /home/devspace/project/data/hyperparameter_tuning/continued_trials\n"
     ]
    }
   ],
   "source": [
    "print(f\"continue_study_path = {cfg_paths.ONGOING_TUNING_STUDY_PICKLE}\")\n",
    "print(f\"output_dir = {cfg_paths.ONGOING_TUNING_STUDY_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TunerDriver object has many default parameters/attributes set by values in `cfg_paths` and `cfg_settings`. Note that its `.tuner` attribute is a `HyperParameterTuner` which in turn has a `.tuning_ranges` attribute that specifies our hyperparameter search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuner_driver.tuner is a <class 'lstm_adversarial_attack.tune_train.hyperparameter_tuner.HyperParameterTuner'>\n",
      "\n",
      "tuner_driver.tuner.tuning_ranges:\n",
      "X19MLSTMTuningRanges(log_lstm_hidden_size=(5, 7),\n",
      "                     lstm_act_options=('ReLU', 'Tanh'),\n",
      "                     dropout=(0, 0.5),\n",
      "                     log_fc_hidden_size=(4, 8),\n",
      "                     fc_act_options=('ReLU', 'Tanh'),\n",
      "                     optimizer_options=('Adam', 'RMSprop', 'SGD'),\n",
      "                     learning_rate=(1e-05, 0.1),\n",
      "                     log_batch_size=(5, 8))\n"
     ]
    }
   ],
   "source": [
    "print(f\"The tuner_driver.tuner is a {type(tuner_driver.tuner)}\\n\")\n",
    "print(\"tuner_driver.tuner.tuning_ranges:\")\n",
    "pprint.pprint(tuner_driver.tuner.tuning_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Run the TunerDriver\n",
    "The code in the next cell will run the Tuner Driver (and its associated HyperParameterTuner). Before starting, a few things to note:\n",
    "* Depending your GPU compute power, running the full 30 trials could take 2 - 20 hours.\n",
    "* If the study is stopped early (via CTRL-C or the Jupyter Stop button), learning from whatever trials have completed up to that point will be saved.\n",
    "* While the tuning trials are running, look ahead to the next Markdown cell for instructions on how to monitor progress in Tensorboard (depending on your notebook output settings you may need to scroll down to see that cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completed_study = tuner_driver.run(num_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Monitor Tuning Progress with Tensorboard\n",
    "\n",
    "While we are tuning hyperparameters, we can monitor results in Tensorboard. We can run tensorboard by starting a zsh session inside the project app container, and launching the tensorboard server from there:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app_dev /bin/zsh\n",
    "> tensorboard --logdir=/home/devspace/project/data/hyperparameter_tuning/continued_trials/tensorboard --host=0.0.0.0\n",
    "```\n",
    "Then, in your browser, go to: `http://localhost:6006/`\n",
    "\n",
    "You should see something like the screenshot below.  The x-axis for all plots is epoch number. (Unfortunately, there is no good way to add axis labels in Tensorboard.)\n",
    "\n",
    "In this example we are in the middle of running trial #21. Trial #20 completed the default number of epochs per fold (100). Trial #19 only ran 20 epochs because it was pruned by the Optuna `MeadianPruner`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard_image](images/tensorboard_hyperparameter_tuning.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Select Final Hyperparameters\n",
    "When we are done tuning, we can view our best set of hyperparameters by examining the `Optuna.Study` object from our above tuning run(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best trial result is from trial # 20.\n",
      "\n",
      "The set of hyperparameters from this trial are:\n",
      "{'dropout': 0.029018875280141854,\n",
      " 'fc_act_name': 'Tanh',\n",
      " 'learning_rate': 0.0002784280532512521,\n",
      " 'log_batch_size': 5,\n",
      " 'log_fc_hidden_size': 4,\n",
      " 'log_lstm_hidden_size': 7,\n",
      " 'lstm_act_name': 'Tanh',\n",
      " 'optimizer_name': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "import lstm_adversarial_attack.resource_io as rio\n",
    "study = rio.ResourceImporter().import_pickle_to_object(\n",
    "    path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE\n",
    ")\n",
    "\n",
    "print(f\"The best trial result is from trial # {study.best_trial.number}.\\n\")\n",
    "print(\"The set of hyperparameters from this trial are:\")\n",
    "pprint.pprint(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Evaluate \"Best\" Hyperparamters with More Training Epochs\n",
    "In the above tuning runs, we only run 100 epochs per fold (in the interest of reducing compute requirements). Based on the validation loss and AUC curves, it appears that the performance vs. epochs slope is still reasonably steep at 100 epochs (i.e. we could gain more performance by training longer). We now run another round of Stratified K-fold cross-validation with our best set of parameters with a larger number of epochs.\n",
    "\n",
    "Some caveats about our methodology:\n",
    "* We have used flat cross-validation (as was done in previous studies on this dataset). This method computationally less expensive than nested cross-validation. Flat cross-validation has the potential to overestimate of model performance. In many cases the magnitude of overestimation is small.\n",
    "* By selecting a model based on the smaller number of epochs (100), we favor models that are faster to to train. It is possible that using a larger number of epochs in the tuning runs would have yielded a different (and better) set of \"best\" hyperparameters.\n",
    "\n",
    "We use a CrossValidatorDriver object to run cross-validation with a single set of hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/checkpoints/fold_0\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/tensorboard\n",
      "\n",
      "\n",
      "fold_0, epoch_1, Loss: 0.5776\n",
      "fold_0, epoch_2, Loss: 0.5461\n",
      "fold_0, epoch_3, Loss: 0.5395\n",
      "fold_0, epoch_4, Loss: 0.5279\n",
      "fold_0, epoch_5, Loss: 0.5250\n",
      "fold_0, epoch_6, Loss: 0.5204\n",
      "fold_0, epoch_7, Loss: 0.5127\n",
      "fold_0, epoch_8, Loss: 0.5110\n",
      "fold_0, epoch_9, Loss: 0.5073\n",
      "fold_0, epoch_10, Loss: 0.5035\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4975\n",
      "Accuracy:\t0.8110\n",
      "AUC:\t\t0.8737\n",
      "Precision:\t0.7933\n",
      "Recall:\t\t0.8410\n",
      "F1:\t\t\t0.8165\n",
      "\n",
      "fold_0, epoch_11, Loss: 0.5031\n",
      "fold_0, epoch_12, Loss: 0.4969\n",
      "fold_0, epoch_13, Loss: 0.4954\n",
      "fold_0, epoch_14, Loss: 0.4936\n",
      "fold_0, epoch_15, Loss: 0.4897\n",
      "fold_0, epoch_16, Loss: 0.4881\n",
      "fold_0, epoch_17, Loss: 0.4852\n",
      "fold_0, epoch_18, Loss: 0.4865\n",
      "fold_0, epoch_19, Loss: 0.4831\n",
      "fold_0, epoch_20, Loss: 0.4818\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4688\n",
      "Accuracy:\t0.8409\n",
      "AUC:\t\t0.8921\n",
      "Precision:\t0.8275\n",
      "Recall:\t\t0.8618\n",
      "F1:\t\t\t0.8443\n",
      "\n",
      "fold_0, epoch_21, Loss: 0.4753\n",
      "fold_0, epoch_22, Loss: 0.4817\n",
      "fold_0, epoch_23, Loss: 0.4769\n",
      "fold_0, epoch_24, Loss: 0.4735\n",
      "fold_0, epoch_25, Loss: 0.4716\n",
      "fold_0, epoch_26, Loss: 0.4712\n",
      "fold_0, epoch_27, Loss: 0.4646\n",
      "fold_0, epoch_28, Loss: 0.4651\n",
      "fold_0, epoch_29, Loss: 0.4656\n",
      "fold_0, epoch_30, Loss: 0.4608\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4548\n",
      "Accuracy:\t0.8560\n",
      "AUC:\t\t0.8942\n",
      "Precision:\t0.8283\n",
      "Recall:\t\t0.8978\n",
      "F1:\t\t\t0.8617\n",
      "\n",
      "fold_0, epoch_31, Loss: 0.4570\n",
      "fold_0, epoch_32, Loss: 0.4575\n",
      "fold_0, epoch_33, Loss: 0.4505\n",
      "fold_0, epoch_34, Loss: 0.4544\n",
      "fold_0, epoch_35, Loss: 0.4515\n",
      "fold_0, epoch_36, Loss: 0.4537\n",
      "fold_0, epoch_37, Loss: 0.4486\n",
      "fold_0, epoch_38, Loss: 0.4465\n",
      "fold_0, epoch_39, Loss: 0.4498\n",
      "fold_0, epoch_40, Loss: 0.4437\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4450\n",
      "Accuracy:\t0.8666\n",
      "AUC:\t\t0.8981\n",
      "Precision:\t0.8718\n",
      "Recall:\t\t0.8603\n",
      "F1:\t\t\t0.8660\n",
      "\n",
      "fold_0, epoch_41, Loss: 0.4496\n",
      "fold_0, epoch_42, Loss: 0.4400\n",
      "fold_0, epoch_43, Loss: 0.4406\n",
      "fold_0, epoch_44, Loss: 0.4376\n",
      "fold_0, epoch_45, Loss: 0.4395\n",
      "fold_0, epoch_46, Loss: 0.4372\n",
      "fold_0, epoch_47, Loss: 0.4382\n",
      "fold_0, epoch_48, Loss: 0.4355\n",
      "fold_0, epoch_49, Loss: 0.4314\n",
      "fold_0, epoch_50, Loss: 0.4301\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4308\n",
      "Accuracy:\t0.8803\n",
      "AUC:\t\t0.9044\n",
      "Precision:\t0.8626\n",
      "Recall:\t\t0.9069\n",
      "F1:\t\t\t0.8842\n",
      "\n",
      "fold_0, epoch_51, Loss: 0.4338\n",
      "fold_0, epoch_52, Loss: 0.4310\n",
      "fold_0, epoch_53, Loss: 0.4329\n",
      "fold_0, epoch_54, Loss: 0.4243\n",
      "fold_0, epoch_55, Loss: 0.4254\n",
      "fold_0, epoch_56, Loss: 0.4390\n",
      "fold_0, epoch_57, Loss: 0.4273\n",
      "fold_0, epoch_58, Loss: 0.4326\n",
      "fold_0, epoch_59, Loss: 0.4255\n",
      "fold_0, epoch_60, Loss: 0.4290\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4191\n",
      "Accuracy:\t0.8929\n",
      "AUC:\t\t0.9116\n",
      "Precision:\t0.8740\n",
      "Recall:\t\t0.9171\n",
      "F1:\t\t\t0.8950\n",
      "\n",
      "fold_0, epoch_61, Loss: 0.4285\n",
      "fold_0, epoch_62, Loss: 0.4271\n",
      "fold_0, epoch_63, Loss: 0.4219\n",
      "fold_0, epoch_64, Loss: 0.4265\n",
      "fold_0, epoch_65, Loss: 0.4240\n",
      "fold_0, epoch_66, Loss: 0.4205\n",
      "fold_0, epoch_67, Loss: 0.4137\n",
      "fold_0, epoch_68, Loss: 0.4186\n",
      "fold_0, epoch_69, Loss: 0.4161\n",
      "fold_0, epoch_70, Loss: 0.4136\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4183\n",
      "Accuracy:\t0.8937\n",
      "AUC:\t\t0.9116\n",
      "Precision:\t0.8787\n",
      "Recall:\t\t0.9127\n",
      "F1:\t\t\t0.8954\n",
      "\n",
      "fold_0, epoch_71, Loss: 0.4256\n",
      "fold_0, epoch_72, Loss: 0.4156\n",
      "fold_0, epoch_73, Loss: 0.4140\n",
      "fold_0, epoch_74, Loss: 0.4150\n",
      "fold_0, epoch_75, Loss: 0.4125\n",
      "fold_0, epoch_76, Loss: 0.4120\n",
      "fold_0, epoch_77, Loss: 0.4103\n",
      "fold_0, epoch_78, Loss: 0.4115\n",
      "fold_0, epoch_79, Loss: 0.4087\n",
      "fold_0, epoch_80, Loss: 0.4136\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4195\n",
      "Accuracy:\t0.8930\n",
      "AUC:\t\t0.9110\n",
      "Precision:\t0.8707\n",
      "Recall:\t\t0.9220\n",
      "F1:\t\t\t0.8956\n",
      "\n",
      "fold_0, epoch_81, Loss: 0.4160\n",
      "fold_0, epoch_82, Loss: 0.4092\n",
      "fold_0, epoch_83, Loss: 0.4081\n",
      "fold_0, epoch_84, Loss: 0.4088\n",
      "fold_0, epoch_85, Loss: 0.4127\n",
      "fold_0, epoch_86, Loss: 0.4144\n",
      "fold_0, epoch_87, Loss: 0.4092\n",
      "fold_0, epoch_88, Loss: 0.4122\n",
      "fold_0, epoch_89, Loss: 0.4059\n",
      "fold_0, epoch_90, Loss: 0.4061\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4019\n",
      "Accuracy:\t0.9108\n",
      "AUC:\t\t0.9237\n",
      "Precision:\t0.9085\n",
      "Recall:\t\t0.9135\n",
      "F1:\t\t\t0.9110\n",
      "\n",
      "fold_0, epoch_91, Loss: 0.4063\n",
      "fold_0, epoch_92, Loss: 0.4031\n",
      "fold_0, epoch_93, Loss: 0.4116\n",
      "fold_0, epoch_94, Loss: 0.4026\n",
      "fold_0, epoch_95, Loss: 0.4009\n",
      "fold_0, epoch_96, Loss: 0.4009\n",
      "fold_0, epoch_97, Loss: 0.4001\n",
      "fold_0, epoch_98, Loss: 0.3977\n",
      "fold_0, epoch_99, Loss: 0.3978\n",
      "fold_0, epoch_100, Loss: 0.4037\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.4062\n",
      "Accuracy:\t0.9051\n",
      "AUC:\t\t0.9258\n",
      "Precision:\t0.9239\n",
      "Recall:\t\t0.8839\n",
      "F1:\t\t\t0.9035\n",
      "\n",
      "fold_0, epoch_101, Loss: 0.4044\n",
      "fold_0, epoch_102, Loss: 0.3973\n",
      "fold_0, epoch_103, Loss: 0.3964\n",
      "fold_0, epoch_104, Loss: 0.4000\n",
      "fold_0, epoch_105, Loss: 0.3970\n",
      "fold_0, epoch_106, Loss: 0.4052\n",
      "fold_0, epoch_107, Loss: 0.3994\n",
      "fold_0, epoch_108, Loss: 0.3984\n",
      "fold_0, epoch_109, Loss: 0.3956\n",
      "fold_0, epoch_110, Loss: 0.3934\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3910\n",
      "Accuracy:\t0.9218\n",
      "AUC:\t\t0.9283\n",
      "Precision:\t0.9210\n",
      "Recall:\t\t0.9224\n",
      "F1:\t\t\t0.9217\n",
      "\n",
      "fold_0, epoch_111, Loss: 0.4004\n",
      "fold_0, epoch_112, Loss: 0.3991\n",
      "fold_0, epoch_113, Loss: 0.3984\n",
      "fold_0, epoch_114, Loss: 0.3980\n",
      "fold_0, epoch_115, Loss: 0.3952\n",
      "fold_0, epoch_116, Loss: 0.3933\n",
      "fold_0, epoch_117, Loss: 0.3938\n",
      "fold_0, epoch_118, Loss: 0.3931\n",
      "fold_0, epoch_119, Loss: 0.3895\n",
      "fold_0, epoch_120, Loss: 0.3948\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3986\n",
      "Accuracy:\t0.9133\n",
      "AUC:\t\t0.9292\n",
      "Precision:\t0.9028\n",
      "Recall:\t\t0.9271\n",
      "F1:\t\t\t0.9148\n",
      "\n",
      "fold_0, epoch_121, Loss: 0.3913\n",
      "fold_0, epoch_122, Loss: 0.3915\n",
      "fold_0, epoch_123, Loss: 0.3871\n",
      "fold_0, epoch_124, Loss: 0.3897\n",
      "fold_0, epoch_125, Loss: 0.3883\n",
      "fold_0, epoch_126, Loss: 0.3930\n",
      "fold_0, epoch_127, Loss: 0.3893\n",
      "fold_0, epoch_128, Loss: 0.3875\n",
      "fold_0, epoch_129, Loss: 0.3883\n",
      "fold_0, epoch_130, Loss: 0.3847\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3814\n",
      "Accuracy:\t0.9308\n",
      "AUC:\t\t0.9399\n",
      "Precision:\t0.9389\n",
      "Recall:\t\t0.9222\n",
      "F1:\t\t\t0.9305\n",
      "\n",
      "fold_0, epoch_131, Loss: 0.3900\n",
      "fold_0, epoch_132, Loss: 0.3902\n",
      "fold_0, epoch_133, Loss: 0.3920\n",
      "fold_0, epoch_134, Loss: 0.3965\n",
      "fold_0, epoch_135, Loss: 0.3912\n",
      "fold_0, epoch_136, Loss: 0.3855\n",
      "fold_0, epoch_137, Loss: 0.3858\n",
      "fold_0, epoch_138, Loss: 0.3930\n",
      "fold_0, epoch_139, Loss: 0.3873\n",
      "fold_0, epoch_140, Loss: 0.3836\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3932\n",
      "Accuracy:\t0.9192\n",
      "AUC:\t\t0.9356\n",
      "Precision:\t0.9403\n",
      "Recall:\t\t0.8965\n",
      "F1:\t\t\t0.9179\n",
      "\n",
      "fold_0, epoch_141, Loss: 0.3917\n",
      "fold_0, epoch_142, Loss: 0.3895\n",
      "fold_0, epoch_143, Loss: 0.3892\n",
      "fold_0, epoch_144, Loss: 0.3915\n",
      "fold_0, epoch_145, Loss: 0.3820\n",
      "fold_0, epoch_146, Loss: 0.3860\n",
      "fold_0, epoch_147, Loss: 0.3841\n",
      "fold_0, epoch_148, Loss: 0.3834\n",
      "fold_0, epoch_149, Loss: 0.3816\n",
      "fold_0, epoch_150, Loss: 0.3839\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3859\n",
      "Accuracy:\t0.9265\n",
      "AUC:\t\t0.9373\n",
      "Precision:\t0.9413\n",
      "Recall:\t\t0.9095\n",
      "F1:\t\t\t0.9251\n",
      "\n",
      "fold_0, epoch_151, Loss: 0.3827\n",
      "fold_0, epoch_152, Loss: 0.3791\n",
      "fold_0, epoch_153, Loss: 0.3836\n",
      "fold_0, epoch_154, Loss: 0.3866\n",
      "fold_0, epoch_155, Loss: 0.3826\n",
      "fold_0, epoch_156, Loss: 0.3821\n",
      "fold_0, epoch_157, Loss: 0.3818\n",
      "fold_0, epoch_158, Loss: 0.3882\n",
      "fold_0, epoch_159, Loss: 0.3813\n",
      "fold_0, epoch_160, Loss: 0.3759\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3798\n",
      "Accuracy:\t0.9332\n",
      "AUC:\t\t0.9383\n",
      "Precision:\t0.9393\n",
      "Recall:\t\t0.9259\n",
      "F1:\t\t\t0.9326\n",
      "\n",
      "fold_0, epoch_161, Loss: 0.3869\n",
      "fold_0, epoch_162, Loss: 0.3826\n",
      "fold_0, epoch_163, Loss: 0.3972\n",
      "fold_0, epoch_164, Loss: 0.3860\n",
      "fold_0, epoch_165, Loss: 0.3820\n",
      "fold_0, epoch_166, Loss: 0.3819\n",
      "fold_0, epoch_167, Loss: 0.3815\n",
      "fold_0, epoch_168, Loss: 0.3816\n",
      "fold_0, epoch_169, Loss: 0.3796\n",
      "fold_0, epoch_170, Loss: 0.3790\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3830\n",
      "Accuracy:\t0.9299\n",
      "AUC:\t\t0.9396\n",
      "Precision:\t0.9418\n",
      "Recall:\t\t0.9165\n",
      "F1:\t\t\t0.9290\n",
      "\n",
      "fold_0, epoch_171, Loss: 0.3794\n",
      "fold_0, epoch_172, Loss: 0.3782\n",
      "fold_0, epoch_173, Loss: 0.3803\n",
      "fold_0, epoch_174, Loss: 0.3805\n",
      "fold_0, epoch_175, Loss: 0.3875\n",
      "fold_0, epoch_176, Loss: 0.3788\n",
      "fold_0, epoch_177, Loss: 0.3735\n",
      "fold_0, epoch_178, Loss: 0.3773\n",
      "fold_0, epoch_179, Loss: 0.3828\n",
      "fold_0, epoch_180, Loss: 0.3795\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3739\n",
      "Accuracy:\t0.9389\n",
      "AUC:\t\t0.9444\n",
      "Precision:\t0.9448\n",
      "Recall:\t\t0.9332\n",
      "F1:\t\t\t0.9390\n",
      "\n",
      "fold_0, epoch_181, Loss: 0.3811\n",
      "fold_0, epoch_182, Loss: 0.3793\n",
      "fold_0, epoch_183, Loss: 0.3744\n",
      "fold_0, epoch_184, Loss: 0.3774\n",
      "fold_0, epoch_185, Loss: 0.3773\n",
      "fold_0, epoch_186, Loss: 0.3727\n",
      "fold_0, epoch_187, Loss: 0.3758\n",
      "fold_0, epoch_188, Loss: 0.3783\n",
      "fold_0, epoch_189, Loss: 0.3794\n",
      "fold_0, epoch_190, Loss: 0.3757\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3757\n",
      "Accuracy:\t0.9368\n",
      "AUC:\t\t0.9451\n",
      "Precision:\t0.9405\n",
      "Recall:\t\t0.9331\n",
      "F1:\t\t\t0.9367\n",
      "\n",
      "fold_0, epoch_191, Loss: 0.3743\n",
      "fold_0, epoch_192, Loss: 0.3727\n",
      "fold_0, epoch_193, Loss: 0.3737\n",
      "fold_0, epoch_194, Loss: 0.3713\n",
      "fold_0, epoch_195, Loss: 0.3742\n",
      "fold_0, epoch_196, Loss: 0.3768\n",
      "fold_0, epoch_197, Loss: 0.3726\n",
      "fold_0, epoch_198, Loss: 0.3705\n",
      "fold_0, epoch_199, Loss: 0.3732\n",
      "fold_0, epoch_200, Loss: 0.3736\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3729\n",
      "Accuracy:\t0.9402\n",
      "AUC:\t\t0.9451\n",
      "Precision:\t0.9499\n",
      "Recall:\t\t0.9295\n",
      "F1:\t\t\t0.9396\n",
      "\n",
      "fold_0, epoch_201, Loss: 0.3774\n",
      "fold_0, epoch_202, Loss: 0.3706\n",
      "fold_0, epoch_203, Loss: 0.3754\n",
      "fold_0, epoch_204, Loss: 0.3753\n",
      "fold_0, epoch_205, Loss: 0.3691\n",
      "fold_0, epoch_206, Loss: 0.3721\n",
      "fold_0, epoch_207, Loss: 0.3720\n",
      "fold_0, epoch_208, Loss: 0.3724\n",
      "fold_0, epoch_209, Loss: 0.3766\n",
      "fold_0, epoch_210, Loss: 0.3713\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3739\n",
      "Accuracy:\t0.9389\n",
      "AUC:\t\t0.9467\n",
      "Precision:\t0.9544\n",
      "Recall:\t\t0.9233\n",
      "F1:\t\t\t0.9386\n",
      "\n",
      "fold_0, epoch_211, Loss: 0.3712\n",
      "fold_0, epoch_212, Loss: 0.3710\n",
      "fold_0, epoch_213, Loss: 0.3678\n",
      "fold_0, epoch_214, Loss: 0.3728\n",
      "fold_0, epoch_215, Loss: 0.3696\n",
      "fold_0, epoch_216, Loss: 0.3723\n",
      "fold_0, epoch_217, Loss: 0.3685\n",
      "fold_0, epoch_218, Loss: 0.3729\n",
      "fold_0, epoch_219, Loss: 0.3695\n",
      "fold_0, epoch_220, Loss: 0.3711\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3748\n",
      "Accuracy:\t0.9378\n",
      "AUC:\t\t0.9445\n",
      "Precision:\t0.9497\n",
      "Recall:\t\t0.9242\n",
      "F1:\t\t\t0.9367\n",
      "\n",
      "fold_0, epoch_221, Loss: 0.3734\n",
      "fold_0, epoch_222, Loss: 0.3698\n",
      "fold_0, epoch_223, Loss: 0.3697\n",
      "fold_0, epoch_224, Loss: 0.3805\n",
      "fold_0, epoch_225, Loss: 0.3734\n",
      "fold_0, epoch_226, Loss: 0.3716\n",
      "fold_0, epoch_227, Loss: 0.3703\n",
      "fold_0, epoch_228, Loss: 0.3679\n",
      "fold_0, epoch_229, Loss: 0.3717\n",
      "fold_0, epoch_230, Loss: 0.3698\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3758\n",
      "Accuracy:\t0.9373\n",
      "AUC:\t\t0.9452\n",
      "Precision:\t0.9512\n",
      "Recall:\t\t0.9224\n",
      "F1:\t\t\t0.9366\n",
      "\n",
      "fold_0, epoch_231, Loss: 0.3733\n",
      "fold_0, epoch_232, Loss: 0.3662\n",
      "fold_0, epoch_233, Loss: 0.3677\n",
      "fold_0, epoch_234, Loss: 0.3693\n",
      "fold_0, epoch_235, Loss: 0.3682\n",
      "fold_0, epoch_236, Loss: 0.3695\n",
      "fold_0, epoch_237, Loss: 0.3685\n",
      "fold_0, epoch_238, Loss: 0.3688\n",
      "fold_0, epoch_239, Loss: 0.3667\n",
      "fold_0, epoch_240, Loss: 0.3641\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3683\n",
      "Accuracy:\t0.9447\n",
      "AUC:\t\t0.9511\n",
      "Precision:\t0.9594\n",
      "Recall:\t\t0.9282\n",
      "F1:\t\t\t0.9435\n",
      "\n",
      "fold_0, epoch_241, Loss: 0.3709\n",
      "fold_0, epoch_242, Loss: 0.3696\n",
      "fold_0, epoch_243, Loss: 0.3667\n",
      "fold_0, epoch_244, Loss: 0.3650\n",
      "fold_0, epoch_245, Loss: 0.3691\n",
      "fold_0, epoch_246, Loss: 0.3682\n",
      "fold_0, epoch_247, Loss: 0.3696\n",
      "fold_0, epoch_248, Loss: 0.3657\n",
      "fold_0, epoch_249, Loss: 0.3654\n",
      "fold_0, epoch_250, Loss: 0.3633\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3695\n",
      "Accuracy:\t0.9434\n",
      "AUC:\t\t0.9490\n",
      "Precision:\t0.9509\n",
      "Recall:\t\t0.9364\n",
      "F1:\t\t\t0.9436\n",
      "\n",
      "fold_0, epoch_251, Loss: 0.3681\n",
      "fold_0, epoch_252, Loss: 0.3654\n",
      "fold_0, epoch_253, Loss: 0.3664\n",
      "fold_0, epoch_254, Loss: 0.3664\n",
      "fold_0, epoch_255, Loss: 0.3652\n",
      "fold_0, epoch_256, Loss: 0.3657\n",
      "fold_0, epoch_257, Loss: 0.3668\n",
      "fold_0, epoch_258, Loss: 0.3630\n",
      "fold_0, epoch_259, Loss: 0.3644\n",
      "fold_0, epoch_260, Loss: 0.3649\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3622\n",
      "Accuracy:\t0.9507\n",
      "AUC:\t\t0.9504\n",
      "Precision:\t0.9631\n",
      "Recall:\t\t0.9384\n",
      "F1:\t\t\t0.9506\n",
      "\n",
      "fold_0, epoch_261, Loss: 0.3661\n",
      "fold_0, epoch_262, Loss: 0.3683\n",
      "fold_0, epoch_263, Loss: 0.3699\n",
      "fold_0, epoch_264, Loss: 0.3672\n",
      "fold_0, epoch_265, Loss: 0.3652\n",
      "fold_0, epoch_266, Loss: 0.3674\n",
      "fold_0, epoch_267, Loss: 0.3647\n",
      "fold_0, epoch_268, Loss: 0.3661\n",
      "fold_0, epoch_269, Loss: 0.3664\n",
      "fold_0, epoch_270, Loss: 0.3623\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3632\n",
      "Accuracy:\t0.9500\n",
      "AUC:\t\t0.9526\n",
      "Precision:\t0.9589\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9496\n",
      "\n",
      "fold_0, epoch_271, Loss: 0.3631\n",
      "fold_0, epoch_272, Loss: 0.3666\n",
      "fold_0, epoch_273, Loss: 0.3639\n",
      "fold_0, epoch_274, Loss: 0.3641\n",
      "fold_0, epoch_275, Loss: 0.3675\n",
      "fold_0, epoch_276, Loss: 0.3654\n",
      "fold_0, epoch_277, Loss: 0.3692\n",
      "fold_0, epoch_278, Loss: 0.3611\n",
      "fold_0, epoch_279, Loss: 0.3630\n",
      "fold_0, epoch_280, Loss: 0.3663\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3674\n",
      "Accuracy:\t0.9455\n",
      "AUC:\t\t0.9516\n",
      "Precision:\t0.9570\n",
      "Recall:\t\t0.9335\n",
      "F1:\t\t\t0.9451\n",
      "\n",
      "fold_0, epoch_281, Loss: 0.3640\n",
      "fold_0, epoch_282, Loss: 0.3637\n",
      "fold_0, epoch_283, Loss: 0.3623\n",
      "fold_0, epoch_284, Loss: 0.3690\n",
      "fold_0, epoch_285, Loss: 0.3660\n",
      "fold_0, epoch_286, Loss: 0.3675\n",
      "fold_0, epoch_287, Loss: 0.3624\n",
      "fold_0, epoch_288, Loss: 0.3621\n",
      "fold_0, epoch_289, Loss: 0.3660\n",
      "fold_0, epoch_290, Loss: 0.3604\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3591\n",
      "Accuracy:\t0.9539\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9679\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9528\n",
      "\n",
      "fold_0, epoch_291, Loss: 0.3615\n",
      "fold_0, epoch_292, Loss: 0.3630\n",
      "fold_0, epoch_293, Loss: 0.3631\n",
      "fold_0, epoch_294, Loss: 0.3659\n",
      "fold_0, epoch_295, Loss: 0.3591\n",
      "fold_0, epoch_296, Loss: 0.3597\n",
      "fold_0, epoch_297, Loss: 0.3618\n",
      "fold_0, epoch_298, Loss: 0.3630\n",
      "fold_0, epoch_299, Loss: 0.3670\n",
      "fold_0, epoch_300, Loss: 0.3659\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3642\n",
      "Accuracy:\t0.9488\n",
      "AUC:\t\t0.9539\n",
      "Precision:\t0.9560\n",
      "Recall:\t\t0.9403\n",
      "F1:\t\t\t0.9481\n",
      "\n",
      "fold_0, epoch_301, Loss: 0.3596\n",
      "fold_0, epoch_302, Loss: 0.3585\n",
      "fold_0, epoch_303, Loss: 0.3647\n",
      "fold_0, epoch_304, Loss: 0.3633\n",
      "fold_0, epoch_305, Loss: 0.3615\n",
      "fold_0, epoch_306, Loss: 0.3632\n",
      "fold_0, epoch_307, Loss: 0.3648\n",
      "fold_0, epoch_308, Loss: 0.3601\n",
      "fold_0, epoch_309, Loss: 0.3612\n",
      "fold_0, epoch_310, Loss: 0.3629\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3655\n",
      "Accuracy:\t0.9473\n",
      "AUC:\t\t0.9538\n",
      "Precision:\t0.9621\n",
      "Recall:\t\t0.9312\n",
      "F1:\t\t\t0.9464\n",
      "\n",
      "fold_0, epoch_311, Loss: 0.3634\n",
      "fold_0, epoch_312, Loss: 0.3663\n",
      "fold_0, epoch_313, Loss: 0.3616\n",
      "fold_0, epoch_314, Loss: 0.3588\n",
      "fold_0, epoch_315, Loss: 0.3630\n",
      "fold_0, epoch_316, Loss: 0.3609\n",
      "fold_0, epoch_317, Loss: 0.3638\n",
      "fold_0, epoch_318, Loss: 0.3603\n",
      "fold_0, epoch_319, Loss: 0.3596\n",
      "fold_0, epoch_320, Loss: 0.3605\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3596\n",
      "Accuracy:\t0.9536\n",
      "AUC:\t\t0.9561\n",
      "Precision:\t0.9701\n",
      "Recall:\t\t0.9373\n",
      "F1:\t\t\t0.9534\n",
      "\n",
      "fold_0, epoch_321, Loss: 0.3630\n",
      "fold_0, epoch_322, Loss: 0.3616\n",
      "fold_0, epoch_323, Loss: 0.3610\n",
      "fold_0, epoch_324, Loss: 0.3614\n",
      "fold_0, epoch_325, Loss: 0.3603\n",
      "fold_0, epoch_326, Loss: 0.3609\n",
      "fold_0, epoch_327, Loss: 0.3618\n",
      "fold_0, epoch_328, Loss: 0.3614\n",
      "fold_0, epoch_329, Loss: 0.3626\n",
      "fold_0, epoch_330, Loss: 0.3637\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3604\n",
      "Accuracy:\t0.9525\n",
      "AUC:\t\t0.9548\n",
      "Precision:\t0.9647\n",
      "Recall:\t\t0.9383\n",
      "F1:\t\t\t0.9513\n",
      "\n",
      "fold_0, epoch_331, Loss: 0.3613\n",
      "fold_0, epoch_332, Loss: 0.3588\n",
      "fold_0, epoch_333, Loss: 0.3615\n",
      "fold_0, epoch_334, Loss: 0.3589\n",
      "fold_0, epoch_335, Loss: 0.3578\n",
      "fold_0, epoch_336, Loss: 0.3587\n",
      "fold_0, epoch_337, Loss: 0.3586\n",
      "fold_0, epoch_338, Loss: 0.3590\n",
      "fold_0, epoch_339, Loss: 0.3586\n",
      "fold_0, epoch_340, Loss: 0.3605\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3587\n",
      "Accuracy:\t0.9546\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9736\n",
      "Recall:\t\t0.9342\n",
      "F1:\t\t\t0.9535\n",
      "\n",
      "fold_0, epoch_341, Loss: 0.3598\n",
      "fold_0, epoch_342, Loss: 0.3592\n",
      "fold_0, epoch_343, Loss: 0.3590\n",
      "fold_0, epoch_344, Loss: 0.3597\n",
      "fold_0, epoch_345, Loss: 0.3587\n",
      "fold_0, epoch_346, Loss: 0.3637\n",
      "fold_0, epoch_347, Loss: 0.3583\n",
      "fold_0, epoch_348, Loss: 0.3586\n",
      "fold_0, epoch_349, Loss: 0.3570\n",
      "fold_0, epoch_350, Loss: 0.3610\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3578\n",
      "Accuracy:\t0.9552\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9682\n",
      "Recall:\t\t0.9407\n",
      "F1:\t\t\t0.9542\n",
      "\n",
      "fold_0, epoch_351, Loss: 0.3581\n",
      "fold_0, epoch_352, Loss: 0.3564\n",
      "fold_0, epoch_353, Loss: 0.3574\n",
      "fold_0, epoch_354, Loss: 0.3581\n",
      "fold_0, epoch_355, Loss: 0.3570\n",
      "fold_0, epoch_356, Loss: 0.3610\n",
      "fold_0, epoch_357, Loss: 0.3595\n",
      "fold_0, epoch_358, Loss: 0.3608\n",
      "fold_0, epoch_359, Loss: 0.3608\n",
      "fold_0, epoch_360, Loss: 0.3613\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3623\n",
      "Accuracy:\t0.9506\n",
      "AUC:\t\t0.9543\n",
      "Precision:\t0.9615\n",
      "Recall:\t\t0.9393\n",
      "F1:\t\t\t0.9503\n",
      "\n",
      "fold_0, epoch_361, Loss: 0.3587\n",
      "fold_0, epoch_362, Loss: 0.3595\n",
      "fold_0, epoch_363, Loss: 0.3554\n",
      "fold_0, epoch_364, Loss: 0.3581\n",
      "fold_0, epoch_365, Loss: 0.3567\n",
      "fold_0, epoch_366, Loss: 0.3565\n",
      "fold_0, epoch_367, Loss: 0.3618\n",
      "fold_0, epoch_368, Loss: 0.3636\n",
      "fold_0, epoch_369, Loss: 0.3582\n",
      "fold_0, epoch_370, Loss: 0.3558\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3629\n",
      "Accuracy:\t0.9501\n",
      "AUC:\t\t0.9543\n",
      "Precision:\t0.9676\n",
      "Recall:\t\t0.9311\n",
      "F1:\t\t\t0.9490\n",
      "\n",
      "fold_0, epoch_371, Loss: 0.3635\n",
      "fold_0, epoch_372, Loss: 0.3558\n",
      "fold_0, epoch_373, Loss: 0.3589\n",
      "fold_0, epoch_374, Loss: 0.3597\n",
      "fold_0, epoch_375, Loss: 0.3571\n",
      "fold_0, epoch_376, Loss: 0.3654\n",
      "fold_0, epoch_377, Loss: 0.3579\n",
      "fold_0, epoch_378, Loss: 0.3593\n",
      "fold_0, epoch_379, Loss: 0.3541\n",
      "fold_0, epoch_380, Loss: 0.3560\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3575\n",
      "Accuracy:\t0.9555\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9681\n",
      "Recall:\t\t0.9418\n",
      "F1:\t\t\t0.9548\n",
      "\n",
      "fold_0, epoch_381, Loss: 0.3580\n",
      "fold_0, epoch_382, Loss: 0.3571\n",
      "fold_0, epoch_383, Loss: 0.3561\n",
      "fold_0, epoch_384, Loss: 0.3565\n",
      "fold_0, epoch_385, Loss: 0.3560\n",
      "fold_0, epoch_386, Loss: 0.3565\n",
      "fold_0, epoch_387, Loss: 0.3561\n",
      "fold_0, epoch_388, Loss: 0.3590\n",
      "fold_0, epoch_389, Loss: 0.3604\n",
      "fold_0, epoch_390, Loss: 0.3587\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3572\n",
      "Accuracy:\t0.9560\n",
      "AUC:\t\t0.9572\n",
      "Precision:\t0.9714\n",
      "Recall:\t\t0.9395\n",
      "F1:\t\t\t0.9552\n",
      "\n",
      "fold_0, epoch_391, Loss: 0.3563\n",
      "fold_0, epoch_392, Loss: 0.3573\n",
      "fold_0, epoch_393, Loss: 0.3569\n",
      "fold_0, epoch_394, Loss: 0.3554\n",
      "fold_0, epoch_395, Loss: 0.3545\n",
      "fold_0, epoch_396, Loss: 0.3594\n",
      "fold_0, epoch_397, Loss: 0.3574\n",
      "fold_0, epoch_398, Loss: 0.3555\n",
      "fold_0, epoch_399, Loss: 0.3563\n",
      "fold_0, epoch_400, Loss: 0.3567\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3558\n",
      "Accuracy:\t0.9572\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9763\n",
      "Recall:\t\t0.9372\n",
      "F1:\t\t\t0.9564\n",
      "\n",
      "fold_0, epoch_401, Loss: 0.3542\n",
      "fold_0, epoch_402, Loss: 0.3550\n",
      "fold_0, epoch_403, Loss: 0.3553\n",
      "fold_0, epoch_404, Loss: 0.3585\n",
      "fold_0, epoch_405, Loss: 0.3579\n",
      "fold_0, epoch_406, Loss: 0.3550\n",
      "fold_0, epoch_407, Loss: 0.3523\n",
      "fold_0, epoch_408, Loss: 0.3595\n",
      "fold_0, epoch_409, Loss: 0.3562\n",
      "fold_0, epoch_410, Loss: 0.3591\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3574\n",
      "Accuracy:\t0.9558\n",
      "AUC:\t\t0.9571\n",
      "Precision:\t0.9691\n",
      "Recall:\t\t0.9415\n",
      "F1:\t\t\t0.9551\n",
      "\n",
      "fold_0, epoch_411, Loss: 0.3556\n",
      "fold_0, epoch_412, Loss: 0.3570\n",
      "fold_0, epoch_413, Loss: 0.3540\n",
      "fold_0, epoch_414, Loss: 0.3549\n",
      "fold_0, epoch_415, Loss: 0.3619\n",
      "fold_0, epoch_416, Loss: 0.3555\n",
      "fold_0, epoch_417, Loss: 0.3562\n",
      "fold_0, epoch_418, Loss: 0.3562\n",
      "fold_0, epoch_419, Loss: 0.3561\n",
      "fold_0, epoch_420, Loss: 0.3548\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3523\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9757\n",
      "Recall:\t\t0.9447\n",
      "F1:\t\t\t0.9600\n",
      "\n",
      "fold_0, epoch_421, Loss: 0.3548\n",
      "fold_0, epoch_422, Loss: 0.3565\n",
      "fold_0, epoch_423, Loss: 0.3557\n",
      "fold_0, epoch_424, Loss: 0.3542\n",
      "fold_0, epoch_425, Loss: 0.3564\n",
      "fold_0, epoch_426, Loss: 0.3529\n",
      "fold_0, epoch_427, Loss: 0.3531\n",
      "fold_0, epoch_428, Loss: 0.3553\n",
      "fold_0, epoch_429, Loss: 0.3589\n",
      "fold_0, epoch_430, Loss: 0.3556\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9614\n",
      "AUC:\t\t0.9614\n",
      "Precision:\t0.9745\n",
      "Recall:\t\t0.9479\n",
      "F1:\t\t\t0.9610\n",
      "\n",
      "fold_0, epoch_431, Loss: 0.3575\n",
      "fold_0, epoch_432, Loss: 0.3542\n",
      "fold_0, epoch_433, Loss: 0.3550\n",
      "fold_0, epoch_434, Loss: 0.3541\n",
      "fold_0, epoch_435, Loss: 0.3553\n",
      "fold_0, epoch_436, Loss: 0.3557\n",
      "fold_0, epoch_437, Loss: 0.3543\n",
      "fold_0, epoch_438, Loss: 0.3565\n",
      "fold_0, epoch_439, Loss: 0.3532\n",
      "fold_0, epoch_440, Loss: 0.3555\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3540\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9596\n",
      "Precision:\t0.9764\n",
      "Recall:\t\t0.9403\n",
      "F1:\t\t\t0.9580\n",
      "\n",
      "fold_0, epoch_441, Loss: 0.3525\n",
      "fold_0, epoch_442, Loss: 0.3557\n",
      "fold_0, epoch_443, Loss: 0.3555\n",
      "fold_0, epoch_444, Loss: 0.3548\n",
      "fold_0, epoch_445, Loss: 0.3532\n",
      "fold_0, epoch_446, Loss: 0.3577\n",
      "fold_0, epoch_447, Loss: 0.3526\n",
      "fold_0, epoch_448, Loss: 0.3534\n",
      "fold_0, epoch_449, Loss: 0.3560\n",
      "fold_0, epoch_450, Loss: 0.3582\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3557\n",
      "Accuracy:\t0.9574\n",
      "AUC:\t\t0.9593\n",
      "Precision:\t0.9761\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9568\n",
      "\n",
      "fold_0, epoch_451, Loss: 0.3563\n",
      "fold_0, epoch_452, Loss: 0.3536\n",
      "fold_0, epoch_453, Loss: 0.3536\n",
      "fold_0, epoch_454, Loss: 0.3524\n",
      "fold_0, epoch_455, Loss: 0.3556\n",
      "fold_0, epoch_456, Loss: 0.3546\n",
      "fold_0, epoch_457, Loss: 0.3531\n",
      "fold_0, epoch_458, Loss: 0.3571\n",
      "fold_0, epoch_459, Loss: 0.3554\n",
      "fold_0, epoch_460, Loss: 0.3548\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3502\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9612\n",
      "Precision:\t0.9781\n",
      "Recall:\t\t0.9474\n",
      "F1:\t\t\t0.9625\n",
      "\n",
      "fold_0, epoch_461, Loss: 0.3558\n",
      "fold_0, epoch_462, Loss: 0.3516\n",
      "fold_0, epoch_463, Loss: 0.3537\n",
      "fold_0, epoch_464, Loss: 0.3559\n",
      "fold_0, epoch_465, Loss: 0.3528\n",
      "fold_0, epoch_466, Loss: 0.3546\n",
      "fold_0, epoch_467, Loss: 0.3582\n",
      "fold_0, epoch_468, Loss: 0.3581\n",
      "fold_0, epoch_469, Loss: 0.3537\n",
      "fold_0, epoch_470, Loss: 0.3551\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3500\n",
      "Accuracy:\t0.9632\n",
      "AUC:\t\t0.9623\n",
      "Precision:\t0.9776\n",
      "Recall:\t\t0.9482\n",
      "F1:\t\t\t0.9627\n",
      "\n",
      "fold_0, epoch_471, Loss: 0.3540\n",
      "fold_0, epoch_472, Loss: 0.3554\n",
      "fold_0, epoch_473, Loss: 0.3511\n",
      "fold_0, epoch_474, Loss: 0.3544\n",
      "fold_0, epoch_475, Loss: 0.3530\n",
      "fold_0, epoch_476, Loss: 0.3540\n",
      "fold_0, epoch_477, Loss: 0.3550\n",
      "fold_0, epoch_478, Loss: 0.3534\n",
      "fold_0, epoch_479, Loss: 0.3524\n",
      "fold_0, epoch_480, Loss: 0.3529\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3515\n",
      "Accuracy:\t0.9616\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9758\n",
      "Recall:\t\t0.9456\n",
      "F1:\t\t\t0.9604\n",
      "\n",
      "fold_0, epoch_481, Loss: 0.3519\n",
      "fold_0, epoch_482, Loss: 0.3552\n",
      "fold_0, epoch_483, Loss: 0.3515\n",
      "fold_0, epoch_484, Loss: 0.3527\n",
      "fold_0, epoch_485, Loss: 0.3549\n",
      "fold_0, epoch_486, Loss: 0.3520\n",
      "fold_0, epoch_487, Loss: 0.3519\n",
      "fold_0, epoch_488, Loss: 0.3533\n",
      "fold_0, epoch_489, Loss: 0.3529\n",
      "fold_0, epoch_490, Loss: 0.3561\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3549\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9798\n",
      "Recall:\t\t0.9359\n",
      "F1:\t\t\t0.9574\n",
      "\n",
      "fold_0, epoch_491, Loss: 0.3524\n",
      "fold_0, epoch_492, Loss: 0.3529\n",
      "fold_0, epoch_493, Loss: 0.3526\n",
      "fold_0, epoch_494, Loss: 0.3507\n",
      "fold_0, epoch_495, Loss: 0.3544\n",
      "fold_0, epoch_496, Loss: 0.3514\n",
      "fold_0, epoch_497, Loss: 0.3540\n",
      "fold_0, epoch_498, Loss: 0.3524\n",
      "fold_0, epoch_499, Loss: 0.3562\n",
      "fold_0, epoch_500, Loss: 0.3575\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3543\n",
      "Accuracy:\t0.9586\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9745\n",
      "Recall:\t\t0.9415\n",
      "F1:\t\t\t0.9577\n",
      "\n",
      "fold_0, epoch_501, Loss: 0.3520\n",
      "fold_0, epoch_502, Loss: 0.3530\n",
      "fold_0, epoch_503, Loss: 0.3494\n",
      "fold_0, epoch_504, Loss: 0.3524\n",
      "fold_0, epoch_505, Loss: 0.3540\n",
      "fold_0, epoch_506, Loss: 0.3497\n",
      "fold_0, epoch_507, Loss: 0.3530\n",
      "fold_0, epoch_508, Loss: 0.3520\n",
      "fold_0, epoch_509, Loss: 0.3533\n",
      "fold_0, epoch_510, Loss: 0.3533\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3512\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9647\n",
      "Precision:\t0.9804\n",
      "Recall:\t\t0.9430\n",
      "F1:\t\t\t0.9614\n",
      "\n",
      "fold_0, epoch_511, Loss: 0.3540\n",
      "fold_0, epoch_512, Loss: 0.3500\n",
      "fold_0, epoch_513, Loss: 0.3531\n",
      "fold_0, epoch_514, Loss: 0.3522\n",
      "fold_0, epoch_515, Loss: 0.3515\n",
      "fold_0, epoch_516, Loss: 0.3522\n",
      "fold_0, epoch_517, Loss: 0.3533\n",
      "fold_0, epoch_518, Loss: 0.3527\n",
      "fold_0, epoch_519, Loss: 0.3513\n",
      "fold_0, epoch_520, Loss: 0.3517\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3506\n",
      "Accuracy:\t0.9624\n",
      "AUC:\t\t0.9619\n",
      "Precision:\t0.9778\n",
      "Recall:\t\t0.9462\n",
      "F1:\t\t\t0.9617\n",
      "\n",
      "fold_0, epoch_521, Loss: 0.3536\n",
      "fold_0, epoch_522, Loss: 0.3511\n",
      "fold_0, epoch_523, Loss: 0.3530\n",
      "fold_0, epoch_524, Loss: 0.3533\n",
      "fold_0, epoch_525, Loss: 0.3506\n",
      "fold_0, epoch_526, Loss: 0.3527\n",
      "fold_0, epoch_527, Loss: 0.3507\n",
      "fold_0, epoch_528, Loss: 0.3520\n",
      "fold_0, epoch_529, Loss: 0.3505\n",
      "fold_0, epoch_530, Loss: 0.3534\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3545\n",
      "Accuracy:\t0.9587\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9727\n",
      "Recall:\t\t0.9441\n",
      "F1:\t\t\t0.9582\n",
      "\n",
      "fold_0, epoch_531, Loss: 0.3517\n",
      "fold_0, epoch_532, Loss: 0.3509\n",
      "fold_0, epoch_533, Loss: 0.3514\n",
      "fold_0, epoch_534, Loss: 0.3520\n",
      "fold_0, epoch_535, Loss: 0.3503\n",
      "fold_0, epoch_536, Loss: 0.3505\n",
      "fold_0, epoch_537, Loss: 0.3532\n",
      "fold_0, epoch_538, Loss: 0.3488\n",
      "fold_0, epoch_539, Loss: 0.3526\n",
      "fold_0, epoch_540, Loss: 0.3505\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3503\n",
      "Accuracy:\t0.9628\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9791\n",
      "Recall:\t\t0.9456\n",
      "F1:\t\t\t0.9620\n",
      "\n",
      "fold_0, epoch_541, Loss: 0.3496\n",
      "fold_0, epoch_542, Loss: 0.3493\n",
      "fold_0, epoch_543, Loss: 0.3502\n",
      "fold_0, epoch_544, Loss: 0.3512\n",
      "fold_0, epoch_545, Loss: 0.3511\n",
      "fold_0, epoch_546, Loss: 0.3529\n",
      "fold_0, epoch_547, Loss: 0.3518\n",
      "fold_0, epoch_548, Loss: 0.3491\n",
      "fold_0, epoch_549, Loss: 0.3521\n",
      "fold_0, epoch_550, Loss: 0.3518\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3492\n",
      "Accuracy:\t0.9641\n",
      "AUC:\t\t0.9636\n",
      "Precision:\t0.9806\n",
      "Recall:\t\t0.9473\n",
      "F1:\t\t\t0.9637\n",
      "\n",
      "fold_0, epoch_551, Loss: 0.3499\n",
      "fold_0, epoch_552, Loss: 0.3496\n",
      "fold_0, epoch_553, Loss: 0.3508\n",
      "fold_0, epoch_554, Loss: 0.3503\n",
      "fold_0, epoch_555, Loss: 0.3487\n",
      "fold_0, epoch_556, Loss: 0.3499\n",
      "fold_0, epoch_557, Loss: 0.3505\n",
      "fold_0, epoch_558, Loss: 0.3527\n",
      "fold_0, epoch_559, Loss: 0.3502\n",
      "fold_0, epoch_560, Loss: 0.3517\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3494\n",
      "Accuracy:\t0.9635\n",
      "AUC:\t\t0.9626\n",
      "Precision:\t0.9817\n",
      "Recall:\t\t0.9446\n",
      "F1:\t\t\t0.9628\n",
      "\n",
      "fold_0, epoch_561, Loss: 0.3507\n",
      "fold_0, epoch_562, Loss: 0.3497\n",
      "fold_0, epoch_563, Loss: 0.3499\n",
      "fold_0, epoch_564, Loss: 0.3509\n",
      "fold_0, epoch_565, Loss: 0.3530\n",
      "fold_0, epoch_566, Loss: 0.3515\n",
      "fold_0, epoch_567, Loss: 0.3474\n",
      "fold_0, epoch_568, Loss: 0.3536\n",
      "fold_0, epoch_569, Loss: 0.3474\n",
      "fold_0, epoch_570, Loss: 0.3504\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3506\n",
      "Accuracy:\t0.9625\n",
      "AUC:\t\t0.9644\n",
      "Precision:\t0.9777\n",
      "Recall:\t\t0.9464\n",
      "F1:\t\t\t0.9618\n",
      "\n",
      "fold_0, epoch_571, Loss: 0.3517\n",
      "fold_0, epoch_572, Loss: 0.3500\n",
      "fold_0, epoch_573, Loss: 0.3511\n",
      "fold_0, epoch_574, Loss: 0.3462\n",
      "fold_0, epoch_575, Loss: 0.3494\n",
      "fold_0, epoch_576, Loss: 0.3496\n",
      "fold_0, epoch_577, Loss: 0.3507\n",
      "fold_0, epoch_578, Loss: 0.3525\n",
      "fold_0, epoch_579, Loss: 0.3506\n",
      "fold_0, epoch_580, Loss: 0.3502\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3500\n",
      "Accuracy:\t0.9632\n",
      "AUC:\t\t0.9633\n",
      "Precision:\t0.9833\n",
      "Recall:\t\t0.9429\n",
      "F1:\t\t\t0.9627\n",
      "\n",
      "fold_0, epoch_581, Loss: 0.3501\n",
      "fold_0, epoch_582, Loss: 0.3500\n",
      "fold_0, epoch_583, Loss: 0.3498\n",
      "fold_0, epoch_584, Loss: 0.3493\n",
      "fold_0, epoch_585, Loss: 0.3477\n",
      "fold_0, epoch_586, Loss: 0.3502\n",
      "fold_0, epoch_587, Loss: 0.3502\n",
      "fold_0, epoch_588, Loss: 0.3503\n",
      "fold_0, epoch_589, Loss: 0.3489\n",
      "fold_0, epoch_590, Loss: 0.3544\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3520\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9797\n",
      "Recall:\t\t0.9414\n",
      "F1:\t\t\t0.9602\n",
      "\n",
      "fold_0, epoch_591, Loss: 0.3511\n",
      "fold_0, epoch_592, Loss: 0.3490\n",
      "fold_0, epoch_593, Loss: 0.3518\n",
      "fold_0, epoch_594, Loss: 0.3495\n",
      "fold_0, epoch_595, Loss: 0.3494\n",
      "fold_0, epoch_596, Loss: 0.3478\n",
      "fold_0, epoch_597, Loss: 0.3506\n",
      "fold_0, epoch_598, Loss: 0.3463\n",
      "fold_0, epoch_599, Loss: 0.3531\n",
      "fold_0, epoch_600, Loss: 0.3503\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3487\n",
      "Accuracy:\t0.9646\n",
      "AUC:\t\t0.9626\n",
      "Precision:\t0.9821\n",
      "Recall:\t\t0.9464\n",
      "F1:\t\t\t0.9639\n",
      "\n",
      "fold_0, epoch_601, Loss: 0.3478\n",
      "fold_0, epoch_602, Loss: 0.3497\n",
      "fold_0, epoch_603, Loss: 0.3501\n",
      "fold_0, epoch_604, Loss: 0.3498\n",
      "fold_0, epoch_605, Loss: 0.3480\n",
      "fold_0, epoch_606, Loss: 0.3483\n",
      "fold_0, epoch_607, Loss: 0.3520\n",
      "fold_0, epoch_608, Loss: 0.3484\n",
      "fold_0, epoch_609, Loss: 0.3514\n",
      "fold_0, epoch_610, Loss: 0.3481\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3489\n",
      "Accuracy:\t0.9644\n",
      "AUC:\t\t0.9637\n",
      "Precision:\t0.9837\n",
      "Recall:\t\t0.9450\n",
      "F1:\t\t\t0.9639\n",
      "\n",
      "fold_0, epoch_611, Loss: 0.3496\n",
      "fold_0, epoch_612, Loss: 0.3505\n",
      "fold_0, epoch_613, Loss: 0.3474\n",
      "fold_0, epoch_614, Loss: 0.3480\n",
      "fold_0, epoch_615, Loss: 0.3515\n",
      "fold_0, epoch_616, Loss: 0.3506\n",
      "fold_0, epoch_617, Loss: 0.3526\n",
      "fold_0, epoch_618, Loss: 0.3486\n",
      "fold_0, epoch_619, Loss: 0.3494\n",
      "fold_0, epoch_620, Loss: 0.3518\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9593\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9783\n",
      "Recall:\t\t0.9393\n",
      "F1:\t\t\t0.9584\n",
      "\n",
      "fold_0, epoch_621, Loss: 0.3505\n",
      "fold_0, epoch_622, Loss: 0.3486\n",
      "fold_0, epoch_623, Loss: 0.3484\n",
      "fold_0, epoch_624, Loss: 0.3477\n",
      "fold_0, epoch_625, Loss: 0.3472\n",
      "fold_0, epoch_626, Loss: 0.3479\n",
      "fold_0, epoch_627, Loss: 0.3501\n",
      "fold_0, epoch_628, Loss: 0.3495\n",
      "fold_0, epoch_629, Loss: 0.3494\n",
      "fold_0, epoch_630, Loss: 0.3505\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3523\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9618\n",
      "Precision:\t0.9763\n",
      "Recall:\t\t0.9444\n",
      "F1:\t\t\t0.9601\n",
      "\n",
      "fold_0, epoch_631, Loss: 0.3494\n",
      "fold_0, epoch_632, Loss: 0.3506\n",
      "fold_0, epoch_633, Loss: 0.3465\n",
      "fold_0, epoch_634, Loss: 0.3491\n",
      "fold_0, epoch_635, Loss: 0.3501\n",
      "fold_0, epoch_636, Loss: 0.3475\n",
      "fold_0, epoch_637, Loss: 0.3507\n",
      "fold_0, epoch_638, Loss: 0.3514\n",
      "fold_0, epoch_639, Loss: 0.3478\n",
      "fold_0, epoch_640, Loss: 0.3492\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3513\n",
      "Accuracy:\t0.9615\n",
      "AUC:\t\t0.9642\n",
      "Precision:\t0.9807\n",
      "Recall:\t\t0.9414\n",
      "F1:\t\t\t0.9607\n",
      "\n",
      "fold_0, epoch_641, Loss: 0.3479\n",
      "fold_0, epoch_642, Loss: 0.3494\n",
      "fold_0, epoch_643, Loss: 0.3494\n",
      "fold_0, epoch_644, Loss: 0.3494\n",
      "fold_0, epoch_645, Loss: 0.3517\n",
      "fold_0, epoch_646, Loss: 0.3483\n",
      "fold_0, epoch_647, Loss: 0.3491\n",
      "fold_0, epoch_648, Loss: 0.3460\n",
      "fold_0, epoch_649, Loss: 0.3504\n",
      "fold_0, epoch_650, Loss: 0.3489\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3466\n",
      "Accuracy:\t0.9668\n",
      "AUC:\t\t0.9644\n",
      "Precision:\t0.9851\n",
      "Recall:\t\t0.9484\n",
      "F1:\t\t\t0.9664\n",
      "\n",
      "fold_0, epoch_651, Loss: 0.3476\n",
      "fold_0, epoch_652, Loss: 0.3476\n",
      "fold_0, epoch_653, Loss: 0.3464\n",
      "fold_0, epoch_654, Loss: 0.3498\n",
      "fold_0, epoch_655, Loss: 0.3479\n",
      "fold_0, epoch_656, Loss: 0.3484\n",
      "fold_0, epoch_657, Loss: 0.3487\n",
      "fold_0, epoch_658, Loss: 0.3471\n",
      "fold_0, epoch_659, Loss: 0.3511\n",
      "fold_0, epoch_660, Loss: 0.3484\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3465\n",
      "Accuracy:\t0.9667\n",
      "AUC:\t\t0.9648\n",
      "Precision:\t0.9866\n",
      "Recall:\t\t0.9465\n",
      "F1:\t\t\t0.9661\n",
      "\n",
      "fold_0, epoch_661, Loss: 0.3483\n",
      "fold_0, epoch_662, Loss: 0.3481\n",
      "fold_0, epoch_663, Loss: 0.3470\n",
      "fold_0, epoch_664, Loss: 0.3477\n",
      "fold_0, epoch_665, Loss: 0.3478\n",
      "fold_0, epoch_666, Loss: 0.3497\n",
      "fold_0, epoch_667, Loss: 0.3456\n",
      "fold_0, epoch_668, Loss: 0.3503\n",
      "fold_0, epoch_669, Loss: 0.3493\n",
      "fold_0, epoch_670, Loss: 0.3482\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9653\n",
      "AUC:\t\t0.9645\n",
      "Precision:\t0.9842\n",
      "Recall:\t\t0.9460\n",
      "F1:\t\t\t0.9647\n",
      "\n",
      "fold_0, epoch_671, Loss: 0.3467\n",
      "fold_0, epoch_672, Loss: 0.3459\n",
      "fold_0, epoch_673, Loss: 0.3489\n",
      "fold_0, epoch_674, Loss: 0.3499\n",
      "fold_0, epoch_675, Loss: 0.3453\n",
      "fold_0, epoch_676, Loss: 0.3460\n",
      "fold_0, epoch_677, Loss: 0.3502\n",
      "fold_0, epoch_678, Loss: 0.3476\n",
      "fold_0, epoch_679, Loss: 0.3466\n",
      "fold_0, epoch_680, Loss: 0.3486\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3492\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9635\n",
      "Precision:\t0.9824\n",
      "Recall:\t\t0.9446\n",
      "F1:\t\t\t0.9632\n",
      "\n",
      "fold_0, epoch_681, Loss: 0.3475\n",
      "fold_0, epoch_682, Loss: 0.3475\n",
      "fold_0, epoch_683, Loss: 0.3500\n",
      "fold_0, epoch_684, Loss: 0.3518\n",
      "fold_0, epoch_685, Loss: 0.3478\n",
      "fold_0, epoch_686, Loss: 0.3449\n",
      "fold_0, epoch_687, Loss: 0.3477\n",
      "fold_0, epoch_688, Loss: 0.3486\n",
      "fold_0, epoch_689, Loss: 0.3480\n",
      "fold_0, epoch_690, Loss: 0.3499\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3462\n",
      "Accuracy:\t0.9671\n",
      "AUC:\t\t0.9657\n",
      "Precision:\t0.9843\n",
      "Recall:\t\t0.9497\n",
      "F1:\t\t\t0.9667\n",
      "\n",
      "fold_0, epoch_691, Loss: 0.3468\n",
      "fold_0, epoch_692, Loss: 0.3498\n",
      "fold_0, epoch_693, Loss: 0.3466\n",
      "fold_0, epoch_694, Loss: 0.3456\n",
      "fold_0, epoch_695, Loss: 0.3494\n",
      "fold_0, epoch_696, Loss: 0.3475\n",
      "fold_0, epoch_697, Loss: 0.3449\n",
      "fold_0, epoch_698, Loss: 0.3484\n",
      "fold_0, epoch_699, Loss: 0.3504\n",
      "fold_0, epoch_700, Loss: 0.3456\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3487\n",
      "Accuracy:\t0.9646\n",
      "AUC:\t\t0.9649\n",
      "Precision:\t0.9840\n",
      "Recall:\t\t0.9449\n",
      "F1:\t\t\t0.9641\n",
      "\n",
      "fold_0, epoch_701, Loss: 0.3476\n",
      "fold_0, epoch_702, Loss: 0.3498\n",
      "fold_0, epoch_703, Loss: 0.3504\n",
      "fold_0, epoch_704, Loss: 0.3452\n",
      "fold_0, epoch_705, Loss: 0.3480\n",
      "fold_0, epoch_706, Loss: 0.3464\n",
      "fold_0, epoch_707, Loss: 0.3480\n",
      "fold_0, epoch_708, Loss: 0.3472\n",
      "fold_0, epoch_709, Loss: 0.3470\n",
      "fold_0, epoch_710, Loss: 0.3510\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3463\n",
      "Accuracy:\t0.9670\n",
      "AUC:\t\t0.9659\n",
      "Precision:\t0.9853\n",
      "Recall:\t\t0.9481\n",
      "F1:\t\t\t0.9664\n",
      "\n",
      "fold_0, epoch_711, Loss: 0.3477\n",
      "fold_0, epoch_712, Loss: 0.3465\n",
      "fold_0, epoch_713, Loss: 0.3457\n",
      "fold_0, epoch_714, Loss: 0.3470\n",
      "fold_0, epoch_715, Loss: 0.3447\n",
      "fold_0, epoch_716, Loss: 0.3458\n",
      "fold_0, epoch_717, Loss: 0.3475\n",
      "fold_0, epoch_718, Loss: 0.3491\n",
      "fold_0, epoch_719, Loss: 0.3484\n",
      "fold_0, epoch_720, Loss: 0.3462\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3456\n",
      "Accuracy:\t0.9676\n",
      "AUC:\t\t0.9655\n",
      "Precision:\t0.9865\n",
      "Recall:\t\t0.9484\n",
      "F1:\t\t\t0.9671\n",
      "\n",
      "fold_0, epoch_721, Loss: 0.3463\n",
      "fold_0, epoch_722, Loss: 0.3456\n",
      "fold_0, epoch_723, Loss: 0.3460\n",
      "fold_0, epoch_724, Loss: 0.3487\n",
      "fold_0, epoch_725, Loss: 0.3474\n",
      "fold_0, epoch_726, Loss: 0.3456\n",
      "fold_0, epoch_727, Loss: 0.3465\n",
      "fold_0, epoch_728, Loss: 0.3473\n",
      "fold_0, epoch_729, Loss: 0.3458\n",
      "fold_0, epoch_730, Loss: 0.3454\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3493\n",
      "Accuracy:\t0.9637\n",
      "AUC:\t\t0.9661\n",
      "Precision:\t0.9851\n",
      "Recall:\t\t0.9420\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_0, epoch_731, Loss: 0.3487\n",
      "fold_0, epoch_732, Loss: 0.3472\n",
      "fold_0, epoch_733, Loss: 0.3458\n",
      "fold_0, epoch_734, Loss: 0.3460\n",
      "fold_0, epoch_735, Loss: 0.3492\n",
      "fold_0, epoch_736, Loss: 0.3464\n",
      "fold_0, epoch_737, Loss: 0.3456\n",
      "fold_0, epoch_738, Loss: 0.3452\n",
      "fold_0, epoch_739, Loss: 0.3479\n",
      "fold_0, epoch_740, Loss: 0.3453\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3494\n",
      "Accuracy:\t0.9637\n",
      "AUC:\t\t0.9643\n",
      "Precision:\t0.9825\n",
      "Recall:\t\t0.9440\n",
      "F1:\t\t\t0.9628\n",
      "\n",
      "fold_0, epoch_741, Loss: 0.3480\n",
      "fold_0, epoch_742, Loss: 0.3469\n",
      "fold_0, epoch_743, Loss: 0.3475\n",
      "fold_0, epoch_744, Loss: 0.3447\n",
      "fold_0, epoch_745, Loss: 0.3477\n",
      "fold_0, epoch_746, Loss: 0.3451\n",
      "fold_0, epoch_747, Loss: 0.3444\n",
      "fold_0, epoch_748, Loss: 0.3464\n",
      "fold_0, epoch_749, Loss: 0.3479\n",
      "fold_0, epoch_750, Loss: 0.3488\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3470\n",
      "Accuracy:\t0.9662\n",
      "AUC:\t\t0.9651\n",
      "Precision:\t0.9875\n",
      "Recall:\t\t0.9436\n",
      "F1:\t\t\t0.9651\n",
      "\n",
      "fold_0, epoch_751, Loss: 0.3469\n",
      "fold_0, epoch_752, Loss: 0.3468\n",
      "fold_0, epoch_753, Loss: 0.3453\n",
      "fold_0, epoch_754, Loss: 0.3454\n",
      "fold_0, epoch_755, Loss: 0.3454\n",
      "fold_0, epoch_756, Loss: 0.3473\n",
      "fold_0, epoch_757, Loss: 0.3462\n",
      "fold_0, epoch_758, Loss: 0.3461\n",
      "fold_0, epoch_759, Loss: 0.3464\n",
      "fold_0, epoch_760, Loss: 0.3497\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3474\n",
      "Accuracy:\t0.9657\n",
      "AUC:\t\t0.9659\n",
      "Precision:\t0.9823\n",
      "Recall:\t\t0.9485\n",
      "F1:\t\t\t0.9651\n",
      "\n",
      "fold_0, epoch_761, Loss: 0.3457\n",
      "fold_0, epoch_762, Loss: 0.3462\n",
      "fold_0, epoch_763, Loss: 0.3472\n",
      "fold_0, epoch_764, Loss: 0.3483\n",
      "fold_0, epoch_765, Loss: 0.3483\n",
      "fold_0, epoch_766, Loss: 0.3469\n",
      "fold_0, epoch_767, Loss: 0.3451\n",
      "fold_0, epoch_768, Loss: 0.3461\n",
      "fold_0, epoch_769, Loss: 0.3477\n",
      "fold_0, epoch_770, Loss: 0.3459\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3447\n",
      "Accuracy:\t0.9685\n",
      "AUC:\t\t0.9671\n",
      "Precision:\t0.9865\n",
      "Recall:\t\t0.9500\n",
      "F1:\t\t\t0.9679\n",
      "\n",
      "fold_0, epoch_771, Loss: 0.3460\n",
      "fold_0, epoch_772, Loss: 0.3474\n",
      "fold_0, epoch_773, Loss: 0.3453\n",
      "fold_0, epoch_774, Loss: 0.3492\n",
      "fold_0, epoch_775, Loss: 0.3482\n",
      "fold_0, epoch_776, Loss: 0.3482\n",
      "fold_0, epoch_777, Loss: 0.3477\n",
      "fold_0, epoch_778, Loss: 0.3468\n",
      "fold_0, epoch_779, Loss: 0.3459\n",
      "fold_0, epoch_780, Loss: 0.3451\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3457\n",
      "Accuracy:\t0.9675\n",
      "AUC:\t\t0.9670\n",
      "Precision:\t0.9886\n",
      "Recall:\t\t0.9463\n",
      "F1:\t\t\t0.9670\n",
      "\n",
      "fold_0, epoch_781, Loss: 0.3463\n",
      "fold_0, epoch_782, Loss: 0.3452\n",
      "fold_0, epoch_783, Loss: 0.3484\n",
      "fold_0, epoch_784, Loss: 0.3448\n",
      "fold_0, epoch_785, Loss: 0.3456\n",
      "fold_0, epoch_786, Loss: 0.3458\n",
      "fold_0, epoch_787, Loss: 0.3461\n",
      "fold_0, epoch_788, Loss: 0.3514\n",
      "fold_0, epoch_789, Loss: 0.3496\n",
      "fold_0, epoch_790, Loss: 0.3465\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3445\n",
      "Accuracy:\t0.9686\n",
      "AUC:\t\t0.9676\n",
      "Precision:\t0.9865\n",
      "Recall:\t\t0.9501\n",
      "F1:\t\t\t0.9680\n",
      "\n",
      "fold_0, epoch_791, Loss: 0.3462\n",
      "fold_0, epoch_792, Loss: 0.3466\n",
      "fold_0, epoch_793, Loss: 0.3456\n",
      "fold_0, epoch_794, Loss: 0.3441\n",
      "fold_0, epoch_795, Loss: 0.3473\n",
      "fold_0, epoch_796, Loss: 0.3480\n",
      "fold_0, epoch_797, Loss: 0.3487\n",
      "fold_0, epoch_798, Loss: 0.3453\n",
      "fold_0, epoch_799, Loss: 0.3447\n",
      "fold_0, epoch_800, Loss: 0.3486\n",
      "\n",
      "fold_0 performance on test data:\n",
      "Loss:\t\t0.3478\n",
      "Accuracy:\t0.9651\n",
      "AUC:\t\t0.9662\n",
      "Precision:\t0.9843\n",
      "Recall:\t\t0.9458\n",
      "F1:\t\t\t0.9647\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/checkpoints/fold_1\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/tensorboard\n",
      "\n",
      "\n",
      "fold_1, epoch_1, Loss: 0.5842\n",
      "fold_1, epoch_2, Loss: 0.5714\n",
      "fold_1, epoch_3, Loss: 0.5416\n",
      "fold_1, epoch_4, Loss: 0.5373\n",
      "fold_1, epoch_5, Loss: 0.5338\n",
      "fold_1, epoch_6, Loss: 0.5267\n",
      "fold_1, epoch_7, Loss: 0.5287\n",
      "fold_1, epoch_8, Loss: 0.5240\n",
      "fold_1, epoch_9, Loss: 0.5209\n",
      "fold_1, epoch_10, Loss: 0.5209\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.5094\n",
      "Accuracy:\t0.7952\n",
      "AUC:\t\t0.8654\n",
      "Precision:\t0.7827\n",
      "Recall:\t\t0.8172\n",
      "F1:\t\t\t0.7996\n",
      "\n",
      "fold_1, epoch_11, Loss: 0.5114\n",
      "fold_1, epoch_12, Loss: 0.5112\n",
      "fold_1, epoch_13, Loss: 0.5013\n",
      "fold_1, epoch_14, Loss: 0.5010\n",
      "fold_1, epoch_15, Loss: 0.4981\n",
      "fold_1, epoch_16, Loss: 0.4961\n",
      "fold_1, epoch_17, Loss: 0.4947\n",
      "fold_1, epoch_18, Loss: 0.4934\n",
      "fold_1, epoch_19, Loss: 0.4904\n",
      "fold_1, epoch_20, Loss: 0.4856\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4818\n",
      "Accuracy:\t0.8254\n",
      "AUC:\t\t0.8875\n",
      "Precision:\t0.8272\n",
      "Recall:\t\t0.8211\n",
      "F1:\t\t\t0.8241\n",
      "\n",
      "fold_1, epoch_21, Loss: 0.4845\n",
      "fold_1, epoch_22, Loss: 0.4805\n",
      "fold_1, epoch_23, Loss: 0.4770\n",
      "fold_1, epoch_24, Loss: 0.4762\n",
      "fold_1, epoch_25, Loss: 0.4741\n",
      "fold_1, epoch_26, Loss: 0.4716\n",
      "fold_1, epoch_27, Loss: 0.4717\n",
      "fold_1, epoch_28, Loss: 0.4702\n",
      "fold_1, epoch_29, Loss: 0.4679\n",
      "fold_1, epoch_30, Loss: 0.4643\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4631\n",
      "Accuracy:\t0.8471\n",
      "AUC:\t\t0.8937\n",
      "Precision:\t0.8262\n",
      "Recall:\t\t0.8809\n",
      "F1:\t\t\t0.8527\n",
      "\n",
      "fold_1, epoch_31, Loss: 0.4606\n",
      "fold_1, epoch_32, Loss: 0.4590\n",
      "fold_1, epoch_33, Loss: 0.4611\n",
      "fold_1, epoch_34, Loss: 0.4552\n",
      "fold_1, epoch_35, Loss: 0.4538\n",
      "fold_1, epoch_36, Loss: 0.4526\n",
      "fold_1, epoch_37, Loss: 0.4507\n",
      "fold_1, epoch_38, Loss: 0.4522\n",
      "fold_1, epoch_39, Loss: 0.4462\n",
      "fold_1, epoch_40, Loss: 0.4463\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4537\n",
      "Accuracy:\t0.8559\n",
      "AUC:\t\t0.9024\n",
      "Precision:\t0.8550\n",
      "Recall:\t\t0.8586\n",
      "F1:\t\t\t0.8568\n",
      "\n",
      "fold_1, epoch_41, Loss: 0.4466\n",
      "fold_1, epoch_42, Loss: 0.4436\n",
      "fold_1, epoch_43, Loss: 0.4442\n",
      "fold_1, epoch_44, Loss: 0.4411\n",
      "fold_1, epoch_45, Loss: 0.4417\n",
      "fold_1, epoch_46, Loss: 0.4401\n",
      "fold_1, epoch_47, Loss: 0.4410\n",
      "fold_1, epoch_48, Loss: 0.4367\n",
      "fold_1, epoch_49, Loss: 0.4361\n",
      "fold_1, epoch_50, Loss: 0.4357\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4390\n",
      "Accuracy:\t0.8724\n",
      "AUC:\t\t0.9025\n",
      "Precision:\t0.8801\n",
      "Recall:\t\t0.8642\n",
      "F1:\t\t\t0.8721\n",
      "\n",
      "fold_1, epoch_51, Loss: 0.4381\n",
      "fold_1, epoch_52, Loss: 0.4358\n",
      "fold_1, epoch_53, Loss: 0.4390\n",
      "fold_1, epoch_54, Loss: 0.4275\n",
      "fold_1, epoch_55, Loss: 0.4301\n",
      "fold_1, epoch_56, Loss: 0.4316\n",
      "fold_1, epoch_57, Loss: 0.4254\n",
      "fold_1, epoch_58, Loss: 0.4280\n",
      "fold_1, epoch_59, Loss: 0.4242\n",
      "fold_1, epoch_60, Loss: 0.4259\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4244\n",
      "Accuracy:\t0.8868\n",
      "AUC:\t\t0.9116\n",
      "Precision:\t0.8780\n",
      "Recall:\t\t0.8980\n",
      "F1:\t\t\t0.8879\n",
      "\n",
      "fold_1, epoch_61, Loss: 0.4239\n",
      "fold_1, epoch_62, Loss: 0.4214\n",
      "fold_1, epoch_63, Loss: 0.4208\n",
      "fold_1, epoch_64, Loss: 0.4224\n",
      "fold_1, epoch_65, Loss: 0.4211\n",
      "fold_1, epoch_66, Loss: 0.4211\n",
      "fold_1, epoch_67, Loss: 0.4174\n",
      "fold_1, epoch_68, Loss: 0.4189\n",
      "fold_1, epoch_69, Loss: 0.4230\n",
      "fold_1, epoch_70, Loss: 0.4200\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4115\n",
      "Accuracy:\t0.9008\n",
      "AUC:\t\t0.9177\n",
      "Precision:\t0.8937\n",
      "Recall:\t\t0.9095\n",
      "F1:\t\t\t0.9015\n",
      "\n",
      "fold_1, epoch_71, Loss: 0.4163\n",
      "fold_1, epoch_72, Loss: 0.4182\n",
      "fold_1, epoch_73, Loss: 0.4156\n",
      "fold_1, epoch_74, Loss: 0.4138\n",
      "fold_1, epoch_75, Loss: 0.4167\n",
      "fold_1, epoch_76, Loss: 0.4117\n",
      "fold_1, epoch_77, Loss: 0.4122\n",
      "fold_1, epoch_78, Loss: 0.4099\n",
      "fold_1, epoch_79, Loss: 0.4125\n",
      "fold_1, epoch_80, Loss: 0.4092\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4054\n",
      "Accuracy:\t0.9068\n",
      "AUC:\t\t0.9228\n",
      "Precision:\t0.9037\n",
      "Recall:\t\t0.9093\n",
      "F1:\t\t\t0.9065\n",
      "\n",
      "fold_1, epoch_81, Loss: 0.4088\n",
      "fold_1, epoch_82, Loss: 0.4167\n",
      "fold_1, epoch_83, Loss: 0.4084\n",
      "fold_1, epoch_84, Loss: 0.4078\n",
      "fold_1, epoch_85, Loss: 0.4073\n",
      "fold_1, epoch_86, Loss: 0.4104\n",
      "fold_1, epoch_87, Loss: 0.4097\n",
      "fold_1, epoch_88, Loss: 0.4077\n",
      "fold_1, epoch_89, Loss: 0.4045\n",
      "fold_1, epoch_90, Loss: 0.4033\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.4008\n",
      "Accuracy:\t0.9122\n",
      "AUC:\t\t0.9237\n",
      "Precision:\t0.9124\n",
      "Recall:\t\t0.9122\n",
      "F1:\t\t\t0.9123\n",
      "\n",
      "fold_1, epoch_91, Loss: 0.4046\n",
      "fold_1, epoch_92, Loss: 0.4113\n",
      "fold_1, epoch_93, Loss: 0.4073\n",
      "fold_1, epoch_94, Loss: 0.4047\n",
      "fold_1, epoch_95, Loss: 0.4002\n",
      "fold_1, epoch_96, Loss: 0.4056\n",
      "fold_1, epoch_97, Loss: 0.4083\n",
      "fold_1, epoch_98, Loss: 0.4087\n",
      "fold_1, epoch_99, Loss: 0.4019\n",
      "fold_1, epoch_100, Loss: 0.4045\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3987\n",
      "Accuracy:\t0.9144\n",
      "AUC:\t\t0.9243\n",
      "Precision:\t0.9086\n",
      "Recall:\t\t0.9196\n",
      "F1:\t\t\t0.9141\n",
      "\n",
      "fold_1, epoch_101, Loss: 0.4066\n",
      "fold_1, epoch_102, Loss: 0.4067\n",
      "fold_1, epoch_103, Loss: 0.3985\n",
      "fold_1, epoch_104, Loss: 0.4010\n",
      "fold_1, epoch_105, Loss: 0.4020\n",
      "fold_1, epoch_106, Loss: 0.3979\n",
      "fold_1, epoch_107, Loss: 0.3998\n",
      "fold_1, epoch_108, Loss: 0.3963\n",
      "fold_1, epoch_109, Loss: 0.3984\n",
      "fold_1, epoch_110, Loss: 0.3964\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3987\n",
      "Accuracy:\t0.9139\n",
      "AUC:\t\t0.9265\n",
      "Precision:\t0.9060\n",
      "Recall:\t\t0.9249\n",
      "F1:\t\t\t0.9154\n",
      "\n",
      "fold_1, epoch_111, Loss: 0.3971\n",
      "fold_1, epoch_112, Loss: 0.3955\n",
      "fold_1, epoch_113, Loss: 0.3968\n",
      "fold_1, epoch_114, Loss: 0.4015\n",
      "fold_1, epoch_115, Loss: 0.3972\n",
      "fold_1, epoch_116, Loss: 0.3967\n",
      "fold_1, epoch_117, Loss: 0.3963\n",
      "fold_1, epoch_118, Loss: 0.3985\n",
      "fold_1, epoch_119, Loss: 0.3955\n",
      "fold_1, epoch_120, Loss: 0.3938\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3971\n",
      "Accuracy:\t0.9159\n",
      "AUC:\t\t0.9256\n",
      "Precision:\t0.9153\n",
      "Recall:\t\t0.9169\n",
      "F1:\t\t\t0.9161\n",
      "\n",
      "fold_1, epoch_121, Loss: 0.3912\n",
      "fold_1, epoch_122, Loss: 0.3896\n",
      "fold_1, epoch_123, Loss: 0.3937\n",
      "fold_1, epoch_124, Loss: 0.3942\n",
      "fold_1, epoch_125, Loss: 0.3907\n",
      "fold_1, epoch_126, Loss: 0.3923\n",
      "fold_1, epoch_127, Loss: 0.3939\n",
      "fold_1, epoch_128, Loss: 0.3938\n",
      "fold_1, epoch_129, Loss: 0.3946\n",
      "fold_1, epoch_130, Loss: 0.3920\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3861\n",
      "Accuracy:\t0.9271\n",
      "AUC:\t\t0.9357\n",
      "Precision:\t0.9336\n",
      "Recall:\t\t0.9198\n",
      "F1:\t\t\t0.9267\n",
      "\n",
      "fold_1, epoch_131, Loss: 0.3971\n",
      "fold_1, epoch_132, Loss: 0.3859\n",
      "fold_1, epoch_133, Loss: 0.3919\n",
      "fold_1, epoch_134, Loss: 0.3931\n",
      "fold_1, epoch_135, Loss: 0.3939\n",
      "fold_1, epoch_136, Loss: 0.3921\n",
      "fold_1, epoch_137, Loss: 0.3937\n",
      "fold_1, epoch_138, Loss: 0.3874\n",
      "fold_1, epoch_139, Loss: 0.3857\n",
      "fold_1, epoch_140, Loss: 0.3920\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3912\n",
      "Accuracy:\t0.9213\n",
      "AUC:\t\t0.9330\n",
      "Precision:\t0.9210\n",
      "Recall:\t\t0.9232\n",
      "F1:\t\t\t0.9221\n",
      "\n",
      "fold_1, epoch_141, Loss: 0.3870\n",
      "fold_1, epoch_142, Loss: 0.3927\n",
      "fold_1, epoch_143, Loss: 0.3909\n",
      "fold_1, epoch_144, Loss: 0.3884\n",
      "fold_1, epoch_145, Loss: 0.3919\n",
      "fold_1, epoch_146, Loss: 0.3904\n",
      "fold_1, epoch_147, Loss: 0.3870\n",
      "fold_1, epoch_148, Loss: 0.3845\n",
      "fold_1, epoch_149, Loss: 0.3908\n",
      "fold_1, epoch_150, Loss: 0.3931\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3950\n",
      "Accuracy:\t0.9176\n",
      "AUC:\t\t0.9307\n",
      "Precision:\t0.9208\n",
      "Recall:\t\t0.9139\n",
      "F1:\t\t\t0.9174\n",
      "\n",
      "fold_1, epoch_151, Loss: 0.3815\n",
      "fold_1, epoch_152, Loss: 0.3877\n",
      "fold_1, epoch_153, Loss: 0.3906\n",
      "fold_1, epoch_154, Loss: 0.3909\n",
      "fold_1, epoch_155, Loss: 0.3825\n",
      "fold_1, epoch_156, Loss: 0.3878\n",
      "fold_1, epoch_157, Loss: 0.3842\n",
      "fold_1, epoch_158, Loss: 0.3879\n",
      "fold_1, epoch_159, Loss: 0.3882\n",
      "fold_1, epoch_160, Loss: 0.3852\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3805\n",
      "Accuracy:\t0.9320\n",
      "AUC:\t\t0.9381\n",
      "Precision:\t0.9425\n",
      "Recall:\t\t0.9203\n",
      "F1:\t\t\t0.9313\n",
      "\n",
      "fold_1, epoch_161, Loss: 0.3789\n",
      "fold_1, epoch_162, Loss: 0.3833\n",
      "fold_1, epoch_163, Loss: 0.3955\n",
      "fold_1, epoch_164, Loss: 0.3854\n",
      "fold_1, epoch_165, Loss: 0.3833\n",
      "fold_1, epoch_166, Loss: 0.3853\n",
      "fold_1, epoch_167, Loss: 0.3852\n",
      "fold_1, epoch_168, Loss: 0.3839\n",
      "fold_1, epoch_169, Loss: 0.3824\n",
      "fold_1, epoch_170, Loss: 0.3891\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3843\n",
      "Accuracy:\t0.9284\n",
      "AUC:\t\t0.9348\n",
      "Precision:\t0.9373\n",
      "Recall:\t\t0.9170\n",
      "F1:\t\t\t0.9270\n",
      "\n",
      "fold_1, epoch_171, Loss: 0.3848\n",
      "fold_1, epoch_172, Loss: 0.3819\n",
      "fold_1, epoch_173, Loss: 0.3886\n",
      "fold_1, epoch_174, Loss: 0.3820\n",
      "fold_1, epoch_175, Loss: 0.3817\n",
      "fold_1, epoch_176, Loss: 0.3811\n",
      "fold_1, epoch_177, Loss: 0.3841\n",
      "fold_1, epoch_178, Loss: 0.3800\n",
      "fold_1, epoch_179, Loss: 0.3799\n",
      "fold_1, epoch_180, Loss: 0.3826\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3829\n",
      "Accuracy:\t0.9296\n",
      "AUC:\t\t0.9402\n",
      "Precision:\t0.9484\n",
      "Recall:\t\t0.9082\n",
      "F1:\t\t\t0.9279\n",
      "\n",
      "fold_1, epoch_181, Loss: 0.3796\n",
      "fold_1, epoch_182, Loss: 0.3820\n",
      "fold_1, epoch_183, Loss: 0.3788\n",
      "fold_1, epoch_184, Loss: 0.3844\n",
      "fold_1, epoch_185, Loss: 0.3765\n",
      "fold_1, epoch_186, Loss: 0.3811\n",
      "fold_1, epoch_187, Loss: 0.3757\n",
      "fold_1, epoch_188, Loss: 0.3806\n",
      "fold_1, epoch_189, Loss: 0.3824\n",
      "fold_1, epoch_190, Loss: 0.3806\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3867\n",
      "Accuracy:\t0.9257\n",
      "AUC:\t\t0.9383\n",
      "Precision:\t0.9465\n",
      "Recall:\t\t0.9030\n",
      "F1:\t\t\t0.9243\n",
      "\n",
      "fold_1, epoch_191, Loss: 0.3782\n",
      "fold_1, epoch_192, Loss: 0.3800\n",
      "fold_1, epoch_193, Loss: 0.3779\n",
      "fold_1, epoch_194, Loss: 0.3816\n",
      "fold_1, epoch_195, Loss: 0.3796\n",
      "fold_1, epoch_196, Loss: 0.3801\n",
      "fold_1, epoch_197, Loss: 0.3764\n",
      "fold_1, epoch_198, Loss: 0.3764\n",
      "fold_1, epoch_199, Loss: 0.3836\n",
      "fold_1, epoch_200, Loss: 0.3754\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3755\n",
      "Accuracy:\t0.9375\n",
      "AUC:\t\t0.9407\n",
      "Precision:\t0.9496\n",
      "Recall:\t\t0.9249\n",
      "F1:\t\t\t0.9371\n",
      "\n",
      "fold_1, epoch_201, Loss: 0.3767\n",
      "fold_1, epoch_202, Loss: 0.3783\n",
      "fold_1, epoch_203, Loss: 0.3764\n",
      "fold_1, epoch_204, Loss: 0.3796\n",
      "fold_1, epoch_205, Loss: 0.3776\n",
      "fold_1, epoch_206, Loss: 0.3780\n",
      "fold_1, epoch_207, Loss: 0.3791\n",
      "fold_1, epoch_208, Loss: 0.3747\n",
      "fold_1, epoch_209, Loss: 0.3808\n",
      "fold_1, epoch_210, Loss: 0.3777\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3750\n",
      "Accuracy:\t0.9378\n",
      "AUC:\t\t0.9432\n",
      "Precision:\t0.9509\n",
      "Recall:\t\t0.9240\n",
      "F1:\t\t\t0.9372\n",
      "\n",
      "fold_1, epoch_211, Loss: 0.3746\n",
      "fold_1, epoch_212, Loss: 0.3788\n",
      "fold_1, epoch_213, Loss: 0.3762\n",
      "fold_1, epoch_214, Loss: 0.3729\n",
      "fold_1, epoch_215, Loss: 0.3798\n",
      "fold_1, epoch_216, Loss: 0.3786\n",
      "fold_1, epoch_217, Loss: 0.3745\n",
      "fold_1, epoch_218, Loss: 0.3781\n",
      "fold_1, epoch_219, Loss: 0.3778\n",
      "fold_1, epoch_220, Loss: 0.3760\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3714\n",
      "Accuracy:\t0.9416\n",
      "AUC:\t\t0.9427\n",
      "Precision:\t0.9554\n",
      "Recall:\t\t0.9271\n",
      "F1:\t\t\t0.9410\n",
      "\n",
      "fold_1, epoch_221, Loss: 0.3766\n",
      "fold_1, epoch_222, Loss: 0.3763\n",
      "fold_1, epoch_223, Loss: 0.3743\n",
      "fold_1, epoch_224, Loss: 0.3777\n",
      "fold_1, epoch_225, Loss: 0.3768\n",
      "fold_1, epoch_226, Loss: 0.3729\n",
      "fold_1, epoch_227, Loss: 0.3757\n",
      "fold_1, epoch_228, Loss: 0.3735\n",
      "fold_1, epoch_229, Loss: 0.3780\n",
      "fold_1, epoch_230, Loss: 0.3705\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3689\n",
      "Accuracy:\t0.9443\n",
      "AUC:\t\t0.9452\n",
      "Precision:\t0.9588\n",
      "Recall:\t\t0.9282\n",
      "F1:\t\t\t0.9433\n",
      "\n",
      "fold_1, epoch_231, Loss: 0.3711\n",
      "fold_1, epoch_232, Loss: 0.3775\n",
      "fold_1, epoch_233, Loss: 0.3781\n",
      "fold_1, epoch_234, Loss: 0.3764\n",
      "fold_1, epoch_235, Loss: 0.3722\n",
      "fold_1, epoch_236, Loss: 0.3753\n",
      "fold_1, epoch_237, Loss: 0.3780\n",
      "fold_1, epoch_238, Loss: 0.3773\n",
      "fold_1, epoch_239, Loss: 0.3713\n",
      "fold_1, epoch_240, Loss: 0.3740\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3681\n",
      "Accuracy:\t0.9449\n",
      "AUC:\t\t0.9452\n",
      "Precision:\t0.9573\n",
      "Recall:\t\t0.9319\n",
      "F1:\t\t\t0.9444\n",
      "\n",
      "fold_1, epoch_241, Loss: 0.3723\n",
      "fold_1, epoch_242, Loss: 0.3746\n",
      "fold_1, epoch_243, Loss: 0.3723\n",
      "fold_1, epoch_244, Loss: 0.3709\n",
      "fold_1, epoch_245, Loss: 0.3757\n",
      "fold_1, epoch_246, Loss: 0.3700\n",
      "fold_1, epoch_247, Loss: 0.3717\n",
      "fold_1, epoch_248, Loss: 0.3714\n",
      "fold_1, epoch_249, Loss: 0.3747\n",
      "fold_1, epoch_250, Loss: 0.3719\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3702\n",
      "Accuracy:\t0.9426\n",
      "AUC:\t\t0.9470\n",
      "Precision:\t0.9590\n",
      "Recall:\t\t0.9246\n",
      "F1:\t\t\t0.9415\n",
      "\n",
      "fold_1, epoch_251, Loss: 0.3705\n",
      "fold_1, epoch_252, Loss: 0.3740\n",
      "fold_1, epoch_253, Loss: 0.3717\n",
      "fold_1, epoch_254, Loss: 0.3683\n",
      "fold_1, epoch_255, Loss: 0.3724\n",
      "fold_1, epoch_256, Loss: 0.3696\n",
      "fold_1, epoch_257, Loss: 0.3695\n",
      "fold_1, epoch_258, Loss: 0.3712\n",
      "fold_1, epoch_259, Loss: 0.3729\n",
      "fold_1, epoch_260, Loss: 0.3709\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3679\n",
      "Accuracy:\t0.9450\n",
      "AUC:\t\t0.9475\n",
      "Precision:\t0.9581\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9439\n",
      "\n",
      "fold_1, epoch_261, Loss: 0.3686\n",
      "fold_1, epoch_262, Loss: 0.3699\n",
      "fold_1, epoch_263, Loss: 0.3720\n",
      "fold_1, epoch_264, Loss: 0.3737\n",
      "fold_1, epoch_265, Loss: 0.3741\n",
      "fold_1, epoch_266, Loss: 0.3753\n",
      "fold_1, epoch_267, Loss: 0.3761\n",
      "fold_1, epoch_268, Loss: 0.3689\n",
      "fold_1, epoch_269, Loss: 0.3751\n",
      "fold_1, epoch_270, Loss: 0.3723\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3671\n",
      "Accuracy:\t0.9460\n",
      "AUC:\t\t0.9465\n",
      "Precision:\t0.9603\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9450\n",
      "\n",
      "fold_1, epoch_271, Loss: 0.3721\n",
      "fold_1, epoch_272, Loss: 0.3662\n",
      "fold_1, epoch_273, Loss: 0.3695\n",
      "fold_1, epoch_274, Loss: 0.3758\n",
      "fold_1, epoch_275, Loss: 0.3758\n",
      "fold_1, epoch_276, Loss: 0.3696\n",
      "fold_1, epoch_277, Loss: 0.3678\n",
      "fold_1, epoch_278, Loss: 0.3683\n",
      "fold_1, epoch_279, Loss: 0.3731\n",
      "fold_1, epoch_280, Loss: 0.3687\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3700\n",
      "Accuracy:\t0.9435\n",
      "AUC:\t\t0.9461\n",
      "Precision:\t0.9640\n",
      "Recall:\t\t0.9203\n",
      "F1:\t\t\t0.9416\n",
      "\n",
      "fold_1, epoch_281, Loss: 0.3683\n",
      "fold_1, epoch_282, Loss: 0.3735\n",
      "fold_1, epoch_283, Loss: 0.3699\n",
      "fold_1, epoch_284, Loss: 0.3664\n",
      "fold_1, epoch_285, Loss: 0.3711\n",
      "fold_1, epoch_286, Loss: 0.3720\n",
      "fold_1, epoch_287, Loss: 0.3685\n",
      "fold_1, epoch_288, Loss: 0.3685\n",
      "fold_1, epoch_289, Loss: 0.3683\n",
      "fold_1, epoch_290, Loss: 0.3688\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3678\n",
      "Accuracy:\t0.9450\n",
      "AUC:\t\t0.9491\n",
      "Precision:\t0.9579\n",
      "Recall:\t\t0.9306\n",
      "F1:\t\t\t0.9440\n",
      "\n",
      "fold_1, epoch_291, Loss: 0.3689\n",
      "fold_1, epoch_292, Loss: 0.3698\n",
      "fold_1, epoch_293, Loss: 0.3713\n",
      "fold_1, epoch_294, Loss: 0.3690\n",
      "fold_1, epoch_295, Loss: 0.3678\n",
      "fold_1, epoch_296, Loss: 0.3676\n",
      "fold_1, epoch_297, Loss: 0.3682\n",
      "fold_1, epoch_298, Loss: 0.3671\n",
      "fold_1, epoch_299, Loss: 0.3662\n",
      "fold_1, epoch_300, Loss: 0.3654\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3665\n",
      "Accuracy:\t0.9466\n",
      "AUC:\t\t0.9516\n",
      "Precision:\t0.9604\n",
      "Recall:\t\t0.9319\n",
      "F1:\t\t\t0.9460\n",
      "\n",
      "fold_1, epoch_301, Loss: 0.3698\n",
      "fold_1, epoch_302, Loss: 0.3674\n",
      "fold_1, epoch_303, Loss: 0.3660\n",
      "fold_1, epoch_304, Loss: 0.3648\n",
      "fold_1, epoch_305, Loss: 0.3683\n",
      "fold_1, epoch_306, Loss: 0.3697\n",
      "fold_1, epoch_307, Loss: 0.3666\n",
      "fold_1, epoch_308, Loss: 0.3693\n",
      "fold_1, epoch_309, Loss: 0.3682\n",
      "fold_1, epoch_310, Loss: 0.3676\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3632\n",
      "Accuracy:\t0.9498\n",
      "AUC:\t\t0.9521\n",
      "Precision:\t0.9651\n",
      "Recall:\t\t0.9340\n",
      "F1:\t\t\t0.9493\n",
      "\n",
      "fold_1, epoch_311, Loss: 0.3646\n",
      "fold_1, epoch_312, Loss: 0.3669\n",
      "fold_1, epoch_313, Loss: 0.3691\n",
      "fold_1, epoch_314, Loss: 0.3669\n",
      "fold_1, epoch_315, Loss: 0.3678\n",
      "fold_1, epoch_316, Loss: 0.3676\n",
      "fold_1, epoch_317, Loss: 0.3691\n",
      "fold_1, epoch_318, Loss: 0.3655\n",
      "fold_1, epoch_319, Loss: 0.3668\n",
      "fold_1, epoch_320, Loss: 0.3661\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3639\n",
      "Accuracy:\t0.9492\n",
      "AUC:\t\t0.9519\n",
      "Precision:\t0.9661\n",
      "Recall:\t\t0.9315\n",
      "F1:\t\t\t0.9485\n",
      "\n",
      "fold_1, epoch_321, Loss: 0.3634\n",
      "fold_1, epoch_322, Loss: 0.3656\n",
      "fold_1, epoch_323, Loss: 0.3684\n",
      "fold_1, epoch_324, Loss: 0.3686\n",
      "fold_1, epoch_325, Loss: 0.3677\n",
      "fold_1, epoch_326, Loss: 0.3691\n",
      "fold_1, epoch_327, Loss: 0.3664\n",
      "fold_1, epoch_328, Loss: 0.3688\n",
      "fold_1, epoch_329, Loss: 0.3674\n",
      "fold_1, epoch_330, Loss: 0.3631\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3658\n",
      "Accuracy:\t0.9472\n",
      "AUC:\t\t0.9513\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9243\n",
      "F1:\t\t\t0.9458\n",
      "\n",
      "fold_1, epoch_331, Loss: 0.3702\n",
      "fold_1, epoch_332, Loss: 0.3648\n",
      "fold_1, epoch_333, Loss: 0.3639\n",
      "fold_1, epoch_334, Loss: 0.3634\n",
      "fold_1, epoch_335, Loss: 0.3632\n",
      "fold_1, epoch_336, Loss: 0.3640\n",
      "fold_1, epoch_337, Loss: 0.3641\n",
      "fold_1, epoch_338, Loss: 0.3717\n",
      "fold_1, epoch_339, Loss: 0.3646\n",
      "fold_1, epoch_340, Loss: 0.3655\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3605\n",
      "Accuracy:\t0.9527\n",
      "AUC:\t\t0.9536\n",
      "Precision:\t0.9691\n",
      "Recall:\t\t0.9360\n",
      "F1:\t\t\t0.9523\n",
      "\n",
      "fold_1, epoch_341, Loss: 0.3627\n",
      "fold_1, epoch_342, Loss: 0.3676\n",
      "fold_1, epoch_343, Loss: 0.3658\n",
      "fold_1, epoch_344, Loss: 0.3628\n",
      "fold_1, epoch_345, Loss: 0.3680\n",
      "fold_1, epoch_346, Loss: 0.3663\n",
      "fold_1, epoch_347, Loss: 0.3629\n",
      "fold_1, epoch_348, Loss: 0.3644\n",
      "fold_1, epoch_349, Loss: 0.3638\n",
      "fold_1, epoch_350, Loss: 0.3648\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3666\n",
      "Accuracy:\t0.9463\n",
      "AUC:\t\t0.9512\n",
      "Precision:\t0.9661\n",
      "Recall:\t\t0.9252\n",
      "F1:\t\t\t0.9452\n",
      "\n",
      "fold_1, epoch_351, Loss: 0.3641\n",
      "fold_1, epoch_352, Loss: 0.3618\n",
      "fold_1, epoch_353, Loss: 0.3638\n",
      "fold_1, epoch_354, Loss: 0.3634\n",
      "fold_1, epoch_355, Loss: 0.3674\n",
      "fold_1, epoch_356, Loss: 0.3677\n",
      "fold_1, epoch_357, Loss: 0.3658\n",
      "fold_1, epoch_358, Loss: 0.3641\n",
      "fold_1, epoch_359, Loss: 0.3616\n",
      "fold_1, epoch_360, Loss: 0.3656\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3684\n",
      "Accuracy:\t0.9445\n",
      "AUC:\t\t0.9511\n",
      "Precision:\t0.9651\n",
      "Recall:\t\t0.9239\n",
      "F1:\t\t\t0.9440\n",
      "\n",
      "fold_1, epoch_361, Loss: 0.3658\n",
      "fold_1, epoch_362, Loss: 0.3628\n",
      "fold_1, epoch_363, Loss: 0.3650\n",
      "fold_1, epoch_364, Loss: 0.3652\n",
      "fold_1, epoch_365, Loss: 0.3651\n",
      "fold_1, epoch_366, Loss: 0.3643\n",
      "fold_1, epoch_367, Loss: 0.3634\n",
      "fold_1, epoch_368, Loss: 0.3619\n",
      "fold_1, epoch_369, Loss: 0.3652\n",
      "fold_1, epoch_370, Loss: 0.3637\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3624\n",
      "Accuracy:\t0.9507\n",
      "AUC:\t\t0.9523\n",
      "Precision:\t0.9685\n",
      "Recall:\t\t0.9321\n",
      "F1:\t\t\t0.9499\n",
      "\n",
      "fold_1, epoch_371, Loss: 0.3634\n",
      "fold_1, epoch_372, Loss: 0.3608\n",
      "fold_1, epoch_373, Loss: 0.3629\n",
      "fold_1, epoch_374, Loss: 0.3602\n",
      "fold_1, epoch_375, Loss: 0.3628\n",
      "fold_1, epoch_376, Loss: 0.3654\n",
      "fold_1, epoch_377, Loss: 0.3632\n",
      "fold_1, epoch_378, Loss: 0.3622\n",
      "fold_1, epoch_379, Loss: 0.3636\n",
      "fold_1, epoch_380, Loss: 0.3663\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3642\n",
      "Accuracy:\t0.9488\n",
      "AUC:\t\t0.9520\n",
      "Precision:\t0.9665\n",
      "Recall:\t\t0.9302\n",
      "F1:\t\t\t0.9480\n",
      "\n",
      "fold_1, epoch_381, Loss: 0.3645\n",
      "fold_1, epoch_382, Loss: 0.3615\n",
      "fold_1, epoch_383, Loss: 0.3600\n",
      "fold_1, epoch_384, Loss: 0.3624\n",
      "fold_1, epoch_385, Loss: 0.3646\n",
      "fold_1, epoch_386, Loss: 0.3636\n",
      "fold_1, epoch_387, Loss: 0.3640\n",
      "fold_1, epoch_388, Loss: 0.3630\n",
      "fold_1, epoch_389, Loss: 0.3616\n",
      "fold_1, epoch_390, Loss: 0.3624\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3629\n",
      "Accuracy:\t0.9504\n",
      "AUC:\t\t0.9512\n",
      "Precision:\t0.9710\n",
      "Recall:\t\t0.9286\n",
      "F1:\t\t\t0.9493\n",
      "\n",
      "fold_1, epoch_391, Loss: 0.3603\n",
      "fold_1, epoch_392, Loss: 0.3627\n",
      "fold_1, epoch_393, Loss: 0.3625\n",
      "fold_1, epoch_394, Loss: 0.3608\n",
      "fold_1, epoch_395, Loss: 0.3610\n",
      "fold_1, epoch_396, Loss: 0.3611\n",
      "fold_1, epoch_397, Loss: 0.3632\n",
      "fold_1, epoch_398, Loss: 0.3627\n",
      "fold_1, epoch_399, Loss: 0.3653\n",
      "fold_1, epoch_400, Loss: 0.3619\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3584\n",
      "Accuracy:\t0.9550\n",
      "AUC:\t\t0.9547\n",
      "Precision:\t0.9743\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9539\n",
      "\n",
      "fold_1, epoch_401, Loss: 0.3609\n",
      "fold_1, epoch_402, Loss: 0.3609\n",
      "fold_1, epoch_403, Loss: 0.3610\n",
      "fold_1, epoch_404, Loss: 0.3602\n",
      "fold_1, epoch_405, Loss: 0.3626\n",
      "fold_1, epoch_406, Loss: 0.3638\n",
      "fold_1, epoch_407, Loss: 0.3613\n",
      "fold_1, epoch_408, Loss: 0.3615\n",
      "fold_1, epoch_409, Loss: 0.3607\n",
      "fold_1, epoch_410, Loss: 0.3634\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3637\n",
      "Accuracy:\t0.9494\n",
      "AUC:\t\t0.9527\n",
      "Precision:\t0.9710\n",
      "Recall:\t\t0.9265\n",
      "F1:\t\t\t0.9482\n",
      "\n",
      "fold_1, epoch_411, Loss: 0.3612\n",
      "fold_1, epoch_412, Loss: 0.3610\n",
      "fold_1, epoch_413, Loss: 0.3606\n",
      "fold_1, epoch_414, Loss: 0.3586\n",
      "fold_1, epoch_415, Loss: 0.3588\n",
      "fold_1, epoch_416, Loss: 0.3601\n",
      "fold_1, epoch_417, Loss: 0.3631\n",
      "fold_1, epoch_418, Loss: 0.3620\n",
      "fold_1, epoch_419, Loss: 0.3606\n",
      "fold_1, epoch_420, Loss: 0.3621\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3588\n",
      "Accuracy:\t0.9545\n",
      "AUC:\t\t0.9557\n",
      "Precision:\t0.9731\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9536\n",
      "\n",
      "fold_1, epoch_421, Loss: 0.3597\n",
      "fold_1, epoch_422, Loss: 0.3588\n",
      "fold_1, epoch_423, Loss: 0.3597\n",
      "fold_1, epoch_424, Loss: 0.3641\n",
      "fold_1, epoch_425, Loss: 0.3612\n",
      "fold_1, epoch_426, Loss: 0.3613\n",
      "fold_1, epoch_427, Loss: 0.3646\n",
      "fold_1, epoch_428, Loss: 0.3624\n",
      "fold_1, epoch_429, Loss: 0.3626\n",
      "fold_1, epoch_430, Loss: 0.3581\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3599\n",
      "Accuracy:\t0.9533\n",
      "AUC:\t\t0.9544\n",
      "Precision:\t0.9719\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9528\n",
      "\n",
      "fold_1, epoch_431, Loss: 0.3575\n",
      "fold_1, epoch_432, Loss: 0.3597\n",
      "fold_1, epoch_433, Loss: 0.3617\n",
      "fold_1, epoch_434, Loss: 0.3588\n",
      "fold_1, epoch_435, Loss: 0.3605\n",
      "fold_1, epoch_436, Loss: 0.3643\n",
      "fold_1, epoch_437, Loss: 0.3600\n",
      "fold_1, epoch_438, Loss: 0.3616\n",
      "fold_1, epoch_439, Loss: 0.3596\n",
      "fold_1, epoch_440, Loss: 0.3611\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3608\n",
      "Accuracy:\t0.9524\n",
      "AUC:\t\t0.9551\n",
      "Precision:\t0.9710\n",
      "Recall:\t\t0.9329\n",
      "F1:\t\t\t0.9516\n",
      "\n",
      "fold_1, epoch_441, Loss: 0.3624\n",
      "fold_1, epoch_442, Loss: 0.3584\n",
      "fold_1, epoch_443, Loss: 0.3566\n",
      "fold_1, epoch_444, Loss: 0.3568\n",
      "fold_1, epoch_445, Loss: 0.3590\n",
      "fold_1, epoch_446, Loss: 0.3586\n",
      "fold_1, epoch_447, Loss: 0.3619\n",
      "fold_1, epoch_448, Loss: 0.3597\n",
      "fold_1, epoch_449, Loss: 0.3581\n",
      "fold_1, epoch_450, Loss: 0.3576\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3608\n",
      "Accuracy:\t0.9524\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9732\n",
      "Recall:\t\t0.9296\n",
      "F1:\t\t\t0.9509\n",
      "\n",
      "fold_1, epoch_451, Loss: 0.3593\n",
      "fold_1, epoch_452, Loss: 0.3597\n",
      "fold_1, epoch_453, Loss: 0.3573\n",
      "fold_1, epoch_454, Loss: 0.3579\n",
      "fold_1, epoch_455, Loss: 0.3577\n",
      "fold_1, epoch_456, Loss: 0.3596\n",
      "fold_1, epoch_457, Loss: 0.3604\n",
      "fold_1, epoch_458, Loss: 0.3581\n",
      "fold_1, epoch_459, Loss: 0.3566\n",
      "fold_1, epoch_460, Loss: 0.3590\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3580\n",
      "Accuracy:\t0.9551\n",
      "AUC:\t\t0.9598\n",
      "Precision:\t0.9775\n",
      "Recall:\t\t0.9306\n",
      "F1:\t\t\t0.9535\n",
      "\n",
      "fold_1, epoch_461, Loss: 0.3598\n",
      "fold_1, epoch_462, Loss: 0.3584\n",
      "fold_1, epoch_463, Loss: 0.3629\n",
      "fold_1, epoch_464, Loss: 0.3594\n",
      "fold_1, epoch_465, Loss: 0.3594\n",
      "fold_1, epoch_466, Loss: 0.3604\n",
      "fold_1, epoch_467, Loss: 0.3586\n",
      "fold_1, epoch_468, Loss: 0.3574\n",
      "fold_1, epoch_469, Loss: 0.3593\n",
      "fold_1, epoch_470, Loss: 0.3579\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3573\n",
      "Accuracy:\t0.9559\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9780\n",
      "Recall:\t\t0.9332\n",
      "F1:\t\t\t0.9551\n",
      "\n",
      "fold_1, epoch_471, Loss: 0.3568\n",
      "fold_1, epoch_472, Loss: 0.3601\n",
      "fold_1, epoch_473, Loss: 0.3563\n",
      "fold_1, epoch_474, Loss: 0.3566\n",
      "fold_1, epoch_475, Loss: 0.3591\n",
      "fold_1, epoch_476, Loss: 0.3586\n",
      "fold_1, epoch_477, Loss: 0.3587\n",
      "fold_1, epoch_478, Loss: 0.3575\n",
      "fold_1, epoch_479, Loss: 0.3576\n",
      "fold_1, epoch_480, Loss: 0.3556\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3634\n",
      "Accuracy:\t0.9496\n",
      "AUC:\t\t0.9536\n",
      "Precision:\t0.9669\n",
      "Recall:\t\t0.9309\n",
      "F1:\t\t\t0.9485\n",
      "\n",
      "fold_1, epoch_481, Loss: 0.3587\n",
      "fold_1, epoch_482, Loss: 0.3582\n",
      "fold_1, epoch_483, Loss: 0.3584\n",
      "fold_1, epoch_484, Loss: 0.3565\n",
      "fold_1, epoch_485, Loss: 0.3574\n",
      "fold_1, epoch_486, Loss: 0.3573\n",
      "fold_1, epoch_487, Loss: 0.3603\n",
      "fold_1, epoch_488, Loss: 0.3565\n",
      "fold_1, epoch_489, Loss: 0.3554\n",
      "fold_1, epoch_490, Loss: 0.3572\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3564\n",
      "Accuracy:\t0.9567\n",
      "AUC:\t\t0.9576\n",
      "Precision:\t0.9768\n",
      "Recall:\t\t0.9355\n",
      "F1:\t\t\t0.9557\n",
      "\n",
      "fold_1, epoch_491, Loss: 0.3566\n",
      "fold_1, epoch_492, Loss: 0.3551\n",
      "fold_1, epoch_493, Loss: 0.3596\n",
      "fold_1, epoch_494, Loss: 0.3557\n",
      "fold_1, epoch_495, Loss: 0.3591\n",
      "fold_1, epoch_496, Loss: 0.3572\n",
      "fold_1, epoch_497, Loss: 0.3591\n",
      "fold_1, epoch_498, Loss: 0.3562\n",
      "fold_1, epoch_499, Loss: 0.3591\n",
      "fold_1, epoch_500, Loss: 0.3554\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3563\n",
      "Accuracy:\t0.9567\n",
      "AUC:\t\t0.9559\n",
      "Precision:\t0.9773\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9553\n",
      "\n",
      "fold_1, epoch_501, Loss: 0.3573\n",
      "fold_1, epoch_502, Loss: 0.3617\n",
      "fold_1, epoch_503, Loss: 0.3588\n",
      "fold_1, epoch_504, Loss: 0.3549\n",
      "fold_1, epoch_505, Loss: 0.3591\n",
      "fold_1, epoch_506, Loss: 0.3577\n",
      "fold_1, epoch_507, Loss: 0.3588\n",
      "fold_1, epoch_508, Loss: 0.3577\n",
      "fold_1, epoch_509, Loss: 0.3586\n",
      "fold_1, epoch_510, Loss: 0.3599\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3550\n",
      "Accuracy:\t0.9580\n",
      "AUC:\t\t0.9587\n",
      "Precision:\t0.9773\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9572\n",
      "\n",
      "fold_1, epoch_511, Loss: 0.3588\n",
      "fold_1, epoch_512, Loss: 0.3570\n",
      "fold_1, epoch_513, Loss: 0.3574\n",
      "fold_1, epoch_514, Loss: 0.3577\n",
      "fold_1, epoch_515, Loss: 0.3570\n",
      "fold_1, epoch_516, Loss: 0.3571\n",
      "fold_1, epoch_517, Loss: 0.3575\n",
      "fold_1, epoch_518, Loss: 0.3553\n",
      "fold_1, epoch_519, Loss: 0.3545\n",
      "fold_1, epoch_520, Loss: 0.3570\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3552\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9575\n",
      "Precision:\t0.9788\n",
      "Recall:\t\t0.9364\n",
      "F1:\t\t\t0.9572\n",
      "\n",
      "fold_1, epoch_521, Loss: 0.3572\n",
      "fold_1, epoch_522, Loss: 0.3590\n",
      "fold_1, epoch_523, Loss: 0.3584\n",
      "fold_1, epoch_524, Loss: 0.3579\n",
      "fold_1, epoch_525, Loss: 0.3585\n",
      "fold_1, epoch_526, Loss: 0.3567\n",
      "fold_1, epoch_527, Loss: 0.3592\n",
      "fold_1, epoch_528, Loss: 0.3576\n",
      "fold_1, epoch_529, Loss: 0.3597\n",
      "fold_1, epoch_530, Loss: 0.3593\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3564\n",
      "Accuracy:\t0.9566\n",
      "AUC:\t\t0.9583\n",
      "Precision:\t0.9765\n",
      "Recall:\t\t0.9354\n",
      "F1:\t\t\t0.9555\n",
      "\n",
      "fold_1, epoch_531, Loss: 0.3554\n",
      "fold_1, epoch_532, Loss: 0.3555\n",
      "fold_1, epoch_533, Loss: 0.3592\n",
      "fold_1, epoch_534, Loss: 0.3575\n",
      "fold_1, epoch_535, Loss: 0.3577\n",
      "fold_1, epoch_536, Loss: 0.3568\n",
      "fold_1, epoch_537, Loss: 0.3576\n",
      "fold_1, epoch_538, Loss: 0.3585\n",
      "fold_1, epoch_539, Loss: 0.3568\n",
      "fold_1, epoch_540, Loss: 0.3588\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3568\n",
      "Accuracy:\t0.9561\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9753\n",
      "Recall:\t\t0.9356\n",
      "F1:\t\t\t0.9550\n",
      "\n",
      "fold_1, epoch_541, Loss: 0.3588\n",
      "fold_1, epoch_542, Loss: 0.3550\n",
      "fold_1, epoch_543, Loss: 0.3581\n",
      "fold_1, epoch_544, Loss: 0.3576\n",
      "fold_1, epoch_545, Loss: 0.3588\n",
      "fold_1, epoch_546, Loss: 0.3549\n",
      "fold_1, epoch_547, Loss: 0.3555\n",
      "fold_1, epoch_548, Loss: 0.3545\n",
      "fold_1, epoch_549, Loss: 0.3577\n",
      "fold_1, epoch_550, Loss: 0.3555\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3521\n",
      "Accuracy:\t0.9610\n",
      "AUC:\t\t0.9605\n",
      "Precision:\t0.9822\n",
      "Recall:\t\t0.9387\n",
      "F1:\t\t\t0.9599\n",
      "\n",
      "fold_1, epoch_551, Loss: 0.3564\n",
      "fold_1, epoch_552, Loss: 0.3567\n",
      "fold_1, epoch_553, Loss: 0.3576\n",
      "fold_1, epoch_554, Loss: 0.3537\n",
      "fold_1, epoch_555, Loss: 0.3557\n",
      "fold_1, epoch_556, Loss: 0.3553\n",
      "fold_1, epoch_557, Loss: 0.3561\n",
      "fold_1, epoch_558, Loss: 0.3557\n",
      "fold_1, epoch_559, Loss: 0.3561\n",
      "fold_1, epoch_560, Loss: 0.3594\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3554\n",
      "Accuracy:\t0.9577\n",
      "AUC:\t\t0.9584\n",
      "Precision:\t0.9803\n",
      "Recall:\t\t0.9342\n",
      "F1:\t\t\t0.9567\n",
      "\n",
      "fold_1, epoch_561, Loss: 0.3561\n",
      "fold_1, epoch_562, Loss: 0.3555\n",
      "fold_1, epoch_563, Loss: 0.3573\n",
      "fold_1, epoch_564, Loss: 0.3558\n",
      "fold_1, epoch_565, Loss: 0.3599\n",
      "fold_1, epoch_566, Loss: 0.3555\n",
      "fold_1, epoch_567, Loss: 0.3563\n",
      "fold_1, epoch_568, Loss: 0.3567\n",
      "fold_1, epoch_569, Loss: 0.3547\n",
      "fold_1, epoch_570, Loss: 0.3558\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3543\n",
      "Accuracy:\t0.9584\n",
      "AUC:\t\t0.9598\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9348\n",
      "F1:\t\t\t0.9573\n",
      "\n",
      "fold_1, epoch_571, Loss: 0.3576\n",
      "fold_1, epoch_572, Loss: 0.3531\n",
      "fold_1, epoch_573, Loss: 0.3553\n",
      "fold_1, epoch_574, Loss: 0.3538\n",
      "fold_1, epoch_575, Loss: 0.3558\n",
      "fold_1, epoch_576, Loss: 0.3581\n",
      "fold_1, epoch_577, Loss: 0.3554\n",
      "fold_1, epoch_578, Loss: 0.3585\n",
      "fold_1, epoch_579, Loss: 0.3572\n",
      "fold_1, epoch_580, Loss: 0.3561\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3624\n",
      "Accuracy:\t0.9507\n",
      "AUC:\t\t0.9552\n",
      "Precision:\t0.9709\n",
      "Recall:\t\t0.9308\n",
      "F1:\t\t\t0.9504\n",
      "\n",
      "fold_1, epoch_581, Loss: 0.3571\n",
      "fold_1, epoch_582, Loss: 0.3564\n",
      "fold_1, epoch_583, Loss: 0.3566\n",
      "fold_1, epoch_584, Loss: 0.3544\n",
      "fold_1, epoch_585, Loss: 0.3566\n",
      "fold_1, epoch_586, Loss: 0.3549\n",
      "fold_1, epoch_587, Loss: 0.3564\n",
      "fold_1, epoch_588, Loss: 0.3563\n",
      "fold_1, epoch_589, Loss: 0.3557\n",
      "fold_1, epoch_590, Loss: 0.3552\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9594\n",
      "AUC:\t\t0.9588\n",
      "Precision:\t0.9793\n",
      "Recall:\t\t0.9385\n",
      "F1:\t\t\t0.9585\n",
      "\n",
      "fold_1, epoch_591, Loss: 0.3551\n",
      "fold_1, epoch_592, Loss: 0.3546\n",
      "fold_1, epoch_593, Loss: 0.3558\n",
      "fold_1, epoch_594, Loss: 0.3552\n",
      "fold_1, epoch_595, Loss: 0.3545\n",
      "fold_1, epoch_596, Loss: 0.3565\n",
      "fold_1, epoch_597, Loss: 0.3555\n",
      "fold_1, epoch_598, Loss: 0.3552\n",
      "fold_1, epoch_599, Loss: 0.3547\n",
      "fold_1, epoch_600, Loss: 0.3555\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3558\n",
      "Accuracy:\t0.9575\n",
      "AUC:\t\t0.9562\n",
      "Precision:\t0.9778\n",
      "Recall:\t\t0.9362\n",
      "F1:\t\t\t0.9565\n",
      "\n",
      "fold_1, epoch_601, Loss: 0.3552\n",
      "fold_1, epoch_602, Loss: 0.3601\n",
      "fold_1, epoch_603, Loss: 0.3575\n",
      "fold_1, epoch_604, Loss: 0.3551\n",
      "fold_1, epoch_605, Loss: 0.3551\n",
      "fold_1, epoch_606, Loss: 0.3547\n",
      "fold_1, epoch_607, Loss: 0.3575\n",
      "fold_1, epoch_608, Loss: 0.3549\n",
      "fold_1, epoch_609, Loss: 0.3557\n",
      "fold_1, epoch_610, Loss: 0.3575\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3573\n",
      "Accuracy:\t0.9557\n",
      "AUC:\t\t0.9580\n",
      "Precision:\t0.9772\n",
      "Recall:\t\t0.9338\n",
      "F1:\t\t\t0.9550\n",
      "\n",
      "fold_1, epoch_611, Loss: 0.3559\n",
      "fold_1, epoch_612, Loss: 0.3539\n",
      "fold_1, epoch_613, Loss: 0.3555\n",
      "fold_1, epoch_614, Loss: 0.3547\n",
      "fold_1, epoch_615, Loss: 0.3554\n",
      "fold_1, epoch_616, Loss: 0.3530\n",
      "fold_1, epoch_617, Loss: 0.3560\n",
      "fold_1, epoch_618, Loss: 0.3576\n",
      "fold_1, epoch_619, Loss: 0.3542\n",
      "fold_1, epoch_620, Loss: 0.3544\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9593\n",
      "AUC:\t\t0.9597\n",
      "Precision:\t0.9798\n",
      "Recall:\t\t0.9381\n",
      "F1:\t\t\t0.9585\n",
      "\n",
      "fold_1, epoch_621, Loss: 0.3542\n",
      "fold_1, epoch_622, Loss: 0.3602\n",
      "fold_1, epoch_623, Loss: 0.3576\n",
      "fold_1, epoch_624, Loss: 0.3559\n",
      "fold_1, epoch_625, Loss: 0.3547\n",
      "fold_1, epoch_626, Loss: 0.3542\n",
      "fold_1, epoch_627, Loss: 0.3559\n",
      "fold_1, epoch_628, Loss: 0.3573\n",
      "fold_1, epoch_629, Loss: 0.3557\n",
      "fold_1, epoch_630, Loss: 0.3540\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9605\n",
      "AUC:\t\t0.9602\n",
      "Precision:\t0.9820\n",
      "Recall:\t\t0.9379\n",
      "F1:\t\t\t0.9595\n",
      "\n",
      "fold_1, epoch_631, Loss: 0.3582\n",
      "fold_1, epoch_632, Loss: 0.3576\n",
      "fold_1, epoch_633, Loss: 0.3516\n",
      "fold_1, epoch_634, Loss: 0.3557\n",
      "fold_1, epoch_635, Loss: 0.3566\n",
      "fold_1, epoch_636, Loss: 0.3543\n",
      "fold_1, epoch_637, Loss: 0.3561\n",
      "fold_1, epoch_638, Loss: 0.3569\n",
      "fold_1, epoch_639, Loss: 0.3548\n",
      "fold_1, epoch_640, Loss: 0.3556\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3531\n",
      "Accuracy:\t0.9603\n",
      "AUC:\t\t0.9597\n",
      "Precision:\t0.9825\n",
      "Recall:\t\t0.9379\n",
      "F1:\t\t\t0.9597\n",
      "\n",
      "fold_1, epoch_641, Loss: 0.3532\n",
      "fold_1, epoch_642, Loss: 0.3537\n",
      "fold_1, epoch_643, Loss: 0.3520\n",
      "fold_1, epoch_644, Loss: 0.3547\n",
      "fold_1, epoch_645, Loss: 0.3538\n",
      "fold_1, epoch_646, Loss: 0.3560\n",
      "fold_1, epoch_647, Loss: 0.3575\n",
      "fold_1, epoch_648, Loss: 0.3534\n",
      "fold_1, epoch_649, Loss: 0.3526\n",
      "fold_1, epoch_650, Loss: 0.3578\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3545\n",
      "Accuracy:\t0.9587\n",
      "AUC:\t\t0.9604\n",
      "Precision:\t0.9801\n",
      "Recall:\t\t0.9363\n",
      "F1:\t\t\t0.9577\n",
      "\n",
      "fold_1, epoch_651, Loss: 0.3556\n",
      "fold_1, epoch_652, Loss: 0.3543\n",
      "fold_1, epoch_653, Loss: 0.3561\n",
      "fold_1, epoch_654, Loss: 0.3560\n",
      "fold_1, epoch_655, Loss: 0.3556\n",
      "fold_1, epoch_656, Loss: 0.3513\n",
      "fold_1, epoch_657, Loss: 0.3526\n",
      "fold_1, epoch_658, Loss: 0.3569\n",
      "fold_1, epoch_659, Loss: 0.3541\n",
      "fold_1, epoch_660, Loss: 0.3556\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9595\n",
      "AUC:\t\t0.9585\n",
      "Precision:\t0.9840\n",
      "Recall:\t\t0.9338\n",
      "F1:\t\t\t0.9582\n",
      "\n",
      "fold_1, epoch_661, Loss: 0.3552\n",
      "fold_1, epoch_662, Loss: 0.3558\n",
      "fold_1, epoch_663, Loss: 0.3550\n",
      "fold_1, epoch_664, Loss: 0.3531\n",
      "fold_1, epoch_665, Loss: 0.3538\n",
      "fold_1, epoch_666, Loss: 0.3560\n",
      "fold_1, epoch_667, Loss: 0.3548\n",
      "fold_1, epoch_668, Loss: 0.3534\n",
      "fold_1, epoch_669, Loss: 0.3551\n",
      "fold_1, epoch_670, Loss: 0.3550\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3521\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9608\n",
      "Precision:\t0.9852\n",
      "Recall:\t\t0.9361\n",
      "F1:\t\t\t0.9600\n",
      "\n",
      "fold_1, epoch_671, Loss: 0.3546\n",
      "fold_1, epoch_672, Loss: 0.3542\n",
      "fold_1, epoch_673, Loss: 0.3583\n",
      "fold_1, epoch_674, Loss: 0.3551\n",
      "fold_1, epoch_675, Loss: 0.3559\n",
      "fold_1, epoch_676, Loss: 0.3547\n",
      "fold_1, epoch_677, Loss: 0.3540\n",
      "fold_1, epoch_678, Loss: 0.3534\n",
      "fold_1, epoch_679, Loss: 0.3577\n",
      "fold_1, epoch_680, Loss: 0.3513\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3510\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9612\n",
      "Precision:\t0.9850\n",
      "Recall:\t\t0.9389\n",
      "F1:\t\t\t0.9614\n",
      "\n",
      "fold_1, epoch_681, Loss: 0.3516\n",
      "fold_1, epoch_682, Loss: 0.3538\n",
      "fold_1, epoch_683, Loss: 0.3557\n",
      "fold_1, epoch_684, Loss: 0.3531\n",
      "fold_1, epoch_685, Loss: 0.3562\n",
      "fold_1, epoch_686, Loss: 0.3546\n",
      "fold_1, epoch_687, Loss: 0.3561\n",
      "fold_1, epoch_688, Loss: 0.3536\n",
      "fold_1, epoch_689, Loss: 0.3522\n",
      "fold_1, epoch_690, Loss: 0.3523\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3533\n",
      "Accuracy:\t0.9597\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9841\n",
      "Recall:\t\t0.9347\n",
      "F1:\t\t\t0.9588\n",
      "\n",
      "fold_1, epoch_691, Loss: 0.3535\n",
      "fold_1, epoch_692, Loss: 0.3538\n",
      "fold_1, epoch_693, Loss: 0.3546\n",
      "fold_1, epoch_694, Loss: 0.3540\n",
      "fold_1, epoch_695, Loss: 0.3532\n",
      "fold_1, epoch_696, Loss: 0.3534\n",
      "fold_1, epoch_697, Loss: 0.3542\n",
      "fold_1, epoch_698, Loss: 0.3567\n",
      "fold_1, epoch_699, Loss: 0.3555\n",
      "fold_1, epoch_700, Loss: 0.3520\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3528\n",
      "Accuracy:\t0.9604\n",
      "AUC:\t\t0.9601\n",
      "Precision:\t0.9825\n",
      "Recall:\t\t0.9378\n",
      "F1:\t\t\t0.9596\n",
      "\n",
      "fold_1, epoch_701, Loss: 0.3526\n",
      "fold_1, epoch_702, Loss: 0.3524\n",
      "fold_1, epoch_703, Loss: 0.3554\n",
      "fold_1, epoch_704, Loss: 0.3540\n",
      "fold_1, epoch_705, Loss: 0.3530\n",
      "fold_1, epoch_706, Loss: 0.3537\n",
      "fold_1, epoch_707, Loss: 0.3530\n",
      "fold_1, epoch_708, Loss: 0.3526\n",
      "fold_1, epoch_709, Loss: 0.3538\n",
      "fold_1, epoch_710, Loss: 0.3503\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3540\n",
      "Accuracy:\t0.9592\n",
      "AUC:\t\t0.9597\n",
      "Precision:\t0.9837\n",
      "Recall:\t\t0.9336\n",
      "F1:\t\t\t0.9580\n",
      "\n",
      "fold_1, epoch_711, Loss: 0.3520\n",
      "fold_1, epoch_712, Loss: 0.3548\n",
      "fold_1, epoch_713, Loss: 0.3531\n",
      "fold_1, epoch_714, Loss: 0.3542\n",
      "fold_1, epoch_715, Loss: 0.3542\n",
      "fold_1, epoch_716, Loss: 0.3524\n",
      "fold_1, epoch_717, Loss: 0.3543\n",
      "fold_1, epoch_718, Loss: 0.3506\n",
      "fold_1, epoch_719, Loss: 0.3510\n",
      "fold_1, epoch_720, Loss: 0.3534\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3521\n",
      "Accuracy:\t0.9609\n",
      "AUC:\t\t0.9619\n",
      "Precision:\t0.9819\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9596\n",
      "\n",
      "fold_1, epoch_721, Loss: 0.3534\n",
      "fold_1, epoch_722, Loss: 0.3558\n",
      "fold_1, epoch_723, Loss: 0.3538\n",
      "fold_1, epoch_724, Loss: 0.3516\n",
      "fold_1, epoch_725, Loss: 0.3517\n",
      "fold_1, epoch_726, Loss: 0.3537\n",
      "fold_1, epoch_727, Loss: 0.3583\n",
      "fold_1, epoch_728, Loss: 0.3555\n",
      "fold_1, epoch_729, Loss: 0.3526\n",
      "fold_1, epoch_730, Loss: 0.3542\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9594\n",
      "AUC:\t\t0.9583\n",
      "Precision:\t0.9837\n",
      "Recall:\t\t0.9340\n",
      "F1:\t\t\t0.9582\n",
      "\n",
      "fold_1, epoch_731, Loss: 0.3504\n",
      "fold_1, epoch_732, Loss: 0.3531\n",
      "fold_1, epoch_733, Loss: 0.3528\n",
      "fold_1, epoch_734, Loss: 0.3528\n",
      "fold_1, epoch_735, Loss: 0.3535\n",
      "fold_1, epoch_736, Loss: 0.3524\n",
      "fold_1, epoch_737, Loss: 0.3563\n",
      "fold_1, epoch_738, Loss: 0.3534\n",
      "fold_1, epoch_739, Loss: 0.3555\n",
      "fold_1, epoch_740, Loss: 0.3529\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3529\n",
      "Accuracy:\t0.9602\n",
      "AUC:\t\t0.9618\n",
      "Precision:\t0.9793\n",
      "Recall:\t\t0.9401\n",
      "F1:\t\t\t0.9593\n",
      "\n",
      "fold_1, epoch_741, Loss: 0.3572\n",
      "fold_1, epoch_742, Loss: 0.3533\n",
      "fold_1, epoch_743, Loss: 0.3528\n",
      "fold_1, epoch_744, Loss: 0.3518\n",
      "fold_1, epoch_745, Loss: 0.3525\n",
      "fold_1, epoch_746, Loss: 0.3546\n",
      "fold_1, epoch_747, Loss: 0.3538\n",
      "fold_1, epoch_748, Loss: 0.3506\n",
      "fold_1, epoch_749, Loss: 0.3528\n",
      "fold_1, epoch_750, Loss: 0.3542\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3525\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9609\n",
      "Precision:\t0.9863\n",
      "Recall:\t\t0.9354\n",
      "F1:\t\t\t0.9602\n",
      "\n",
      "fold_1, epoch_751, Loss: 0.3545\n",
      "fold_1, epoch_752, Loss: 0.3519\n",
      "fold_1, epoch_753, Loss: 0.3530\n",
      "fold_1, epoch_754, Loss: 0.3529\n",
      "fold_1, epoch_755, Loss: 0.3498\n",
      "fold_1, epoch_756, Loss: 0.3527\n",
      "fold_1, epoch_757, Loss: 0.3531\n",
      "fold_1, epoch_758, Loss: 0.3559\n",
      "fold_1, epoch_759, Loss: 0.3530\n",
      "fold_1, epoch_760, Loss: 0.3532\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3555\n",
      "Accuracy:\t0.9577\n",
      "AUC:\t\t0.9578\n",
      "Precision:\t0.9813\n",
      "Recall:\t\t0.9327\n",
      "F1:\t\t\t0.9564\n",
      "\n",
      "fold_1, epoch_761, Loss: 0.3532\n",
      "fold_1, epoch_762, Loss: 0.3525\n",
      "fold_1, epoch_763, Loss: 0.3510\n",
      "fold_1, epoch_764, Loss: 0.3525\n",
      "fold_1, epoch_765, Loss: 0.3501\n",
      "fold_1, epoch_766, Loss: 0.3547\n",
      "fold_1, epoch_767, Loss: 0.3527\n",
      "fold_1, epoch_768, Loss: 0.3509\n",
      "fold_1, epoch_769, Loss: 0.3533\n",
      "fold_1, epoch_770, Loss: 0.3502\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3499\n",
      "Accuracy:\t0.9633\n",
      "AUC:\t\t0.9628\n",
      "Precision:\t0.9856\n",
      "Recall:\t\t0.9411\n",
      "F1:\t\t\t0.9628\n",
      "\n",
      "fold_1, epoch_771, Loss: 0.3532\n",
      "fold_1, epoch_772, Loss: 0.3537\n",
      "fold_1, epoch_773, Loss: 0.3500\n",
      "fold_1, epoch_774, Loss: 0.3524\n",
      "fold_1, epoch_775, Loss: 0.3522\n",
      "fold_1, epoch_776, Loss: 0.3561\n",
      "fold_1, epoch_777, Loss: 0.3546\n",
      "fold_1, epoch_778, Loss: 0.3539\n",
      "fold_1, epoch_779, Loss: 0.3513\n",
      "fold_1, epoch_780, Loss: 0.3524\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3531\n",
      "Accuracy:\t0.9600\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9812\n",
      "Recall:\t\t0.9378\n",
      "F1:\t\t\t0.9590\n",
      "\n",
      "fold_1, epoch_781, Loss: 0.3530\n",
      "fold_1, epoch_782, Loss: 0.3518\n",
      "fold_1, epoch_783, Loss: 0.3523\n",
      "fold_1, epoch_784, Loss: 0.3521\n",
      "fold_1, epoch_785, Loss: 0.3541\n",
      "fold_1, epoch_786, Loss: 0.3526\n",
      "fold_1, epoch_787, Loss: 0.3529\n",
      "fold_1, epoch_788, Loss: 0.3514\n",
      "fold_1, epoch_789, Loss: 0.3542\n",
      "fold_1, epoch_790, Loss: 0.3531\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9605\n",
      "Precision:\t0.9815\n",
      "Recall:\t\t0.9358\n",
      "F1:\t\t\t0.9581\n",
      "\n",
      "fold_1, epoch_791, Loss: 0.3533\n",
      "fold_1, epoch_792, Loss: 0.3511\n",
      "fold_1, epoch_793, Loss: 0.3517\n",
      "fold_1, epoch_794, Loss: 0.3520\n",
      "fold_1, epoch_795, Loss: 0.3547\n",
      "fold_1, epoch_796, Loss: 0.3502\n",
      "fold_1, epoch_797, Loss: 0.3522\n",
      "fold_1, epoch_798, Loss: 0.3504\n",
      "fold_1, epoch_799, Loss: 0.3513\n",
      "fold_1, epoch_800, Loss: 0.3515\n",
      "\n",
      "fold_1 performance on test data:\n",
      "Loss:\t\t0.3522\n",
      "Accuracy:\t0.9610\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9849\n",
      "Recall:\t\t0.9359\n",
      "F1:\t\t\t0.9598\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/checkpoints/fold_2\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/tensorboard\n",
      "\n",
      "\n",
      "fold_2, epoch_1, Loss: 0.5816\n",
      "fold_2, epoch_2, Loss: 0.5470\n",
      "fold_2, epoch_3, Loss: 0.5405\n",
      "fold_2, epoch_4, Loss: 0.5266\n",
      "fold_2, epoch_5, Loss: 0.5240\n",
      "fold_2, epoch_6, Loss: 0.5187\n",
      "fold_2, epoch_7, Loss: 0.5177\n",
      "fold_2, epoch_8, Loss: 0.5105\n",
      "fold_2, epoch_9, Loss: 0.5068\n",
      "fold_2, epoch_10, Loss: 0.5057\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4994\n",
      "Accuracy:\t0.8054\n",
      "AUC:\t\t0.8738\n",
      "Precision:\t0.8067\n",
      "Recall:\t\t0.8006\n",
      "F1:\t\t\t0.8037\n",
      "\n",
      "fold_2, epoch_11, Loss: 0.4994\n",
      "fold_2, epoch_12, Loss: 0.4990\n",
      "fold_2, epoch_13, Loss: 0.4957\n",
      "fold_2, epoch_14, Loss: 0.4922\n",
      "fold_2, epoch_15, Loss: 0.4904\n",
      "fold_2, epoch_16, Loss: 0.4859\n",
      "fold_2, epoch_17, Loss: 0.4845\n",
      "fold_2, epoch_18, Loss: 0.4842\n",
      "fold_2, epoch_19, Loss: 0.4780\n",
      "fold_2, epoch_20, Loss: 0.4769\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4775\n",
      "Accuracy:\t0.8319\n",
      "AUC:\t\t0.8810\n",
      "Precision:\t0.8266\n",
      "Recall:\t\t0.8401\n",
      "F1:\t\t\t0.8333\n",
      "\n",
      "fold_2, epoch_21, Loss: 0.4763\n",
      "fold_2, epoch_22, Loss: 0.4729\n",
      "fold_2, epoch_23, Loss: 0.4696\n",
      "fold_2, epoch_24, Loss: 0.4714\n",
      "fold_2, epoch_25, Loss: 0.4685\n",
      "fold_2, epoch_26, Loss: 0.4696\n",
      "fold_2, epoch_27, Loss: 0.4649\n",
      "fold_2, epoch_28, Loss: 0.4647\n",
      "fold_2, epoch_29, Loss: 0.4540\n",
      "fold_2, epoch_30, Loss: 0.4547\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4631\n",
      "Accuracy:\t0.8462\n",
      "AUC:\t\t0.8913\n",
      "Precision:\t0.8286\n",
      "Recall:\t\t0.8745\n",
      "F1:\t\t\t0.8509\n",
      "\n",
      "fold_2, epoch_31, Loss: 0.4532\n",
      "fold_2, epoch_32, Loss: 0.4608\n",
      "fold_2, epoch_33, Loss: 0.4521\n",
      "fold_2, epoch_34, Loss: 0.4510\n",
      "fold_2, epoch_35, Loss: 0.4500\n",
      "fold_2, epoch_36, Loss: 0.4474\n",
      "fold_2, epoch_37, Loss: 0.4567\n",
      "fold_2, epoch_38, Loss: 0.4438\n",
      "fold_2, epoch_39, Loss: 0.4394\n",
      "fold_2, epoch_40, Loss: 0.4380\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4431\n",
      "Accuracy:\t0.8679\n",
      "AUC:\t\t0.9042\n",
      "Precision:\t0.8365\n",
      "Recall:\t\t0.9110\n",
      "F1:\t\t\t0.8721\n",
      "\n",
      "fold_2, epoch_41, Loss: 0.4440\n",
      "fold_2, epoch_42, Loss: 0.4360\n",
      "fold_2, epoch_43, Loss: 0.4409\n",
      "fold_2, epoch_44, Loss: 0.4346\n",
      "fold_2, epoch_45, Loss: 0.4296\n",
      "fold_2, epoch_46, Loss: 0.4296\n",
      "fold_2, epoch_47, Loss: 0.4324\n",
      "fold_2, epoch_48, Loss: 0.4365\n",
      "fold_2, epoch_49, Loss: 0.4285\n",
      "fold_2, epoch_50, Loss: 0.4290\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4301\n",
      "Accuracy:\t0.8816\n",
      "AUC:\t\t0.9103\n",
      "Precision:\t0.8911\n",
      "Recall:\t\t0.8697\n",
      "F1:\t\t\t0.8803\n",
      "\n",
      "fold_2, epoch_51, Loss: 0.4276\n",
      "fold_2, epoch_52, Loss: 0.4284\n",
      "fold_2, epoch_53, Loss: 0.4249\n",
      "fold_2, epoch_54, Loss: 0.4242\n",
      "fold_2, epoch_55, Loss: 0.4235\n",
      "fold_2, epoch_56, Loss: 0.4246\n",
      "fold_2, epoch_57, Loss: 0.4239\n",
      "fold_2, epoch_58, Loss: 0.4223\n",
      "fold_2, epoch_59, Loss: 0.4208\n",
      "fold_2, epoch_60, Loss: 0.4229\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4164\n",
      "Accuracy:\t0.8962\n",
      "AUC:\t\t0.9163\n",
      "Precision:\t0.8923\n",
      "Recall:\t\t0.8992\n",
      "F1:\t\t\t0.8957\n",
      "\n",
      "fold_2, epoch_61, Loss: 0.4161\n",
      "fold_2, epoch_62, Loss: 0.4219\n",
      "fold_2, epoch_63, Loss: 0.4185\n",
      "fold_2, epoch_64, Loss: 0.4160\n",
      "fold_2, epoch_65, Loss: 0.4140\n",
      "fold_2, epoch_66, Loss: 0.4093\n",
      "fold_2, epoch_67, Loss: 0.4192\n",
      "fold_2, epoch_68, Loss: 0.4110\n",
      "fold_2, epoch_69, Loss: 0.4119\n",
      "fold_2, epoch_70, Loss: 0.4138\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4301\n",
      "Accuracy:\t0.8819\n",
      "AUC:\t\t0.9083\n",
      "Precision:\t0.8753\n",
      "Recall:\t\t0.8924\n",
      "F1:\t\t\t0.8837\n",
      "\n",
      "fold_2, epoch_71, Loss: 0.4105\n",
      "fold_2, epoch_72, Loss: 0.4110\n",
      "fold_2, epoch_73, Loss: 0.4074\n",
      "fold_2, epoch_74, Loss: 0.4100\n",
      "fold_2, epoch_75, Loss: 0.4057\n",
      "fold_2, epoch_76, Loss: 0.4099\n",
      "fold_2, epoch_77, Loss: 0.4048\n",
      "fold_2, epoch_78, Loss: 0.4051\n",
      "fold_2, epoch_79, Loss: 0.4090\n",
      "fold_2, epoch_80, Loss: 0.4072\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4111\n",
      "Accuracy:\t0.9012\n",
      "AUC:\t\t0.9198\n",
      "Precision:\t0.9044\n",
      "Recall:\t\t0.8976\n",
      "F1:\t\t\t0.9010\n",
      "\n",
      "fold_2, epoch_81, Loss: 0.4049\n",
      "fold_2, epoch_82, Loss: 0.4011\n",
      "fold_2, epoch_83, Loss: 0.4001\n",
      "fold_2, epoch_84, Loss: 0.4054\n",
      "fold_2, epoch_85, Loss: 0.4115\n",
      "fold_2, epoch_86, Loss: 0.4044\n",
      "fold_2, epoch_87, Loss: 0.4065\n",
      "fold_2, epoch_88, Loss: 0.4068\n",
      "fold_2, epoch_89, Loss: 0.4022\n",
      "fold_2, epoch_90, Loss: 0.4025\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3995\n",
      "Accuracy:\t0.9133\n",
      "AUC:\t\t0.9256\n",
      "Precision:\t0.9190\n",
      "Recall:\t\t0.9076\n",
      "F1:\t\t\t0.9133\n",
      "\n",
      "fold_2, epoch_91, Loss: 0.3990\n",
      "fold_2, epoch_92, Loss: 0.3999\n",
      "fold_2, epoch_93, Loss: 0.4034\n",
      "fold_2, epoch_94, Loss: 0.4038\n",
      "fold_2, epoch_95, Loss: 0.3969\n",
      "fold_2, epoch_96, Loss: 0.3975\n",
      "fold_2, epoch_97, Loss: 0.3997\n",
      "fold_2, epoch_98, Loss: 0.3964\n",
      "fold_2, epoch_99, Loss: 0.3962\n",
      "fold_2, epoch_100, Loss: 0.3982\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3920\n",
      "Accuracy:\t0.9209\n",
      "AUC:\t\t0.9283\n",
      "Precision:\t0.9215\n",
      "Recall:\t\t0.9206\n",
      "F1:\t\t\t0.9211\n",
      "\n",
      "fold_2, epoch_101, Loss: 0.3942\n",
      "fold_2, epoch_102, Loss: 0.3917\n",
      "fold_2, epoch_103, Loss: 0.3940\n",
      "fold_2, epoch_104, Loss: 0.3928\n",
      "fold_2, epoch_105, Loss: 0.3975\n",
      "fold_2, epoch_106, Loss: 0.3966\n",
      "fold_2, epoch_107, Loss: 0.3915\n",
      "fold_2, epoch_108, Loss: 0.3932\n",
      "fold_2, epoch_109, Loss: 0.3941\n",
      "fold_2, epoch_110, Loss: 0.3886\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3876\n",
      "Accuracy:\t0.9253\n",
      "AUC:\t\t0.9329\n",
      "Precision:\t0.9252\n",
      "Recall:\t\t0.9252\n",
      "F1:\t\t\t0.9252\n",
      "\n",
      "fold_2, epoch_111, Loss: 0.3886\n",
      "fold_2, epoch_112, Loss: 0.3943\n",
      "fold_2, epoch_113, Loss: 0.3903\n",
      "fold_2, epoch_114, Loss: 0.3891\n",
      "fold_2, epoch_115, Loss: 0.3870\n",
      "fold_2, epoch_116, Loss: 0.3923\n",
      "fold_2, epoch_117, Loss: 0.3912\n",
      "fold_2, epoch_118, Loss: 0.3971\n",
      "fold_2, epoch_119, Loss: 0.3889\n",
      "fold_2, epoch_120, Loss: 0.3893\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3909\n",
      "Accuracy:\t0.9215\n",
      "AUC:\t\t0.9332\n",
      "Precision:\t0.9350\n",
      "Recall:\t\t0.9060\n",
      "F1:\t\t\t0.9203\n",
      "\n",
      "fold_2, epoch_121, Loss: 0.3889\n",
      "fold_2, epoch_122, Loss: 0.3892\n",
      "fold_2, epoch_123, Loss: 0.3907\n",
      "fold_2, epoch_124, Loss: 0.3899\n",
      "fold_2, epoch_125, Loss: 0.3930\n",
      "fold_2, epoch_126, Loss: 0.3896\n",
      "fold_2, epoch_127, Loss: 0.3879\n",
      "fold_2, epoch_128, Loss: 0.3908\n",
      "fold_2, epoch_129, Loss: 0.3855\n",
      "fold_2, epoch_130, Loss: 0.3885\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3836\n",
      "Accuracy:\t0.9292\n",
      "AUC:\t\t0.9383\n",
      "Precision:\t0.9307\n",
      "Recall:\t\t0.9270\n",
      "F1:\t\t\t0.9289\n",
      "\n",
      "fold_2, epoch_131, Loss: 0.3879\n",
      "fold_2, epoch_132, Loss: 0.3850\n",
      "fold_2, epoch_133, Loss: 0.3863\n",
      "fold_2, epoch_134, Loss: 0.3849\n",
      "fold_2, epoch_135, Loss: 0.3826\n",
      "fold_2, epoch_136, Loss: 0.3843\n",
      "fold_2, epoch_137, Loss: 0.3832\n",
      "fold_2, epoch_138, Loss: 0.3893\n",
      "fold_2, epoch_139, Loss: 0.3882\n",
      "fold_2, epoch_140, Loss: 0.3846\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3874\n",
      "Accuracy:\t0.9249\n",
      "AUC:\t\t0.9370\n",
      "Precision:\t0.9385\n",
      "Recall:\t\t0.9102\n",
      "F1:\t\t\t0.9241\n",
      "\n",
      "fold_2, epoch_141, Loss: 0.3884\n",
      "fold_2, epoch_142, Loss: 0.3837\n",
      "fold_2, epoch_143, Loss: 0.3862\n",
      "fold_2, epoch_144, Loss: 0.3800\n",
      "fold_2, epoch_145, Loss: 0.3857\n",
      "fold_2, epoch_146, Loss: 0.3857\n",
      "fold_2, epoch_147, Loss: 0.3855\n",
      "fold_2, epoch_148, Loss: 0.3827\n",
      "fold_2, epoch_149, Loss: 0.3854\n",
      "fold_2, epoch_150, Loss: 0.3837\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.4129\n",
      "Accuracy:\t0.8978\n",
      "AUC:\t\t0.9313\n",
      "Precision:\t0.9369\n",
      "Recall:\t\t0.8535\n",
      "F1:\t\t\t0.8933\n",
      "\n",
      "fold_2, epoch_151, Loss: 0.3821\n",
      "fold_2, epoch_152, Loss: 0.3818\n",
      "fold_2, epoch_153, Loss: 0.3843\n",
      "fold_2, epoch_154, Loss: 0.3827\n",
      "fold_2, epoch_155, Loss: 0.3782\n",
      "fold_2, epoch_156, Loss: 0.3782\n",
      "fold_2, epoch_157, Loss: 0.3795\n",
      "fold_2, epoch_158, Loss: 0.3787\n",
      "fold_2, epoch_159, Loss: 0.3813\n",
      "fold_2, epoch_160, Loss: 0.3808\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3717\n",
      "Accuracy:\t0.9419\n",
      "AUC:\t\t0.9424\n",
      "Precision:\t0.9485\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9414\n",
      "\n",
      "fold_2, epoch_161, Loss: 0.3803\n",
      "fold_2, epoch_162, Loss: 0.3813\n",
      "fold_2, epoch_163, Loss: 0.3824\n",
      "fold_2, epoch_164, Loss: 0.3791\n",
      "fold_2, epoch_165, Loss: 0.3777\n",
      "fold_2, epoch_166, Loss: 0.3800\n",
      "fold_2, epoch_167, Loss: 0.3766\n",
      "fold_2, epoch_168, Loss: 0.3772\n",
      "fold_2, epoch_169, Loss: 0.3791\n",
      "fold_2, epoch_170, Loss: 0.3781\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3725\n",
      "Accuracy:\t0.9405\n",
      "AUC:\t\t0.9442\n",
      "Precision:\t0.9490\n",
      "Recall:\t\t0.9311\n",
      "F1:\t\t\t0.9400\n",
      "\n",
      "fold_2, epoch_171, Loss: 0.3800\n",
      "fold_2, epoch_172, Loss: 0.3786\n",
      "fold_2, epoch_173, Loss: 0.3792\n",
      "fold_2, epoch_174, Loss: 0.3781\n",
      "fold_2, epoch_175, Loss: 0.3853\n",
      "fold_2, epoch_176, Loss: 0.3805\n",
      "fold_2, epoch_177, Loss: 0.3736\n",
      "fold_2, epoch_178, Loss: 0.3741\n",
      "fold_2, epoch_179, Loss: 0.3775\n",
      "fold_2, epoch_180, Loss: 0.3765\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3734\n",
      "Accuracy:\t0.9396\n",
      "AUC:\t\t0.9434\n",
      "Precision:\t0.9488\n",
      "Recall:\t\t0.9298\n",
      "F1:\t\t\t0.9392\n",
      "\n",
      "fold_2, epoch_181, Loss: 0.3736\n",
      "fold_2, epoch_182, Loss: 0.3776\n",
      "fold_2, epoch_183, Loss: 0.3777\n",
      "fold_2, epoch_184, Loss: 0.3735\n",
      "fold_2, epoch_185, Loss: 0.3750\n",
      "fold_2, epoch_186, Loss: 0.3750\n",
      "fold_2, epoch_187, Loss: 0.3828\n",
      "fold_2, epoch_188, Loss: 0.3774\n",
      "fold_2, epoch_189, Loss: 0.3748\n",
      "fold_2, epoch_190, Loss: 0.3753\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3772\n",
      "Accuracy:\t0.9358\n",
      "AUC:\t\t0.9439\n",
      "Precision:\t0.9476\n",
      "Recall:\t\t0.9222\n",
      "F1:\t\t\t0.9347\n",
      "\n",
      "fold_2, epoch_191, Loss: 0.3770\n",
      "fold_2, epoch_192, Loss: 0.3761\n",
      "fold_2, epoch_193, Loss: 0.3769\n",
      "fold_2, epoch_194, Loss: 0.3747\n",
      "fold_2, epoch_195, Loss: 0.3744\n",
      "fold_2, epoch_196, Loss: 0.3732\n",
      "fold_2, epoch_197, Loss: 0.3760\n",
      "fold_2, epoch_198, Loss: 0.3762\n",
      "fold_2, epoch_199, Loss: 0.3752\n",
      "fold_2, epoch_200, Loss: 0.3729\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3691\n",
      "Accuracy:\t0.9441\n",
      "AUC:\t\t0.9470\n",
      "Precision:\t0.9557\n",
      "Recall:\t\t0.9311\n",
      "F1:\t\t\t0.9433\n",
      "\n",
      "fold_2, epoch_201, Loss: 0.3712\n",
      "fold_2, epoch_202, Loss: 0.3743\n",
      "fold_2, epoch_203, Loss: 0.3733\n",
      "fold_2, epoch_204, Loss: 0.3714\n",
      "fold_2, epoch_205, Loss: 0.3708\n",
      "fold_2, epoch_206, Loss: 0.3711\n",
      "fold_2, epoch_207, Loss: 0.3728\n",
      "fold_2, epoch_208, Loss: 0.3732\n",
      "fold_2, epoch_209, Loss: 0.3732\n",
      "fold_2, epoch_210, Loss: 0.3703\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3735\n",
      "Accuracy:\t0.9393\n",
      "AUC:\t\t0.9447\n",
      "Precision:\t0.9453\n",
      "Recall:\t\t0.9326\n",
      "F1:\t\t\t0.9389\n",
      "\n",
      "fold_2, epoch_211, Loss: 0.3712\n",
      "fold_2, epoch_212, Loss: 0.3685\n",
      "fold_2, epoch_213, Loss: 0.3692\n",
      "fold_2, epoch_214, Loss: 0.3747\n",
      "fold_2, epoch_215, Loss: 0.3707\n",
      "fold_2, epoch_216, Loss: 0.3711\n",
      "fold_2, epoch_217, Loss: 0.3695\n",
      "fold_2, epoch_218, Loss: 0.3726\n",
      "fold_2, epoch_219, Loss: 0.3701\n",
      "fold_2, epoch_220, Loss: 0.3718\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3741\n",
      "Accuracy:\t0.9385\n",
      "AUC:\t\t0.9462\n",
      "Precision:\t0.9476\n",
      "Recall:\t\t0.9271\n",
      "F1:\t\t\t0.9372\n",
      "\n",
      "fold_2, epoch_221, Loss: 0.3721\n",
      "fold_2, epoch_222, Loss: 0.3721\n",
      "fold_2, epoch_223, Loss: 0.3706\n",
      "fold_2, epoch_224, Loss: 0.3708\n",
      "fold_2, epoch_225, Loss: 0.3685\n",
      "fold_2, epoch_226, Loss: 0.3723\n",
      "fold_2, epoch_227, Loss: 0.3684\n",
      "fold_2, epoch_228, Loss: 0.3690\n",
      "fold_2, epoch_229, Loss: 0.3714\n",
      "fold_2, epoch_230, Loss: 0.3721\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3693\n",
      "Accuracy:\t0.9434\n",
      "AUC:\t\t0.9475\n",
      "Precision:\t0.9541\n",
      "Recall:\t\t0.9314\n",
      "F1:\t\t\t0.9426\n",
      "\n",
      "fold_2, epoch_231, Loss: 0.3689\n",
      "fold_2, epoch_232, Loss: 0.3683\n",
      "fold_2, epoch_233, Loss: 0.3701\n",
      "fold_2, epoch_234, Loss: 0.3694\n",
      "fold_2, epoch_235, Loss: 0.3725\n",
      "fold_2, epoch_236, Loss: 0.3689\n",
      "fold_2, epoch_237, Loss: 0.3678\n",
      "fold_2, epoch_238, Loss: 0.3690\n",
      "fold_2, epoch_239, Loss: 0.3687\n",
      "fold_2, epoch_240, Loss: 0.3702\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3645\n",
      "Accuracy:\t0.9490\n",
      "AUC:\t\t0.9502\n",
      "Precision:\t0.9634\n",
      "Recall:\t\t0.9341\n",
      "F1:\t\t\t0.9485\n",
      "\n",
      "fold_2, epoch_241, Loss: 0.3680\n",
      "fold_2, epoch_242, Loss: 0.3704\n",
      "fold_2, epoch_243, Loss: 0.3722\n",
      "fold_2, epoch_244, Loss: 0.3740\n",
      "fold_2, epoch_245, Loss: 0.3684\n",
      "fold_2, epoch_246, Loss: 0.3681\n",
      "fold_2, epoch_247, Loss: 0.3748\n",
      "fold_2, epoch_248, Loss: 0.3660\n",
      "fold_2, epoch_249, Loss: 0.3673\n",
      "fold_2, epoch_250, Loss: 0.3642\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3645\n",
      "Accuracy:\t0.9487\n",
      "AUC:\t\t0.9488\n",
      "Precision:\t0.9633\n",
      "Recall:\t\t0.9326\n",
      "F1:\t\t\t0.9477\n",
      "\n",
      "fold_2, epoch_251, Loss: 0.3635\n",
      "fold_2, epoch_252, Loss: 0.3655\n",
      "fold_2, epoch_253, Loss: 0.3658\n",
      "fold_2, epoch_254, Loss: 0.3692\n",
      "fold_2, epoch_255, Loss: 0.3712\n",
      "fold_2, epoch_256, Loss: 0.3662\n",
      "fold_2, epoch_257, Loss: 0.3666\n",
      "fold_2, epoch_258, Loss: 0.3683\n",
      "fold_2, epoch_259, Loss: 0.3646\n",
      "fold_2, epoch_260, Loss: 0.3648\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3653\n",
      "Accuracy:\t0.9476\n",
      "AUC:\t\t0.9500\n",
      "Precision:\t0.9595\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9467\n",
      "\n",
      "fold_2, epoch_261, Loss: 0.3703\n",
      "fold_2, epoch_262, Loss: 0.3677\n",
      "fold_2, epoch_263, Loss: 0.3656\n",
      "fold_2, epoch_264, Loss: 0.3673\n",
      "fold_2, epoch_265, Loss: 0.3658\n",
      "fold_2, epoch_266, Loss: 0.3705\n",
      "fold_2, epoch_267, Loss: 0.3689\n",
      "fold_2, epoch_268, Loss: 0.3657\n",
      "fold_2, epoch_269, Loss: 0.3656\n",
      "fold_2, epoch_270, Loss: 0.3683\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3640\n",
      "Accuracy:\t0.9487\n",
      "AUC:\t\t0.9501\n",
      "Precision:\t0.9613\n",
      "Recall:\t\t0.9342\n",
      "F1:\t\t\t0.9476\n",
      "\n",
      "fold_2, epoch_271, Loss: 0.3653\n",
      "fold_2, epoch_272, Loss: 0.3664\n",
      "fold_2, epoch_273, Loss: 0.3691\n",
      "fold_2, epoch_274, Loss: 0.3658\n",
      "fold_2, epoch_275, Loss: 0.3662\n",
      "fold_2, epoch_276, Loss: 0.3665\n",
      "fold_2, epoch_277, Loss: 0.3721\n",
      "fold_2, epoch_278, Loss: 0.3656\n",
      "fold_2, epoch_279, Loss: 0.3667\n",
      "fold_2, epoch_280, Loss: 0.3629\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3639\n",
      "Accuracy:\t0.9494\n",
      "AUC:\t\t0.9502\n",
      "Precision:\t0.9673\n",
      "Recall:\t\t0.9299\n",
      "F1:\t\t\t0.9482\n",
      "\n",
      "fold_2, epoch_281, Loss: 0.3640\n",
      "fold_2, epoch_282, Loss: 0.3643\n",
      "fold_2, epoch_283, Loss: 0.3655\n",
      "fold_2, epoch_284, Loss: 0.3667\n",
      "fold_2, epoch_285, Loss: 0.3662\n",
      "fold_2, epoch_286, Loss: 0.3654\n",
      "fold_2, epoch_287, Loss: 0.3639\n",
      "fold_2, epoch_288, Loss: 0.3649\n",
      "fold_2, epoch_289, Loss: 0.3676\n",
      "fold_2, epoch_290, Loss: 0.3631\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3694\n",
      "Accuracy:\t0.9437\n",
      "AUC:\t\t0.9492\n",
      "Precision:\t0.9598\n",
      "Recall:\t\t0.9253\n",
      "F1:\t\t\t0.9422\n",
      "\n",
      "fold_2, epoch_291, Loss: 0.3671\n",
      "fold_2, epoch_292, Loss: 0.3642\n",
      "fold_2, epoch_293, Loss: 0.3608\n",
      "fold_2, epoch_294, Loss: 0.3634\n",
      "fold_2, epoch_295, Loss: 0.3636\n",
      "fold_2, epoch_296, Loss: 0.3642\n",
      "fold_2, epoch_297, Loss: 0.3592\n",
      "fold_2, epoch_298, Loss: 0.3636\n",
      "fold_2, epoch_299, Loss: 0.3616\n",
      "fold_2, epoch_300, Loss: 0.3652\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3606\n",
      "Accuracy:\t0.9522\n",
      "AUC:\t\t0.9531\n",
      "Precision:\t0.9662\n",
      "Recall:\t\t0.9368\n",
      "F1:\t\t\t0.9513\n",
      "\n",
      "fold_2, epoch_301, Loss: 0.3628\n",
      "fold_2, epoch_302, Loss: 0.3630\n",
      "fold_2, epoch_303, Loss: 0.3660\n",
      "fold_2, epoch_304, Loss: 0.3646\n",
      "fold_2, epoch_305, Loss: 0.3631\n",
      "fold_2, epoch_306, Loss: 0.3613\n",
      "fold_2, epoch_307, Loss: 0.3657\n",
      "fold_2, epoch_308, Loss: 0.3591\n",
      "fold_2, epoch_309, Loss: 0.3638\n",
      "fold_2, epoch_310, Loss: 0.3652\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3602\n",
      "Accuracy:\t0.9528\n",
      "AUC:\t\t0.9531\n",
      "Precision:\t0.9637\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9519\n",
      "\n",
      "fold_2, epoch_311, Loss: 0.3631\n",
      "fold_2, epoch_312, Loss: 0.3633\n",
      "fold_2, epoch_313, Loss: 0.3617\n",
      "fold_2, epoch_314, Loss: 0.3656\n",
      "fold_2, epoch_315, Loss: 0.3612\n",
      "fold_2, epoch_316, Loss: 0.3640\n",
      "fold_2, epoch_317, Loss: 0.3605\n",
      "fold_2, epoch_318, Loss: 0.3617\n",
      "fold_2, epoch_319, Loss: 0.3608\n",
      "fold_2, epoch_320, Loss: 0.3608\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3641\n",
      "Accuracy:\t0.9490\n",
      "AUC:\t\t0.9515\n",
      "Precision:\t0.9652\n",
      "Recall:\t\t0.9318\n",
      "F1:\t\t\t0.9482\n",
      "\n",
      "fold_2, epoch_321, Loss: 0.3614\n",
      "fold_2, epoch_322, Loss: 0.3624\n",
      "fold_2, epoch_323, Loss: 0.3623\n",
      "fold_2, epoch_324, Loss: 0.3602\n",
      "fold_2, epoch_325, Loss: 0.3637\n",
      "fold_2, epoch_326, Loss: 0.3623\n",
      "fold_2, epoch_327, Loss: 0.3623\n",
      "fold_2, epoch_328, Loss: 0.3631\n",
      "fold_2, epoch_329, Loss: 0.3617\n",
      "fold_2, epoch_330, Loss: 0.3621\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3604\n",
      "Accuracy:\t0.9528\n",
      "AUC:\t\t0.9545\n",
      "Precision:\t0.9686\n",
      "Recall:\t\t0.9370\n",
      "F1:\t\t\t0.9526\n",
      "\n",
      "fold_2, epoch_331, Loss: 0.3620\n",
      "fold_2, epoch_332, Loss: 0.3615\n",
      "fold_2, epoch_333, Loss: 0.3606\n",
      "fold_2, epoch_334, Loss: 0.3595\n",
      "fold_2, epoch_335, Loss: 0.3635\n",
      "fold_2, epoch_336, Loss: 0.3582\n",
      "fold_2, epoch_337, Loss: 0.3629\n",
      "fold_2, epoch_338, Loss: 0.3660\n",
      "fold_2, epoch_339, Loss: 0.3616\n",
      "fold_2, epoch_340, Loss: 0.3595\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3618\n",
      "Accuracy:\t0.9515\n",
      "AUC:\t\t0.9553\n",
      "Precision:\t0.9716\n",
      "Recall:\t\t0.9303\n",
      "F1:\t\t\t0.9505\n",
      "\n",
      "fold_2, epoch_341, Loss: 0.3628\n",
      "fold_2, epoch_342, Loss: 0.3618\n",
      "fold_2, epoch_343, Loss: 0.3587\n",
      "fold_2, epoch_344, Loss: 0.3594\n",
      "fold_2, epoch_345, Loss: 0.3594\n",
      "fold_2, epoch_346, Loss: 0.3680\n",
      "fold_2, epoch_347, Loss: 0.3602\n",
      "fold_2, epoch_348, Loss: 0.3621\n",
      "fold_2, epoch_349, Loss: 0.3636\n",
      "fold_2, epoch_350, Loss: 0.3567\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3624\n",
      "Accuracy:\t0.9510\n",
      "AUC:\t\t0.9547\n",
      "Precision:\t0.9717\n",
      "Recall:\t\t0.9292\n",
      "F1:\t\t\t0.9500\n",
      "\n",
      "fold_2, epoch_351, Loss: 0.3620\n",
      "fold_2, epoch_352, Loss: 0.3604\n",
      "fold_2, epoch_353, Loss: 0.3583\n",
      "fold_2, epoch_354, Loss: 0.3607\n",
      "fold_2, epoch_355, Loss: 0.3590\n",
      "fold_2, epoch_356, Loss: 0.3627\n",
      "fold_2, epoch_357, Loss: 0.3583\n",
      "fold_2, epoch_358, Loss: 0.3625\n",
      "fold_2, epoch_359, Loss: 0.3572\n",
      "fold_2, epoch_360, Loss: 0.3583\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3616\n",
      "Accuracy:\t0.9513\n",
      "AUC:\t\t0.9514\n",
      "Precision:\t0.9668\n",
      "Recall:\t\t0.9350\n",
      "F1:\t\t\t0.9506\n",
      "\n",
      "fold_2, epoch_361, Loss: 0.3602\n",
      "fold_2, epoch_362, Loss: 0.3574\n",
      "fold_2, epoch_363, Loss: 0.3598\n",
      "fold_2, epoch_364, Loss: 0.3578\n",
      "fold_2, epoch_365, Loss: 0.3594\n",
      "fold_2, epoch_366, Loss: 0.3579\n",
      "fold_2, epoch_367, Loss: 0.3568\n",
      "fold_2, epoch_368, Loss: 0.3588\n",
      "fold_2, epoch_369, Loss: 0.3621\n",
      "fold_2, epoch_370, Loss: 0.3621\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3596\n",
      "Accuracy:\t0.9535\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9684\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9530\n",
      "\n",
      "fold_2, epoch_371, Loss: 0.3578\n",
      "fold_2, epoch_372, Loss: 0.3571\n",
      "fold_2, epoch_373, Loss: 0.3597\n",
      "fold_2, epoch_374, Loss: 0.3605\n",
      "fold_2, epoch_375, Loss: 0.3580\n",
      "fold_2, epoch_376, Loss: 0.3575\n",
      "fold_2, epoch_377, Loss: 0.3565\n",
      "fold_2, epoch_378, Loss: 0.3587\n",
      "fold_2, epoch_379, Loss: 0.3593\n",
      "fold_2, epoch_380, Loss: 0.3597\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3618\n",
      "Accuracy:\t0.9509\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9739\n",
      "Recall:\t\t0.9275\n",
      "F1:\t\t\t0.9501\n",
      "\n",
      "fold_2, epoch_381, Loss: 0.3604\n",
      "fold_2, epoch_382, Loss: 0.3580\n",
      "fold_2, epoch_383, Loss: 0.3596\n",
      "fold_2, epoch_384, Loss: 0.3579\n",
      "fold_2, epoch_385, Loss: 0.3567\n",
      "fold_2, epoch_386, Loss: 0.3645\n",
      "fold_2, epoch_387, Loss: 0.3590\n",
      "fold_2, epoch_388, Loss: 0.3585\n",
      "fold_2, epoch_389, Loss: 0.3609\n",
      "fold_2, epoch_390, Loss: 0.3567\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3550\n",
      "Accuracy:\t0.9583\n",
      "AUC:\t\t0.9565\n",
      "Precision:\t0.9769\n",
      "Recall:\t\t0.9390\n",
      "F1:\t\t\t0.9576\n",
      "\n",
      "fold_2, epoch_391, Loss: 0.3571\n",
      "fold_2, epoch_392, Loss: 0.3591\n",
      "fold_2, epoch_393, Loss: 0.3586\n",
      "fold_2, epoch_394, Loss: 0.3585\n",
      "fold_2, epoch_395, Loss: 0.3614\n",
      "fold_2, epoch_396, Loss: 0.3605\n",
      "fold_2, epoch_397, Loss: 0.3561\n",
      "fold_2, epoch_398, Loss: 0.3622\n",
      "fold_2, epoch_399, Loss: 0.3602\n",
      "fold_2, epoch_400, Loss: 0.3580\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3579\n",
      "Accuracy:\t0.9551\n",
      "AUC:\t\t0.9571\n",
      "Precision:\t0.9753\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9544\n",
      "\n",
      "fold_2, epoch_401, Loss: 0.3615\n",
      "fold_2, epoch_402, Loss: 0.3560\n",
      "fold_2, epoch_403, Loss: 0.3592\n",
      "fold_2, epoch_404, Loss: 0.3613\n",
      "fold_2, epoch_405, Loss: 0.3578\n",
      "fold_2, epoch_406, Loss: 0.3541\n",
      "fold_2, epoch_407, Loss: 0.3573\n",
      "fold_2, epoch_408, Loss: 0.3566\n",
      "fold_2, epoch_409, Loss: 0.3593\n",
      "fold_2, epoch_410, Loss: 0.3605\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3597\n",
      "Accuracy:\t0.9535\n",
      "AUC:\t\t0.9553\n",
      "Precision:\t0.9713\n",
      "Recall:\t\t0.9347\n",
      "F1:\t\t\t0.9526\n",
      "\n",
      "fold_2, epoch_411, Loss: 0.3577\n",
      "fold_2, epoch_412, Loss: 0.3580\n",
      "fold_2, epoch_413, Loss: 0.3584\n",
      "fold_2, epoch_414, Loss: 0.3584\n",
      "fold_2, epoch_415, Loss: 0.3571\n",
      "fold_2, epoch_416, Loss: 0.3591\n",
      "fold_2, epoch_417, Loss: 0.3573\n",
      "fold_2, epoch_418, Loss: 0.3572\n",
      "fold_2, epoch_419, Loss: 0.3574\n",
      "fold_2, epoch_420, Loss: 0.3592\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3558\n",
      "Accuracy:\t0.9575\n",
      "AUC:\t\t0.9580\n",
      "Precision:\t0.9760\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9566\n",
      "\n",
      "fold_2, epoch_421, Loss: 0.3587\n",
      "fold_2, epoch_422, Loss: 0.3586\n",
      "fold_2, epoch_423, Loss: 0.3577\n",
      "fold_2, epoch_424, Loss: 0.3604\n",
      "fold_2, epoch_425, Loss: 0.3563\n",
      "fold_2, epoch_426, Loss: 0.3551\n",
      "fold_2, epoch_427, Loss: 0.3561\n",
      "fold_2, epoch_428, Loss: 0.3609\n",
      "fold_2, epoch_429, Loss: 0.3589\n",
      "fold_2, epoch_430, Loss: 0.3553\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3617\n",
      "Accuracy:\t0.9516\n",
      "AUC:\t\t0.9550\n",
      "Precision:\t0.9711\n",
      "Recall:\t\t0.9307\n",
      "F1:\t\t\t0.9505\n",
      "\n",
      "fold_2, epoch_431, Loss: 0.3574\n",
      "fold_2, epoch_432, Loss: 0.3555\n",
      "fold_2, epoch_433, Loss: 0.3593\n",
      "fold_2, epoch_434, Loss: 0.3581\n",
      "fold_2, epoch_435, Loss: 0.3591\n",
      "fold_2, epoch_436, Loss: 0.3560\n",
      "fold_2, epoch_437, Loss: 0.3562\n",
      "fold_2, epoch_438, Loss: 0.3606\n",
      "fold_2, epoch_439, Loss: 0.3554\n",
      "fold_2, epoch_440, Loss: 0.3580\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3553\n",
      "Accuracy:\t0.9578\n",
      "AUC:\t\t0.9567\n",
      "Precision:\t0.9757\n",
      "Recall:\t\t0.9389\n",
      "F1:\t\t\t0.9569\n",
      "\n",
      "fold_2, epoch_441, Loss: 0.3554\n",
      "fold_2, epoch_442, Loss: 0.3583\n",
      "fold_2, epoch_443, Loss: 0.3586\n",
      "fold_2, epoch_444, Loss: 0.3569\n",
      "fold_2, epoch_445, Loss: 0.3577\n",
      "fold_2, epoch_446, Loss: 0.3545\n",
      "fold_2, epoch_447, Loss: 0.3606\n",
      "fold_2, epoch_448, Loss: 0.3630\n",
      "fold_2, epoch_449, Loss: 0.3563\n",
      "fold_2, epoch_450, Loss: 0.3622\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3670\n",
      "Accuracy:\t0.9459\n",
      "AUC:\t\t0.9528\n",
      "Precision:\t0.9619\n",
      "Recall:\t\t0.9277\n",
      "F1:\t\t\t0.9445\n",
      "\n",
      "fold_2, epoch_451, Loss: 0.3593\n",
      "fold_2, epoch_452, Loss: 0.3551\n",
      "fold_2, epoch_453, Loss: 0.3545\n",
      "fold_2, epoch_454, Loss: 0.3548\n",
      "fold_2, epoch_455, Loss: 0.3566\n",
      "fold_2, epoch_456, Loss: 0.3563\n",
      "fold_2, epoch_457, Loss: 0.3542\n",
      "fold_2, epoch_458, Loss: 0.3573\n",
      "fold_2, epoch_459, Loss: 0.3573\n",
      "fold_2, epoch_460, Loss: 0.3573\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3580\n",
      "Accuracy:\t0.9549\n",
      "AUC:\t\t0.9571\n",
      "Precision:\t0.9747\n",
      "Recall:\t\t0.9341\n",
      "F1:\t\t\t0.9540\n",
      "\n",
      "fold_2, epoch_461, Loss: 0.3574\n",
      "fold_2, epoch_462, Loss: 0.3575\n",
      "fold_2, epoch_463, Loss: 0.3567\n",
      "fold_2, epoch_464, Loss: 0.3581\n",
      "fold_2, epoch_465, Loss: 0.3581\n",
      "fold_2, epoch_466, Loss: 0.3594\n",
      "fold_2, epoch_467, Loss: 0.3548\n",
      "fold_2, epoch_468, Loss: 0.3549\n",
      "fold_2, epoch_469, Loss: 0.3565\n",
      "fold_2, epoch_470, Loss: 0.3541\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3584\n",
      "Accuracy:\t0.9548\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9738\n",
      "Recall:\t\t0.9358\n",
      "F1:\t\t\t0.9544\n",
      "\n",
      "fold_2, epoch_471, Loss: 0.3596\n",
      "fold_2, epoch_472, Loss: 0.3565\n",
      "fold_2, epoch_473, Loss: 0.3553\n",
      "fold_2, epoch_474, Loss: 0.3564\n",
      "fold_2, epoch_475, Loss: 0.3540\n",
      "fold_2, epoch_476, Loss: 0.3562\n",
      "fold_2, epoch_477, Loss: 0.3577\n",
      "fold_2, epoch_478, Loss: 0.3553\n",
      "fold_2, epoch_479, Loss: 0.3577\n",
      "fold_2, epoch_480, Loss: 0.3542\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3511\n",
      "Accuracy:\t0.9621\n",
      "AUC:\t\t0.9614\n",
      "Precision:\t0.9820\n",
      "Recall:\t\t0.9418\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_2, epoch_481, Loss: 0.3543\n",
      "fold_2, epoch_482, Loss: 0.3570\n",
      "fold_2, epoch_483, Loss: 0.3549\n",
      "fold_2, epoch_484, Loss: 0.3530\n",
      "fold_2, epoch_485, Loss: 0.3552\n",
      "fold_2, epoch_486, Loss: 0.3560\n",
      "fold_2, epoch_487, Loss: 0.3576\n",
      "fold_2, epoch_488, Loss: 0.3560\n",
      "fold_2, epoch_489, Loss: 0.3580\n",
      "fold_2, epoch_490, Loss: 0.3583\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3543\n",
      "Accuracy:\t0.9589\n",
      "AUC:\t\t0.9585\n",
      "Precision:\t0.9768\n",
      "Recall:\t\t0.9399\n",
      "F1:\t\t\t0.9580\n",
      "\n",
      "fold_2, epoch_491, Loss: 0.3537\n",
      "fold_2, epoch_492, Loss: 0.3538\n",
      "fold_2, epoch_493, Loss: 0.3537\n",
      "fold_2, epoch_494, Loss: 0.3549\n",
      "fold_2, epoch_495, Loss: 0.3577\n",
      "fold_2, epoch_496, Loss: 0.3559\n",
      "fold_2, epoch_497, Loss: 0.3609\n",
      "fold_2, epoch_498, Loss: 0.3548\n",
      "fold_2, epoch_499, Loss: 0.3563\n",
      "fold_2, epoch_500, Loss: 0.3563\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3527\n",
      "Accuracy:\t0.9605\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9799\n",
      "Recall:\t\t0.9403\n",
      "F1:\t\t\t0.9597\n",
      "\n",
      "fold_2, epoch_501, Loss: 0.3548\n",
      "fold_2, epoch_502, Loss: 0.3564\n",
      "fold_2, epoch_503, Loss: 0.3553\n",
      "fold_2, epoch_504, Loss: 0.3560\n",
      "fold_2, epoch_505, Loss: 0.3578\n",
      "fold_2, epoch_506, Loss: 0.3552\n",
      "fold_2, epoch_507, Loss: 0.3545\n",
      "fold_2, epoch_508, Loss: 0.3534\n",
      "fold_2, epoch_509, Loss: 0.3541\n",
      "fold_2, epoch_510, Loss: 0.3567\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3571\n",
      "Accuracy:\t0.9558\n",
      "AUC:\t\t0.9576\n",
      "Precision:\t0.9738\n",
      "Recall:\t\t0.9368\n",
      "F1:\t\t\t0.9550\n",
      "\n",
      "fold_2, epoch_511, Loss: 0.3572\n",
      "fold_2, epoch_512, Loss: 0.3568\n",
      "fold_2, epoch_513, Loss: 0.3555\n",
      "fold_2, epoch_514, Loss: 0.3529\n",
      "fold_2, epoch_515, Loss: 0.3592\n",
      "fold_2, epoch_516, Loss: 0.3574\n",
      "fold_2, epoch_517, Loss: 0.3549\n",
      "fold_2, epoch_518, Loss: 0.3525\n",
      "fold_2, epoch_519, Loss: 0.3541\n",
      "fold_2, epoch_520, Loss: 0.3539\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3518\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9611\n",
      "Precision:\t0.9805\n",
      "Recall:\t\t0.9411\n",
      "F1:\t\t\t0.9604\n",
      "\n",
      "fold_2, epoch_521, Loss: 0.3532\n",
      "fold_2, epoch_522, Loss: 0.3540\n",
      "fold_2, epoch_523, Loss: 0.3545\n",
      "fold_2, epoch_524, Loss: 0.3561\n",
      "fold_2, epoch_525, Loss: 0.3563\n",
      "fold_2, epoch_526, Loss: 0.3533\n",
      "fold_2, epoch_527, Loss: 0.3550\n",
      "fold_2, epoch_528, Loss: 0.3516\n",
      "fold_2, epoch_529, Loss: 0.3556\n",
      "fold_2, epoch_530, Loss: 0.3524\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3493\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9625\n",
      "Precision:\t0.9854\n",
      "Recall:\t\t0.9423\n",
      "F1:\t\t\t0.9633\n",
      "\n",
      "fold_2, epoch_531, Loss: 0.3533\n",
      "fold_2, epoch_532, Loss: 0.3536\n",
      "fold_2, epoch_533, Loss: 0.3560\n",
      "fold_2, epoch_534, Loss: 0.3534\n",
      "fold_2, epoch_535, Loss: 0.3522\n",
      "fold_2, epoch_536, Loss: 0.3540\n",
      "fold_2, epoch_537, Loss: 0.3554\n",
      "fold_2, epoch_538, Loss: 0.3529\n",
      "fold_2, epoch_539, Loss: 0.3510\n",
      "fold_2, epoch_540, Loss: 0.3546\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3537\n",
      "Accuracy:\t0.9593\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9778\n",
      "Recall:\t\t0.9405\n",
      "F1:\t\t\t0.9588\n",
      "\n",
      "fold_2, epoch_541, Loss: 0.3536\n",
      "fold_2, epoch_542, Loss: 0.3545\n",
      "fold_2, epoch_543, Loss: 0.3507\n",
      "fold_2, epoch_544, Loss: 0.3548\n",
      "fold_2, epoch_545, Loss: 0.3533\n",
      "fold_2, epoch_546, Loss: 0.3533\n",
      "fold_2, epoch_547, Loss: 0.3504\n",
      "fold_2, epoch_548, Loss: 0.3535\n",
      "fold_2, epoch_549, Loss: 0.3544\n",
      "fold_2, epoch_550, Loss: 0.3511\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3524\n",
      "Accuracy:\t0.9608\n",
      "AUC:\t\t0.9606\n",
      "Precision:\t0.9821\n",
      "Recall:\t\t0.9388\n",
      "F1:\t\t\t0.9599\n",
      "\n",
      "fold_2, epoch_551, Loss: 0.3523\n",
      "fold_2, epoch_552, Loss: 0.3533\n",
      "fold_2, epoch_553, Loss: 0.3513\n",
      "fold_2, epoch_554, Loss: 0.3510\n",
      "fold_2, epoch_555, Loss: 0.3528\n",
      "fold_2, epoch_556, Loss: 0.3513\n",
      "fold_2, epoch_557, Loss: 0.3526\n",
      "fold_2, epoch_558, Loss: 0.3513\n",
      "fold_2, epoch_559, Loss: 0.3508\n",
      "fold_2, epoch_560, Loss: 0.3515\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3498\n",
      "Accuracy:\t0.9634\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9825\n",
      "Recall:\t\t0.9436\n",
      "F1:\t\t\t0.9627\n",
      "\n",
      "fold_2, epoch_561, Loss: 0.3537\n",
      "fold_2, epoch_562, Loss: 0.3542\n",
      "fold_2, epoch_563, Loss: 0.3508\n",
      "fold_2, epoch_564, Loss: 0.3538\n",
      "fold_2, epoch_565, Loss: 0.3560\n",
      "fold_2, epoch_566, Loss: 0.3525\n",
      "fold_2, epoch_567, Loss: 0.3522\n",
      "fold_2, epoch_568, Loss: 0.3528\n",
      "fold_2, epoch_569, Loss: 0.3503\n",
      "fold_2, epoch_570, Loss: 0.3527\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3523\n",
      "Accuracy:\t0.9609\n",
      "AUC:\t\t0.9610\n",
      "Precision:\t0.9802\n",
      "Recall:\t\t0.9405\n",
      "F1:\t\t\t0.9599\n",
      "\n",
      "fold_2, epoch_571, Loss: 0.3531\n",
      "fold_2, epoch_572, Loss: 0.3526\n",
      "fold_2, epoch_573, Loss: 0.3516\n",
      "fold_2, epoch_574, Loss: 0.3560\n",
      "fold_2, epoch_575, Loss: 0.3534\n",
      "fold_2, epoch_576, Loss: 0.3508\n",
      "fold_2, epoch_577, Loss: 0.3539\n",
      "fold_2, epoch_578, Loss: 0.3512\n",
      "fold_2, epoch_579, Loss: 0.3517\n",
      "fold_2, epoch_580, Loss: 0.3544\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3497\n",
      "Accuracy:\t0.9635\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9815\n",
      "Recall:\t\t0.9451\n",
      "F1:\t\t\t0.9629\n",
      "\n",
      "fold_2, epoch_581, Loss: 0.3558\n",
      "fold_2, epoch_582, Loss: 0.3542\n",
      "fold_2, epoch_583, Loss: 0.3536\n",
      "fold_2, epoch_584, Loss: 0.3537\n",
      "fold_2, epoch_585, Loss: 0.3502\n",
      "fold_2, epoch_586, Loss: 0.3512\n",
      "fold_2, epoch_587, Loss: 0.3508\n",
      "fold_2, epoch_588, Loss: 0.3508\n",
      "fold_2, epoch_589, Loss: 0.3526\n",
      "fold_2, epoch_590, Loss: 0.3511\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3578\n",
      "Accuracy:\t0.9550\n",
      "AUC:\t\t0.9601\n",
      "Precision:\t0.9797\n",
      "Recall:\t\t0.9292\n",
      "F1:\t\t\t0.9538\n",
      "\n",
      "fold_2, epoch_591, Loss: 0.3518\n",
      "fold_2, epoch_592, Loss: 0.3521\n",
      "fold_2, epoch_593, Loss: 0.3510\n",
      "fold_2, epoch_594, Loss: 0.3527\n",
      "fold_2, epoch_595, Loss: 0.3521\n",
      "fold_2, epoch_596, Loss: 0.3535\n",
      "fold_2, epoch_597, Loss: 0.3518\n",
      "fold_2, epoch_598, Loss: 0.3519\n",
      "fold_2, epoch_599, Loss: 0.3572\n",
      "fold_2, epoch_600, Loss: 0.3508\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3496\n",
      "Accuracy:\t0.9636\n",
      "AUC:\t\t0.9628\n",
      "Precision:\t0.9831\n",
      "Recall:\t\t0.9438\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_2, epoch_601, Loss: 0.3504\n",
      "fold_2, epoch_602, Loss: 0.3528\n",
      "fold_2, epoch_603, Loss: 0.3492\n",
      "fold_2, epoch_604, Loss: 0.3521\n",
      "fold_2, epoch_605, Loss: 0.3521\n",
      "fold_2, epoch_606, Loss: 0.3525\n",
      "fold_2, epoch_607, Loss: 0.3491\n",
      "fold_2, epoch_608, Loss: 0.3517\n",
      "fold_2, epoch_609, Loss: 0.3529\n",
      "fold_2, epoch_610, Loss: 0.3507\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3512\n",
      "Accuracy:\t0.9616\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9814\n",
      "Recall:\t\t0.9416\n",
      "F1:\t\t\t0.9611\n",
      "\n",
      "fold_2, epoch_611, Loss: 0.3511\n",
      "fold_2, epoch_612, Loss: 0.3531\n",
      "fold_2, epoch_613, Loss: 0.3478\n",
      "fold_2, epoch_614, Loss: 0.3509\n",
      "fold_2, epoch_615, Loss: 0.3530\n",
      "fold_2, epoch_616, Loss: 0.3520\n",
      "fold_2, epoch_617, Loss: 0.3515\n",
      "fold_2, epoch_618, Loss: 0.3529\n",
      "fold_2, epoch_619, Loss: 0.3509\n",
      "fold_2, epoch_620, Loss: 0.3524\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3484\n",
      "Accuracy:\t0.9648\n",
      "AUC:\t\t0.9631\n",
      "Precision:\t0.9852\n",
      "Recall:\t\t0.9438\n",
      "F1:\t\t\t0.9641\n",
      "\n",
      "fold_2, epoch_621, Loss: 0.3508\n",
      "fold_2, epoch_622, Loss: 0.3505\n",
      "fold_2, epoch_623, Loss: 0.3522\n",
      "fold_2, epoch_624, Loss: 0.3502\n",
      "fold_2, epoch_625, Loss: 0.3528\n",
      "fold_2, epoch_626, Loss: 0.3510\n",
      "fold_2, epoch_627, Loss: 0.3489\n",
      "fold_2, epoch_628, Loss: 0.3499\n",
      "fold_2, epoch_629, Loss: 0.3503\n",
      "fold_2, epoch_630, Loss: 0.3510\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3504\n",
      "Accuracy:\t0.9627\n",
      "AUC:\t\t0.9621\n",
      "Precision:\t0.9800\n",
      "Recall:\t\t0.9450\n",
      "F1:\t\t\t0.9622\n",
      "\n",
      "fold_2, epoch_631, Loss: 0.3496\n",
      "fold_2, epoch_632, Loss: 0.3510\n",
      "fold_2, epoch_633, Loss: 0.3509\n",
      "fold_2, epoch_634, Loss: 0.3461\n",
      "fold_2, epoch_635, Loss: 0.3494\n",
      "fold_2, epoch_636, Loss: 0.3487\n",
      "fold_2, epoch_637, Loss: 0.3521\n",
      "fold_2, epoch_638, Loss: 0.3498\n",
      "fold_2, epoch_639, Loss: 0.3514\n",
      "fold_2, epoch_640, Loss: 0.3493\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3499\n",
      "Accuracy:\t0.9635\n",
      "AUC:\t\t0.9630\n",
      "Precision:\t0.9853\n",
      "Recall:\t\t0.9409\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_2, epoch_641, Loss: 0.3501\n",
      "fold_2, epoch_642, Loss: 0.3500\n",
      "fold_2, epoch_643, Loss: 0.3501\n",
      "fold_2, epoch_644, Loss: 0.3527\n",
      "fold_2, epoch_645, Loss: 0.3500\n",
      "fold_2, epoch_646, Loss: 0.3494\n",
      "fold_2, epoch_647, Loss: 0.3515\n",
      "fold_2, epoch_648, Loss: 0.3490\n",
      "fold_2, epoch_649, Loss: 0.3496\n",
      "fold_2, epoch_650, Loss: 0.3501\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3496\n",
      "Accuracy:\t0.9635\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9849\n",
      "Recall:\t\t0.9419\n",
      "F1:\t\t\t0.9629\n",
      "\n",
      "fold_2, epoch_651, Loss: 0.3502\n",
      "fold_2, epoch_652, Loss: 0.3509\n",
      "fold_2, epoch_653, Loss: 0.3515\n",
      "fold_2, epoch_654, Loss: 0.3516\n",
      "fold_2, epoch_655, Loss: 0.3496\n",
      "fold_2, epoch_656, Loss: 0.3496\n",
      "fold_2, epoch_657, Loss: 0.3502\n",
      "fold_2, epoch_658, Loss: 0.3526\n",
      "fold_2, epoch_659, Loss: 0.3496\n",
      "fold_2, epoch_660, Loss: 0.3488\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3490\n",
      "Accuracy:\t0.9642\n",
      "AUC:\t\t0.9630\n",
      "Precision:\t0.9834\n",
      "Recall:\t\t0.9439\n",
      "F1:\t\t\t0.9633\n",
      "\n",
      "fold_2, epoch_661, Loss: 0.3511\n",
      "fold_2, epoch_662, Loss: 0.3518\n",
      "fold_2, epoch_663, Loss: 0.3515\n",
      "fold_2, epoch_664, Loss: 0.3499\n",
      "fold_2, epoch_665, Loss: 0.3508\n",
      "fold_2, epoch_666, Loss: 0.3509\n",
      "fold_2, epoch_667, Loss: 0.3506\n",
      "fold_2, epoch_668, Loss: 0.3512\n",
      "fold_2, epoch_669, Loss: 0.3489\n",
      "fold_2, epoch_670, Loss: 0.3501\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3493\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9616\n",
      "Precision:\t0.9838\n",
      "Recall:\t\t0.9431\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_2, epoch_671, Loss: 0.3483\n",
      "fold_2, epoch_672, Loss: 0.3511\n",
      "fold_2, epoch_673, Loss: 0.3525\n",
      "fold_2, epoch_674, Loss: 0.3511\n",
      "fold_2, epoch_675, Loss: 0.3524\n",
      "fold_2, epoch_676, Loss: 0.3499\n",
      "fold_2, epoch_677, Loss: 0.3498\n",
      "fold_2, epoch_678, Loss: 0.3516\n",
      "fold_2, epoch_679, Loss: 0.3503\n",
      "fold_2, epoch_680, Loss: 0.3502\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3478\n",
      "Accuracy:\t0.9652\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9854\n",
      "Recall:\t\t0.9445\n",
      "F1:\t\t\t0.9645\n",
      "\n",
      "fold_2, epoch_681, Loss: 0.3494\n",
      "fold_2, epoch_682, Loss: 0.3502\n",
      "fold_2, epoch_683, Loss: 0.3518\n",
      "fold_2, epoch_684, Loss: 0.3534\n",
      "fold_2, epoch_685, Loss: 0.3510\n",
      "fold_2, epoch_686, Loss: 0.3492\n",
      "fold_2, epoch_687, Loss: 0.3518\n",
      "fold_2, epoch_688, Loss: 0.3484\n",
      "fold_2, epoch_689, Loss: 0.3500\n",
      "fold_2, epoch_690, Loss: 0.3526\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9811\n",
      "Recall:\t\t0.9419\n",
      "F1:\t\t\t0.9611\n",
      "\n",
      "fold_2, epoch_691, Loss: 0.3487\n",
      "fold_2, epoch_692, Loss: 0.3539\n",
      "fold_2, epoch_693, Loss: 0.3488\n",
      "fold_2, epoch_694, Loss: 0.3491\n",
      "fold_2, epoch_695, Loss: 0.3492\n",
      "fold_2, epoch_696, Loss: 0.3495\n",
      "fold_2, epoch_697, Loss: 0.3501\n",
      "fold_2, epoch_698, Loss: 0.3534\n",
      "fold_2, epoch_699, Loss: 0.3498\n",
      "fold_2, epoch_700, Loss: 0.3505\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3503\n",
      "Accuracy:\t0.9629\n",
      "AUC:\t\t0.9624\n",
      "Precision:\t0.9818\n",
      "Recall:\t\t0.9441\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_2, epoch_701, Loss: 0.3513\n",
      "fold_2, epoch_702, Loss: 0.3525\n",
      "fold_2, epoch_703, Loss: 0.3510\n",
      "fold_2, epoch_704, Loss: 0.3491\n",
      "fold_2, epoch_705, Loss: 0.3490\n",
      "fold_2, epoch_706, Loss: 0.3504\n",
      "fold_2, epoch_707, Loss: 0.3495\n",
      "fold_2, epoch_708, Loss: 0.3506\n",
      "fold_2, epoch_709, Loss: 0.3511\n",
      "fold_2, epoch_710, Loss: 0.3486\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9625\n",
      "AUC:\t\t0.9628\n",
      "Precision:\t0.9823\n",
      "Recall:\t\t0.9423\n",
      "F1:\t\t\t0.9619\n",
      "\n",
      "fold_2, epoch_711, Loss: 0.3485\n",
      "fold_2, epoch_712, Loss: 0.3501\n",
      "fold_2, epoch_713, Loss: 0.3511\n",
      "fold_2, epoch_714, Loss: 0.3477\n",
      "fold_2, epoch_715, Loss: 0.3494\n",
      "fold_2, epoch_716, Loss: 0.3511\n",
      "fold_2, epoch_717, Loss: 0.3511\n",
      "fold_2, epoch_718, Loss: 0.3477\n",
      "fold_2, epoch_719, Loss: 0.3483\n",
      "fold_2, epoch_720, Loss: 0.3493\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3562\n",
      "Accuracy:\t0.9567\n",
      "AUC:\t\t0.9596\n",
      "Precision:\t0.9794\n",
      "Recall:\t\t0.9328\n",
      "F1:\t\t\t0.9555\n",
      "\n",
      "fold_2, epoch_721, Loss: 0.3507\n",
      "fold_2, epoch_722, Loss: 0.3468\n",
      "fold_2, epoch_723, Loss: 0.3489\n",
      "fold_2, epoch_724, Loss: 0.3502\n",
      "fold_2, epoch_725, Loss: 0.3488\n",
      "fold_2, epoch_726, Loss: 0.3526\n",
      "fold_2, epoch_727, Loss: 0.3498\n",
      "fold_2, epoch_728, Loss: 0.3506\n",
      "fold_2, epoch_729, Loss: 0.3506\n",
      "fold_2, epoch_730, Loss: 0.3497\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9634\n",
      "Precision:\t0.9874\n",
      "Recall:\t\t0.9359\n",
      "F1:\t\t\t0.9609\n",
      "\n",
      "fold_2, epoch_731, Loss: 0.3505\n",
      "fold_2, epoch_732, Loss: 0.3527\n",
      "fold_2, epoch_733, Loss: 0.3511\n",
      "fold_2, epoch_734, Loss: 0.3498\n",
      "fold_2, epoch_735, Loss: 0.3511\n",
      "fold_2, epoch_736, Loss: 0.3486\n",
      "fold_2, epoch_737, Loss: 0.3483\n",
      "fold_2, epoch_738, Loss: 0.3499\n",
      "fold_2, epoch_739, Loss: 0.3505\n",
      "fold_2, epoch_740, Loss: 0.3480\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3508\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9624\n",
      "Precision:\t0.9840\n",
      "Recall:\t\t0.9402\n",
      "F1:\t\t\t0.9616\n",
      "\n",
      "fold_2, epoch_741, Loss: 0.3525\n",
      "fold_2, epoch_742, Loss: 0.3495\n",
      "fold_2, epoch_743, Loss: 0.3494\n",
      "fold_2, epoch_744, Loss: 0.3495\n",
      "fold_2, epoch_745, Loss: 0.3515\n",
      "fold_2, epoch_746, Loss: 0.3491\n",
      "fold_2, epoch_747, Loss: 0.3507\n",
      "fold_2, epoch_748, Loss: 0.3499\n",
      "fold_2, epoch_749, Loss: 0.3502\n",
      "fold_2, epoch_750, Loss: 0.3496\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3473\n",
      "Accuracy:\t0.9659\n",
      "AUC:\t\t0.9640\n",
      "Precision:\t0.9863\n",
      "Recall:\t\t0.9451\n",
      "F1:\t\t\t0.9653\n",
      "\n",
      "fold_2, epoch_751, Loss: 0.3496\n",
      "fold_2, epoch_752, Loss: 0.3489\n",
      "fold_2, epoch_753, Loss: 0.3477\n",
      "fold_2, epoch_754, Loss: 0.3505\n",
      "fold_2, epoch_755, Loss: 0.3500\n",
      "fold_2, epoch_756, Loss: 0.3475\n",
      "fold_2, epoch_757, Loss: 0.3482\n",
      "fold_2, epoch_758, Loss: 0.3486\n",
      "fold_2, epoch_759, Loss: 0.3521\n",
      "fold_2, epoch_760, Loss: 0.3496\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3486\n",
      "Accuracy:\t0.9645\n",
      "AUC:\t\t0.9637\n",
      "Precision:\t0.9854\n",
      "Recall:\t\t0.9432\n",
      "F1:\t\t\t0.9639\n",
      "\n",
      "fold_2, epoch_761, Loss: 0.3482\n",
      "fold_2, epoch_762, Loss: 0.3502\n",
      "fold_2, epoch_763, Loss: 0.3483\n",
      "fold_2, epoch_764, Loss: 0.3498\n",
      "fold_2, epoch_765, Loss: 0.3489\n",
      "fold_2, epoch_766, Loss: 0.3506\n",
      "fold_2, epoch_767, Loss: 0.3499\n",
      "fold_2, epoch_768, Loss: 0.3470\n",
      "fold_2, epoch_769, Loss: 0.3452\n",
      "fold_2, epoch_770, Loss: 0.3491\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3482\n",
      "Accuracy:\t0.9653\n",
      "AUC:\t\t0.9650\n",
      "Precision:\t0.9843\n",
      "Recall:\t\t0.9455\n",
      "F1:\t\t\t0.9645\n",
      "\n",
      "fold_2, epoch_771, Loss: 0.3476\n",
      "fold_2, epoch_772, Loss: 0.3478\n",
      "fold_2, epoch_773, Loss: 0.3476\n",
      "fold_2, epoch_774, Loss: 0.3522\n",
      "fold_2, epoch_775, Loss: 0.3495\n",
      "fold_2, epoch_776, Loss: 0.3513\n",
      "fold_2, epoch_777, Loss: 0.3480\n",
      "fold_2, epoch_778, Loss: 0.3497\n",
      "fold_2, epoch_779, Loss: 0.3484\n",
      "fold_2, epoch_780, Loss: 0.3477\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3488\n",
      "Accuracy:\t0.9644\n",
      "AUC:\t\t0.9631\n",
      "Precision:\t0.9859\n",
      "Recall:\t\t0.9422\n",
      "F1:\t\t\t0.9636\n",
      "\n",
      "fold_2, epoch_781, Loss: 0.3481\n",
      "fold_2, epoch_782, Loss: 0.3470\n",
      "fold_2, epoch_783, Loss: 0.3446\n",
      "fold_2, epoch_784, Loss: 0.3467\n",
      "fold_2, epoch_785, Loss: 0.3487\n",
      "fold_2, epoch_786, Loss: 0.3468\n",
      "fold_2, epoch_787, Loss: 0.3478\n",
      "fold_2, epoch_788, Loss: 0.3477\n",
      "fold_2, epoch_789, Loss: 0.3477\n",
      "fold_2, epoch_790, Loss: 0.3464\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3481\n",
      "Accuracy:\t0.9651\n",
      "AUC:\t\t0.9636\n",
      "Precision:\t0.9864\n",
      "Recall:\t\t0.9439\n",
      "F1:\t\t\t0.9647\n",
      "\n",
      "fold_2, epoch_791, Loss: 0.3490\n",
      "fold_2, epoch_792, Loss: 0.3480\n",
      "fold_2, epoch_793, Loss: 0.3483\n",
      "fold_2, epoch_794, Loss: 0.3500\n",
      "fold_2, epoch_795, Loss: 0.3467\n",
      "fold_2, epoch_796, Loss: 0.3481\n",
      "fold_2, epoch_797, Loss: 0.3482\n",
      "fold_2, epoch_798, Loss: 0.3460\n",
      "fold_2, epoch_799, Loss: 0.3502\n",
      "fold_2, epoch_800, Loss: 0.3472\n",
      "\n",
      "fold_2 performance on test data:\n",
      "Loss:\t\t0.3459\n",
      "Accuracy:\t0.9673\n",
      "AUC:\t\t0.9663\n",
      "Precision:\t0.9874\n",
      "Recall:\t\t0.9471\n",
      "F1:\t\t\t0.9668\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/checkpoints/fold_3\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/tensorboard\n",
      "\n",
      "\n",
      "fold_3, epoch_1, Loss: 0.5842\n",
      "fold_3, epoch_2, Loss: 0.5478\n",
      "fold_3, epoch_3, Loss: 0.5360\n",
      "fold_3, epoch_4, Loss: 0.5266\n",
      "fold_3, epoch_5, Loss: 0.5248\n",
      "fold_3, epoch_6, Loss: 0.5212\n",
      "fold_3, epoch_7, Loss: 0.5143\n",
      "fold_3, epoch_8, Loss: 0.5138\n",
      "fold_3, epoch_9, Loss: 0.5043\n",
      "fold_3, epoch_10, Loss: 0.4983\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.5039\n",
      "Accuracy:\t0.7983\n",
      "AUC:\t\t0.8742\n",
      "Precision:\t0.8326\n",
      "Recall:\t\t0.7482\n",
      "F1:\t\t\t0.7882\n",
      "\n",
      "fold_3, epoch_11, Loss: 0.5004\n",
      "fold_3, epoch_12, Loss: 0.4974\n",
      "fold_3, epoch_13, Loss: 0.4953\n",
      "fold_3, epoch_14, Loss: 0.4909\n",
      "fold_3, epoch_15, Loss: 0.4855\n",
      "fold_3, epoch_16, Loss: 0.4887\n",
      "fold_3, epoch_17, Loss: 0.4825\n",
      "fold_3, epoch_18, Loss: 0.4816\n",
      "fold_3, epoch_19, Loss: 0.4756\n",
      "fold_3, epoch_20, Loss: 0.4804\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4713\n",
      "Accuracy:\t0.8387\n",
      "AUC:\t\t0.8864\n",
      "Precision:\t0.8263\n",
      "Recall:\t\t0.8540\n",
      "F1:\t\t\t0.8399\n",
      "\n",
      "fold_3, epoch_21, Loss: 0.4724\n",
      "fold_3, epoch_22, Loss: 0.4664\n",
      "fold_3, epoch_23, Loss: 0.4689\n",
      "fold_3, epoch_24, Loss: 0.4629\n",
      "fold_3, epoch_25, Loss: 0.4629\n",
      "fold_3, epoch_26, Loss: 0.4594\n",
      "fold_3, epoch_27, Loss: 0.4588\n",
      "fold_3, epoch_28, Loss: 0.4619\n",
      "fold_3, epoch_29, Loss: 0.4574\n",
      "fold_3, epoch_30, Loss: 0.4525\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4455\n",
      "Accuracy:\t0.8658\n",
      "AUC:\t\t0.8993\n",
      "Precision:\t0.8575\n",
      "Recall:\t\t0.8782\n",
      "F1:\t\t\t0.8677\n",
      "\n",
      "fold_3, epoch_31, Loss: 0.4496\n",
      "fold_3, epoch_32, Loss: 0.4526\n",
      "fold_3, epoch_33, Loss: 0.4575\n",
      "fold_3, epoch_34, Loss: 0.4481\n",
      "fold_3, epoch_35, Loss: 0.4439\n",
      "fold_3, epoch_36, Loss: 0.4411\n",
      "fold_3, epoch_37, Loss: 0.4399\n",
      "fold_3, epoch_38, Loss: 0.4440\n",
      "fold_3, epoch_39, Loss: 0.4420\n",
      "fold_3, epoch_40, Loss: 0.4365\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4349\n",
      "Accuracy:\t0.8765\n",
      "AUC:\t\t0.9080\n",
      "Precision:\t0.8822\n",
      "Recall:\t\t0.8694\n",
      "F1:\t\t\t0.8758\n",
      "\n",
      "fold_3, epoch_41, Loss: 0.4386\n",
      "fold_3, epoch_42, Loss: 0.4383\n",
      "fold_3, epoch_43, Loss: 0.4353\n",
      "fold_3, epoch_44, Loss: 0.4305\n",
      "fold_3, epoch_45, Loss: 0.4304\n",
      "fold_3, epoch_46, Loss: 0.4240\n",
      "fold_3, epoch_47, Loss: 0.4352\n",
      "fold_3, epoch_48, Loss: 0.4273\n",
      "fold_3, epoch_49, Loss: 0.4261\n",
      "fold_3, epoch_50, Loss: 0.4464\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4434\n",
      "Accuracy:\t0.8683\n",
      "AUC:\t\t0.9014\n",
      "Precision:\t0.8506\n",
      "Recall:\t\t0.8912\n",
      "F1:\t\t\t0.8704\n",
      "\n",
      "fold_3, epoch_51, Loss: 0.4400\n",
      "fold_3, epoch_52, Loss: 0.4295\n",
      "fold_3, epoch_53, Loss: 0.4249\n",
      "fold_3, epoch_54, Loss: 0.4243\n",
      "fold_3, epoch_55, Loss: 0.4227\n",
      "fold_3, epoch_56, Loss: 0.4243\n",
      "fold_3, epoch_57, Loss: 0.4212\n",
      "fold_3, epoch_58, Loss: 0.4241\n",
      "fold_3, epoch_59, Loss: 0.4155\n",
      "fold_3, epoch_60, Loss: 0.4170\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4192\n",
      "Accuracy:\t0.8939\n",
      "AUC:\t\t0.9109\n",
      "Precision:\t0.9034\n",
      "Recall:\t\t0.8828\n",
      "F1:\t\t\t0.8930\n",
      "\n",
      "fold_3, epoch_61, Loss: 0.4185\n",
      "fold_3, epoch_62, Loss: 0.4270\n",
      "fold_3, epoch_63, Loss: 0.4132\n",
      "fold_3, epoch_64, Loss: 0.4179\n",
      "fold_3, epoch_65, Loss: 0.4126\n",
      "fold_3, epoch_66, Loss: 0.4129\n",
      "fold_3, epoch_67, Loss: 0.4142\n",
      "fold_3, epoch_68, Loss: 0.4177\n",
      "fold_3, epoch_69, Loss: 0.4111\n",
      "fold_3, epoch_70, Loss: 0.4125\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4109\n",
      "Accuracy:\t0.9013\n",
      "AUC:\t\t0.9177\n",
      "Precision:\t0.8890\n",
      "Recall:\t\t0.9181\n",
      "F1:\t\t\t0.9033\n",
      "\n",
      "fold_3, epoch_71, Loss: 0.4129\n",
      "fold_3, epoch_72, Loss: 0.4108\n",
      "fold_3, epoch_73, Loss: 0.4136\n",
      "fold_3, epoch_74, Loss: 0.4056\n",
      "fold_3, epoch_75, Loss: 0.4035\n",
      "fold_3, epoch_76, Loss: 0.4132\n",
      "fold_3, epoch_77, Loss: 0.4007\n",
      "fold_3, epoch_78, Loss: 0.4046\n",
      "fold_3, epoch_79, Loss: 0.4089\n",
      "fold_3, epoch_80, Loss: 0.4053\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4104\n",
      "Accuracy:\t0.9012\n",
      "AUC:\t\t0.9192\n",
      "Precision:\t0.9021\n",
      "Recall:\t\t0.9008\n",
      "F1:\t\t\t0.9014\n",
      "\n",
      "fold_3, epoch_81, Loss: 0.4123\n",
      "fold_3, epoch_82, Loss: 0.4047\n",
      "fold_3, epoch_83, Loss: 0.4048\n",
      "fold_3, epoch_84, Loss: 0.4019\n",
      "fold_3, epoch_85, Loss: 0.4021\n",
      "fold_3, epoch_86, Loss: 0.3960\n",
      "fold_3, epoch_87, Loss: 0.4003\n",
      "fold_3, epoch_88, Loss: 0.4051\n",
      "fold_3, epoch_89, Loss: 0.3980\n",
      "fold_3, epoch_90, Loss: 0.4016\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3944\n",
      "Accuracy:\t0.9183\n",
      "AUC:\t\t0.9293\n",
      "Precision:\t0.9175\n",
      "Recall:\t\t0.9192\n",
      "F1:\t\t\t0.9184\n",
      "\n",
      "fold_3, epoch_91, Loss: 0.3962\n",
      "fold_3, epoch_92, Loss: 0.3991\n",
      "fold_3, epoch_93, Loss: 0.4064\n",
      "fold_3, epoch_94, Loss: 0.4007\n",
      "fold_3, epoch_95, Loss: 0.4002\n",
      "fold_3, epoch_96, Loss: 0.3943\n",
      "fold_3, epoch_97, Loss: 0.3951\n",
      "fold_3, epoch_98, Loss: 0.3983\n",
      "fold_3, epoch_99, Loss: 0.3960\n",
      "fold_3, epoch_100, Loss: 0.3949\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3978\n",
      "Accuracy:\t0.9145\n",
      "AUC:\t\t0.9268\n",
      "Precision:\t0.9208\n",
      "Recall:\t\t0.9060\n",
      "F1:\t\t\t0.9134\n",
      "\n",
      "fold_3, epoch_101, Loss: 0.3956\n",
      "fold_3, epoch_102, Loss: 0.3937\n",
      "fold_3, epoch_103, Loss: 0.3952\n",
      "fold_3, epoch_104, Loss: 0.3980\n",
      "fold_3, epoch_105, Loss: 0.3974\n",
      "fold_3, epoch_106, Loss: 0.3954\n",
      "fold_3, epoch_107, Loss: 0.3919\n",
      "fold_3, epoch_108, Loss: 0.3906\n",
      "fold_3, epoch_109, Loss: 0.3953\n",
      "fold_3, epoch_110, Loss: 0.3989\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3956\n",
      "Accuracy:\t0.9167\n",
      "AUC:\t\t0.9299\n",
      "Precision:\t0.9282\n",
      "Recall:\t\t0.9029\n",
      "F1:\t\t\t0.9154\n",
      "\n",
      "fold_3, epoch_111, Loss: 0.3943\n",
      "fold_3, epoch_112, Loss: 0.3933\n",
      "fold_3, epoch_113, Loss: 0.3892\n",
      "fold_3, epoch_114, Loss: 0.3957\n",
      "fold_3, epoch_115, Loss: 0.3921\n",
      "fold_3, epoch_116, Loss: 0.3916\n",
      "fold_3, epoch_117, Loss: 0.3906\n",
      "fold_3, epoch_118, Loss: 0.3849\n",
      "fold_3, epoch_119, Loss: 0.3919\n",
      "fold_3, epoch_120, Loss: 0.3954\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3894\n",
      "Accuracy:\t0.9238\n",
      "AUC:\t\t0.9322\n",
      "Precision:\t0.9297\n",
      "Recall:\t\t0.9177\n",
      "F1:\t\t\t0.9237\n",
      "\n",
      "fold_3, epoch_121, Loss: 0.3886\n",
      "fold_3, epoch_122, Loss: 0.3897\n",
      "fold_3, epoch_123, Loss: 0.3883\n",
      "fold_3, epoch_124, Loss: 0.3885\n",
      "fold_3, epoch_125, Loss: 0.3896\n",
      "fold_3, epoch_126, Loss: 0.3859\n",
      "fold_3, epoch_127, Loss: 0.3867\n",
      "fold_3, epoch_128, Loss: 0.3929\n",
      "fold_3, epoch_129, Loss: 0.3822\n",
      "fold_3, epoch_130, Loss: 0.3869\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.4012\n",
      "Accuracy:\t0.9110\n",
      "AUC:\t\t0.9288\n",
      "Precision:\t0.9355\n",
      "Recall:\t\t0.8825\n",
      "F1:\t\t\t0.9082\n",
      "\n",
      "fold_3, epoch_131, Loss: 0.3921\n",
      "fold_3, epoch_132, Loss: 0.3820\n",
      "fold_3, epoch_133, Loss: 0.3864\n",
      "fold_3, epoch_134, Loss: 0.3881\n",
      "fold_3, epoch_135, Loss: 0.3837\n",
      "fold_3, epoch_136, Loss: 0.3872\n",
      "fold_3, epoch_137, Loss: 0.3875\n",
      "fold_3, epoch_138, Loss: 0.3843\n",
      "fold_3, epoch_139, Loss: 0.3865\n",
      "fold_3, epoch_140, Loss: 0.3870\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3870\n",
      "Accuracy:\t0.9250\n",
      "AUC:\t\t0.9362\n",
      "Precision:\t0.9297\n",
      "Recall:\t\t0.9214\n",
      "F1:\t\t\t0.9256\n",
      "\n",
      "fold_3, epoch_141, Loss: 0.3847\n",
      "fold_3, epoch_142, Loss: 0.3859\n",
      "fold_3, epoch_143, Loss: 0.3809\n",
      "fold_3, epoch_144, Loss: 0.3806\n",
      "fold_3, epoch_145, Loss: 0.3798\n",
      "fold_3, epoch_146, Loss: 0.3841\n",
      "fold_3, epoch_147, Loss: 0.3857\n",
      "fold_3, epoch_148, Loss: 0.3862\n",
      "fold_3, epoch_149, Loss: 0.3819\n",
      "fold_3, epoch_150, Loss: 0.3800\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3773\n",
      "Accuracy:\t0.9358\n",
      "AUC:\t\t0.9403\n",
      "Precision:\t0.9474\n",
      "Recall:\t\t0.9235\n",
      "F1:\t\t\t0.9353\n",
      "\n",
      "fold_3, epoch_151, Loss: 0.3821\n",
      "fold_3, epoch_152, Loss: 0.3752\n",
      "fold_3, epoch_153, Loss: 0.3821\n",
      "fold_3, epoch_154, Loss: 0.3818\n",
      "fold_3, epoch_155, Loss: 0.3758\n",
      "fold_3, epoch_156, Loss: 0.3785\n",
      "fold_3, epoch_157, Loss: 0.3808\n",
      "fold_3, epoch_158, Loss: 0.3782\n",
      "fold_3, epoch_159, Loss: 0.3743\n",
      "fold_3, epoch_160, Loss: 0.3813\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3751\n",
      "Accuracy:\t0.9381\n",
      "AUC:\t\t0.9415\n",
      "Precision:\t0.9444\n",
      "Recall:\t\t0.9315\n",
      "F1:\t\t\t0.9379\n",
      "\n",
      "fold_3, epoch_161, Loss: 0.3797\n",
      "fold_3, epoch_162, Loss: 0.3799\n",
      "fold_3, epoch_163, Loss: 0.3801\n",
      "fold_3, epoch_164, Loss: 0.3754\n",
      "fold_3, epoch_165, Loss: 0.3768\n",
      "fold_3, epoch_166, Loss: 0.3766\n",
      "fold_3, epoch_167, Loss: 0.3767\n",
      "fold_3, epoch_168, Loss: 0.3756\n",
      "fold_3, epoch_169, Loss: 0.3743\n",
      "fold_3, epoch_170, Loss: 0.3736\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3764\n",
      "Accuracy:\t0.9368\n",
      "AUC:\t\t0.9420\n",
      "Precision:\t0.9409\n",
      "Recall:\t\t0.9329\n",
      "F1:\t\t\t0.9369\n",
      "\n",
      "fold_3, epoch_171, Loss: 0.3755\n",
      "fold_3, epoch_172, Loss: 0.3794\n",
      "fold_3, epoch_173, Loss: 0.3761\n",
      "fold_3, epoch_174, Loss: 0.3777\n",
      "fold_3, epoch_175, Loss: 0.3775\n",
      "fold_3, epoch_176, Loss: 0.3756\n",
      "fold_3, epoch_177, Loss: 0.3784\n",
      "fold_3, epoch_178, Loss: 0.3777\n",
      "fold_3, epoch_179, Loss: 0.3820\n",
      "fold_3, epoch_180, Loss: 0.3750\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3734\n",
      "Accuracy:\t0.9398\n",
      "AUC:\t\t0.9445\n",
      "Precision:\t0.9520\n",
      "Recall:\t\t0.9260\n",
      "F1:\t\t\t0.9388\n",
      "\n",
      "fold_3, epoch_181, Loss: 0.3722\n",
      "fold_3, epoch_182, Loss: 0.3742\n",
      "fold_3, epoch_183, Loss: 0.3729\n",
      "fold_3, epoch_184, Loss: 0.3771\n",
      "fold_3, epoch_185, Loss: 0.3743\n",
      "fold_3, epoch_186, Loss: 0.3806\n",
      "fold_3, epoch_187, Loss: 0.3776\n",
      "fold_3, epoch_188, Loss: 0.3877\n",
      "fold_3, epoch_189, Loss: 0.3733\n",
      "fold_3, epoch_190, Loss: 0.3716\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3737\n",
      "Accuracy:\t0.9392\n",
      "AUC:\t\t0.9435\n",
      "Precision:\t0.9529\n",
      "Recall:\t\t0.9240\n",
      "F1:\t\t\t0.9383\n",
      "\n",
      "fold_3, epoch_191, Loss: 0.3705\n",
      "fold_3, epoch_192, Loss: 0.3758\n",
      "fold_3, epoch_193, Loss: 0.3752\n",
      "fold_3, epoch_194, Loss: 0.3765\n",
      "fold_3, epoch_195, Loss: 0.3762\n",
      "fold_3, epoch_196, Loss: 0.3725\n",
      "fold_3, epoch_197, Loss: 0.3725\n",
      "fold_3, epoch_198, Loss: 0.3742\n",
      "fold_3, epoch_199, Loss: 0.3755\n",
      "fold_3, epoch_200, Loss: 0.3789\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3668\n",
      "Accuracy:\t0.9462\n",
      "AUC:\t\t0.9483\n",
      "Precision:\t0.9572\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9460\n",
      "\n",
      "fold_3, epoch_201, Loss: 0.3709\n",
      "fold_3, epoch_202, Loss: 0.3741\n",
      "fold_3, epoch_203, Loss: 0.3683\n",
      "fold_3, epoch_204, Loss: 0.3674\n",
      "fold_3, epoch_205, Loss: 0.3738\n",
      "fold_3, epoch_206, Loss: 0.3707\n",
      "fold_3, epoch_207, Loss: 0.3742\n",
      "fold_3, epoch_208, Loss: 0.3720\n",
      "fold_3, epoch_209, Loss: 0.3713\n",
      "fold_3, epoch_210, Loss: 0.3727\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3717\n",
      "Accuracy:\t0.9412\n",
      "AUC:\t\t0.9456\n",
      "Precision:\t0.9503\n",
      "Recall:\t\t0.9316\n",
      "F1:\t\t\t0.9408\n",
      "\n",
      "fold_3, epoch_211, Loss: 0.3709\n",
      "fold_3, epoch_212, Loss: 0.3702\n",
      "fold_3, epoch_213, Loss: 0.3734\n",
      "fold_3, epoch_214, Loss: 0.3688\n",
      "fold_3, epoch_215, Loss: 0.3724\n",
      "fold_3, epoch_216, Loss: 0.3700\n",
      "fold_3, epoch_217, Loss: 0.3711\n",
      "fold_3, epoch_218, Loss: 0.3703\n",
      "fold_3, epoch_219, Loss: 0.3683\n",
      "fold_3, epoch_220, Loss: 0.3748\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3849\n",
      "Accuracy:\t0.9274\n",
      "AUC:\t\t0.9427\n",
      "Precision:\t0.9390\n",
      "Recall:\t\t0.9158\n",
      "F1:\t\t\t0.9273\n",
      "\n",
      "fold_3, epoch_221, Loss: 0.3751\n",
      "fold_3, epoch_222, Loss: 0.3695\n",
      "fold_3, epoch_223, Loss: 0.3715\n",
      "fold_3, epoch_224, Loss: 0.3696\n",
      "fold_3, epoch_225, Loss: 0.3686\n",
      "fold_3, epoch_226, Loss: 0.3688\n",
      "fold_3, epoch_227, Loss: 0.3659\n",
      "fold_3, epoch_228, Loss: 0.3693\n",
      "fold_3, epoch_229, Loss: 0.3652\n",
      "fold_3, epoch_230, Loss: 0.3732\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3704\n",
      "Accuracy:\t0.9424\n",
      "AUC:\t\t0.9483\n",
      "Precision:\t0.9673\n",
      "Recall:\t\t0.9165\n",
      "F1:\t\t\t0.9412\n",
      "\n",
      "fold_3, epoch_231, Loss: 0.3636\n",
      "fold_3, epoch_232, Loss: 0.3688\n",
      "fold_3, epoch_233, Loss: 0.3694\n",
      "fold_3, epoch_234, Loss: 0.3678\n",
      "fold_3, epoch_235, Loss: 0.3661\n",
      "fold_3, epoch_236, Loss: 0.3684\n",
      "fold_3, epoch_237, Loss: 0.3670\n",
      "fold_3, epoch_238, Loss: 0.3678\n",
      "fold_3, epoch_239, Loss: 0.3673\n",
      "fold_3, epoch_240, Loss: 0.3676\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3665\n",
      "Accuracy:\t0.9468\n",
      "AUC:\t\t0.9505\n",
      "Precision:\t0.9653\n",
      "Recall:\t\t0.9277\n",
      "F1:\t\t\t0.9461\n",
      "\n",
      "fold_3, epoch_241, Loss: 0.3685\n",
      "fold_3, epoch_242, Loss: 0.3687\n",
      "fold_3, epoch_243, Loss: 0.3671\n",
      "fold_3, epoch_244, Loss: 0.3686\n",
      "fold_3, epoch_245, Loss: 0.3670\n",
      "fold_3, epoch_246, Loss: 0.3629\n",
      "fold_3, epoch_247, Loss: 0.3673\n",
      "fold_3, epoch_248, Loss: 0.3659\n",
      "fold_3, epoch_249, Loss: 0.3650\n",
      "fold_3, epoch_250, Loss: 0.3670\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3657\n",
      "Accuracy:\t0.9468\n",
      "AUC:\t\t0.9505\n",
      "Precision:\t0.9646\n",
      "Recall:\t\t0.9280\n",
      "F1:\t\t\t0.9460\n",
      "\n",
      "fold_3, epoch_251, Loss: 0.3650\n",
      "fold_3, epoch_252, Loss: 0.3682\n",
      "fold_3, epoch_253, Loss: 0.3692\n",
      "fold_3, epoch_254, Loss: 0.3635\n",
      "fold_3, epoch_255, Loss: 0.3661\n",
      "fold_3, epoch_256, Loss: 0.3691\n",
      "fold_3, epoch_257, Loss: 0.3654\n",
      "fold_3, epoch_258, Loss: 0.3667\n",
      "fold_3, epoch_259, Loss: 0.3624\n",
      "fold_3, epoch_260, Loss: 0.3654\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3707\n",
      "Accuracy:\t0.9413\n",
      "AUC:\t\t0.9506\n",
      "Precision:\t0.9654\n",
      "Recall:\t\t0.9154\n",
      "F1:\t\t\t0.9397\n",
      "\n",
      "fold_3, epoch_261, Loss: 0.3698\n",
      "fold_3, epoch_262, Loss: 0.3694\n",
      "fold_3, epoch_263, Loss: 0.3639\n",
      "fold_3, epoch_264, Loss: 0.3654\n",
      "fold_3, epoch_265, Loss: 0.3623\n",
      "fold_3, epoch_266, Loss: 0.3663\n",
      "fold_3, epoch_267, Loss: 0.3651\n",
      "fold_3, epoch_268, Loss: 0.3727\n",
      "fold_3, epoch_269, Loss: 0.3686\n",
      "fold_3, epoch_270, Loss: 0.3639\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3616\n",
      "Accuracy:\t0.9513\n",
      "AUC:\t\t0.9550\n",
      "Precision:\t0.9661\n",
      "Recall:\t\t0.9354\n",
      "F1:\t\t\t0.9505\n",
      "\n",
      "fold_3, epoch_271, Loss: 0.3662\n",
      "fold_3, epoch_272, Loss: 0.3634\n",
      "fold_3, epoch_273, Loss: 0.3630\n",
      "fold_3, epoch_274, Loss: 0.3619\n",
      "fold_3, epoch_275, Loss: 0.3684\n",
      "fold_3, epoch_276, Loss: 0.3616\n",
      "fold_3, epoch_277, Loss: 0.3647\n",
      "fold_3, epoch_278, Loss: 0.3669\n",
      "fold_3, epoch_279, Loss: 0.3617\n",
      "fold_3, epoch_280, Loss: 0.3627\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3623\n",
      "Accuracy:\t0.9509\n",
      "AUC:\t\t0.9524\n",
      "Precision:\t0.9654\n",
      "Recall:\t\t0.9359\n",
      "F1:\t\t\t0.9504\n",
      "\n",
      "fold_3, epoch_281, Loss: 0.3646\n",
      "fold_3, epoch_282, Loss: 0.3647\n",
      "fold_3, epoch_283, Loss: 0.3607\n",
      "fold_3, epoch_284, Loss: 0.3669\n",
      "fold_3, epoch_285, Loss: 0.3629\n",
      "fold_3, epoch_286, Loss: 0.3647\n",
      "fold_3, epoch_287, Loss: 0.3652\n",
      "fold_3, epoch_288, Loss: 0.3609\n",
      "fold_3, epoch_289, Loss: 0.3643\n",
      "fold_3, epoch_290, Loss: 0.3613\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3635\n",
      "Accuracy:\t0.9496\n",
      "AUC:\t\t0.9508\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9488\n",
      "\n",
      "fold_3, epoch_291, Loss: 0.3621\n",
      "fold_3, epoch_292, Loss: 0.3617\n",
      "fold_3, epoch_293, Loss: 0.3656\n",
      "fold_3, epoch_294, Loss: 0.3630\n",
      "fold_3, epoch_295, Loss: 0.3666\n",
      "fold_3, epoch_296, Loss: 0.3599\n",
      "fold_3, epoch_297, Loss: 0.3597\n",
      "fold_3, epoch_298, Loss: 0.3628\n",
      "fold_3, epoch_299, Loss: 0.3613\n",
      "fold_3, epoch_300, Loss: 0.3609\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3614\n",
      "Accuracy:\t0.9518\n",
      "AUC:\t\t0.9536\n",
      "Precision:\t0.9700\n",
      "Recall:\t\t0.9329\n",
      "F1:\t\t\t0.9511\n",
      "\n",
      "fold_3, epoch_301, Loss: 0.3628\n",
      "fold_3, epoch_302, Loss: 0.3621\n",
      "fold_3, epoch_303, Loss: 0.3586\n",
      "fold_3, epoch_304, Loss: 0.3626\n",
      "fold_3, epoch_305, Loss: 0.3658\n",
      "fold_3, epoch_306, Loss: 0.3588\n",
      "fold_3, epoch_307, Loss: 0.3608\n",
      "fold_3, epoch_308, Loss: 0.3606\n",
      "fold_3, epoch_309, Loss: 0.3629\n",
      "fold_3, epoch_310, Loss: 0.3597\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3568\n",
      "Accuracy:\t0.9564\n",
      "AUC:\t\t0.9565\n",
      "Precision:\t0.9735\n",
      "Recall:\t\t0.9381\n",
      "F1:\t\t\t0.9555\n",
      "\n",
      "fold_3, epoch_311, Loss: 0.3593\n",
      "fold_3, epoch_312, Loss: 0.3627\n",
      "fold_3, epoch_313, Loss: 0.3592\n",
      "fold_3, epoch_314, Loss: 0.3590\n",
      "fold_3, epoch_315, Loss: 0.3579\n",
      "fold_3, epoch_316, Loss: 0.3590\n",
      "fold_3, epoch_317, Loss: 0.3619\n",
      "fold_3, epoch_318, Loss: 0.3567\n",
      "fold_3, epoch_319, Loss: 0.3613\n",
      "fold_3, epoch_320, Loss: 0.3626\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3635\n",
      "Accuracy:\t0.9495\n",
      "AUC:\t\t0.9546\n",
      "Precision:\t0.9623\n",
      "Recall:\t\t0.9355\n",
      "F1:\t\t\t0.9487\n",
      "\n",
      "fold_3, epoch_321, Loss: 0.3578\n",
      "fold_3, epoch_322, Loss: 0.3620\n",
      "fold_3, epoch_323, Loss: 0.3595\n",
      "fold_3, epoch_324, Loss: 0.3614\n",
      "fold_3, epoch_325, Loss: 0.3570\n",
      "fold_3, epoch_326, Loss: 0.3636\n",
      "fold_3, epoch_327, Loss: 0.3598\n",
      "fold_3, epoch_328, Loss: 0.3591\n",
      "fold_3, epoch_329, Loss: 0.3611\n",
      "fold_3, epoch_330, Loss: 0.3610\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3595\n",
      "Accuracy:\t0.9534\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9692\n",
      "Recall:\t\t0.9372\n",
      "F1:\t\t\t0.9529\n",
      "\n",
      "fold_3, epoch_331, Loss: 0.3582\n",
      "fold_3, epoch_332, Loss: 0.3614\n",
      "fold_3, epoch_333, Loss: 0.3627\n",
      "fold_3, epoch_334, Loss: 0.3584\n",
      "fold_3, epoch_335, Loss: 0.3575\n",
      "fold_3, epoch_336, Loss: 0.3610\n",
      "fold_3, epoch_337, Loss: 0.3600\n",
      "fold_3, epoch_338, Loss: 0.3599\n",
      "fold_3, epoch_339, Loss: 0.3607\n",
      "fold_3, epoch_340, Loss: 0.3577\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3565\n",
      "Accuracy:\t0.9566\n",
      "AUC:\t\t0.9582\n",
      "Precision:\t0.9752\n",
      "Recall:\t\t0.9370\n",
      "F1:\t\t\t0.9557\n",
      "\n",
      "fold_3, epoch_341, Loss: 0.3584\n",
      "fold_3, epoch_342, Loss: 0.3610\n",
      "fold_3, epoch_343, Loss: 0.3590\n",
      "fold_3, epoch_344, Loss: 0.3589\n",
      "fold_3, epoch_345, Loss: 0.3628\n",
      "fold_3, epoch_346, Loss: 0.3585\n",
      "fold_3, epoch_347, Loss: 0.3586\n",
      "fold_3, epoch_348, Loss: 0.3611\n",
      "fold_3, epoch_349, Loss: 0.3577\n",
      "fold_3, epoch_350, Loss: 0.3577\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3568\n",
      "Accuracy:\t0.9566\n",
      "AUC:\t\t0.9567\n",
      "Precision:\t0.9745\n",
      "Recall:\t\t0.9369\n",
      "F1:\t\t\t0.9553\n",
      "\n",
      "fold_3, epoch_351, Loss: 0.3587\n",
      "fold_3, epoch_352, Loss: 0.3581\n",
      "fold_3, epoch_353, Loss: 0.3646\n",
      "fold_3, epoch_354, Loss: 0.3596\n",
      "fold_3, epoch_355, Loss: 0.3565\n",
      "fold_3, epoch_356, Loss: 0.3550\n",
      "fold_3, epoch_357, Loss: 0.3575\n",
      "fold_3, epoch_358, Loss: 0.3573\n",
      "fold_3, epoch_359, Loss: 0.3580\n",
      "fold_3, epoch_360, Loss: 0.3580\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3603\n",
      "Accuracy:\t0.9526\n",
      "AUC:\t\t0.9559\n",
      "Precision:\t0.9733\n",
      "Recall:\t\t0.9304\n",
      "F1:\t\t\t0.9514\n",
      "\n",
      "fold_3, epoch_361, Loss: 0.3582\n",
      "fold_3, epoch_362, Loss: 0.3567\n",
      "fold_3, epoch_363, Loss: 0.3575\n",
      "fold_3, epoch_364, Loss: 0.3571\n",
      "fold_3, epoch_365, Loss: 0.3582\n",
      "fold_3, epoch_366, Loss: 0.3597\n",
      "fold_3, epoch_367, Loss: 0.3550\n",
      "fold_3, epoch_368, Loss: 0.3580\n",
      "fold_3, epoch_369, Loss: 0.3567\n",
      "fold_3, epoch_370, Loss: 0.3600\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3719\n",
      "Accuracy:\t0.9404\n",
      "AUC:\t\t0.9562\n",
      "Precision:\t0.9701\n",
      "Recall:\t\t0.9100\n",
      "F1:\t\t\t0.9391\n",
      "\n",
      "fold_3, epoch_371, Loss: 0.3622\n",
      "fold_3, epoch_372, Loss: 0.3560\n",
      "fold_3, epoch_373, Loss: 0.3560\n",
      "fold_3, epoch_374, Loss: 0.3631\n",
      "fold_3, epoch_375, Loss: 0.3562\n",
      "fold_3, epoch_376, Loss: 0.3553\n",
      "fold_3, epoch_377, Loss: 0.3627\n",
      "fold_3, epoch_378, Loss: 0.3564\n",
      "fold_3, epoch_379, Loss: 0.3571\n",
      "fold_3, epoch_380, Loss: 0.3547\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3571\n",
      "Accuracy:\t0.9560\n",
      "AUC:\t\t0.9555\n",
      "Precision:\t0.9723\n",
      "Recall:\t\t0.9388\n",
      "F1:\t\t\t0.9552\n",
      "\n",
      "fold_3, epoch_381, Loss: 0.3534\n",
      "fold_3, epoch_382, Loss: 0.3565\n",
      "fold_3, epoch_383, Loss: 0.3604\n",
      "fold_3, epoch_384, Loss: 0.3561\n",
      "fold_3, epoch_385, Loss: 0.3586\n",
      "fold_3, epoch_386, Loss: 0.3562\n",
      "fold_3, epoch_387, Loss: 0.3542\n",
      "fold_3, epoch_388, Loss: 0.3582\n",
      "fold_3, epoch_389, Loss: 0.3586\n",
      "fold_3, epoch_390, Loss: 0.3567\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3668\n",
      "Accuracy:\t0.9457\n",
      "AUC:\t\t0.9554\n",
      "Precision:\t0.9532\n",
      "Recall:\t\t0.9376\n",
      "F1:\t\t\t0.9453\n",
      "\n",
      "fold_3, epoch_391, Loss: 0.3559\n",
      "fold_3, epoch_392, Loss: 0.3572\n",
      "fold_3, epoch_393, Loss: 0.3600\n",
      "fold_3, epoch_394, Loss: 0.3593\n",
      "fold_3, epoch_395, Loss: 0.3573\n",
      "fold_3, epoch_396, Loss: 0.3633\n",
      "fold_3, epoch_397, Loss: 0.3551\n",
      "fold_3, epoch_398, Loss: 0.3545\n",
      "fold_3, epoch_399, Loss: 0.3549\n",
      "fold_3, epoch_400, Loss: 0.3556\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3562\n",
      "Accuracy:\t0.9569\n",
      "AUC:\t\t0.9582\n",
      "Precision:\t0.9724\n",
      "Recall:\t\t0.9402\n",
      "F1:\t\t\t0.9560\n",
      "\n",
      "fold_3, epoch_401, Loss: 0.3596\n",
      "fold_3, epoch_402, Loss: 0.3560\n",
      "fold_3, epoch_403, Loss: 0.3556\n",
      "fold_3, epoch_404, Loss: 0.3573\n",
      "fold_3, epoch_405, Loss: 0.3552\n",
      "fold_3, epoch_406, Loss: 0.3568\n",
      "fold_3, epoch_407, Loss: 0.3565\n",
      "fold_3, epoch_408, Loss: 0.3581\n",
      "fold_3, epoch_409, Loss: 0.3557\n",
      "fold_3, epoch_410, Loss: 0.3561\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3567\n",
      "Accuracy:\t0.9563\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9759\n",
      "Recall:\t\t0.9360\n",
      "F1:\t\t\t0.9555\n",
      "\n",
      "fold_3, epoch_411, Loss: 0.3566\n",
      "fold_3, epoch_412, Loss: 0.3577\n",
      "fold_3, epoch_413, Loss: 0.3539\n",
      "fold_3, epoch_414, Loss: 0.3557\n",
      "fold_3, epoch_415, Loss: 0.3563\n",
      "fold_3, epoch_416, Loss: 0.3564\n",
      "fold_3, epoch_417, Loss: 0.3568\n",
      "fold_3, epoch_418, Loss: 0.3579\n",
      "fold_3, epoch_419, Loss: 0.3550\n",
      "fold_3, epoch_420, Loss: 0.3548\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3549\n",
      "Accuracy:\t0.9581\n",
      "AUC:\t\t0.9593\n",
      "Precision:\t0.9771\n",
      "Recall:\t\t0.9380\n",
      "F1:\t\t\t0.9571\n",
      "\n",
      "fold_3, epoch_421, Loss: 0.3574\n",
      "fold_3, epoch_422, Loss: 0.3549\n",
      "fold_3, epoch_423, Loss: 0.3533\n",
      "fold_3, epoch_424, Loss: 0.3550\n",
      "fold_3, epoch_425, Loss: 0.3558\n",
      "fold_3, epoch_426, Loss: 0.3582\n",
      "fold_3, epoch_427, Loss: 0.3548\n",
      "fold_3, epoch_428, Loss: 0.3556\n",
      "fold_3, epoch_429, Loss: 0.3595\n",
      "fold_3, epoch_430, Loss: 0.3537\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3535\n",
      "Accuracy:\t0.9597\n",
      "AUC:\t\t0.9602\n",
      "Precision:\t0.9765\n",
      "Recall:\t\t0.9418\n",
      "F1:\t\t\t0.9588\n",
      "\n",
      "fold_3, epoch_431, Loss: 0.3525\n",
      "fold_3, epoch_432, Loss: 0.3550\n",
      "fold_3, epoch_433, Loss: 0.3552\n",
      "fold_3, epoch_434, Loss: 0.3577\n",
      "fold_3, epoch_435, Loss: 0.3516\n",
      "fold_3, epoch_436, Loss: 0.3585\n",
      "fold_3, epoch_437, Loss: 0.3552\n",
      "fold_3, epoch_438, Loss: 0.3532\n",
      "fold_3, epoch_439, Loss: 0.3548\n",
      "fold_3, epoch_440, Loss: 0.3528\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3514\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9604\n",
      "Precision:\t0.9801\n",
      "Recall:\t\t0.9422\n",
      "F1:\t\t\t0.9608\n",
      "\n",
      "fold_3, epoch_441, Loss: 0.3561\n",
      "fold_3, epoch_442, Loss: 0.3557\n",
      "fold_3, epoch_443, Loss: 0.3546\n",
      "fold_3, epoch_444, Loss: 0.3510\n",
      "fold_3, epoch_445, Loss: 0.3526\n",
      "fold_3, epoch_446, Loss: 0.3530\n",
      "fold_3, epoch_447, Loss: 0.3544\n",
      "fold_3, epoch_448, Loss: 0.3560\n",
      "fold_3, epoch_449, Loss: 0.3556\n",
      "fold_3, epoch_450, Loss: 0.3564\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9587\n",
      "AUC:\t\t0.9610\n",
      "Precision:\t0.9805\n",
      "Recall:\t\t0.9364\n",
      "F1:\t\t\t0.9579\n",
      "\n",
      "fold_3, epoch_451, Loss: 0.3529\n",
      "fold_3, epoch_452, Loss: 0.3559\n",
      "fold_3, epoch_453, Loss: 0.3553\n",
      "fold_3, epoch_454, Loss: 0.3543\n",
      "fold_3, epoch_455, Loss: 0.3525\n",
      "fold_3, epoch_456, Loss: 0.3529\n",
      "fold_3, epoch_457, Loss: 0.3537\n",
      "fold_3, epoch_458, Loss: 0.3562\n",
      "fold_3, epoch_459, Loss: 0.3533\n",
      "fold_3, epoch_460, Loss: 0.3552\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9623\n",
      "AUC:\t\t0.9629\n",
      "Precision:\t0.9808\n",
      "Recall:\t\t0.9429\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_3, epoch_461, Loss: 0.3543\n",
      "fold_3, epoch_462, Loss: 0.3554\n",
      "fold_3, epoch_463, Loss: 0.3527\n",
      "fold_3, epoch_464, Loss: 0.3516\n",
      "fold_3, epoch_465, Loss: 0.3511\n",
      "fold_3, epoch_466, Loss: 0.3550\n",
      "fold_3, epoch_467, Loss: 0.3543\n",
      "fold_3, epoch_468, Loss: 0.3555\n",
      "fold_3, epoch_469, Loss: 0.3550\n",
      "fold_3, epoch_470, Loss: 0.3530\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3551\n",
      "Accuracy:\t0.9580\n",
      "AUC:\t\t0.9589\n",
      "Precision:\t0.9786\n",
      "Recall:\t\t0.9367\n",
      "F1:\t\t\t0.9572\n",
      "\n",
      "fold_3, epoch_471, Loss: 0.3534\n",
      "fold_3, epoch_472, Loss: 0.3529\n",
      "fold_3, epoch_473, Loss: 0.3551\n",
      "fold_3, epoch_474, Loss: 0.3522\n",
      "fold_3, epoch_475, Loss: 0.3527\n",
      "fold_3, epoch_476, Loss: 0.3525\n",
      "fold_3, epoch_477, Loss: 0.3523\n",
      "fold_3, epoch_478, Loss: 0.3519\n",
      "fold_3, epoch_479, Loss: 0.3546\n",
      "fold_3, epoch_480, Loss: 0.3543\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9614\n",
      "AUC:\t\t0.9621\n",
      "Precision:\t0.9831\n",
      "Recall:\t\t0.9395\n",
      "F1:\t\t\t0.9608\n",
      "\n",
      "fold_3, epoch_481, Loss: 0.3518\n",
      "fold_3, epoch_482, Loss: 0.3533\n",
      "fold_3, epoch_483, Loss: 0.3564\n",
      "fold_3, epoch_484, Loss: 0.3510\n",
      "fold_3, epoch_485, Loss: 0.3518\n",
      "fold_3, epoch_486, Loss: 0.3534\n",
      "fold_3, epoch_487, Loss: 0.3532\n",
      "fold_3, epoch_488, Loss: 0.3523\n",
      "fold_3, epoch_489, Loss: 0.3560\n",
      "fold_3, epoch_490, Loss: 0.3510\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3564\n",
      "Accuracy:\t0.9567\n",
      "AUC:\t\t0.9596\n",
      "Precision:\t0.9794\n",
      "Recall:\t\t0.9328\n",
      "F1:\t\t\t0.9556\n",
      "\n",
      "fold_3, epoch_491, Loss: 0.3542\n",
      "fold_3, epoch_492, Loss: 0.3526\n",
      "fold_3, epoch_493, Loss: 0.3525\n",
      "fold_3, epoch_494, Loss: 0.3505\n",
      "fold_3, epoch_495, Loss: 0.3533\n",
      "fold_3, epoch_496, Loss: 0.3528\n",
      "fold_3, epoch_497, Loss: 0.3521\n",
      "fold_3, epoch_498, Loss: 0.3557\n",
      "fold_3, epoch_499, Loss: 0.3536\n",
      "fold_3, epoch_500, Loss: 0.3524\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3513\n",
      "Accuracy:\t0.9619\n",
      "AUC:\t\t0.9609\n",
      "Precision:\t0.9815\n",
      "Recall:\t\t0.9413\n",
      "F1:\t\t\t0.9610\n",
      "\n",
      "fold_3, epoch_501, Loss: 0.3545\n",
      "fold_3, epoch_502, Loss: 0.3536\n",
      "fold_3, epoch_503, Loss: 0.3536\n",
      "fold_3, epoch_504, Loss: 0.3544\n",
      "fold_3, epoch_505, Loss: 0.3539\n",
      "fold_3, epoch_506, Loss: 0.3526\n",
      "fold_3, epoch_507, Loss: 0.3514\n",
      "fold_3, epoch_508, Loss: 0.3537\n",
      "fold_3, epoch_509, Loss: 0.3535\n",
      "fold_3, epoch_510, Loss: 0.3536\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3514\n",
      "Accuracy:\t0.9619\n",
      "AUC:\t\t0.9600\n",
      "Precision:\t0.9846\n",
      "Recall:\t\t0.9384\n",
      "F1:\t\t\t0.9610\n",
      "\n",
      "fold_3, epoch_511, Loss: 0.3508\n",
      "fold_3, epoch_512, Loss: 0.3510\n",
      "fold_3, epoch_513, Loss: 0.3544\n",
      "fold_3, epoch_514, Loss: 0.3539\n",
      "fold_3, epoch_515, Loss: 0.3524\n",
      "fold_3, epoch_516, Loss: 0.3487\n",
      "fold_3, epoch_517, Loss: 0.3535\n",
      "fold_3, epoch_518, Loss: 0.3528\n",
      "fold_3, epoch_519, Loss: 0.3543\n",
      "fold_3, epoch_520, Loss: 0.3509\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3539\n",
      "Accuracy:\t0.9591\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9798\n",
      "Recall:\t\t0.9386\n",
      "F1:\t\t\t0.9588\n",
      "\n",
      "fold_3, epoch_521, Loss: 0.3526\n",
      "fold_3, epoch_522, Loss: 0.3502\n",
      "fold_3, epoch_523, Loss: 0.3615\n",
      "fold_3, epoch_524, Loss: 0.3554\n",
      "fold_3, epoch_525, Loss: 0.3519\n",
      "fold_3, epoch_526, Loss: 0.3515\n",
      "fold_3, epoch_527, Loss: 0.3515\n",
      "fold_3, epoch_528, Loss: 0.3511\n",
      "fold_3, epoch_529, Loss: 0.3505\n",
      "fold_3, epoch_530, Loss: 0.3526\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3516\n",
      "Accuracy:\t0.9617\n",
      "AUC:\t\t0.9613\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9411\n",
      "F1:\t\t\t0.9606\n",
      "\n",
      "fold_3, epoch_531, Loss: 0.3514\n",
      "fold_3, epoch_532, Loss: 0.3531\n",
      "fold_3, epoch_533, Loss: 0.3538\n",
      "fold_3, epoch_534, Loss: 0.3541\n",
      "fold_3, epoch_535, Loss: 0.3516\n",
      "fold_3, epoch_536, Loss: 0.3522\n",
      "fold_3, epoch_537, Loss: 0.3505\n",
      "fold_3, epoch_538, Loss: 0.3522\n",
      "fold_3, epoch_539, Loss: 0.3510\n",
      "fold_3, epoch_540, Loss: 0.3507\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3483\n",
      "Accuracy:\t0.9648\n",
      "AUC:\t\t0.9658\n",
      "Precision:\t0.9845\n",
      "Recall:\t\t0.9446\n",
      "F1:\t\t\t0.9641\n",
      "\n",
      "fold_3, epoch_541, Loss: 0.3546\n",
      "fold_3, epoch_542, Loss: 0.3519\n",
      "fold_3, epoch_543, Loss: 0.3511\n",
      "fold_3, epoch_544, Loss: 0.3523\n",
      "fold_3, epoch_545, Loss: 0.3513\n",
      "fold_3, epoch_546, Loss: 0.3520\n",
      "fold_3, epoch_547, Loss: 0.3507\n",
      "fold_3, epoch_548, Loss: 0.3508\n",
      "fold_3, epoch_549, Loss: 0.3514\n",
      "fold_3, epoch_550, Loss: 0.3503\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3488\n",
      "Accuracy:\t0.9644\n",
      "AUC:\t\t0.9629\n",
      "Precision:\t0.9844\n",
      "Recall:\t\t0.9437\n",
      "F1:\t\t\t0.9636\n",
      "\n",
      "fold_3, epoch_551, Loss: 0.3499\n",
      "fold_3, epoch_552, Loss: 0.3553\n",
      "fold_3, epoch_553, Loss: 0.3549\n",
      "fold_3, epoch_554, Loss: 0.3522\n",
      "fold_3, epoch_555, Loss: 0.3516\n",
      "fold_3, epoch_556, Loss: 0.3506\n",
      "fold_3, epoch_557, Loss: 0.3534\n",
      "fold_3, epoch_558, Loss: 0.3537\n",
      "fold_3, epoch_559, Loss: 0.3507\n",
      "fold_3, epoch_560, Loss: 0.3511\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3533\n",
      "Accuracy:\t0.9600\n",
      "AUC:\t\t0.9617\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9384\n",
      "F1:\t\t\t0.9592\n",
      "\n",
      "fold_3, epoch_561, Loss: 0.3534\n",
      "fold_3, epoch_562, Loss: 0.3520\n",
      "fold_3, epoch_563, Loss: 0.3521\n",
      "fold_3, epoch_564, Loss: 0.3540\n",
      "fold_3, epoch_565, Loss: 0.3507\n",
      "fold_3, epoch_566, Loss: 0.3505\n",
      "fold_3, epoch_567, Loss: 0.3500\n",
      "fold_3, epoch_568, Loss: 0.3527\n",
      "fold_3, epoch_569, Loss: 0.3515\n",
      "fold_3, epoch_570, Loss: 0.3493\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3476\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9644\n",
      "Precision:\t0.9867\n",
      "Recall:\t\t0.9437\n",
      "F1:\t\t\t0.9648\n",
      "\n",
      "fold_3, epoch_571, Loss: 0.3516\n",
      "fold_3, epoch_572, Loss: 0.3552\n",
      "fold_3, epoch_573, Loss: 0.3566\n",
      "fold_3, epoch_574, Loss: 0.3512\n",
      "fold_3, epoch_575, Loss: 0.3492\n",
      "fold_3, epoch_576, Loss: 0.3516\n",
      "fold_3, epoch_577, Loss: 0.3488\n",
      "fold_3, epoch_578, Loss: 0.3526\n",
      "fold_3, epoch_579, Loss: 0.3510\n",
      "fold_3, epoch_580, Loss: 0.3540\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3492\n",
      "Accuracy:\t0.9641\n",
      "AUC:\t\t0.9639\n",
      "Precision:\t0.9860\n",
      "Recall:\t\t0.9423\n",
      "F1:\t\t\t0.9637\n",
      "\n",
      "fold_3, epoch_581, Loss: 0.3514\n",
      "fold_3, epoch_582, Loss: 0.3495\n",
      "fold_3, epoch_583, Loss: 0.3514\n",
      "fold_3, epoch_584, Loss: 0.3487\n",
      "fold_3, epoch_585, Loss: 0.3537\n",
      "fold_3, epoch_586, Loss: 0.3530\n",
      "fold_3, epoch_587, Loss: 0.3508\n",
      "fold_3, epoch_588, Loss: 0.3523\n",
      "fold_3, epoch_589, Loss: 0.3487\n",
      "fold_3, epoch_590, Loss: 0.3500\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3501\n",
      "Accuracy:\t0.9631\n",
      "AUC:\t\t0.9637\n",
      "Precision:\t0.9834\n",
      "Recall:\t\t0.9427\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "fold_3, epoch_591, Loss: 0.3517\n",
      "fold_3, epoch_592, Loss: 0.3489\n",
      "fold_3, epoch_593, Loss: 0.3525\n",
      "fold_3, epoch_594, Loss: 0.3516\n",
      "fold_3, epoch_595, Loss: 0.3510\n",
      "fold_3, epoch_596, Loss: 0.3542\n",
      "fold_3, epoch_597, Loss: 0.3501\n",
      "fold_3, epoch_598, Loss: 0.3502\n",
      "fold_3, epoch_599, Loss: 0.3507\n",
      "fold_3, epoch_600, Loss: 0.3517\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3518\n",
      "Accuracy:\t0.9614\n",
      "AUC:\t\t0.9618\n",
      "Precision:\t0.9848\n",
      "Recall:\t\t0.9374\n",
      "F1:\t\t\t0.9605\n",
      "\n",
      "fold_3, epoch_601, Loss: 0.3504\n",
      "fold_3, epoch_602, Loss: 0.3504\n",
      "fold_3, epoch_603, Loss: 0.3524\n",
      "fold_3, epoch_604, Loss: 0.3524\n",
      "fold_3, epoch_605, Loss: 0.3499\n",
      "fold_3, epoch_606, Loss: 0.3495\n",
      "fold_3, epoch_607, Loss: 0.3503\n",
      "fold_3, epoch_608, Loss: 0.3525\n",
      "fold_3, epoch_609, Loss: 0.3529\n",
      "fold_3, epoch_610, Loss: 0.3491\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3509\n",
      "Accuracy:\t0.9620\n",
      "AUC:\t\t0.9629\n",
      "Precision:\t0.9819\n",
      "Recall:\t\t0.9419\n",
      "F1:\t\t\t0.9615\n",
      "\n",
      "fold_3, epoch_611, Loss: 0.3510\n",
      "fold_3, epoch_612, Loss: 0.3485\n",
      "fold_3, epoch_613, Loss: 0.3497\n",
      "fold_3, epoch_614, Loss: 0.3500\n",
      "fold_3, epoch_615, Loss: 0.3497\n",
      "fold_3, epoch_616, Loss: 0.3495\n",
      "fold_3, epoch_617, Loss: 0.3514\n",
      "fold_3, epoch_618, Loss: 0.3536\n",
      "fold_3, epoch_619, Loss: 0.3496\n",
      "fold_3, epoch_620, Loss: 0.3490\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9627\n",
      "AUC:\t\t0.9627\n",
      "Precision:\t0.9839\n",
      "Recall:\t\t0.9408\n",
      "F1:\t\t\t0.9619\n",
      "\n",
      "fold_3, epoch_621, Loss: 0.3515\n",
      "fold_3, epoch_622, Loss: 0.3519\n",
      "fold_3, epoch_623, Loss: 0.3486\n",
      "fold_3, epoch_624, Loss: 0.3509\n",
      "fold_3, epoch_625, Loss: 0.3508\n",
      "fold_3, epoch_626, Loss: 0.3505\n",
      "fold_3, epoch_627, Loss: 0.3510\n",
      "fold_3, epoch_628, Loss: 0.3488\n",
      "fold_3, epoch_629, Loss: 0.3495\n",
      "fold_3, epoch_630, Loss: 0.3517\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3521\n",
      "Accuracy:\t0.9611\n",
      "AUC:\t\t0.9633\n",
      "Precision:\t0.9818\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9606\n",
      "\n",
      "fold_3, epoch_631, Loss: 0.3500\n",
      "fold_3, epoch_632, Loss: 0.3501\n",
      "fold_3, epoch_633, Loss: 0.3491\n",
      "fold_3, epoch_634, Loss: 0.3490\n",
      "fold_3, epoch_635, Loss: 0.3474\n",
      "fold_3, epoch_636, Loss: 0.3487\n",
      "fold_3, epoch_637, Loss: 0.3491\n",
      "fold_3, epoch_638, Loss: 0.3481\n",
      "fold_3, epoch_639, Loss: 0.3509\n",
      "fold_3, epoch_640, Loss: 0.3514\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3529\n",
      "Accuracy:\t0.9601\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9798\n",
      "Recall:\t\t0.9396\n",
      "F1:\t\t\t0.9593\n",
      "\n",
      "fold_3, epoch_641, Loss: 0.3512\n",
      "fold_3, epoch_642, Loss: 0.3498\n",
      "fold_3, epoch_643, Loss: 0.3504\n",
      "fold_3, epoch_644, Loss: 0.3500\n",
      "fold_3, epoch_645, Loss: 0.3478\n",
      "fold_3, epoch_646, Loss: 0.3507\n",
      "fold_3, epoch_647, Loss: 0.3511\n",
      "fold_3, epoch_648, Loss: 0.3497\n",
      "fold_3, epoch_649, Loss: 0.3491\n",
      "fold_3, epoch_650, Loss: 0.3481\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3486\n",
      "Accuracy:\t0.9646\n",
      "AUC:\t\t0.9645\n",
      "Precision:\t0.9876\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9634\n",
      "\n",
      "fold_3, epoch_651, Loss: 0.3517\n",
      "fold_3, epoch_652, Loss: 0.3504\n",
      "fold_3, epoch_653, Loss: 0.3469\n",
      "fold_3, epoch_654, Loss: 0.3480\n",
      "fold_3, epoch_655, Loss: 0.3490\n",
      "fold_3, epoch_656, Loss: 0.3474\n",
      "fold_3, epoch_657, Loss: 0.3513\n",
      "fold_3, epoch_658, Loss: 0.3511\n",
      "fold_3, epoch_659, Loss: 0.3484\n",
      "fold_3, epoch_660, Loss: 0.3512\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9653\n",
      "AUC:\t\t0.9646\n",
      "Precision:\t0.9837\n",
      "Recall:\t\t0.9463\n",
      "F1:\t\t\t0.9646\n",
      "\n",
      "fold_3, epoch_661, Loss: 0.3491\n",
      "fold_3, epoch_662, Loss: 0.3501\n",
      "fold_3, epoch_663, Loss: 0.3501\n",
      "fold_3, epoch_664, Loss: 0.3492\n",
      "fold_3, epoch_665, Loss: 0.3494\n",
      "fold_3, epoch_666, Loss: 0.3502\n",
      "fold_3, epoch_667, Loss: 0.3485\n",
      "fold_3, epoch_668, Loss: 0.3492\n",
      "fold_3, epoch_669, Loss: 0.3488\n",
      "fold_3, epoch_670, Loss: 0.3491\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9653\n",
      "AUC:\t\t0.9633\n",
      "Precision:\t0.9872\n",
      "Recall:\t\t0.9426\n",
      "F1:\t\t\t0.9644\n",
      "\n",
      "fold_3, epoch_671, Loss: 0.3488\n",
      "fold_3, epoch_672, Loss: 0.3499\n",
      "fold_3, epoch_673, Loss: 0.3499\n",
      "fold_3, epoch_674, Loss: 0.3481\n",
      "fold_3, epoch_675, Loss: 0.3510\n",
      "fold_3, epoch_676, Loss: 0.3489\n",
      "fold_3, epoch_677, Loss: 0.3501\n",
      "fold_3, epoch_678, Loss: 0.3495\n",
      "fold_3, epoch_679, Loss: 0.3489\n",
      "fold_3, epoch_680, Loss: 0.3516\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3479\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9629\n",
      "Precision:\t0.9863\n",
      "Recall:\t\t0.9441\n",
      "F1:\t\t\t0.9648\n",
      "\n",
      "fold_3, epoch_681, Loss: 0.3488\n",
      "fold_3, epoch_682, Loss: 0.3486\n",
      "fold_3, epoch_683, Loss: 0.3521\n",
      "fold_3, epoch_684, Loss: 0.3489\n",
      "fold_3, epoch_685, Loss: 0.3508\n",
      "fold_3, epoch_686, Loss: 0.3491\n",
      "fold_3, epoch_687, Loss: 0.3484\n",
      "fold_3, epoch_688, Loss: 0.3510\n",
      "fold_3, epoch_689, Loss: 0.3458\n",
      "fold_3, epoch_690, Loss: 0.3514\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3482\n",
      "Accuracy:\t0.9649\n",
      "AUC:\t\t0.9637\n",
      "Precision:\t0.9859\n",
      "Recall:\t\t0.9429\n",
      "F1:\t\t\t0.9639\n",
      "\n",
      "fold_3, epoch_691, Loss: 0.3498\n",
      "fold_3, epoch_692, Loss: 0.3503\n",
      "fold_3, epoch_693, Loss: 0.3474\n",
      "fold_3, epoch_694, Loss: 0.3488\n",
      "fold_3, epoch_695, Loss: 0.3522\n",
      "fold_3, epoch_696, Loss: 0.3515\n",
      "fold_3, epoch_697, Loss: 0.3497\n",
      "fold_3, epoch_698, Loss: 0.3486\n",
      "fold_3, epoch_699, Loss: 0.3497\n",
      "fold_3, epoch_700, Loss: 0.3497\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3475\n",
      "Accuracy:\t0.9657\n",
      "AUC:\t\t0.9643\n",
      "Precision:\t0.9860\n",
      "Recall:\t\t0.9451\n",
      "F1:\t\t\t0.9651\n",
      "\n",
      "fold_3, epoch_701, Loss: 0.3481\n",
      "fold_3, epoch_702, Loss: 0.3499\n",
      "fold_3, epoch_703, Loss: 0.3502\n",
      "fold_3, epoch_704, Loss: 0.3500\n",
      "fold_3, epoch_705, Loss: 0.3473\n",
      "fold_3, epoch_706, Loss: 0.3507\n",
      "fold_3, epoch_707, Loss: 0.3476\n",
      "fold_3, epoch_708, Loss: 0.3489\n",
      "fold_3, epoch_709, Loss: 0.3476\n",
      "fold_3, epoch_710, Loss: 0.3484\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3488\n",
      "Accuracy:\t0.9645\n",
      "AUC:\t\t0.9659\n",
      "Precision:\t0.9875\n",
      "Recall:\t\t0.9415\n",
      "F1:\t\t\t0.9639\n",
      "\n",
      "fold_3, epoch_711, Loss: 0.3512\n",
      "fold_3, epoch_712, Loss: 0.3491\n",
      "fold_3, epoch_713, Loss: 0.3473\n",
      "fold_3, epoch_714, Loss: 0.3478\n",
      "fold_3, epoch_715, Loss: 0.3501\n",
      "fold_3, epoch_716, Loss: 0.3507\n",
      "fold_3, epoch_717, Loss: 0.3506\n",
      "fold_3, epoch_718, Loss: 0.3569\n",
      "fold_3, epoch_719, Loss: 0.3511\n",
      "fold_3, epoch_720, Loss: 0.3491\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3507\n",
      "Accuracy:\t0.9622\n",
      "AUC:\t\t0.9632\n",
      "Precision:\t0.9838\n",
      "Recall:\t\t0.9404\n",
      "F1:\t\t\t0.9616\n",
      "\n",
      "fold_3, epoch_721, Loss: 0.3487\n",
      "fold_3, epoch_722, Loss: 0.3513\n",
      "fold_3, epoch_723, Loss: 0.3533\n",
      "fold_3, epoch_724, Loss: 0.3502\n",
      "fold_3, epoch_725, Loss: 0.3501\n",
      "fold_3, epoch_726, Loss: 0.3473\n",
      "fold_3, epoch_727, Loss: 0.3502\n",
      "fold_3, epoch_728, Loss: 0.3477\n",
      "fold_3, epoch_729, Loss: 0.3502\n",
      "fold_3, epoch_730, Loss: 0.3509\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3541\n",
      "Accuracy:\t0.9590\n",
      "AUC:\t\t0.9615\n",
      "Precision:\t0.9809\n",
      "Recall:\t\t0.9367\n",
      "F1:\t\t\t0.9583\n",
      "\n",
      "fold_3, epoch_731, Loss: 0.3496\n",
      "fold_3, epoch_732, Loss: 0.3488\n",
      "fold_3, epoch_733, Loss: 0.3509\n",
      "fold_3, epoch_734, Loss: 0.3490\n",
      "fold_3, epoch_735, Loss: 0.3494\n",
      "fold_3, epoch_736, Loss: 0.3517\n",
      "fold_3, epoch_737, Loss: 0.3487\n",
      "fold_3, epoch_738, Loss: 0.3461\n",
      "fold_3, epoch_739, Loss: 0.3490\n",
      "fold_3, epoch_740, Loss: 0.3485\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3484\n",
      "Accuracy:\t0.9647\n",
      "AUC:\t\t0.9634\n",
      "Precision:\t0.9859\n",
      "Recall:\t\t0.9424\n",
      "F1:\t\t\t0.9637\n",
      "\n",
      "fold_3, epoch_741, Loss: 0.3473\n",
      "fold_3, epoch_742, Loss: 0.3487\n",
      "fold_3, epoch_743, Loss: 0.3485\n",
      "fold_3, epoch_744, Loss: 0.3503\n",
      "fold_3, epoch_745, Loss: 0.3497\n",
      "fold_3, epoch_746, Loss: 0.3495\n",
      "fold_3, epoch_747, Loss: 0.3476\n",
      "fold_3, epoch_748, Loss: 0.3487\n",
      "fold_3, epoch_749, Loss: 0.3465\n",
      "fold_3, epoch_750, Loss: 0.3491\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3456\n",
      "Accuracy:\t0.9675\n",
      "AUC:\t\t0.9667\n",
      "Precision:\t0.9868\n",
      "Recall:\t\t0.9476\n",
      "F1:\t\t\t0.9668\n",
      "\n",
      "fold_3, epoch_751, Loss: 0.3500\n",
      "fold_3, epoch_752, Loss: 0.3456\n",
      "fold_3, epoch_753, Loss: 0.3496\n",
      "fold_3, epoch_754, Loss: 0.3505\n",
      "fold_3, epoch_755, Loss: 0.3480\n",
      "fold_3, epoch_756, Loss: 0.3470\n",
      "fold_3, epoch_757, Loss: 0.3510\n",
      "fold_3, epoch_758, Loss: 0.3486\n",
      "fold_3, epoch_759, Loss: 0.3483\n",
      "fold_3, epoch_760, Loss: 0.3492\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3488\n",
      "Accuracy:\t0.9644\n",
      "AUC:\t\t0.9636\n",
      "Precision:\t0.9883\n",
      "Recall:\t\t0.9395\n",
      "F1:\t\t\t0.9633\n",
      "\n",
      "fold_3, epoch_761, Loss: 0.3463\n",
      "fold_3, epoch_762, Loss: 0.3486\n",
      "fold_3, epoch_763, Loss: 0.3500\n",
      "fold_3, epoch_764, Loss: 0.3493\n",
      "fold_3, epoch_765, Loss: 0.3476\n",
      "fold_3, epoch_766, Loss: 0.3490\n",
      "fold_3, epoch_767, Loss: 0.3502\n",
      "fold_3, epoch_768, Loss: 0.3482\n",
      "fold_3, epoch_769, Loss: 0.3473\n",
      "fold_3, epoch_770, Loss: 0.3452\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3475\n",
      "Accuracy:\t0.9655\n",
      "AUC:\t\t0.9647\n",
      "Precision:\t0.9853\n",
      "Recall:\t\t0.9452\n",
      "F1:\t\t\t0.9649\n",
      "\n",
      "fold_3, epoch_771, Loss: 0.3486\n",
      "fold_3, epoch_772, Loss: 0.3494\n",
      "fold_3, epoch_773, Loss: 0.3492\n",
      "fold_3, epoch_774, Loss: 0.3487\n",
      "fold_3, epoch_775, Loss: 0.3479\n",
      "fold_3, epoch_776, Loss: 0.3482\n",
      "fold_3, epoch_777, Loss: 0.3474\n",
      "fold_3, epoch_778, Loss: 0.3473\n",
      "fold_3, epoch_779, Loss: 0.3489\n",
      "fold_3, epoch_780, Loss: 0.3507\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3501\n",
      "Accuracy:\t0.9632\n",
      "AUC:\t\t0.9637\n",
      "Precision:\t0.9870\n",
      "Recall:\t\t0.9389\n",
      "F1:\t\t\t0.9624\n",
      "\n",
      "fold_3, epoch_781, Loss: 0.3472\n",
      "fold_3, epoch_782, Loss: 0.3466\n",
      "fold_3, epoch_783, Loss: 0.3475\n",
      "fold_3, epoch_784, Loss: 0.3499\n",
      "fold_3, epoch_785, Loss: 0.3484\n",
      "fold_3, epoch_786, Loss: 0.3488\n",
      "fold_3, epoch_787, Loss: 0.3495\n",
      "fold_3, epoch_788, Loss: 0.3483\n",
      "fold_3, epoch_789, Loss: 0.3487\n",
      "fold_3, epoch_790, Loss: 0.3491\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3495\n",
      "Accuracy:\t0.9636\n",
      "AUC:\t\t0.9636\n",
      "Precision:\t0.9850\n",
      "Recall:\t\t0.9419\n",
      "F1:\t\t\t0.9630\n",
      "\n",
      "fold_3, epoch_791, Loss: 0.3503\n",
      "fold_3, epoch_792, Loss: 0.3485\n",
      "fold_3, epoch_793, Loss: 0.3486\n",
      "fold_3, epoch_794, Loss: 0.3472\n",
      "fold_3, epoch_795, Loss: 0.3465\n",
      "fold_3, epoch_796, Loss: 0.3500\n",
      "fold_3, epoch_797, Loss: 0.3479\n",
      "fold_3, epoch_798, Loss: 0.3490\n",
      "fold_3, epoch_799, Loss: 0.3486\n",
      "fold_3, epoch_800, Loss: 0.3468\n",
      "\n",
      "fold_3 performance on test data:\n",
      "Loss:\t\t0.3493\n",
      "Accuracy:\t0.9639\n",
      "AUC:\t\t0.9653\n",
      "Precision:\t0.9871\n",
      "Recall:\t\t0.9392\n",
      "F1:\t\t\t0.9626\n",
      "\n",
      "Training model.\n",
      "Checkpoints will be saved in:\n",
      "/home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/checkpoints/fold_4\n",
      "\n",
      "Tensorboard logs will be saved in:\n",
      " /home/devspace/project/data/cv_assessments/2023-06-17_00_25_30.796533/tensorboard\n",
      "\n",
      "\n",
      "fold_4, epoch_1, Loss: 0.5906\n",
      "fold_4, epoch_2, Loss: 0.5467\n",
      "fold_4, epoch_3, Loss: 0.5396\n",
      "fold_4, epoch_4, Loss: 0.7601\n",
      "fold_4, epoch_5, Loss: 0.8131\n",
      "fold_4, epoch_6, Loss: 0.6084\n",
      "fold_4, epoch_7, Loss: 0.5687\n",
      "fold_4, epoch_8, Loss: 0.5626\n",
      "fold_4, epoch_9, Loss: 0.5617\n",
      "fold_4, epoch_10, Loss: 0.5624\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.5607\n",
      "Accuracy:\t0.7388\n",
      "AUC:\t\t0.8141\n",
      "Precision:\t0.7912\n",
      "Recall:\t\t0.6418\n",
      "F1:\t\t\t0.7087\n",
      "\n",
      "fold_4, epoch_11, Loss: 0.5578\n",
      "fold_4, epoch_12, Loss: 0.5541\n",
      "fold_4, epoch_13, Loss: 0.5547\n",
      "fold_4, epoch_14, Loss: 0.5462\n",
      "fold_4, epoch_15, Loss: 0.5456\n",
      "fold_4, epoch_16, Loss: 0.5422\n",
      "fold_4, epoch_17, Loss: 0.5377\n",
      "fold_4, epoch_18, Loss: 0.5317\n",
      "fold_4, epoch_19, Loss: 0.5288\n",
      "fold_4, epoch_20, Loss: 0.5203\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.5187\n",
      "Accuracy:\t0.7804\n",
      "AUC:\t\t0.8632\n",
      "Precision:\t0.7930\n",
      "Recall:\t\t0.7640\n",
      "F1:\t\t\t0.7782\n",
      "\n",
      "fold_4, epoch_21, Loss: 0.5202\n",
      "fold_4, epoch_22, Loss: 0.5155\n",
      "fold_4, epoch_23, Loss: 0.5172\n",
      "fold_4, epoch_24, Loss: 0.5145\n",
      "fold_4, epoch_25, Loss: 0.5095\n",
      "fold_4, epoch_26, Loss: 0.5090\n",
      "fold_4, epoch_27, Loss: 0.5091\n",
      "fold_4, epoch_28, Loss: 0.5040\n",
      "fold_4, epoch_29, Loss: 0.5019\n",
      "fold_4, epoch_30, Loss: 0.4958\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4952\n",
      "Accuracy:\t0.8121\n",
      "AUC:\t\t0.8811\n",
      "Precision:\t0.8185\n",
      "Recall:\t\t0.8044\n",
      "F1:\t\t\t0.8114\n",
      "\n",
      "fold_4, epoch_31, Loss: 0.4921\n",
      "fold_4, epoch_32, Loss: 0.4920\n",
      "fold_4, epoch_33, Loss: 0.4915\n",
      "fold_4, epoch_34, Loss: 0.4878\n",
      "fold_4, epoch_35, Loss: 0.4840\n",
      "fold_4, epoch_36, Loss: 0.4814\n",
      "fold_4, epoch_37, Loss: 0.4789\n",
      "fold_4, epoch_38, Loss: 0.4771\n",
      "fold_4, epoch_39, Loss: 0.4791\n",
      "fold_4, epoch_40, Loss: 0.4739\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4724\n",
      "Accuracy:\t0.8367\n",
      "AUC:\t\t0.8905\n",
      "Precision:\t0.8252\n",
      "Recall:\t\t0.8538\n",
      "F1:\t\t\t0.8392\n",
      "\n",
      "fold_4, epoch_41, Loss: 0.4725\n",
      "fold_4, epoch_42, Loss: 0.4732\n",
      "fold_4, epoch_43, Loss: 0.4702\n",
      "fold_4, epoch_44, Loss: 0.4678\n",
      "fold_4, epoch_45, Loss: 0.4682\n",
      "fold_4, epoch_46, Loss: 0.4674\n",
      "fold_4, epoch_47, Loss: 0.4636\n",
      "fold_4, epoch_48, Loss: 0.4601\n",
      "fold_4, epoch_49, Loss: 0.4629\n",
      "fold_4, epoch_50, Loss: 0.4609\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4512\n",
      "Accuracy:\t0.8606\n",
      "AUC:\t\t0.8983\n",
      "Precision:\t0.8437\n",
      "Recall:\t\t0.8840\n",
      "F1:\t\t\t0.8634\n",
      "\n",
      "fold_4, epoch_51, Loss: 0.4532\n",
      "fold_4, epoch_52, Loss: 0.4566\n",
      "fold_4, epoch_53, Loss: 0.4546\n",
      "fold_4, epoch_54, Loss: 0.4540\n",
      "fold_4, epoch_55, Loss: 0.4556\n",
      "fold_4, epoch_56, Loss: 0.4537\n",
      "fold_4, epoch_57, Loss: 0.4530\n",
      "fold_4, epoch_58, Loss: 0.4530\n",
      "fold_4, epoch_59, Loss: 0.4480\n",
      "fold_4, epoch_60, Loss: 0.4470\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4440\n",
      "Accuracy:\t0.8678\n",
      "AUC:\t\t0.9017\n",
      "Precision:\t0.8508\n",
      "Recall:\t\t0.8908\n",
      "F1:\t\t\t0.8704\n",
      "\n",
      "fold_4, epoch_61, Loss: 0.4462\n",
      "fold_4, epoch_62, Loss: 0.4462\n",
      "fold_4, epoch_63, Loss: 0.4425\n",
      "fold_4, epoch_64, Loss: 0.4409\n",
      "fold_4, epoch_65, Loss: 0.4403\n",
      "fold_4, epoch_66, Loss: 0.4435\n",
      "fold_4, epoch_67, Loss: 0.4444\n",
      "fold_4, epoch_68, Loss: 0.4383\n",
      "fold_4, epoch_69, Loss: 0.4357\n",
      "fold_4, epoch_70, Loss: 0.4404\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4312\n",
      "Accuracy:\t0.8814\n",
      "AUC:\t\t0.9072\n",
      "Precision:\t0.8824\n",
      "Recall:\t\t0.8829\n",
      "F1:\t\t\t0.8826\n",
      "\n",
      "fold_4, epoch_71, Loss: 0.4346\n",
      "fold_4, epoch_72, Loss: 0.4377\n",
      "fold_4, epoch_73, Loss: 0.4380\n",
      "fold_4, epoch_74, Loss: 0.4370\n",
      "fold_4, epoch_75, Loss: 0.4334\n",
      "fold_4, epoch_76, Loss: 0.4342\n",
      "fold_4, epoch_77, Loss: 0.4304\n",
      "fold_4, epoch_78, Loss: 0.4290\n",
      "fold_4, epoch_79, Loss: 0.4261\n",
      "fold_4, epoch_80, Loss: 0.4370\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4350\n",
      "Accuracy:\t0.8760\n",
      "AUC:\t\t0.9065\n",
      "Precision:\t0.8780\n",
      "Recall:\t\t0.8722\n",
      "F1:\t\t\t0.8751\n",
      "\n",
      "fold_4, epoch_81, Loss: 0.4281\n",
      "fold_4, epoch_82, Loss: 0.4296\n",
      "fold_4, epoch_83, Loss: 0.4254\n",
      "fold_4, epoch_84, Loss: 0.4276\n",
      "fold_4, epoch_85, Loss: 0.4252\n",
      "fold_4, epoch_86, Loss: 0.4246\n",
      "fold_4, epoch_87, Loss: 0.4284\n",
      "fold_4, epoch_88, Loss: 0.4258\n",
      "fold_4, epoch_89, Loss: 0.4240\n",
      "fold_4, epoch_90, Loss: 0.4204\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4233\n",
      "Accuracy:\t0.8891\n",
      "AUC:\t\t0.9098\n",
      "Precision:\t0.8776\n",
      "Recall:\t\t0.9006\n",
      "F1:\t\t\t0.8890\n",
      "\n",
      "fold_4, epoch_91, Loss: 0.4272\n",
      "fold_4, epoch_92, Loss: 0.4233\n",
      "fold_4, epoch_93, Loss: 0.4212\n",
      "fold_4, epoch_94, Loss: 0.4289\n",
      "fold_4, epoch_95, Loss: 0.4219\n",
      "fold_4, epoch_96, Loss: 0.4182\n",
      "fold_4, epoch_97, Loss: 0.4148\n",
      "fold_4, epoch_98, Loss: 0.4170\n",
      "fold_4, epoch_99, Loss: 0.4190\n",
      "fold_4, epoch_100, Loss: 0.4215\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4169\n",
      "Accuracy:\t0.8946\n",
      "AUC:\t\t0.9149\n",
      "Precision:\t0.8886\n",
      "Recall:\t\t0.9036\n",
      "F1:\t\t\t0.8960\n",
      "\n",
      "fold_4, epoch_101, Loss: 0.4162\n",
      "fold_4, epoch_102, Loss: 0.4246\n",
      "fold_4, epoch_103, Loss: 0.4186\n",
      "fold_4, epoch_104, Loss: 0.4155\n",
      "fold_4, epoch_105, Loss: 0.4131\n",
      "fold_4, epoch_106, Loss: 0.4135\n",
      "fold_4, epoch_107, Loss: 0.4188\n",
      "fold_4, epoch_108, Loss: 0.4128\n",
      "fold_4, epoch_109, Loss: 0.4109\n",
      "fold_4, epoch_110, Loss: 0.4131\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4146\n",
      "Accuracy:\t0.8977\n",
      "AUC:\t\t0.9149\n",
      "Precision:\t0.8814\n",
      "Recall:\t\t0.9179\n",
      "F1:\t\t\t0.8993\n",
      "\n",
      "fold_4, epoch_111, Loss: 0.4121\n",
      "fold_4, epoch_112, Loss: 0.4129\n",
      "fold_4, epoch_113, Loss: 0.4099\n",
      "fold_4, epoch_114, Loss: 0.4139\n",
      "fold_4, epoch_115, Loss: 0.4088\n",
      "fold_4, epoch_116, Loss: 0.4190\n",
      "fold_4, epoch_117, Loss: 0.4087\n",
      "fold_4, epoch_118, Loss: 0.4067\n",
      "fold_4, epoch_119, Loss: 0.4090\n",
      "fold_4, epoch_120, Loss: 0.4131\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4074\n",
      "Accuracy:\t0.9054\n",
      "AUC:\t\t0.9207\n",
      "Precision:\t0.9095\n",
      "Recall:\t\t0.9017\n",
      "F1:\t\t\t0.9056\n",
      "\n",
      "fold_4, epoch_121, Loss: 0.4076\n",
      "fold_4, epoch_122, Loss: 0.4106\n",
      "fold_4, epoch_123, Loss: 0.4082\n",
      "fold_4, epoch_124, Loss: 0.4084\n",
      "fold_4, epoch_125, Loss: 0.4081\n",
      "fold_4, epoch_126, Loss: 0.4066\n",
      "fold_4, epoch_127, Loss: 0.4042\n",
      "fold_4, epoch_128, Loss: 0.4049\n",
      "fold_4, epoch_129, Loss: 0.4013\n",
      "fold_4, epoch_130, Loss: 0.4047\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4007\n",
      "Accuracy:\t0.9125\n",
      "AUC:\t\t0.9202\n",
      "Precision:\t0.9112\n",
      "Recall:\t\t0.9134\n",
      "F1:\t\t\t0.9123\n",
      "\n",
      "fold_4, epoch_131, Loss: 0.4057\n",
      "fold_4, epoch_132, Loss: 0.4040\n",
      "fold_4, epoch_133, Loss: 0.4095\n",
      "fold_4, epoch_134, Loss: 0.4049\n",
      "fold_4, epoch_135, Loss: 0.4032\n",
      "fold_4, epoch_136, Loss: 0.4056\n",
      "fold_4, epoch_137, Loss: 0.4032\n",
      "fold_4, epoch_138, Loss: 0.4056\n",
      "fold_4, epoch_139, Loss: 0.4022\n",
      "fold_4, epoch_140, Loss: 0.4013\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3986\n",
      "Accuracy:\t0.9144\n",
      "AUC:\t\t0.9239\n",
      "Precision:\t0.9187\n",
      "Recall:\t\t0.9087\n",
      "F1:\t\t\t0.9136\n",
      "\n",
      "fold_4, epoch_141, Loss: 0.4064\n",
      "fold_4, epoch_142, Loss: 0.4039\n",
      "fold_4, epoch_143, Loss: 0.4010\n",
      "fold_4, epoch_144, Loss: 0.4056\n",
      "fold_4, epoch_145, Loss: 0.3993\n",
      "fold_4, epoch_146, Loss: 0.3978\n",
      "fold_4, epoch_147, Loss: 0.3995\n",
      "fold_4, epoch_148, Loss: 0.3987\n",
      "fold_4, epoch_149, Loss: 0.4061\n",
      "fold_4, epoch_150, Loss: 0.3954\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3954\n",
      "Accuracy:\t0.9175\n",
      "AUC:\t\t0.9250\n",
      "Precision:\t0.9141\n",
      "Recall:\t\t0.9227\n",
      "F1:\t\t\t0.9184\n",
      "\n",
      "fold_4, epoch_151, Loss: 0.3992\n",
      "fold_4, epoch_152, Loss: 0.4020\n",
      "fold_4, epoch_153, Loss: 0.4110\n",
      "fold_4, epoch_154, Loss: 0.4014\n",
      "fold_4, epoch_155, Loss: 0.4023\n",
      "fold_4, epoch_156, Loss: 0.3976\n",
      "fold_4, epoch_157, Loss: 0.3985\n",
      "fold_4, epoch_158, Loss: 0.3952\n",
      "fold_4, epoch_159, Loss: 0.3970\n",
      "fold_4, epoch_160, Loss: 0.4214\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4130\n",
      "Accuracy:\t0.8997\n",
      "AUC:\t\t0.9181\n",
      "Precision:\t0.9018\n",
      "Recall:\t\t0.8979\n",
      "F1:\t\t\t0.8999\n",
      "\n",
      "fold_4, epoch_161, Loss: 0.4083\n",
      "fold_4, epoch_162, Loss: 0.3999\n",
      "fold_4, epoch_163, Loss: 0.3957\n",
      "fold_4, epoch_164, Loss: 0.4003\n",
      "fold_4, epoch_165, Loss: 0.3925\n",
      "fold_4, epoch_166, Loss: 0.3986\n",
      "fold_4, epoch_167, Loss: 0.3977\n",
      "fold_4, epoch_168, Loss: 0.3962\n",
      "fold_4, epoch_169, Loss: 0.3955\n",
      "fold_4, epoch_170, Loss: 0.3965\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.4074\n",
      "Accuracy:\t0.9044\n",
      "AUC:\t\t0.9221\n",
      "Precision:\t0.8888\n",
      "Recall:\t\t0.9237\n",
      "F1:\t\t\t0.9059\n",
      "\n",
      "fold_4, epoch_171, Loss: 0.3966\n",
      "fold_4, epoch_172, Loss: 0.3937\n",
      "fold_4, epoch_173, Loss: 0.3991\n",
      "fold_4, epoch_174, Loss: 0.3973\n",
      "fold_4, epoch_175, Loss: 0.3986\n",
      "fold_4, epoch_176, Loss: 0.3961\n",
      "fold_4, epoch_177, Loss: 0.3985\n",
      "fold_4, epoch_178, Loss: 0.3946\n",
      "fold_4, epoch_179, Loss: 0.3941\n",
      "fold_4, epoch_180, Loss: 0.3983\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3922\n",
      "Accuracy:\t0.9207\n",
      "AUC:\t\t0.9294\n",
      "Precision:\t0.9296\n",
      "Recall:\t\t0.9094\n",
      "F1:\t\t\t0.9194\n",
      "\n",
      "fold_4, epoch_181, Loss: 0.3955\n",
      "fold_4, epoch_182, Loss: 0.3911\n",
      "fold_4, epoch_183, Loss: 0.3908\n",
      "fold_4, epoch_184, Loss: 0.3988\n",
      "fold_4, epoch_185, Loss: 0.3954\n",
      "fold_4, epoch_186, Loss: 0.3938\n",
      "fold_4, epoch_187, Loss: 0.4001\n",
      "fold_4, epoch_188, Loss: 0.3925\n",
      "fold_4, epoch_189, Loss: 0.3916\n",
      "fold_4, epoch_190, Loss: 0.3915\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3836\n",
      "Accuracy:\t0.9297\n",
      "AUC:\t\t0.9332\n",
      "Precision:\t0.9344\n",
      "Recall:\t\t0.9244\n",
      "F1:\t\t\t0.9294\n",
      "\n",
      "fold_4, epoch_191, Loss: 0.3887\n",
      "fold_4, epoch_192, Loss: 0.3943\n",
      "fold_4, epoch_193, Loss: 0.3934\n",
      "fold_4, epoch_194, Loss: 0.3901\n",
      "fold_4, epoch_195, Loss: 0.4009\n",
      "fold_4, epoch_196, Loss: 0.3922\n",
      "fold_4, epoch_197, Loss: 0.3904\n",
      "fold_4, epoch_198, Loss: 0.3889\n",
      "fold_4, epoch_199, Loss: 0.3935\n",
      "fold_4, epoch_200, Loss: 0.3878\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3896\n",
      "Accuracy:\t0.9231\n",
      "AUC:\t\t0.9325\n",
      "Precision:\t0.9247\n",
      "Recall:\t\t0.9191\n",
      "F1:\t\t\t0.9219\n",
      "\n",
      "fold_4, epoch_201, Loss: 0.3922\n",
      "fold_4, epoch_202, Loss: 0.3836\n",
      "fold_4, epoch_203, Loss: 0.3895\n",
      "fold_4, epoch_204, Loss: 0.3920\n",
      "fold_4, epoch_205, Loss: 0.3880\n",
      "fold_4, epoch_206, Loss: 0.3898\n",
      "fold_4, epoch_207, Loss: 0.3885\n",
      "fold_4, epoch_208, Loss: 0.3918\n",
      "fold_4, epoch_209, Loss: 0.3911\n",
      "fold_4, epoch_210, Loss: 0.3918\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3949\n",
      "Accuracy:\t0.9174\n",
      "AUC:\t\t0.9313\n",
      "Precision:\t0.9080\n",
      "Recall:\t\t0.9282\n",
      "F1:\t\t\t0.9180\n",
      "\n",
      "fold_4, epoch_211, Loss: 0.3928\n",
      "fold_4, epoch_212, Loss: 0.3889\n",
      "fold_4, epoch_213, Loss: 0.3842\n",
      "fold_4, epoch_214, Loss: 0.3840\n",
      "fold_4, epoch_215, Loss: 0.3889\n",
      "fold_4, epoch_216, Loss: 0.3854\n",
      "fold_4, epoch_217, Loss: 0.3898\n",
      "fold_4, epoch_218, Loss: 0.3874\n",
      "fold_4, epoch_219, Loss: 0.3938\n",
      "fold_4, epoch_220, Loss: 0.3866\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3857\n",
      "Accuracy:\t0.9268\n",
      "AUC:\t\t0.9333\n",
      "Precision:\t0.9308\n",
      "Recall:\t\t0.9221\n",
      "F1:\t\t\t0.9264\n",
      "\n",
      "fold_4, epoch_221, Loss: 0.3893\n",
      "fold_4, epoch_222, Loss: 0.3881\n",
      "fold_4, epoch_223, Loss: 0.3863\n",
      "fold_4, epoch_224, Loss: 0.3856\n",
      "fold_4, epoch_225, Loss: 0.3878\n",
      "fold_4, epoch_226, Loss: 0.3853\n",
      "fold_4, epoch_227, Loss: 0.3874\n",
      "fold_4, epoch_228, Loss: 0.3908\n",
      "fold_4, epoch_229, Loss: 0.3873\n",
      "fold_4, epoch_230, Loss: 0.3831\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3869\n",
      "Accuracy:\t0.9252\n",
      "AUC:\t\t0.9326\n",
      "Precision:\t0.9337\n",
      "Recall:\t\t0.9160\n",
      "F1:\t\t\t0.9248\n",
      "\n",
      "fold_4, epoch_231, Loss: 0.3882\n",
      "fold_4, epoch_232, Loss: 0.3845\n",
      "fold_4, epoch_233, Loss: 0.3814\n",
      "fold_4, epoch_234, Loss: 0.3866\n",
      "fold_4, epoch_235, Loss: 0.3806\n",
      "fold_4, epoch_236, Loss: 0.3868\n",
      "fold_4, epoch_237, Loss: 0.3838\n",
      "fold_4, epoch_238, Loss: 0.3830\n",
      "fold_4, epoch_239, Loss: 0.3855\n",
      "fold_4, epoch_240, Loss: 0.3833\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3901\n",
      "Accuracy:\t0.9220\n",
      "AUC:\t\t0.9342\n",
      "Precision:\t0.9344\n",
      "Recall:\t\t0.9080\n",
      "F1:\t\t\t0.9210\n",
      "\n",
      "fold_4, epoch_241, Loss: 0.3829\n",
      "fold_4, epoch_242, Loss: 0.3868\n",
      "fold_4, epoch_243, Loss: 0.3850\n",
      "fold_4, epoch_244, Loss: 0.3826\n",
      "fold_4, epoch_245, Loss: 0.3909\n",
      "fold_4, epoch_246, Loss: 0.3838\n",
      "fold_4, epoch_247, Loss: 0.3848\n",
      "fold_4, epoch_248, Loss: 0.3861\n",
      "fold_4, epoch_249, Loss: 0.3838\n",
      "fold_4, epoch_250, Loss: 0.3845\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3805\n",
      "Accuracy:\t0.9324\n",
      "AUC:\t\t0.9371\n",
      "Precision:\t0.9384\n",
      "Recall:\t\t0.9266\n",
      "F1:\t\t\t0.9325\n",
      "\n",
      "fold_4, epoch_251, Loss: 0.3811\n",
      "fold_4, epoch_252, Loss: 0.3802\n",
      "fold_4, epoch_253, Loss: 0.3791\n",
      "fold_4, epoch_254, Loss: 0.3825\n",
      "fold_4, epoch_255, Loss: 0.3844\n",
      "fold_4, epoch_256, Loss: 0.3828\n",
      "fold_4, epoch_257, Loss: 0.3801\n",
      "fold_4, epoch_258, Loss: 0.3838\n",
      "fold_4, epoch_259, Loss: 0.3797\n",
      "fold_4, epoch_260, Loss: 0.3816\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3795\n",
      "Accuracy:\t0.9338\n",
      "AUC:\t\t0.9375\n",
      "Precision:\t0.9422\n",
      "Recall:\t\t0.9243\n",
      "F1:\t\t\t0.9332\n",
      "\n",
      "fold_4, epoch_261, Loss: 0.3843\n",
      "fold_4, epoch_262, Loss: 0.3818\n",
      "fold_4, epoch_263, Loss: 0.3846\n",
      "fold_4, epoch_264, Loss: 0.3817\n",
      "fold_4, epoch_265, Loss: 0.3821\n",
      "fold_4, epoch_266, Loss: 0.3788\n",
      "fold_4, epoch_267, Loss: 0.3827\n",
      "fold_4, epoch_268, Loss: 0.3787\n",
      "fold_4, epoch_269, Loss: 0.3806\n",
      "fold_4, epoch_270, Loss: 0.3855\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3771\n",
      "Accuracy:\t0.9357\n",
      "AUC:\t\t0.9427\n",
      "Precision:\t0.9396\n",
      "Recall:\t\t0.9316\n",
      "F1:\t\t\t0.9356\n",
      "\n",
      "fold_4, epoch_271, Loss: 0.3762\n",
      "fold_4, epoch_272, Loss: 0.3800\n",
      "fold_4, epoch_273, Loss: 0.3782\n",
      "fold_4, epoch_274, Loss: 0.3818\n",
      "fold_4, epoch_275, Loss: 0.3826\n",
      "fold_4, epoch_276, Loss: 0.3780\n",
      "fold_4, epoch_277, Loss: 0.3801\n",
      "fold_4, epoch_278, Loss: 0.3802\n",
      "fold_4, epoch_279, Loss: 0.3793\n",
      "fold_4, epoch_280, Loss: 0.3766\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3819\n",
      "Accuracy:\t0.9312\n",
      "AUC:\t\t0.9372\n",
      "Precision:\t0.9417\n",
      "Recall:\t\t0.9187\n",
      "F1:\t\t\t0.9301\n",
      "\n",
      "fold_4, epoch_281, Loss: 0.3817\n",
      "fold_4, epoch_282, Loss: 0.3792\n",
      "fold_4, epoch_283, Loss: 0.3790\n",
      "fold_4, epoch_284, Loss: 0.3772\n",
      "fold_4, epoch_285, Loss: 0.3805\n",
      "fold_4, epoch_286, Loss: 0.3816\n",
      "fold_4, epoch_287, Loss: 0.3784\n",
      "fold_4, epoch_288, Loss: 0.3814\n",
      "fold_4, epoch_289, Loss: 0.3785\n",
      "fold_4, epoch_290, Loss: 0.3797\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3871\n",
      "Accuracy:\t0.9261\n",
      "AUC:\t\t0.9350\n",
      "Precision:\t0.9402\n",
      "Recall:\t\t0.9111\n",
      "F1:\t\t\t0.9254\n",
      "\n",
      "fold_4, epoch_291, Loss: 0.3817\n",
      "fold_4, epoch_292, Loss: 0.3770\n",
      "fold_4, epoch_293, Loss: 0.3797\n",
      "fold_4, epoch_294, Loss: 0.3755\n",
      "fold_4, epoch_295, Loss: 0.3784\n",
      "fold_4, epoch_296, Loss: 0.3844\n",
      "fold_4, epoch_297, Loss: 0.3780\n",
      "fold_4, epoch_298, Loss: 0.3761\n",
      "fold_4, epoch_299, Loss: 0.3748\n",
      "fold_4, epoch_300, Loss: 0.3768\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3773\n",
      "Accuracy:\t0.9356\n",
      "AUC:\t\t0.9403\n",
      "Precision:\t0.9442\n",
      "Recall:\t\t0.9260\n",
      "F1:\t\t\t0.9350\n",
      "\n",
      "fold_4, epoch_301, Loss: 0.3792\n",
      "fold_4, epoch_302, Loss: 0.3771\n",
      "fold_4, epoch_303, Loss: 0.3813\n",
      "fold_4, epoch_304, Loss: 0.3799\n",
      "fold_4, epoch_305, Loss: 0.3776\n",
      "fold_4, epoch_306, Loss: 0.3750\n",
      "fold_4, epoch_307, Loss: 0.3764\n",
      "fold_4, epoch_308, Loss: 0.3731\n",
      "fold_4, epoch_309, Loss: 0.3781\n",
      "fold_4, epoch_310, Loss: 0.3758\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3716\n",
      "Accuracy:\t0.9417\n",
      "AUC:\t\t0.9425\n",
      "Precision:\t0.9560\n",
      "Recall:\t\t0.9262\n",
      "F1:\t\t\t0.9409\n",
      "\n",
      "fold_4, epoch_311, Loss: 0.3785\n",
      "fold_4, epoch_312, Loss: 0.3727\n",
      "fold_4, epoch_313, Loss: 0.3771\n",
      "fold_4, epoch_314, Loss: 0.3764\n",
      "fold_4, epoch_315, Loss: 0.3743\n",
      "fold_4, epoch_316, Loss: 0.3770\n",
      "fold_4, epoch_317, Loss: 0.3766\n",
      "fold_4, epoch_318, Loss: 0.3769\n",
      "fold_4, epoch_319, Loss: 0.3771\n",
      "fold_4, epoch_320, Loss: 0.3773\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3741\n",
      "Accuracy:\t0.9391\n",
      "AUC:\t\t0.9425\n",
      "Precision:\t0.9498\n",
      "Recall:\t\t0.9272\n",
      "F1:\t\t\t0.9384\n",
      "\n",
      "fold_4, epoch_321, Loss: 0.3746\n",
      "fold_4, epoch_322, Loss: 0.3777\n",
      "fold_4, epoch_323, Loss: 0.3746\n",
      "fold_4, epoch_324, Loss: 0.3748\n",
      "fold_4, epoch_325, Loss: 0.3758\n",
      "fold_4, epoch_326, Loss: 0.3765\n",
      "fold_4, epoch_327, Loss: 0.3794\n",
      "fold_4, epoch_328, Loss: 0.3767\n",
      "fold_4, epoch_329, Loss: 0.3740\n",
      "fold_4, epoch_330, Loss: 0.3729\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3734\n",
      "Accuracy:\t0.9395\n",
      "AUC:\t\t0.9453\n",
      "Precision:\t0.9554\n",
      "Recall:\t\t0.9222\n",
      "F1:\t\t\t0.9385\n",
      "\n",
      "fold_4, epoch_331, Loss: 0.3761\n",
      "fold_4, epoch_332, Loss: 0.3761\n",
      "fold_4, epoch_333, Loss: 0.3722\n",
      "fold_4, epoch_334, Loss: 0.3772\n",
      "fold_4, epoch_335, Loss: 0.3748\n",
      "fold_4, epoch_336, Loss: 0.3739\n",
      "fold_4, epoch_337, Loss: 0.3808\n",
      "fold_4, epoch_338, Loss: 0.3741\n",
      "fold_4, epoch_339, Loss: 0.3744\n",
      "fold_4, epoch_340, Loss: 0.3757\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3748\n",
      "Accuracy:\t0.9383\n",
      "AUC:\t\t0.9434\n",
      "Precision:\t0.9485\n",
      "Recall:\t\t0.9275\n",
      "F1:\t\t\t0.9379\n",
      "\n",
      "fold_4, epoch_341, Loss: 0.3770\n",
      "fold_4, epoch_342, Loss: 0.3720\n",
      "fold_4, epoch_343, Loss: 0.3703\n",
      "fold_4, epoch_344, Loss: 0.3711\n",
      "fold_4, epoch_345, Loss: 0.3716\n",
      "fold_4, epoch_346, Loss: 0.3803\n",
      "fold_4, epoch_347, Loss: 0.3770\n",
      "fold_4, epoch_348, Loss: 0.3688\n",
      "fold_4, epoch_349, Loss: 0.3771\n",
      "fold_4, epoch_350, Loss: 0.3717\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3707\n",
      "Accuracy:\t0.9422\n",
      "AUC:\t\t0.9468\n",
      "Precision:\t0.9530\n",
      "Recall:\t\t0.9309\n",
      "F1:\t\t\t0.9418\n",
      "\n",
      "fold_4, epoch_351, Loss: 0.3752\n",
      "fold_4, epoch_352, Loss: 0.3711\n",
      "fold_4, epoch_353, Loss: 0.3727\n",
      "fold_4, epoch_354, Loss: 0.3708\n",
      "fold_4, epoch_355, Loss: 0.3745\n",
      "fold_4, epoch_356, Loss: 0.3766\n",
      "fold_4, epoch_357, Loss: 0.3726\n",
      "fold_4, epoch_358, Loss: 0.3700\n",
      "fold_4, epoch_359, Loss: 0.3732\n",
      "fold_4, epoch_360, Loss: 0.3705\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3666\n",
      "Accuracy:\t0.9466\n",
      "AUC:\t\t0.9484\n",
      "Precision:\t0.9578\n",
      "Recall:\t\t0.9353\n",
      "F1:\t\t\t0.9464\n",
      "\n",
      "fold_4, epoch_361, Loss: 0.3723\n",
      "fold_4, epoch_362, Loss: 0.3728\n",
      "fold_4, epoch_363, Loss: 0.3748\n",
      "fold_4, epoch_364, Loss: 0.3684\n",
      "fold_4, epoch_365, Loss: 0.3709\n",
      "fold_4, epoch_366, Loss: 0.3705\n",
      "fold_4, epoch_367, Loss: 0.3696\n",
      "fold_4, epoch_368, Loss: 0.3747\n",
      "fold_4, epoch_369, Loss: 0.3749\n",
      "fold_4, epoch_370, Loss: 0.3724\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3713\n",
      "Accuracy:\t0.9415\n",
      "AUC:\t\t0.9463\n",
      "Precision:\t0.9521\n",
      "Recall:\t\t0.9295\n",
      "F1:\t\t\t0.9406\n",
      "\n",
      "fold_4, epoch_371, Loss: 0.3723\n",
      "fold_4, epoch_372, Loss: 0.3700\n",
      "fold_4, epoch_373, Loss: 0.3724\n",
      "fold_4, epoch_374, Loss: 0.3694\n",
      "fold_4, epoch_375, Loss: 0.3699\n",
      "fold_4, epoch_376, Loss: 0.3715\n",
      "fold_4, epoch_377, Loss: 0.3693\n",
      "fold_4, epoch_378, Loss: 0.3718\n",
      "fold_4, epoch_379, Loss: 0.3694\n",
      "fold_4, epoch_380, Loss: 0.3723\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3725\n",
      "Accuracy:\t0.9402\n",
      "AUC:\t\t0.9477\n",
      "Precision:\t0.9503\n",
      "Recall:\t\t0.9295\n",
      "F1:\t\t\t0.9398\n",
      "\n",
      "fold_4, epoch_381, Loss: 0.3681\n",
      "fold_4, epoch_382, Loss: 0.3718\n",
      "fold_4, epoch_383, Loss: 0.3696\n",
      "fold_4, epoch_384, Loss: 0.3686\n",
      "fold_4, epoch_385, Loss: 0.3696\n",
      "fold_4, epoch_386, Loss: 0.3716\n",
      "fold_4, epoch_387, Loss: 0.3688\n",
      "fold_4, epoch_388, Loss: 0.3693\n",
      "fold_4, epoch_389, Loss: 0.3712\n",
      "fold_4, epoch_390, Loss: 0.3700\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3716\n",
      "Accuracy:\t0.9411\n",
      "AUC:\t\t0.9451\n",
      "Precision:\t0.9535\n",
      "Recall:\t\t0.9271\n",
      "F1:\t\t\t0.9401\n",
      "\n",
      "fold_4, epoch_391, Loss: 0.3690\n",
      "fold_4, epoch_392, Loss: 0.3719\n",
      "fold_4, epoch_393, Loss: 0.3720\n",
      "fold_4, epoch_394, Loss: 0.3703\n",
      "fold_4, epoch_395, Loss: 0.3679\n",
      "fold_4, epoch_396, Loss: 0.3659\n",
      "fold_4, epoch_397, Loss: 0.3685\n",
      "fold_4, epoch_398, Loss: 0.3682\n",
      "fold_4, epoch_399, Loss: 0.3715\n",
      "fold_4, epoch_400, Loss: 0.3714\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3795\n",
      "Accuracy:\t0.9332\n",
      "AUC:\t\t0.9425\n",
      "Precision:\t0.9497\n",
      "Recall:\t\t0.9146\n",
      "F1:\t\t\t0.9318\n",
      "\n",
      "fold_4, epoch_401, Loss: 0.3748\n",
      "fold_4, epoch_402, Loss: 0.3676\n",
      "fold_4, epoch_403, Loss: 0.3685\n",
      "fold_4, epoch_404, Loss: 0.3683\n",
      "fold_4, epoch_405, Loss: 0.3741\n",
      "fold_4, epoch_406, Loss: 0.3716\n",
      "fold_4, epoch_407, Loss: 0.3687\n",
      "fold_4, epoch_408, Loss: 0.3676\n",
      "fold_4, epoch_409, Loss: 0.3715\n",
      "fold_4, epoch_410, Loss: 0.3734\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3663\n",
      "Accuracy:\t0.9466\n",
      "AUC:\t\t0.9492\n",
      "Precision:\t0.9634\n",
      "Recall:\t\t0.9283\n",
      "F1:\t\t\t0.9455\n",
      "\n",
      "fold_4, epoch_411, Loss: 0.3683\n",
      "fold_4, epoch_412, Loss: 0.3672\n",
      "fold_4, epoch_413, Loss: 0.3729\n",
      "fold_4, epoch_414, Loss: 0.3706\n",
      "fold_4, epoch_415, Loss: 0.3701\n",
      "fold_4, epoch_416, Loss: 0.3683\n",
      "fold_4, epoch_417, Loss: 0.3701\n",
      "fold_4, epoch_418, Loss: 0.3684\n",
      "fold_4, epoch_419, Loss: 0.3706\n",
      "fold_4, epoch_420, Loss: 0.3720\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3687\n",
      "Accuracy:\t0.9444\n",
      "AUC:\t\t0.9484\n",
      "Precision:\t0.9604\n",
      "Recall:\t\t0.9276\n",
      "F1:\t\t\t0.9437\n",
      "\n",
      "fold_4, epoch_421, Loss: 0.3666\n",
      "fold_4, epoch_422, Loss: 0.3671\n",
      "fold_4, epoch_423, Loss: 0.3719\n",
      "fold_4, epoch_424, Loss: 0.3705\n",
      "fold_4, epoch_425, Loss: 0.3681\n",
      "fold_4, epoch_426, Loss: 0.3663\n",
      "fold_4, epoch_427, Loss: 0.3680\n",
      "fold_4, epoch_428, Loss: 0.3713\n",
      "fold_4, epoch_429, Loss: 0.3659\n",
      "fold_4, epoch_430, Loss: 0.3669\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3645\n",
      "Accuracy:\t0.9488\n",
      "AUC:\t\t0.9502\n",
      "Precision:\t0.9591\n",
      "Recall:\t\t0.9364\n",
      "F1:\t\t\t0.9476\n",
      "\n",
      "fold_4, epoch_431, Loss: 0.3657\n",
      "fold_4, epoch_432, Loss: 0.3680\n",
      "fold_4, epoch_433, Loss: 0.3714\n",
      "fold_4, epoch_434, Loss: 0.3703\n",
      "fold_4, epoch_435, Loss: 0.3750\n",
      "fold_4, epoch_436, Loss: 0.3663\n",
      "fold_4, epoch_437, Loss: 0.3728\n",
      "fold_4, epoch_438, Loss: 0.3684\n",
      "fold_4, epoch_439, Loss: 0.3689\n",
      "fold_4, epoch_440, Loss: 0.3651\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3657\n",
      "Accuracy:\t0.9472\n",
      "AUC:\t\t0.9512\n",
      "Precision:\t0.9593\n",
      "Recall:\t\t0.9343\n",
      "F1:\t\t\t0.9466\n",
      "\n",
      "fold_4, epoch_441, Loss: 0.3636\n",
      "fold_4, epoch_442, Loss: 0.3680\n",
      "fold_4, epoch_443, Loss: 0.3688\n",
      "fold_4, epoch_444, Loss: 0.3692\n",
      "fold_4, epoch_445, Loss: 0.3654\n",
      "fold_4, epoch_446, Loss: 0.3690\n",
      "fold_4, epoch_447, Loss: 0.3698\n",
      "fold_4, epoch_448, Loss: 0.3673\n",
      "fold_4, epoch_449, Loss: 0.3655\n",
      "fold_4, epoch_450, Loss: 0.3695\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3726\n",
      "Accuracy:\t0.9403\n",
      "AUC:\t\t0.9467\n",
      "Precision:\t0.9512\n",
      "Recall:\t\t0.9270\n",
      "F1:\t\t\t0.9389\n",
      "\n",
      "fold_4, epoch_451, Loss: 0.3684\n",
      "fold_4, epoch_452, Loss: 0.3655\n",
      "fold_4, epoch_453, Loss: 0.3773\n",
      "fold_4, epoch_454, Loss: 0.3657\n",
      "fold_4, epoch_455, Loss: 0.3673\n",
      "fold_4, epoch_456, Loss: 0.3715\n",
      "fold_4, epoch_457, Loss: 0.3666\n",
      "fold_4, epoch_458, Loss: 0.3687\n",
      "fold_4, epoch_459, Loss: 0.3696\n",
      "fold_4, epoch_460, Loss: 0.3674\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3642\n",
      "Accuracy:\t0.9491\n",
      "AUC:\t\t0.9522\n",
      "Precision:\t0.9674\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9484\n",
      "\n",
      "fold_4, epoch_461, Loss: 0.3674\n",
      "fold_4, epoch_462, Loss: 0.3678\n",
      "fold_4, epoch_463, Loss: 0.3705\n",
      "fold_4, epoch_464, Loss: 0.3658\n",
      "fold_4, epoch_465, Loss: 0.3667\n",
      "fold_4, epoch_466, Loss: 0.3630\n",
      "fold_4, epoch_467, Loss: 0.3654\n",
      "fold_4, epoch_468, Loss: 0.3646\n",
      "fold_4, epoch_469, Loss: 0.3661\n",
      "fold_4, epoch_470, Loss: 0.3687\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3676\n",
      "Accuracy:\t0.9454\n",
      "AUC:\t\t0.9506\n",
      "Precision:\t0.9590\n",
      "Recall:\t\t0.9294\n",
      "F1:\t\t\t0.9440\n",
      "\n",
      "fold_4, epoch_471, Loss: 0.3656\n",
      "fold_4, epoch_472, Loss: 0.3634\n",
      "fold_4, epoch_473, Loss: 0.3659\n",
      "fold_4, epoch_474, Loss: 0.3646\n",
      "fold_4, epoch_475, Loss: 0.3680\n",
      "fold_4, epoch_476, Loss: 0.3688\n",
      "fold_4, epoch_477, Loss: 0.3661\n",
      "fold_4, epoch_478, Loss: 0.3660\n",
      "fold_4, epoch_479, Loss: 0.3732\n",
      "fold_4, epoch_480, Loss: 0.3682\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3664\n",
      "Accuracy:\t0.9467\n",
      "AUC:\t\t0.9491\n",
      "Precision:\t0.9626\n",
      "Recall:\t\t0.9287\n",
      "F1:\t\t\t0.9454\n",
      "\n",
      "fold_4, epoch_481, Loss: 0.3695\n",
      "fold_4, epoch_482, Loss: 0.3680\n",
      "fold_4, epoch_483, Loss: 0.3646\n",
      "fold_4, epoch_484, Loss: 0.3676\n",
      "fold_4, epoch_485, Loss: 0.3681\n",
      "fold_4, epoch_486, Loss: 0.3669\n",
      "fold_4, epoch_487, Loss: 0.3671\n",
      "fold_4, epoch_488, Loss: 0.3650\n",
      "fold_4, epoch_489, Loss: 0.3673\n",
      "fold_4, epoch_490, Loss: 0.3667\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3666\n",
      "Accuracy:\t0.9466\n",
      "AUC:\t\t0.9504\n",
      "Precision:\t0.9639\n",
      "Recall:\t\t0.9276\n",
      "F1:\t\t\t0.9454\n",
      "\n",
      "fold_4, epoch_491, Loss: 0.3693\n",
      "fold_4, epoch_492, Loss: 0.3644\n",
      "fold_4, epoch_493, Loss: 0.3668\n",
      "fold_4, epoch_494, Loss: 0.3631\n",
      "fold_4, epoch_495, Loss: 0.3632\n",
      "fold_4, epoch_496, Loss: 0.3683\n",
      "fold_4, epoch_497, Loss: 0.3646\n",
      "fold_4, epoch_498, Loss: 0.3659\n",
      "fold_4, epoch_499, Loss: 0.3641\n",
      "fold_4, epoch_500, Loss: 0.3674\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3642\n",
      "Accuracy:\t0.9490\n",
      "AUC:\t\t0.9510\n",
      "Precision:\t0.9645\n",
      "Recall:\t\t0.9320\n",
      "F1:\t\t\t0.9480\n",
      "\n",
      "fold_4, epoch_501, Loss: 0.3664\n",
      "fold_4, epoch_502, Loss: 0.3650\n",
      "fold_4, epoch_503, Loss: 0.3663\n",
      "fold_4, epoch_504, Loss: 0.3659\n",
      "fold_4, epoch_505, Loss: 0.3684\n",
      "fold_4, epoch_506, Loss: 0.3634\n",
      "fold_4, epoch_507, Loss: 0.3605\n",
      "fold_4, epoch_508, Loss: 0.3649\n",
      "fold_4, epoch_509, Loss: 0.3652\n",
      "fold_4, epoch_510, Loss: 0.3623\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3683\n",
      "Accuracy:\t0.9444\n",
      "AUC:\t\t0.9501\n",
      "Precision:\t0.9575\n",
      "Recall:\t\t0.9300\n",
      "F1:\t\t\t0.9436\n",
      "\n",
      "fold_4, epoch_511, Loss: 0.3691\n",
      "fold_4, epoch_512, Loss: 0.3674\n",
      "fold_4, epoch_513, Loss: 0.3638\n",
      "fold_4, epoch_514, Loss: 0.3665\n",
      "fold_4, epoch_515, Loss: 0.3608\n",
      "fold_4, epoch_516, Loss: 0.3627\n",
      "fold_4, epoch_517, Loss: 0.3635\n",
      "fold_4, epoch_518, Loss: 0.3625\n",
      "fold_4, epoch_519, Loss: 0.3621\n",
      "fold_4, epoch_520, Loss: 0.3612\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3606\n",
      "Accuracy:\t0.9527\n",
      "AUC:\t\t0.9521\n",
      "Precision:\t0.9690\n",
      "Recall:\t\t0.9350\n",
      "F1:\t\t\t0.9517\n",
      "\n",
      "fold_4, epoch_521, Loss: 0.3623\n",
      "fold_4, epoch_522, Loss: 0.3637\n",
      "fold_4, epoch_523, Loss: 0.3677\n",
      "fold_4, epoch_524, Loss: 0.3618\n",
      "fold_4, epoch_525, Loss: 0.3629\n",
      "fold_4, epoch_526, Loss: 0.3634\n",
      "fold_4, epoch_527, Loss: 0.3625\n",
      "fold_4, epoch_528, Loss: 0.3643\n",
      "fold_4, epoch_529, Loss: 0.3657\n",
      "fold_4, epoch_530, Loss: 0.3658\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3611\n",
      "Accuracy:\t0.9520\n",
      "AUC:\t\t0.9528\n",
      "Precision:\t0.9670\n",
      "Recall:\t\t0.9360\n",
      "F1:\t\t\t0.9512\n",
      "\n",
      "fold_4, epoch_531, Loss: 0.3617\n",
      "fold_4, epoch_532, Loss: 0.3638\n",
      "fold_4, epoch_533, Loss: 0.3634\n",
      "fold_4, epoch_534, Loss: 0.3667\n",
      "fold_4, epoch_535, Loss: 0.3651\n",
      "fold_4, epoch_536, Loss: 0.3661\n",
      "fold_4, epoch_537, Loss: 0.3647\n",
      "fold_4, epoch_538, Loss: 0.3668\n",
      "fold_4, epoch_539, Loss: 0.3615\n",
      "fold_4, epoch_540, Loss: 0.3604\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3634\n",
      "Accuracy:\t0.9496\n",
      "AUC:\t\t0.9514\n",
      "Precision:\t0.9627\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9486\n",
      "\n",
      "fold_4, epoch_541, Loss: 0.3617\n",
      "fold_4, epoch_542, Loss: 0.3628\n",
      "fold_4, epoch_543, Loss: 0.3611\n",
      "fold_4, epoch_544, Loss: 0.3635\n",
      "fold_4, epoch_545, Loss: 0.3615\n",
      "fold_4, epoch_546, Loss: 0.3703\n",
      "fold_4, epoch_547, Loss: 0.3648\n",
      "fold_4, epoch_548, Loss: 0.3619\n",
      "fold_4, epoch_549, Loss: 0.3648\n",
      "fold_4, epoch_550, Loss: 0.3634\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3632\n",
      "Accuracy:\t0.9500\n",
      "AUC:\t\t0.9520\n",
      "Precision:\t0.9698\n",
      "Recall:\t\t0.9284\n",
      "F1:\t\t\t0.9487\n",
      "\n",
      "fold_4, epoch_551, Loss: 0.3625\n",
      "fold_4, epoch_552, Loss: 0.3639\n",
      "fold_4, epoch_553, Loss: 0.3639\n",
      "fold_4, epoch_554, Loss: 0.3605\n",
      "fold_4, epoch_555, Loss: 0.3635\n",
      "fold_4, epoch_556, Loss: 0.3633\n",
      "fold_4, epoch_557, Loss: 0.3595\n",
      "fold_4, epoch_558, Loss: 0.3650\n",
      "fold_4, epoch_559, Loss: 0.3629\n",
      "fold_4, epoch_560, Loss: 0.3593\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3616\n",
      "Accuracy:\t0.9515\n",
      "AUC:\t\t0.9538\n",
      "Precision:\t0.9698\n",
      "Recall:\t\t0.9322\n",
      "F1:\t\t\t0.9506\n",
      "\n",
      "fold_4, epoch_561, Loss: 0.3633\n",
      "fold_4, epoch_562, Loss: 0.3632\n",
      "fold_4, epoch_563, Loss: 0.3616\n",
      "fold_4, epoch_564, Loss: 0.3622\n",
      "fold_4, epoch_565, Loss: 0.3608\n",
      "fold_4, epoch_566, Loss: 0.3634\n",
      "fold_4, epoch_567, Loss: 0.3614\n",
      "fold_4, epoch_568, Loss: 0.3664\n",
      "fold_4, epoch_569, Loss: 0.3637\n",
      "fold_4, epoch_570, Loss: 0.3616\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3625\n",
      "Accuracy:\t0.9507\n",
      "AUC:\t\t0.9540\n",
      "Precision:\t0.9615\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9497\n",
      "\n",
      "fold_4, epoch_571, Loss: 0.3616\n",
      "fold_4, epoch_572, Loss: 0.3660\n",
      "fold_4, epoch_573, Loss: 0.3634\n",
      "fold_4, epoch_574, Loss: 0.3578\n",
      "fold_4, epoch_575, Loss: 0.3617\n",
      "fold_4, epoch_576, Loss: 0.3628\n",
      "fold_4, epoch_577, Loss: 0.3654\n",
      "fold_4, epoch_578, Loss: 0.3634\n",
      "fold_4, epoch_579, Loss: 0.3621\n",
      "fold_4, epoch_580, Loss: 0.3615\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3602\n",
      "Accuracy:\t0.9532\n",
      "AUC:\t\t0.9550\n",
      "Precision:\t0.9710\n",
      "Recall:\t\t0.9344\n",
      "F1:\t\t\t0.9524\n",
      "\n",
      "fold_4, epoch_581, Loss: 0.3652\n",
      "fold_4, epoch_582, Loss: 0.3645\n",
      "fold_4, epoch_583, Loss: 0.3642\n",
      "fold_4, epoch_584, Loss: 0.3627\n",
      "fold_4, epoch_585, Loss: 0.3608\n",
      "fold_4, epoch_586, Loss: 0.3593\n",
      "fold_4, epoch_587, Loss: 0.3609\n",
      "fold_4, epoch_588, Loss: 0.3602\n",
      "fold_4, epoch_589, Loss: 0.3654\n",
      "fold_4, epoch_590, Loss: 0.3624\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3610\n",
      "Accuracy:\t0.9518\n",
      "AUC:\t\t0.9543\n",
      "Precision:\t0.9724\n",
      "Recall:\t\t0.9301\n",
      "F1:\t\t\t0.9508\n",
      "\n",
      "fold_4, epoch_591, Loss: 0.3571\n",
      "fold_4, epoch_592, Loss: 0.3602\n",
      "fold_4, epoch_593, Loss: 0.3621\n",
      "fold_4, epoch_594, Loss: 0.3607\n",
      "fold_4, epoch_595, Loss: 0.3610\n",
      "fold_4, epoch_596, Loss: 0.3676\n",
      "fold_4, epoch_597, Loss: 0.3657\n",
      "fold_4, epoch_598, Loss: 0.3606\n",
      "fold_4, epoch_599, Loss: 0.3589\n",
      "fold_4, epoch_600, Loss: 0.3658\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3596\n",
      "Accuracy:\t0.9536\n",
      "AUC:\t\t0.9559\n",
      "Precision:\t0.9710\n",
      "Recall:\t\t0.9354\n",
      "F1:\t\t\t0.9529\n",
      "\n",
      "fold_4, epoch_601, Loss: 0.3610\n",
      "fold_4, epoch_602, Loss: 0.3607\n",
      "fold_4, epoch_603, Loss: 0.3620\n",
      "fold_4, epoch_604, Loss: 0.3631\n",
      "fold_4, epoch_605, Loss: 0.3630\n",
      "fold_4, epoch_606, Loss: 0.3618\n",
      "fold_4, epoch_607, Loss: 0.3606\n",
      "fold_4, epoch_608, Loss: 0.3622\n",
      "fold_4, epoch_609, Loss: 0.3602\n",
      "fold_4, epoch_610, Loss: 0.3595\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3618\n",
      "Accuracy:\t0.9513\n",
      "AUC:\t\t0.9536\n",
      "Precision:\t0.9683\n",
      "Recall:\t\t0.9334\n",
      "F1:\t\t\t0.9506\n",
      "\n",
      "fold_4, epoch_611, Loss: 0.3575\n",
      "fold_4, epoch_612, Loss: 0.3608\n",
      "fold_4, epoch_613, Loss: 0.3601\n",
      "fold_4, epoch_614, Loss: 0.3613\n",
      "fold_4, epoch_615, Loss: 0.3628\n",
      "fold_4, epoch_616, Loss: 0.3606\n",
      "fold_4, epoch_617, Loss: 0.3608\n",
      "fold_4, epoch_618, Loss: 0.3593\n",
      "fold_4, epoch_619, Loss: 0.3607\n",
      "fold_4, epoch_620, Loss: 0.3647\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3570\n",
      "Accuracy:\t0.9561\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9741\n",
      "Recall:\t\t0.9371\n",
      "F1:\t\t\t0.9552\n",
      "\n",
      "fold_4, epoch_621, Loss: 0.3576\n",
      "fold_4, epoch_622, Loss: 0.3617\n",
      "fold_4, epoch_623, Loss: 0.3604\n",
      "fold_4, epoch_624, Loss: 0.3598\n",
      "fold_4, epoch_625, Loss: 0.3618\n",
      "fold_4, epoch_626, Loss: 0.3629\n",
      "fold_4, epoch_627, Loss: 0.3592\n",
      "fold_4, epoch_628, Loss: 0.3636\n",
      "fold_4, epoch_629, Loss: 0.3576\n",
      "fold_4, epoch_630, Loss: 0.3619\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3625\n",
      "Accuracy:\t0.9507\n",
      "AUC:\t\t0.9526\n",
      "Precision:\t0.9676\n",
      "Recall:\t\t0.9330\n",
      "F1:\t\t\t0.9500\n",
      "\n",
      "fold_4, epoch_631, Loss: 0.3601\n",
      "fold_4, epoch_632, Loss: 0.3660\n",
      "fold_4, epoch_633, Loss: 0.3588\n",
      "fold_4, epoch_634, Loss: 0.3582\n",
      "fold_4, epoch_635, Loss: 0.3619\n",
      "fold_4, epoch_636, Loss: 0.3602\n",
      "fold_4, epoch_637, Loss: 0.3598\n",
      "fold_4, epoch_638, Loss: 0.3588\n",
      "fold_4, epoch_639, Loss: 0.3599\n",
      "fold_4, epoch_640, Loss: 0.3637\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3596\n",
      "Accuracy:\t0.9534\n",
      "AUC:\t\t0.9557\n",
      "Precision:\t0.9720\n",
      "Recall:\t\t0.9346\n",
      "F1:\t\t\t0.9529\n",
      "\n",
      "fold_4, epoch_641, Loss: 0.3595\n",
      "fold_4, epoch_642, Loss: 0.3619\n",
      "fold_4, epoch_643, Loss: 0.3598\n",
      "fold_4, epoch_644, Loss: 0.3603\n",
      "fold_4, epoch_645, Loss: 0.3585\n",
      "fold_4, epoch_646, Loss: 0.3626\n",
      "fold_4, epoch_647, Loss: 0.3588\n",
      "fold_4, epoch_648, Loss: 0.3599\n",
      "fold_4, epoch_649, Loss: 0.3585\n",
      "fold_4, epoch_650, Loss: 0.3593\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3580\n",
      "Accuracy:\t0.9552\n",
      "AUC:\t\t0.9549\n",
      "Precision:\t0.9730\n",
      "Recall:\t\t0.9363\n",
      "F1:\t\t\t0.9543\n",
      "\n",
      "fold_4, epoch_651, Loss: 0.3592\n",
      "fold_4, epoch_652, Loss: 0.3592\n",
      "fold_4, epoch_653, Loss: 0.3596\n",
      "fold_4, epoch_654, Loss: 0.3610\n",
      "fold_4, epoch_655, Loss: 0.3595\n",
      "fold_4, epoch_656, Loss: 0.3615\n",
      "fold_4, epoch_657, Loss: 0.3595\n",
      "fold_4, epoch_658, Loss: 0.3625\n",
      "fold_4, epoch_659, Loss: 0.3591\n",
      "fold_4, epoch_660, Loss: 0.3618\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3628\n",
      "Accuracy:\t0.9502\n",
      "AUC:\t\t0.9527\n",
      "Precision:\t0.9654\n",
      "Recall:\t\t0.9341\n",
      "F1:\t\t\t0.9495\n",
      "\n",
      "fold_4, epoch_661, Loss: 0.3607\n",
      "fold_4, epoch_662, Loss: 0.3591\n",
      "fold_4, epoch_663, Loss: 0.3584\n",
      "fold_4, epoch_664, Loss: 0.3585\n",
      "fold_4, epoch_665, Loss: 0.3578\n",
      "fold_4, epoch_666, Loss: 0.3604\n",
      "fold_4, epoch_667, Loss: 0.3637\n",
      "fold_4, epoch_668, Loss: 0.3613\n",
      "fold_4, epoch_669, Loss: 0.3583\n",
      "fold_4, epoch_670, Loss: 0.3569\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3551\n",
      "Accuracy:\t0.9582\n",
      "AUC:\t\t0.9579\n",
      "Precision:\t0.9778\n",
      "Recall:\t\t0.9382\n",
      "F1:\t\t\t0.9576\n",
      "\n",
      "fold_4, epoch_671, Loss: 0.3600\n",
      "fold_4, epoch_672, Loss: 0.3610\n",
      "fold_4, epoch_673, Loss: 0.3652\n",
      "fold_4, epoch_674, Loss: 0.3616\n",
      "fold_4, epoch_675, Loss: 0.3581\n",
      "fold_4, epoch_676, Loss: 0.3585\n",
      "fold_4, epoch_677, Loss: 0.3589\n",
      "fold_4, epoch_678, Loss: 0.3582\n",
      "fold_4, epoch_679, Loss: 0.3585\n",
      "fold_4, epoch_680, Loss: 0.3572\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3628\n",
      "Accuracy:\t0.9502\n",
      "AUC:\t\t0.9535\n",
      "Precision:\t0.9655\n",
      "Recall:\t\t0.9330\n",
      "F1:\t\t\t0.9490\n",
      "\n",
      "fold_4, epoch_681, Loss: 0.3591\n",
      "fold_4, epoch_682, Loss: 0.3598\n",
      "fold_4, epoch_683, Loss: 0.3601\n",
      "fold_4, epoch_684, Loss: 0.3604\n",
      "fold_4, epoch_685, Loss: 0.3580\n",
      "fold_4, epoch_686, Loss: 0.3580\n",
      "fold_4, epoch_687, Loss: 0.3606\n",
      "fold_4, epoch_688, Loss: 0.3604\n",
      "fold_4, epoch_689, Loss: 0.3604\n",
      "fold_4, epoch_690, Loss: 0.3554\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3578\n",
      "Accuracy:\t0.9557\n",
      "AUC:\t\t0.9563\n",
      "Precision:\t0.9775\n",
      "Recall:\t\t0.9333\n",
      "F1:\t\t\t0.9549\n",
      "\n",
      "fold_4, epoch_691, Loss: 0.3587\n",
      "fold_4, epoch_692, Loss: 0.3585\n",
      "fold_4, epoch_693, Loss: 0.3616\n",
      "fold_4, epoch_694, Loss: 0.3617\n",
      "fold_4, epoch_695, Loss: 0.3639\n",
      "fold_4, epoch_696, Loss: 0.3606\n",
      "fold_4, epoch_697, Loss: 0.3608\n",
      "fold_4, epoch_698, Loss: 0.3588\n",
      "fold_4, epoch_699, Loss: 0.3582\n",
      "fold_4, epoch_700, Loss: 0.3564\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3599\n",
      "Accuracy:\t0.9533\n",
      "AUC:\t\t0.9564\n",
      "Precision:\t0.9772\n",
      "Recall:\t\t0.9286\n",
      "F1:\t\t\t0.9523\n",
      "\n",
      "fold_4, epoch_701, Loss: 0.3587\n",
      "fold_4, epoch_702, Loss: 0.3587\n",
      "fold_4, epoch_703, Loss: 0.3582\n",
      "fold_4, epoch_704, Loss: 0.3586\n",
      "fold_4, epoch_705, Loss: 0.3595\n",
      "fold_4, epoch_706, Loss: 0.3650\n",
      "fold_4, epoch_707, Loss: 0.3597\n",
      "fold_4, epoch_708, Loss: 0.3572\n",
      "fold_4, epoch_709, Loss: 0.3605\n",
      "fold_4, epoch_710, Loss: 0.3611\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3570\n",
      "Accuracy:\t0.9562\n",
      "AUC:\t\t0.9590\n",
      "Precision:\t0.9767\n",
      "Recall:\t\t0.9353\n",
      "F1:\t\t\t0.9556\n",
      "\n",
      "fold_4, epoch_711, Loss: 0.3585\n",
      "fold_4, epoch_712, Loss: 0.3581\n",
      "fold_4, epoch_713, Loss: 0.3558\n",
      "fold_4, epoch_714, Loss: 0.3584\n",
      "fold_4, epoch_715, Loss: 0.3563\n",
      "fold_4, epoch_716, Loss: 0.3582\n",
      "fold_4, epoch_717, Loss: 0.3596\n",
      "fold_4, epoch_718, Loss: 0.3569\n",
      "fold_4, epoch_719, Loss: 0.3589\n",
      "fold_4, epoch_720, Loss: 0.3599\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3564\n",
      "Accuracy:\t0.9569\n",
      "AUC:\t\t0.9555\n",
      "Precision:\t0.9785\n",
      "Recall:\t\t0.9349\n",
      "F1:\t\t\t0.9562\n",
      "\n",
      "fold_4, epoch_721, Loss: 0.3558\n",
      "fold_4, epoch_722, Loss: 0.3581\n",
      "fold_4, epoch_723, Loss: 0.3602\n",
      "fold_4, epoch_724, Loss: 0.3605\n",
      "fold_4, epoch_725, Loss: 0.3592\n",
      "fold_4, epoch_726, Loss: 0.3579\n",
      "fold_4, epoch_727, Loss: 0.3554\n",
      "fold_4, epoch_728, Loss: 0.3559\n",
      "fold_4, epoch_729, Loss: 0.3574\n",
      "fold_4, epoch_730, Loss: 0.3603\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3564\n",
      "Accuracy:\t0.9569\n",
      "AUC:\t\t0.9578\n",
      "Precision:\t0.9749\n",
      "Recall:\t\t0.9374\n",
      "F1:\t\t\t0.9558\n",
      "\n",
      "fold_4, epoch_731, Loss: 0.3593\n",
      "fold_4, epoch_732, Loss: 0.3562\n",
      "fold_4, epoch_733, Loss: 0.3572\n",
      "fold_4, epoch_734, Loss: 0.3569\n",
      "fold_4, epoch_735, Loss: 0.3550\n",
      "fold_4, epoch_736, Loss: 0.3585\n",
      "fold_4, epoch_737, Loss: 0.3566\n",
      "fold_4, epoch_738, Loss: 0.3567\n",
      "fold_4, epoch_739, Loss: 0.3624\n",
      "fold_4, epoch_740, Loss: 0.3575\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3564\n",
      "Accuracy:\t0.9568\n",
      "AUC:\t\t0.9576\n",
      "Precision:\t0.9754\n",
      "Recall:\t\t0.9368\n",
      "F1:\t\t\t0.9557\n",
      "\n",
      "fold_4, epoch_741, Loss: 0.3563\n",
      "fold_4, epoch_742, Loss: 0.3583\n",
      "fold_4, epoch_743, Loss: 0.3554\n",
      "fold_4, epoch_744, Loss: 0.3593\n",
      "fold_4, epoch_745, Loss: 0.3589\n",
      "fold_4, epoch_746, Loss: 0.3578\n",
      "fold_4, epoch_747, Loss: 0.3554\n",
      "fold_4, epoch_748, Loss: 0.3571\n",
      "fold_4, epoch_749, Loss: 0.3587\n",
      "fold_4, epoch_750, Loss: 0.3644\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3620\n",
      "Accuracy:\t0.9513\n",
      "AUC:\t\t0.9545\n",
      "Precision:\t0.9676\n",
      "Recall:\t\t0.9335\n",
      "F1:\t\t\t0.9502\n",
      "\n",
      "fold_4, epoch_751, Loss: 0.3621\n",
      "fold_4, epoch_752, Loss: 0.3598\n",
      "fold_4, epoch_753, Loss: 0.3567\n",
      "fold_4, epoch_754, Loss: 0.3548\n",
      "fold_4, epoch_755, Loss: 0.3538\n",
      "fold_4, epoch_756, Loss: 0.3560\n",
      "fold_4, epoch_757, Loss: 0.3564\n",
      "fold_4, epoch_758, Loss: 0.3566\n",
      "fold_4, epoch_759, Loss: 0.3577\n",
      "fold_4, epoch_760, Loss: 0.3554\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3563\n",
      "Accuracy:\t0.9570\n",
      "AUC:\t\t0.9575\n",
      "Precision:\t0.9772\n",
      "Recall:\t\t0.9364\n",
      "F1:\t\t\t0.9563\n",
      "\n",
      "fold_4, epoch_761, Loss: 0.3595\n",
      "fold_4, epoch_762, Loss: 0.3585\n",
      "fold_4, epoch_763, Loss: 0.3556\n",
      "fold_4, epoch_764, Loss: 0.3573\n",
      "fold_4, epoch_765, Loss: 0.3562\n",
      "fold_4, epoch_766, Loss: 0.3559\n",
      "fold_4, epoch_767, Loss: 0.3588\n",
      "fold_4, epoch_768, Loss: 0.3570\n",
      "fold_4, epoch_769, Loss: 0.3576\n",
      "fold_4, epoch_770, Loss: 0.3574\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3558\n",
      "Accuracy:\t0.9573\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9807\n",
      "Recall:\t\t0.9334\n",
      "F1:\t\t\t0.9564\n",
      "\n",
      "fold_4, epoch_771, Loss: 0.3534\n",
      "fold_4, epoch_772, Loss: 0.3540\n",
      "fold_4, epoch_773, Loss: 0.3561\n",
      "fold_4, epoch_774, Loss: 0.3554\n",
      "fold_4, epoch_775, Loss: 0.3566\n",
      "fold_4, epoch_776, Loss: 0.3580\n",
      "fold_4, epoch_777, Loss: 0.3572\n",
      "fold_4, epoch_778, Loss: 0.3587\n",
      "fold_4, epoch_779, Loss: 0.3544\n",
      "fold_4, epoch_780, Loss: 0.3571\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3600\n",
      "Accuracy:\t0.9529\n",
      "AUC:\t\t0.9570\n",
      "Precision:\t0.9727\n",
      "Recall:\t\t0.9316\n",
      "F1:\t\t\t0.9517\n",
      "\n",
      "fold_4, epoch_781, Loss: 0.3572\n",
      "fold_4, epoch_782, Loss: 0.3583\n",
      "fold_4, epoch_783, Loss: 0.3561\n",
      "fold_4, epoch_784, Loss: 0.3600\n",
      "fold_4, epoch_785, Loss: 0.3590\n",
      "fold_4, epoch_786, Loss: 0.3567\n",
      "fold_4, epoch_787, Loss: 0.3575\n",
      "fold_4, epoch_788, Loss: 0.3548\n",
      "fold_4, epoch_789, Loss: 0.3558\n",
      "fold_4, epoch_790, Loss: 0.3617\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3544\n",
      "Accuracy:\t0.9589\n",
      "AUC:\t\t0.9595\n",
      "Precision:\t0.9781\n",
      "Recall:\t\t0.9377\n",
      "F1:\t\t\t0.9575\n",
      "\n",
      "fold_4, epoch_791, Loss: 0.3557\n",
      "fold_4, epoch_792, Loss: 0.3543\n",
      "fold_4, epoch_793, Loss: 0.3581\n",
      "fold_4, epoch_794, Loss: 0.3566\n",
      "fold_4, epoch_795, Loss: 0.3564\n",
      "fold_4, epoch_796, Loss: 0.3543\n",
      "fold_4, epoch_797, Loss: 0.3567\n",
      "fold_4, epoch_798, Loss: 0.3523\n",
      "fold_4, epoch_799, Loss: 0.3536\n",
      "fold_4, epoch_800, Loss: 0.3552\n",
      "\n",
      "fold_4 performance on test data:\n",
      "Loss:\t\t0.3562\n",
      "Accuracy:\t0.9568\n",
      "AUC:\t\t0.9580\n",
      "Precision:\t0.9756\n",
      "Recall:\t\t0.9363\n",
      "F1:\t\t\t0.9556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lstm_adversarial_attack.tune_train.cross_validator_driver as cvd\n",
    "import lstm_adversarial_attack.x19_mort_general_dataset as xmd\n",
    "\n",
    "cv_driver = cvd.CrossValidatorDriver.from_study_path(\n",
    "        device=cur_device,\n",
    "        dataset=dataset,\n",
    "        study_path=cfg_paths.ONGOING_TUNING_STUDY_PICKLE\n",
    "    )\n",
    "\n",
    "cv_driver.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 Monitor Training Progress in Tensorboard\n",
    "Near the start of the terminal output from the previous code cell, look for the lines:\n",
    "```\n",
    "Checkpoints will be saved in:\n",
    "/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard\n",
    "```\n",
    "Then, start a zsh shell inside the app container, and launch tensorboard server:\n",
    "```\n",
    "$ docker exec -it lstm_aa_app /bin/zsh\n",
    "$ tensorboard --logdir=/home/devspace/project/data/cv_assessments/<timestamped_directory_name>/tensorboard --host=0.0.0.0\n",
    "```\n",
    "The Tensorboard output can now be viewed in your browswer at http://localhost:6006.\n",
    "\n",
    "Here are example training loss, validation loss, and AUC curves from 5-fold cross-validation with 800 epochs per cycle..\n",
    "![tensorboard_image](images/cross_validation_800epochs_trial20_hyperparams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 Comparison with Prior Studies\n",
    "\n",
    "#### 7.4.1 Model Architecture and Hyperparameters\n",
    "\n",
    "|                    | Sun et al.  | Tang et al. | Tang et al | Tang et al | Tang et al | This work |\n",
    "|--------------------|-------------|-------------|------------|------------|-------------|-----------|\n",
    "| Model Architecture |  LSTM + 2FC | LSTM + 1FC  | CNN + LSTM | \n",
    "| Input Features          |  128       | 256         |   128     | \n",
    "| AUC      |   -        | Tanh        |   Tanh    |\n",
    "| F1                      |   -        | 0.5         |   0.03    |\n",
    "| Precision            |  32        | none        |   16\n",
    "| Recall            |  32        | none        |   16\n",
    "\n",
    "#### 7.3.2 Predictive Performance\n",
    "\n",
    "| Study       | Model  | Input Features  | F1     | Precision | Recall |  |\n",
    "|-------------|--------|------------------|--------|-----------|--------|--|\n",
    "| Sun et al.  | LSTM +  | 0.5429 | 0.4100    | 0.8071 |\n",
    "| Tang et al. | 0.907  | 0.526  |    -      |    -   | \n",
    "| Tang et al. | 0.907  | 0.526  |    -      |    -   | \n",
    "| This work   | 0.9660 | 0.9652 | 0.9875    | 0.9440 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Adversarial Attack Algorithm on the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
